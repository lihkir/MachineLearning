{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "206bf5dd-c1da-4cca-8eac-ed85a58eac96",
   "metadata": {},
   "source": [
    "# Soluciones a ejercicios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424aca4b-7b9b-4243-91fd-2132731f1e90",
   "metadata": {},
   "source": [
    "````{admonition} Autoria de soluciones\n",
    ":class: information\n",
    "\n",
    "- A continuación, se presentan las **soluciones a algunos ejercicios propuestos en las distintas secciones de estas notas de clase**. Cada solución incluirá el enlace de **LinkedIn** de los estudiantes del [Pregrado en Ciencia de Datos](https://www.uninorte.edu.co/web/ciencia-de-datos?utm_source=google&utm_medium=cpc&utm_campaign=pre_google_2025&gad_source=1&gclid=EAIaIQobChMIhtrPupOmjAMVZa1aBR1D7QcNEAAYASAAEgL4W_D_BwE) que los resolvieron como parte de la evaluación del curso.  \n",
    "\n",
    "- Para cualquier **corrección, duda o inquietud**, se puede contactar directamente al autor del ejercicio o, en su defecto, al responsable de los apuntes del curso de Machine Learning, [Lihki Rubio, PhD.](https://www.researchgate.net/profile/Lihki-Rubio-2/research)\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d8f328-8d07-4884-adc4-addd48dff1ee",
   "metadata": {},
   "source": [
    "<h2>Sección: Random Forest y XGBoost</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afaeeaaa-9a41-4356-a1d1-72cc23647189",
   "metadata": {},
   "source": [
    "<h3>Ejercicio 6</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e539123-9e11-4953-822f-2f6f5474150a",
   "metadata": {},
   "source": [
    "**Solución propuesta por**: [Kanery Marcela Camargo Rodriguez, DS.](https://www.linkedin.com/in/kanerym/?originalSubdomain=co) y [Valentina Esther Cabrera De la Rosa, DS.](https://www.linkedin.com/in/valentina-esther-cabrera-de-la-rosa-7421322b0/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44446d85-c30a-4843-921d-4d8d7bee2117",
   "metadata": {},
   "source": [
    "**Paso 1: Evaluación del cambio de impureza para cada característica (variable)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d86ec3-f753-46ae-b71f-80d4e368fb80",
   "metadata": {},
   "source": [
    "**Variable 1: Age**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad52cb39-23c6-41ad-b769-60df6bae3069",
   "metadata": {},
   "source": [
    "- Se observa que esta variable es de tipo numérico. Por consiguiente, antes de calcular los índices correspondientes, es fundamental establecer los umbrales que definirán las condiciones o categorías que caracterizan dicha variable. Para este propósito, se empleará la siguiente fórmula, la cual está vinculada a la mediana.\n",
    "\n",
    "$$\\text{Umbral} = \\frac{x_i + x_{(i+1)}}{2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e824e3aa-e2fe-4fc8-b5b2-a817f945e6e6",
   "metadata": {},
   "source": [
    "- De este modo, se obtienen los siguientes valores: $$27, 33, 36, 39, 43, 45, 46.5, 47, 49$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50906eac-eab6-49e2-a5cd-b69f37d058d9",
   "metadata": {},
   "source": [
    "- Para calcular el índice de Gini en función de cada umbral, se seguirá un procedimiento sistemático con el objetivo de identificar el umbral que minimiza la impureza. Los pasos a seguir son los siguientes:  \n",
    "\n",
    "1. **Definir el umbral**: Seleccionar un valor que sirva como punto de partición para dividir las observaciones en dos grupos.  \n",
    "\n",
    "2. **Segmentar los datos en función del umbral**:  \n",
    "   - **Grupo 1**: Observaciones en las que la edad es menor que el umbral.  \n",
    "   - **Grupo 2**: Observaciones en las que la edad es mayor o igual al umbral.  \n",
    "\n",
    "3. **Determinar la distribución de las observaciones en cada grupo**:  \n",
    "   - Contabilizar la cantidad de observaciones en cada grupo.  \n",
    "\n",
    "4. **Clasificar las observaciones por categoría en cada grupo**:  \n",
    "   - Contar cuántas observaciones pertenecen a la clase **SI (1)** y cuántas a la clase **NO (0)** dentro de la variable objetivo binaria.  \n",
    "\n",
    "5. **Calcular el índice de Gini para cada grupo**:  \n",
    "   - Aplicar la fórmula del índice de Gini en cada subconjunto, considerando las proporciones de las clases **SI** y **NO**.  \n",
    "\n",
    "6. **Calcular el índice de Gini ponderado para el umbral**:  \n",
    "   - Obtener el índice de Gini total combinando los valores calculados en los grupos, ponderados por el número de observaciones en cada uno.  \n",
    "\n",
    "- Este procedimiento se repite para cada posible umbral, seleccionando aquel que genere la mayor reducción en la impureza. A continuación, se presenta el análisis detallado para cada umbral.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "445006ef-1152-409d-a511-1dad46e2f54b",
   "metadata": {},
   "source": [
    "````{figure} ./imgs/TREEDECISION1.png\n",
    ":align: center\n",
    "\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30713416-b356-4849-9e73-0abb973581ca",
   "metadata": {},
   "source": [
    "- En este caso, el umbral que presenta el menor índice de Gini es **27**. En situaciones donde exista un empate entre varios umbrales, se seleccionará el primero que alcance dicho valor. Procedamos ahora con el análisis de las demás variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b66ee8-8995-4f8a-a5db-2838f2b8d4d3",
   "metadata": {},
   "source": [
    "**Variable 2: Like Dogs**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03ddbba-5844-4f13-8de1-81e7e5201ef9",
   "metadata": {},
   "source": [
    "- A continuación, se analiza la segunda característica o variable, **`Like Dogs`**, la cual es de tipo binario. El procedimiento a seguir es similar al utilizado para la variable numérica; sin embargo, en este caso, la segmentación se realiza directamente sobre los dos valores posibles: **SI** (1) y **NO** (0). Los pasos para el cálculo del índice de Gini son los siguientes:  \n",
    "\n",
    "1. **Segmentar los datos en función de la variable binaria**:  \n",
    "   - **Grupo 1**: Observaciones en las que **`Like Dogs`** es **SI** (1).  \n",
    "   - **Grupo 2**: Observaciones en las que **`Like Dogs`** es **NO** (0).  \n",
    "\n",
    "2. **Determinar la distribución de las observaciones en cada grupo**:  \n",
    "   - Contabilizar la cantidad de observaciones en cada grupo.  \n",
    "\n",
    "3. **Clasificar las observaciones según la variable objetivo**:  \n",
    "   - Contar cuántas observaciones pertenecen a la clase **SI** (1) y cuántas a la clase **NO** (0) dentro de cada grupo.  \n",
    "\n",
    "4. **Calcular el índice de Gini para cada grupo**:  \n",
    "   - Aplicar la fórmula del índice de Gini considerando las proporciones de las clases **SI** y **NO** en la variable objetivo.  \n",
    "\n",
    "5. **Calcular el índice de Gini ponderado**:  \n",
    "   - Obtener el índice de Gini total combinando los valores calculados en ambos grupos, ponderados por la cantidad de observaciones en cada uno.  \n",
    "\n",
    "6. **Seleccionar la división óptima**:  \n",
    "   - La partición con el menor índice de Gini representará la mejor segmentación en términos de reducción de impureza.  \n",
    "\n",
    "- Este análisis permitirá evaluar el impacto de la variable binaria **`Like Dogs`** en la reducción de la impureza y su relevancia en la construcción del modelo."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fd3c652d-39df-4791-94ae-da6b6a138083",
   "metadata": {},
   "source": [
    "````{figure} ./imgs/TREEDECISION2.png\n",
    ":align: center\n",
    "\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa3b0e7-6314-4bef-930a-e37e8e2a4c48",
   "metadata": {},
   "source": [
    "**Variable 3: Like gravity**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c4c487-1c1f-43e8-81c0-205563a97583",
   "metadata": {},
   "source": [
    "- Ahora, para la última variable (`Like gravity`) procedemos de la misma manera que con la anterior variable."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "04effa14-0167-4570-8d2d-0a401bd4d51f",
   "metadata": {},
   "source": [
    "````{figure} ./imgs/TREEDECISION3.png\n",
    ":align: center\n",
    "\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d82ce7-3966-44bb-ba1d-00dbd50976a9",
   "metadata": {},
   "source": [
    "- Después de analizar el cambio de impureza para cada variable, se observa que el menor valor corresponde a la variable **`Like Gravity`** (0.17). Por lo tanto, esta será seleccionada como nuestro nodo padre.  \n",
    "\n",
    "- Además, dentro de este nodo padre, identificamos un nodo puro, que se caracteriza por tener un índice de Gini igual a **0**. Esto significa que, dentro de la categoría correspondiente a la clase **NO**, se puede establecer directamente que **`Gonna Be an Astronaut`** es igual a **NO**. Es decir, si **`Like Gravity`** es **NO**, entonces **`Gonna Be an Astronaut`** también será **NO**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0207092f-aba8-49be-9e01-6369688bc6c1",
   "metadata": {},
   "source": [
    "**Paso 2: Construcción del árbol luego de haber encontrado el nodo padre**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df16db8d-c182-43af-b044-b84d55bb2208",
   "metadata": {},
   "source": [
    "- Para continuar con la construcción del árbol, seguimos estos pasos:\n",
    "\n",
    "1. **Filtrar las observaciones correspondientes a la clase **SI** en la variable `Like Gravity`**:\n",
    "   - Esto crea un subconjunto de datos (nodo no nulo) donde solo se consideran las observaciones en las que **`Like Gravity`** es **SI**.\n",
    "\n",
    "2. **Repetir el proceso de partición**:\n",
    "   - Aplicar los mismos pasos que en la etapa anterior: evaluar el cambio de impureza para las variables restantes y seleccionar la mejor partición para dividir aún más el nodo actual.\n",
    "\n",
    "- Este enfoque iterativo garantiza que el árbol se construya de manera óptima, dividiendo en cada nivel de acuerdo con la variable que maximice la pureza del nodo resultante."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02811cac-5e86-46d7-91fd-5914f2102301",
   "metadata": {},
   "source": [
    "- Teniendo en cuenta lo anterior, la nueva tabla para realizar los cálculos queda de la siguiente manera:\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "|  `Age`  | `Like Dogs` | `Gonna Be an Astronaut` |\n",
    "|:-------:|:-----------:|:-----------------------:|\n",
    "|   30    |      1      |            1           |\n",
    "|   36    |      0      |            1           |\n",
    "|   44    |      1      |            1           |\n",
    "|   47    |      1      |            1           |\n",
    "|   47    |      0      |            1           |\n",
    "|   51    |      1      |            0           |\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ad0180-d298-4dc4-aa73-b9d2e01b8e1f",
   "metadata": {},
   "source": [
    "**Variable 1: Age**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c449fec-5503-4fd4-8ed0-38a6414feebd",
   "metadata": {},
   "source": [
    "- Procedemos de manera similar al **Paso 1**, con la diferencia de que los umbrales cambian debido a que ahora trabajamos únicamente con las 6 observaciones filtradas del nodo anterior. Este ajuste garantiza que los cálculos sean específicos para el subconjunto de datos resultante y continúen optimizando la partición en función del índice de Gini."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d10354e4-492c-4aff-94fd-a9a1fab3f368",
   "metadata": {},
   "source": [
    "````{figure} ./imgs/TREEDECISION4.png\n",
    ":align: center\n",
    "\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8730206a-33f3-48f9-9084-6adbda1df9c6",
   "metadata": {},
   "source": [
    "- En este caso, el umbral con el índice de Gini más bajo es `Umbral 45,5` (**0,22**)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4b4619-6605-4b26-8ad6-d8d71810b012",
   "metadata": {},
   "source": [
    "**Variable 2: Like dogs**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65ee7b4-6d86-4fe3-b697-8d7d1621d928",
   "metadata": {},
   "source": [
    "- Ahora, analizaremos la variable **`Like Dogs`** tras la filtración realizada en el nodo padre."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8d8ad61a-d5ef-47c1-b6fe-1401f487c0da",
   "metadata": {},
   "source": [
    "````{figure} ./imgs/TREEDECISION5.png\n",
    ":align: center\n",
    "\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2c5d99-76f6-42cb-b159-70528bb46c68",
   "metadata": {},
   "source": [
    "- Nótese que el índice de Gini para esta variable es igual a **0,17**. En este paso, observamos que la variable con el menor índice de Gini es **`Like Dogs`**. Por lo tanto, esta variable se selecciona como el siguiente nodo del árbol, ya que permite una mayor reducción en la impureza del nodo actual y contribuye a una partición más pura en el árbol de decisión."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456066a7-5f0a-4088-8663-7778d369db35",
   "metadata": {},
   "source": [
    "**Paso 3: Construcción del árbol final**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5598c6-8257-4534-9433-42a02e23ef02",
   "metadata": {},
   "source": [
    "- Ahora, al filtrar los datos según la variable **`Like Dogs`**, observamos que solo queda una característica disponible, la cual es la **edad**. Por lo tanto, esta se convierte en el siguiente nodo del árbol. Este nodo se genera a partir de la clase **NO** de la variable **`Like Dogs`**, dado que la clase **SI** es un nodo hoja. En este caso, se define que si **te gusta la gravedad** y **te gustan los perros**, entonces **sí vas a ser astronauta**.\n",
    "\n",
    "- Finalmente, dado que el umbral con el menor índice de Gini es **45,5**, la edad se utiliza como criterio de partición. La edad menor a **45,5** se convierte en el siguiente nodo, donde ambas clases derivadas se convierten en nodos hoja:\n",
    "\n",
    "1. **Clase SI (Nodo hoja)**:\n",
    "   - Si **te gusta la gravedad**, **no te gustan los perros**, pero **tienes menos de 45,5 años**, entonces **vas a ser astronauta**.\n",
    "\n",
    "2. **Clase NO (Nodo hoja)**:\n",
    "   - Si **te gusta la gravedad**, **no te gustan los perros**, pero **tienes más de 45,5 años**, entonces **no vas a ser astronauta**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5d26da90-cb7e-4ddc-bb0d-09f5ce1a5c6c",
   "metadata": {},
   "source": [
    "````{figure} ./imgs/TREEDECISION6.png\n",
    ":align: center\n",
    "\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1bb3ff2-e08c-49dd-a238-227fe2e14b69",
   "metadata": {},
   "source": [
    "- Finalmente, así se completa la construcción del árbol de decisión, asegurando que cada nodo optimice la pureza en función de las variables disponibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59028d4-4beb-4ff4-b3d7-80f078ee26e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
