

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Modelos lineales &#8212; Machine Learning</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'linear_model';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Clasificadores Naive Bayes" href="bayes_model.html" />
    <link rel="prev" title="\(k\)-Vecinos más cercanos" href="knn_model.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
    
    
      
    
    
    <img src="_static/logo-uninorte.png" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="_static/logo-uninorte.png" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Machine Learning
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="supervised_intro.html">Aprendizaje supervisado</a></li>
<li class="toctree-l1"><a class="reference internal" href="knn_model.html"><span class="math notranslate nohighlight">\(k\)</span>-Vecinos más cercanos</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Modelos lineales</a></li>
<li class="toctree-l1"><a class="reference internal" href="bayes_model.html">Clasificadores Naive Bayes</a></li>
<li class="toctree-l1"><a class="reference internal" href="decisiontree_model.html">Árboles de decisión</a></li>

<li class="toctree-l1"><a class="reference internal" href="svm_model.html">Máquinas de vectores de soporte</a></li>
<li class="toctree-l1"><a class="reference internal" href="ann_model.html">Redes Neuronales y Deep Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="practical_pca.html">Análisis de Componentes Principales</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_evaluation.html">Evaluación de modelos</a></li>
<li class="toctree-l1"><a class="reference internal" href="chains_pipelines.html">Cadenas de Algoritmos y Pipelines</a></li>
<li class="toctree-l1"><a class="reference internal" href="appendix.html">Apéndice</a></li>
<li class="toctree-l1"><a class="reference internal" href="biblio.html">Bibliografía</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2Flinear_model.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/linear_model.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Modelos lineales</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#modelo-de-regresion-lineal">Modelo de regresión lineal</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#minimos-cuadrados-ordinarios">Mínimos Cuadrados Ordinarios</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#aplicacion-regresion-ridge-y-ols">Aplicación: Regresión Ridge y OLS</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#analisis-exploratorio-de-datos">Análisis Exploratorio de Datos</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#regresion-ridge">Regresión ridge</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#analisis">Análisis</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#implementacion">Implementación</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lasso">Lasso</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#aplicacion-regresion-lasso">Aplicación: Regresión Lasso</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#modelos-lineales-para-clasificacion">Modelos lineales para clasificación</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#modelos-lineales-para-la-clasificacion-multiclase">Modelos lineales para la clasificación multiclase</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="modelos-lineales">
<h1>Modelos lineales<a class="headerlink" href="#modelos-lineales" title="Permalink to this heading">#</a></h1>
<ul class="simple">
<li><p>Los <code class="docutils literal notranslate"><span class="pre">modelos</span> <span class="pre">lineales</span></code> son una clase de modelos que se utilizan ampliamente en la práctica y se han estudiado mucho en las últimas décadas, con raíces que se remontan a más de cien años. Los <code class="docutils literal notranslate"><span class="pre">modelos</span> <span class="pre">lineales</span></code> hacen una <code class="docutils literal notranslate"><span class="pre">predicción</span> <span class="pre">utilizando</span> <span class="pre">una</span> <span class="pre">función</span> <span class="pre">lineal</span> <span class="pre">de</span> <span class="pre">las</span> <span class="pre">características</span> <span class="pre">de</span> <span class="pre">entrada</span></code>, que explicaremos en breve.</p></li>
</ul>
<section id="modelo-de-regresion-lineal">
<h2>Modelo de regresión lineal<a class="headerlink" href="#modelo-de-regresion-lineal" title="Permalink to this heading">#</a></h2>
<p><strong><code class="docutils literal notranslate"><span class="pre">Formulación</span></code></strong></p>
<p>El modelo</p>
<div class="math notranslate nohighlight" id="equation-linear-reg">
<span class="eqno">(5)<a class="headerlink" href="#equation-linear-reg" title="Permalink to this equation">#</a></span>\[
\boldsymbol{y}=\boldsymbol{X}\boldsymbol{\beta}+\boldsymbol{\varepsilon},
\]</div>
<p>se denomina, <code class="docutils literal notranslate"><span class="pre">modelo</span> <span class="pre">de</span> <span class="pre">regresión</span> <span class="pre">lineal</span></code> clásico, si se cumplen los siguientes supuestos:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbb{E}(\boldsymbol{\varepsilon})=\boldsymbol{0}\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\text{Cov}(\boldsymbol{\varepsilon})=\mathbb{E}(\boldsymbol{\varepsilon}\boldsymbol{\varepsilon}^{T})=\sigma^{2}\boldsymbol{I}\)</span></p></li>
<li><p>La matriz de diseño <span class="math notranslate nohighlight">\(\boldsymbol{X}\)</span> tiene <code class="docutils literal notranslate"><span class="pre">rango</span> <span class="pre">completo</span></code>, es decir <span class="math notranslate nohighlight">\(\textrm{rk}(\boldsymbol{X})=p+1\)</span></p></li>
<li><p>El <code class="docutils literal notranslate"><span class="pre">modelo</span> <span class="pre">de</span> <span class="pre">regresión</span> <span class="pre">normal</span></code> clasico es obtenido si adicionalmente  se tiene que <span class="math notranslate nohighlight">\(\boldsymbol{\varepsilon}\sim N(\boldsymbol{0}, \sigma^{2}\boldsymbol{I})\)</span>.</p></li>
<li><p>El <code class="docutils literal notranslate"><span class="pre">modelo</span> <span class="pre">de</span> <span class="pre">regresión</span> <span class="pre">lineal</span></code> <a class="reference internal" href="#equation-linear-reg">(5)</a> puede escribirse en la siguiente forma</p></li>
</ul>
<div class="math notranslate nohighlight" id="equation-linear-reg-mat">
<span class="eqno">(6)<a class="headerlink" href="#equation-linear-reg-mat" title="Permalink to this equation">#</a></span>\[\begin{split}
\begin{pmatrix}
y_{1}\\
y_{2}\\
\vdots\\
y_{i}\\
\vdots\\
y_{n}
\end{pmatrix}
=
\begin{pmatrix}
1 &amp; x_{11} &amp; x_{12} &amp; \cdots &amp; x_{1p}\\
1 &amp; x_{21} &amp; x_{22} &amp; \cdots &amp; x_{2p}\\
\vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots\\
1 &amp; x_{i1} &amp; x_{i2} &amp; \cdots &amp; x_{ip}\\
\vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots\\
1 &amp; x_{n1} &amp; x_{n2} &amp; \cdots &amp; x_{np}
\end{pmatrix}
\begin{pmatrix}
\beta_{0}\\[2mm]
\beta_{1}\\[2mm]
\beta_{2}\\
\vdots\\[2mm]
\beta_{p}
\end{pmatrix}
+
\begin{pmatrix}
\varepsilon_{1}\\
\varepsilon_{2}\\
\vdots\\
\varepsilon_{i}\\
\vdots\\
\varepsilon_{n}
\end{pmatrix}
\end{split}\]</div>
<ul class="simple">
<li><p>A partir del sistema <a class="reference internal" href="#equation-linear-reg-mat">(6)</a>, se puede observar que la <span class="math notranslate nohighlight">\(i\)</span>-esima <code class="docutils literal notranslate"><span class="pre">predicción</span> <span class="pre">para</span> <span class="pre">un</span> <span class="pre">modelo</span> <span class="pre">lineal</span></code> es la siguiente:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\hat{y}_{i}=\hat{\beta}_{0}+\hat{\beta}_{1}\cdot x_{i1}+\hat{\beta}_{2}\cdot x_{i2}+\cdots+\hat{\beta}_{p}\cdot x_{ip}=\boldsymbol{\hat{\beta}}^{T}\boldsymbol{x}_{i},~i = 1,2,\dots, n.
\]</div>
<ul class="simple">
<li><p>Aquí, <span class="math notranslate nohighlight">\(x_{i1},\dots, x_{ip}\)</span> denotan las <code class="docutils literal notranslate"><span class="pre">variables</span> <span class="pre">predictoras</span> <span class="pre">o</span> <span class="pre">características</span></code> (en este ejemplo, el número de características es <span class="math notranslate nohighlight">\(p\)</span>). Los valores, <span class="math notranslate nohighlight">\(\hat{\beta}_{i},~i=0,1,\dots,p\)</span>, son los <code class="docutils literal notranslate"><span class="pre">parámetros</span> <span class="pre">aprendidos</span> <span class="pre">por</span> <span class="pre">el</span> <span class="pre">modelo</span></code> y <span class="math notranslate nohighlight">\(\hat{y}_{i}\)</span> es la <code class="docutils literal notranslate"><span class="pre">predicción</span> <span class="pre">obtenida</span> <span class="pre">por</span> <span class="pre">el</span> <span class="pre">modelo</span></code>. Por ejemplo, para un conjunto de datos con una sola característica, se tiene que:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\hat{y}_{i} = \hat{\beta}_{0}+\hat{\beta}_{1}\cdot x_{i1},~i=1,2,\dots,n.
\]</div>
<ul class="simple">
<li><p>Aquí, <span class="math notranslate nohighlight">\(\hat{\beta}_{1}\)</span> es la <code class="docutils literal notranslate"><span class="pre">pendiente</span></code> y <span class="math notranslate nohighlight">\(\hat{\beta}_{0}\)</span> es el <code class="docutils literal notranslate"><span class="pre">desplazamiento</span> <span class="pre">en</span> <span class="pre">el</span> <span class="pre">eje</span></code> <span class="math notranslate nohighlight">\(y\)</span>. Para más características, <span class="math notranslate nohighlight">\(\boldsymbol{\hat{\beta}}\)</span> contiene las <code class="docutils literal notranslate"><span class="pre">pendientes</span> <span class="pre">a</span> <span class="pre">lo</span> <span class="pre">largo</span> <span class="pre">de</span> <span class="pre">cada</span> <span class="pre">eje</span> <span class="pre">de</span> <span class="pre">características</span></code>. Alternativamente, se puede pensar en la <code class="docutils literal notranslate"><span class="pre">respuesta</span> <span class="pre">predicha</span></code> como una <code class="docutils literal notranslate"><span class="pre">suma</span> <span class="pre">ponderada</span> <span class="pre">de</span> <span class="pre">las</span> <span class="pre">características</span> <span class="pre">de</span> <span class="pre">entrada</span></code>, con pesos (que pueden ser negativos) dados por las entradas de <span class="math notranslate nohighlight">\(\boldsymbol{\hat{\beta}}\)</span>.</p></li>
</ul>
<p><strong><code class="docutils literal notranslate"><span class="pre">Ilustración</span></code></strong></p>
<ul class="simple">
<li><p>Considere el ejemplo de intentar <code class="docutils literal notranslate"><span class="pre">aprender</span> <span class="pre">los</span> <span class="pre">parámetros</span></code> <span class="math notranslate nohighlight">\(\hat{\beta}_{1}:=w[0]\)</span> y <span class="math notranslate nohighlight">\(\hat{\beta}_{0}:=b\)</span> en nuestro <code class="docutils literal notranslate"><span class="pre">conjunto</span> <span class="pre">de</span> <span class="pre">datos</span> <span class="pre">de</span> <span class="pre">ondas</span> <span class="pre">unidimensionales</span> <span class="pre">(wave)</span></code> usando <code class="docutils literal notranslate"><span class="pre">plot_linear_regression_wave()</span></code>. En este caso, la función para la regresión lineal de ondas unidimensionales, usa la librería <code class="docutils literal notranslate"><span class="pre">LinearRegression()</span></code>, para ajustar la recta de regresión, basada en mínimos cuadrados.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mglearn</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set_style</span><span class="p">(</span><span class="s2">&quot;darkgrid&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mglearn</span><span class="o">.</span><span class="n">plots</span><span class="o">.</span><span class="n">plot_linear_regression_wave</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>w[0]: 0.393906  b: -0.031804
</pre></div>
</div>
<img alt="_images/3a56db647f064837c6e7d69b4183eb9119494200a2a63d0fd617215dc73dca0e.png" src="_images/3a56db647f064837c6e7d69b4183eb9119494200a2a63d0fd617215dc73dca0e.png" />
</div>
</div>
<ul class="simple">
<li><p>Si observamos <span class="math notranslate nohighlight">\(\hat{\beta}_{1}\)</span>, vemos que <code class="docutils literal notranslate"><span class="pre">la</span> <span class="pre">pendiente</span> <span class="pre">debería</span> <span class="pre">estar</span> <span class="pre">en</span> <span class="pre">torno</span> <span class="pre">a</span> <span class="pre">0.4</span></code>, lo que podemos confirmar visualmente en el gráfico. <code class="docutils literal notranslate"><span class="pre">El</span> <span class="pre">intercepto</span></code>, punto en el que la línea de predicción debería cruzar el eje <span class="math notranslate nohighlight">\(y\)</span>, está <code class="docutils literal notranslate"><span class="pre">ligeramente</span> <span class="pre">por</span> <span class="pre">debajo</span> <span class="pre">de</span> <span class="pre">cero</span></code>, lo que también se puede confirmar en la imagen.</p></li>
<li><p>Los <code class="docutils literal notranslate"><span class="pre">modelos</span> <span class="pre">de</span> <span class="pre">regresión</span> <span class="pre">lineal</span></code> pueden caracterizarse como <code class="docutils literal notranslate"><span class="pre">modelos</span> <span class="pre">de</span> <span class="pre">regresión</span></code> en los que <code class="docutils literal notranslate"><span class="pre">la</span> <span class="pre">predicción</span> <span class="pre">es</span> <span class="pre">una</span> <span class="pre">línea</span> <span class="pre">para</span> <span class="pre">una</span> <span class="pre">sola</span> <span class="pre">característica,</span> <span class="pre">un</span> <span class="pre">plano</span> <span class="pre">cuando</span> <span class="pre">se</span> <span class="pre">utilizan</span> <span class="pre">dos</span> <span class="pre">características,</span> <span class="pre">o</span> <span class="pre">un</span> <span class="pre">hiperplano</span> <span class="pre">en</span> <span class="pre">dimensiones</span> <span class="pre">más</span> <span class="pre">altas</span></code> (es decir, cuando se utilizan más características).</p></li>
<li><p>Si se comparan las <code class="docutils literal notranslate"><span class="pre">predicciones</span> <span class="pre">realizadas</span> <span class="pre">por</span> <span class="pre">la</span> <span class="pre">línea</span> <span class="pre">recta</span></code> con las <code class="docutils literal notranslate"><span class="pre">realizadas</span> <span class="pre">por</span> <span class="pre">el</span> <span class="pre">modelo</span> <span class="pre">KNeighborsRegressor</span></code>, <code class="docutils literal notranslate"><span class="pre">usar</span> <span class="pre">una</span> <span class="pre">línea</span> <span class="pre">recta</span> <span class="pre">para</span> <span class="pre">hacer</span> <span class="pre">predicciones</span> <span class="pre">parece</span> <span class="pre">muy</span> <span class="pre">restrictivo.</span> <span class="pre">Parece</span> <span class="pre">que</span> <span class="pre">se</span> <span class="pre">pierden</span> <span class="pre">todos</span> <span class="pre">los</span> <span class="pre">detalles</span> <span class="pre">finos</span> <span class="pre">de</span> <span class="pre">los</span> <span class="pre">datos</span></code>. En cierto sentido, esto es cierto. Es una suposición fuerte (y algo irreal) que nuestro objetivo <span class="math notranslate nohighlight">\(y\)</span> es una combinación lineal de las características. Observar los datos de forma unidimensional da una perspectiva algo sesgada.</p></li>
</ul>
<div class="tip admonition">
<p class="admonition-title">Observación</p>
<ul class="simple">
<li><p>Para los <code class="docutils literal notranslate"><span class="pre">conjuntos</span> <span class="pre">de</span> <span class="pre">datos</span> <span class="pre">con</span> <span class="pre">muchas</span> <span class="pre">características,</span> <span class="pre">los</span> <span class="pre">modelos</span> <span class="pre">lineales</span> <span class="pre">pueden</span> <span class="pre">ser</span> <span class="pre">muy</span> <span class="pre">potentes</span></code>. En particular, si tiene <code class="docutils literal notranslate"><span class="pre">más</span> <span class="pre">características</span> <span class="pre">que</span> <span class="pre">puntos</span> <span class="pre">de</span> <span class="pre">datos</span> <span class="pre">de</span> <span class="pre">entrenamiento,</span> <span class="pre">cualquier</span> <span class="pre">objetivo</span></code> <span class="math notranslate nohighlight">\(y\)</span> <code class="docutils literal notranslate"><span class="pre">puede</span> <span class="pre">modelarse</span> <span class="pre">perfectamente</span> <span class="pre">(en</span> <span class="pre">el</span> <span class="pre">conjunto</span> <span class="pre">de</span> <span class="pre">entrenamiento)</span> <span class="pre">como</span> <span class="pre">una</span> <span class="pre">función</span> <span class="pre">lineal</span></code>.</p></li>
<li><p>Hay muchos modelos lineales diferentes para la regresión. <code class="docutils literal notranslate"><span class="pre">La</span> <span class="pre">diferencia</span> <span class="pre">entre</span> <span class="pre">estos</span> <span class="pre">modelos</span> <span class="pre">radica</span> <span class="pre">en</span> <span class="pre">cómo</span> <span class="pre">se</span> <span class="pre">aprenden</span> <span class="pre">los</span> <span class="pre">parámetros</span> <span class="pre">del</span> <span class="pre">modelo</span></code> <span class="math notranslate nohighlight">\(\boldsymbol{\beta}_{1}\)</span> y <span class="math notranslate nohighlight">\(\boldsymbol{\beta}_{0}\)</span> a partir de los datos de entrenamiento, y en <code class="docutils literal notranslate"><span class="pre">cómo</span> <span class="pre">se</span> <span class="pre">puede</span> <span class="pre">controlar</span> <span class="pre">la</span> <span class="pre">complejidad</span> <span class="pre">del</span> <span class="pre">modelo</span></code>. A continuación veremos los modelos lineales más populares.</p></li>
</ul>
</div>
</section>
<section id="minimos-cuadrados-ordinarios">
<h2>Mínimos Cuadrados Ordinarios<a class="headerlink" href="#minimos-cuadrados-ordinarios" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">La</span> <span class="pre">regresión</span> <span class="pre">lineal,</span> <span class="pre">o</span> <span class="pre">mínimos</span> <span class="pre">cuadrados</span> <span class="pre">ordinarios</span> <span class="pre">(Ordinary</span> <span class="pre">Least</span> <span class="pre">Squares</span> <span class="pre">(OLS))</span></code>, es el modelo lineal <code class="docutils literal notranslate"><span class="pre">más</span> <span class="pre">sencillo</span> <span class="pre">y</span> <span class="pre">clásico</span> <span class="pre">para</span> <span class="pre">la</span> <span class="pre">regresión</span></code>. La regresión lineal <code class="docutils literal notranslate"><span class="pre">encuentra</span> <span class="pre">el</span> <span class="pre">vector</span> <span class="pre">de</span> <span class="pre">parámetros</span></code> <span class="math notranslate nohighlight">\(\boldsymbol{\hat{\beta}}\)</span> <code class="docutils literal notranslate"><span class="pre">que</span> <span class="pre">minimiza</span> <span class="pre">el</span> <span class="pre">error</span> <span class="pre">cuadrático</span> <span class="pre">medio</span> <span class="pre">entre</span> <span class="pre">las</span> <span class="pre">predicciones</span> <span class="pre">y</span> <span class="pre">los</span> <span class="pre">verdaderos</span> <span class="pre">objetivos</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">regresión</span></code>, <span class="math notranslate nohighlight">\(y\)</span>, <code class="docutils literal notranslate"><span class="pre">en</span> <span class="pre">el</span> <span class="pre">conjunto</span> <span class="pre">de</span> <span class="pre">entrenamiento</span></code>.</p></li>
<li><p>El error cuadrático medio es la suma de las diferencias al cuadrado entre las predicciones y los valores reales. La regresión lineal no tiene parámetros, lo cual es una ventaja, pero, <code class="docutils literal notranslate"><span class="pre">no</span> <span class="pre">tiene</span> <span class="pre">forma</span> <span class="pre">de</span> <span class="pre">controlar</span> <span class="pre">la</span> <span class="pre">complejidad</span> <span class="pre">del</span> <span class="pre">modelo</span></code>.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">import</span> <span class="nn">matplotlib</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">mglearn</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">make_wave</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">60</span><span class="p">)</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">lr</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="tip admonition">
<p class="admonition-title">Observación</p>
<ul class="simple">
<li><p>El número <code class="docutils literal notranslate"><span class="pre">42</span></code> es normalmente elegido en la literatura relacionadas con <code class="docutils literal notranslate"><span class="pre">AI</span></code>, como homenaje al libro de la <code class="docutils literal notranslate"><span class="pre">Douglas</span> <span class="pre">Adams</span></code> “<a class="reference external" href="https://en.wikipedia.org/wiki/Phrases_from_The_Hitchhiker%27s_Guide_to_the_Galaxy#The_number_42">The Hitchhiker’s Guide to the Galaxy</a>”, una serie de cómic de ciencia ficción creada por <code class="docutils literal notranslate"><span class="pre">Douglas</span> <span class="pre">Adams</span></code> que se ha hecho popular entre los aficionados al género y los <code class="docutils literal notranslate"><span class="pre">miembros</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">comunidad</span> <span class="pre">científica</span></code>.</p></li>
<li><p>El número 42 corresponde a la respuesta a la gran pregunta <code class="docutils literal notranslate"><span class="pre">&quot;Life,</span> <span class="pre">the</span> <span class="pre">universe,</span> <span class="pre">and</span> <span class="pre">everything&quot;</span></code>, calculada por un ordenador (llamado <code class="docutils literal notranslate"><span class="pre">&quot;Deep</span> <span class="pre">Thought&quot;</span></code>) creado específicamente para resolverla <code class="docutils literal notranslate"><span class="pre">:)</span></code>. Supuestamente, el pensamiento profundo (Deep Thought) tarda <span class="math notranslate nohighlight">\(7\frac{1}{2}\)</span> millones de años en calcular y comprobar la respuesta, que resulta ser 42.</p></li>
</ul>
</div>
<ul class="simple">
<li><p>Sin embargo, <code class="docutils literal notranslate"><span class="pre">random_state</span></code> puede ser cualquier número entero, mas aún, podemos realizar un <code class="docutils literal notranslate"><span class="pre">grid</span> <span class="pre">search</span></code> para conseguir aquel parámetro <code class="docutils literal notranslate"><span class="pre">random_state</span></code> que nos entrega el mejor score. Mas adelante abordaremos el uso de <code class="docutils literal notranslate"><span class="pre">GridSearch</span></code>. Si no establece <code class="docutils literal notranslate"><span class="pre">random_state</span></code> en <code class="docutils literal notranslate"><span class="pre">42</span></code> o cualquier otro entero positivo, cada vez que ejecute su código de nuevo, generará un conjunto de pruebas diferente.</p></li>
</ul>
<ul class="simple">
<li><p>Los <code class="docutils literal notranslate"><span class="pre">parámetros</span> <span class="pre">de</span> <span class="pre">&quot;pendiente&quot;</span></code> (<span class="math notranslate nohighlight">\(\hat{\beta}_{i},~i=1,2,\dots,p\)</span>), también llamados <code class="docutils literal notranslate"><span class="pre">pesos</span> <span class="pre">o</span> <span class="pre">coeficientes,</span> <span class="pre">se</span> <span class="pre">almacenan</span> <span class="pre">en</span> <span class="pre">el</span> <span class="pre">atributo</span> <span class="pre">coef_</span></code>, mientras que el <code class="docutils literal notranslate"><span class="pre">desplazamiento</span> <span class="pre">o</span> <span class="pre">intercepto</span></code> (<span class="math notranslate nohighlight">\(\hat{\beta}_{0}\)</span>) se almacena en el atributo <code class="docutils literal notranslate"><span class="pre">intercept_</span></code>:</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;lr.coef_: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">lr</span><span class="o">.</span><span class="n">coef_</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;lr.intercept_: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">lr</span><span class="o">.</span><span class="n">intercept_</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>lr.coef_: [0.39390555]
lr.intercept_: -0.031804343026759746
</pre></div>
</div>
</div>
</div>
<div class="proof observation admonition" id="observation_lm1">
<p class="admonition-title"><span class="caption-number">Observation 3 </span></p>
<section class="observation-content" id="proof-content">
<p>El extraño <code class="docutils literal notranslate"><span class="pre">guion</span> <span class="pre">bajo</span></code> al final de <code class="docutils literal notranslate"><span class="pre">coef_</span></code> e <code class="docutils literal notranslate"><span class="pre">intercept</span></code>_ es usado a menudo por <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code> para almacenar cualquier <code class="docutils literal notranslate"><span class="pre">objeto</span> <span class="pre">que</span> <span class="pre">se</span> <span class="pre">deriva</span> <span class="pre">de</span> <span class="pre">los</span> <span class="pre">datos</span> <span class="pre">de</span> <span class="pre">entrenamiento</span></code>, usando atributos que terminan con un guion bajo al final. Esto es <code class="docutils literal notranslate"><span class="pre">para</span> <span class="pre">separarlos</span> <span class="pre">de</span> <span class="pre">los</span> <span class="pre">parámetros</span> <span class="pre">que</span> <span class="pre">son</span> <span class="pre">establecidos</span> <span class="pre">por</span> <span class="pre">el</span> <span class="pre">usuario</span></code>.</p>
</section>
</div><ul class="simple">
<li><p>El atributo <code class="docutils literal notranslate"><span class="pre">intercept_</span></code> es siempre un <code class="docutils literal notranslate"><span class="pre">único</span> <span class="pre">número</span> <span class="pre">flotante</span></code>, mientras que el atributo <code class="docutils literal notranslate"><span class="pre">coef_</span> <span class="pre">es</span> <span class="pre">una</span> <span class="pre">matriz</span> <span class="pre">NumPy</span> <span class="pre">con</span> <span class="pre">una</span> <span class="pre">entrada</span> <span class="pre">por</span> <span class="pre">característica</span></code>. Como sólo tenemos una característica de entrada en el conjunto de datos <code class="docutils literal notranslate"><span class="pre">wave</span></code>, <code class="docutils literal notranslate"><span class="pre">lr.coef_</span></code> sólo tiene una entrada. Veamos el rendimiento del conjunto de entrenamiento y del conjunto de prueba</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training set score: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">lr</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test set score: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">lr</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training set score: 0.67
Test set score: 0.66
</pre></div>
</div>
</div>
</div>
<div class="tip dropdown admonition">
<p class="admonition-title">¿Cual sería un buen score?</p>
<p>Definir un <code class="docutils literal notranslate"><span class="pre">buen</span> <span class="pre">score</span></code> en machine learning es un tema subjetivo, y bastante ligado a los datos. Pero, <code class="docutils literal notranslate"><span class="pre">de</span> <span class="pre">forma</span> <span class="pre">coherente</span> <span class="pre">con</span> <span class="pre">los</span> <span class="pre">estándares</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">industria,</span> <span class="pre">cualquier</span> <span class="pre">score</span> <span class="pre">superior</span> <span class="pre">al</span> <span class="pre">70%</span> <span class="pre">es</span> <span class="pre">un</span> <span class="pre">gran</span> <span class="pre">rendimiento</span> <span class="pre">del</span> <span class="pre">modelo</span></code>. De hecho, <code class="docutils literal notranslate"><span class="pre">una</span> <span class="pre">medida</span> <span class="pre">de</span> <span class="pre">precisión</span> <span class="pre">de</span> <span class="pre">entre</span> <span class="pre">el</span> <span class="pre">70%</span> <span class="pre">y</span> <span class="pre">el</span> <span class="pre">90%</span> <span class="pre">no</span> <span class="pre">sólo</span> <span class="pre">es</span> <span class="pre">ideal,</span> <span class="pre">sino</span> <span class="pre">que</span> <span class="pre">es</span> <span class="pre">realista</span></code>.</p>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Un</span></code> <span class="math notranslate nohighlight">\(R^2\)</span> <code class="docutils literal notranslate"><span class="pre">en</span> <span class="pre">torno</span> <span class="pre">a</span> <span class="pre">0.66</span> <span class="pre">no</span> <span class="pre">es</span> <span class="pre">muy</span> <span class="pre">bueno</span></code>, pero podemos ver que los <code class="docutils literal notranslate"><span class="pre">score</span> <span class="pre">en</span> <span class="pre">los</span> <span class="pre">conjuntos</span> <span class="pre">de</span> <span class="pre">entrenamiento</span> <span class="pre">y</span> <span class="pre">de</span> <span class="pre">prueba</span> <span class="pre">están</span> <span class="pre">muy</span> <span class="pre">cerca</span></code>. Esto significa que probablemente estemos <code class="docutils literal notranslate"><span class="pre">subajustando</span> <span class="pre">(underfitting)</span></code>, no <code class="docutils literal notranslate"><span class="pre">sobreajustando</span> <span class="pre">(overfitting)</span></code> nuestro modelo de regresión lineal. Para este conjunto de datos unidimensional, hay poco peligro de overfitting, ya que el modelo es muy simple (o restringido).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">En</span> <span class="pre">este</span> <span class="pre">tipo</span> <span class="pre">de</span> <span class="pre">casos,</span> <span class="pre">optamos</span> <span class="pre">por</span> <span class="pre">complejizar</span> <span class="pre">el</span> <span class="pre">modelo</span> <span class="pre">para</span> <span class="pre">obtener</span> <span class="pre">un</span> <span class="pre">modelo</span> <span class="pre">menos</span> <span class="pre">simple</span></code>. Sin embargo, <code class="docutils literal notranslate"><span class="pre">con</span> <span class="pre">conjuntos</span> <span class="pre">de</span> <span class="pre">datos</span> <span class="pre">de</span> <span class="pre">mayor</span> <span class="pre">dimensión</span></code> (i.e dataset con un gran número de características), <code class="docutils literal notranslate"><span class="pre">los</span> <span class="pre">modelos</span> <span class="pre">lineales</span> <span class="pre">son</span> <span class="pre">más</span> <span class="pre">potentes,</span> <span class="pre">y</span> <span class="pre">hay</span> <span class="pre">más</span> <span class="pre">posibilidades</span> <span class="pre">de</span> <span class="pre">que</span> <span class="pre">se</span> <span class="pre">ajusten</span> <span class="pre">en</span> <span class="pre">exceso</span></code>.</p></li>
</ul>
</section>
<section id="aplicacion-regresion-ridge-y-ols">
<h2>Aplicación: Regresión Ridge y OLS<a class="headerlink" href="#aplicacion-regresion-ridge-y-ols" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Veamos cómo se comporta <code class="docutils literal notranslate"><span class="pre">LinearRegression</span></code> en un conjunto de datos más complejo, como el conjunto de datos de <code class="docutils literal notranslate"><span class="pre">viviendas</span> <span class="pre">de</span> <span class="pre">Boston</span></code>. Recordemos que este conjunto de datos tiene <code class="docutils literal notranslate"><span class="pre">506</span> <span class="pre">muestras</span> <span class="pre">y</span> <span class="pre">105</span> <span class="pre">características</span></code> derivadas. En primer lugar, <code class="docutils literal notranslate"><span class="pre">cargamos</span> <span class="pre">el</span> <span class="pre">conjunto</span> <span class="pre">de</span> <span class="pre">datos</span></code> y lo <code class="docutils literal notranslate"><span class="pre">dividimos</span> <span class="pre">en</span> <span class="pre">un</span> <span class="pre">conjunto</span> <span class="pre">de</span> <span class="pre">entrenamiento</span> <span class="pre">y</span> <span class="pre">otro</span> <span class="pre">de</span> <span class="pre">prueba</span></code>. A continuación, construimos el modelo de regresión lineal como antes. Iniciemos realizando un <code class="docutils literal notranslate"><span class="pre">análisis</span> <span class="pre">exploratorio</span> <span class="pre">de</span> <span class="pre">datos</span></code>.</p></li>
</ul>
<figure class="align-center" id="boston-houses-ds-numref">
<a class="reference internal image-reference" href="_images/boston_houses_ds.jpeg"><img alt="_images/boston_houses_ds.jpeg" src="_images/boston_houses_ds.jpeg" style="width: 672.0px; height: 448.7px;" /></a>
</figure>
<section id="analisis-exploratorio-de-datos">
<h3>Análisis Exploratorio de Datos<a class="headerlink" href="#analisis-exploratorio-de-datos" title="Permalink to this heading">#</a></h3>
<p><strong><code class="docutils literal notranslate"><span class="pre">1.</span> <span class="pre">Importar</span> <span class="pre">librerías</span> <span class="pre">PythonImportar</span> <span class="pre">librerías</span> <span class="pre">Python</span></code></strong></p>
<ul class="simple">
<li><p>Se importan las <code class="docutils literal notranslate"><span class="pre">librerías</span> <span class="pre">esenciales</span></code> para facilitar el análisis que abarca la <code class="docutils literal notranslate"><span class="pre">carga</span> <span class="pre">de</span> <span class="pre">datos,</span> <span class="pre">la</span> <span class="pre">evaluación</span> <span class="pre">estadística,</span> <span class="pre">la</span> <span class="pre">visualización,</span> <span class="pre">la</span> <span class="pre">transformación</span> <span class="pre">de</span> <span class="pre">datos,</span> <span class="pre">la</span> <span class="pre">fusión</span> <span class="pre">y</span> <span class="pre">la</span> <span class="pre">unión</span></code></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
</pre></div>
</div>
</div>
</div>
<p><strong><code class="docutils literal notranslate"><span class="pre">2.</span> <span class="pre">Lectura</span> <span class="pre">de</span> <span class="pre">datos</span></code></strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;https://raw.githubusercontent.com/lihkir/Data/main/boston.csv&#39;</span><span class="p">,</span> <span class="n">index_col</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p><strong><code class="docutils literal notranslate"><span class="pre">Análisis</span> <span class="pre">de</span> <span class="pre">Datos</span></code></strong>: El objetivo principal de la <code class="docutils literal notranslate"><span class="pre">comprensión</span> <span class="pre">de</span> <span class="pre">datos</span></code> es obtener información general sobre los datos, que abarca el <code class="docutils literal notranslate"><span class="pre">número</span> <span class="pre">de</span> <span class="pre">filas</span> <span class="pre">y</span> <span class="pre">columnas,</span> <span class="pre">valores</span> <span class="pre">y</span> <span class="pre">tipos</span> <span class="pre">de</span> <span class="pre">datos</span> <span class="pre">así</span> <span class="pre">como</span> <span class="pre">también</span> <span class="pre">datos</span> <span class="pre">faltantes.</span></code></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>crim</th>
      <th>zn</th>
      <th>indus</th>
      <th>chas</th>
      <th>nox</th>
      <th>rm</th>
      <th>age</th>
      <th>dis</th>
      <th>rad</th>
      <th>tax</th>
      <th>ptratio</th>
      <th>black</th>
      <th>lstat</th>
      <th>medv</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>0.00632</td>
      <td>18.0</td>
      <td>2.31</td>
      <td>0</td>
      <td>0.538</td>
      <td>6.575</td>
      <td>65.2</td>
      <td>4.0900</td>
      <td>1</td>
      <td>296</td>
      <td>15.3</td>
      <td>396.90</td>
      <td>4.98</td>
      <td>24.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.02731</td>
      <td>0.0</td>
      <td>7.07</td>
      <td>0</td>
      <td>0.469</td>
      <td>6.421</td>
      <td>78.9</td>
      <td>4.9671</td>
      <td>2</td>
      <td>242</td>
      <td>17.8</td>
      <td>396.90</td>
      <td>9.14</td>
      <td>21.6</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.02729</td>
      <td>0.0</td>
      <td>7.07</td>
      <td>0</td>
      <td>0.469</td>
      <td>7.185</td>
      <td>61.1</td>
      <td>4.9671</td>
      <td>2</td>
      <td>242</td>
      <td>17.8</td>
      <td>392.83</td>
      <td>4.03</td>
      <td>34.7</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.03237</td>
      <td>0.0</td>
      <td>2.18</td>
      <td>0</td>
      <td>0.458</td>
      <td>6.998</td>
      <td>45.8</td>
      <td>6.0622</td>
      <td>3</td>
      <td>222</td>
      <td>18.7</td>
      <td>394.63</td>
      <td>2.94</td>
      <td>33.4</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0.06905</td>
      <td>0.0</td>
      <td>2.18</td>
      <td>0</td>
      <td>0.458</td>
      <td>7.147</td>
      <td>54.2</td>
      <td>6.0622</td>
      <td>3</td>
      <td>222</td>
      <td>18.7</td>
      <td>396.90</td>
      <td>5.33</td>
      <td>36.2</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data</span><span class="o">.</span><span class="n">tail</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>crim</th>
      <th>zn</th>
      <th>indus</th>
      <th>chas</th>
      <th>nox</th>
      <th>rm</th>
      <th>age</th>
      <th>dis</th>
      <th>rad</th>
      <th>tax</th>
      <th>ptratio</th>
      <th>black</th>
      <th>lstat</th>
      <th>medv</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>502</th>
      <td>0.06263</td>
      <td>0.0</td>
      <td>11.93</td>
      <td>0</td>
      <td>0.573</td>
      <td>6.593</td>
      <td>69.1</td>
      <td>2.4786</td>
      <td>1</td>
      <td>273</td>
      <td>21.0</td>
      <td>391.99</td>
      <td>9.67</td>
      <td>22.4</td>
    </tr>
    <tr>
      <th>503</th>
      <td>0.04527</td>
      <td>0.0</td>
      <td>11.93</td>
      <td>0</td>
      <td>0.573</td>
      <td>6.120</td>
      <td>76.7</td>
      <td>2.2875</td>
      <td>1</td>
      <td>273</td>
      <td>21.0</td>
      <td>396.90</td>
      <td>9.08</td>
      <td>20.6</td>
    </tr>
    <tr>
      <th>504</th>
      <td>0.06076</td>
      <td>0.0</td>
      <td>11.93</td>
      <td>0</td>
      <td>0.573</td>
      <td>6.976</td>
      <td>91.0</td>
      <td>2.1675</td>
      <td>1</td>
      <td>273</td>
      <td>21.0</td>
      <td>396.90</td>
      <td>5.64</td>
      <td>23.9</td>
    </tr>
    <tr>
      <th>505</th>
      <td>0.10959</td>
      <td>0.0</td>
      <td>11.93</td>
      <td>0</td>
      <td>0.573</td>
      <td>6.794</td>
      <td>89.3</td>
      <td>2.3889</td>
      <td>1</td>
      <td>273</td>
      <td>21.0</td>
      <td>393.45</td>
      <td>6.48</td>
      <td>22.0</td>
    </tr>
    <tr>
      <th>506</th>
      <td>0.04741</td>
      <td>0.0</td>
      <td>11.93</td>
      <td>0</td>
      <td>0.573</td>
      <td>6.030</td>
      <td>80.8</td>
      <td>2.5050</td>
      <td>1</td>
      <td>273</td>
      <td>21.0</td>
      <td>396.90</td>
      <td>7.88</td>
      <td>11.9</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data</span><span class="o">.</span><span class="n">info</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
Index: 506 entries, 1 to 506
Data columns (total 14 columns):
 #   Column   Non-Null Count  Dtype  
---  ------   --------------  -----  
 0   crim     506 non-null    float64
 1   zn       506 non-null    float64
 2   indus    506 non-null    float64
 3   chas     506 non-null    int64  
 4   nox      506 non-null    float64
 5   rm       506 non-null    float64
 6   age      506 non-null    float64
 7   dis      506 non-null    float64
 8   rad      506 non-null    int64  
 9   tax      506 non-null    int64  
 10  ptratio  506 non-null    float64
 11  black    506 non-null    float64
 12  lstat    506 non-null    float64
 13  medv     506 non-null    float64
dtypes: float64(11), int64(3)
memory usage: 59.3 KB
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Información</span> <span class="pre">de</span> <span class="pre">atributos</span> <span class="pre">(por</span> <span class="pre">orden)</span></code>:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">CRIM</span></code>: tasa de criminalidad per cápita por ciudad</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">ZN</span></code>: proporción de suelo residencial para parcelas de más de 25.000 pies cuadrados</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">INDUS</span></code>: proporción de acres comerciales no minoristas por ciudad</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">CHAS</span></code>: Variable dummy del Río Charles (= 1 si el tramo limita con el río; 0 en caso contrario)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">NOX</span></code>: concentración de óxidos nítricos (partes por 10 millones)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">RM</span></code>: número medio de habitaciones por vivienda</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">AGE</span></code>: proporción de unidades ocupadas por sus propietarios construidas antes de 1940</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">DIS</span></code>: distancias ponderadas a cinco centros de empleo de Boston</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">RAD</span></code>: índice de accesibilidad a autopistas radiales</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">TAX</span></code>: tipo del impuesto sobre bienes inmuebles de valor íntegro por 10.000 dólares</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">PTRATIO</span></code>: relación alumnos-profesor por ciudad</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">B</span></code>: 1000(Bk - 0,63)^2 donde Bk es la proporción de negros por ciudad</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">LSTAT</span></code>: % más bajo de la población</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">MEDV</span></code>: Valor medio de las viviendas ocupadas por sus propietarios en $1000’s.</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p><strong><code class="docutils literal notranslate"><span class="pre">Comprobación</span> <span class="pre">de</span> <span class="pre">duplicados</span></code></strong></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data</span><span class="o">.</span><span class="n">nunique</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>crim       504
zn          26
indus       76
chas         2
nox         81
rm         446
age        356
dis        412
rad          9
tax         66
ptratio     46
black      357
lstat      455
medv       229
dtype: int64
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p><strong><code class="docutils literal notranslate"><span class="pre">Conteo</span> <span class="pre">de</span> <span class="pre">datos</span> <span class="pre">faltantes</span> <span class="pre">y</span> <span class="pre">porcentaje</span></code></strong></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>crim       0
zn         0
indus      0
chas       0
nox        0
rm         0
age        0
dis        0
rad        0
tax        0
ptratio    0
black      0
lstat      0
medv       0
dtype: int64
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">/</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)))</span><span class="o">*</span><span class="mi">100</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>crim       0.0
zn         0.0
indus      0.0
chas       0.0
nox        0.0
rm         0.0
age        0.0
dis        0.0
rad        0.0
tax        0.0
ptratio    0.0
black      0.0
lstat      0.0
medv       0.0
dtype: float64
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Operaciones relacionadas con <code class="docutils literal notranslate"><span class="pre">Feature</span> <span class="pre">Engineering,</span> <span class="pre">Reducción</span> <span class="pre">y</span> <span class="pre">Gestión</span></code> pueden llevarse a cabo de ser necesarias.</p></li>
</ul>
<p><strong><code class="docutils literal notranslate"><span class="pre">3.</span> <span class="pre">EDA</span> <span class="pre">Análisis</span> <span class="pre">exploratorio</span> <span class="pre">de</span> <span class="pre">datos</span></code></strong></p>
<ul class="simple">
<li><p>El <code class="docutils literal notranslate"><span class="pre">análisis</span> <span class="pre">exploratorio</span> <span class="pre">de</span> <span class="pre">datos</span></code> se refiere al proceso crucial de realizar investigaciones iniciales sobre los datos para <code class="docutils literal notranslate"><span class="pre">descubrir</span> <span class="pre">patrones</span> <span class="pre">y</span> <span class="pre">comprobar</span> <span class="pre">supuestos</span></code> con la ayuda de <code class="docutils literal notranslate"><span class="pre">estadísticas</span> <span class="pre">resumidas</span> <span class="pre">y</span> <span class="pre">representaciones</span> <span class="pre">gráficas</span></code>.</p>
<ul>
<li><p>El <code class="docutils literal notranslate"><span class="pre">EDA</span></code> puede utilizarse para buscar <code class="docutils literal notranslate"><span class="pre">valores</span> <span class="pre">atípicos,</span> <span class="pre">patrones</span> <span class="pre">y</span> <span class="pre">tendencias</span> <span class="pre">en</span> <span class="pre">los</span> <span class="pre">datos</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">EDA</span></code> ayuda a encontrar <code class="docutils literal notranslate"><span class="pre">patrones</span> <span class="pre">significativos</span> <span class="pre">en</span> <span class="pre">los</span> <span class="pre">datos</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">EDA</span></code> proporciona una <code class="docutils literal notranslate"><span class="pre">visión</span> <span class="pre">en</span> <span class="pre">profundidad</span> <span class="pre">de</span> <span class="pre">los</span> <span class="pre">conjuntos</span> <span class="pre">de</span> <span class="pre">datos</span></code> para resolver nuestros problemas de negocio.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">EDA</span></code> proporciona una pista para <code class="docutils literal notranslate"><span class="pre">imputar</span> <span class="pre">los</span> <span class="pre">valores</span> <span class="pre">que</span> <span class="pre">faltan</span> <span class="pre">en</span> <span class="pre">el</span> <span class="pre">conjunto</span> <span class="pre">de</span> <span class="pre">datos</span></code>.</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p><strong><code class="docutils literal notranslate"><span class="pre">Resumen</span> <span class="pre">estadístico</span></code></strong></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;chas&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;chas&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">object</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span><span class="o">.</span><span class="n">T</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>count</th>
      <th>mean</th>
      <th>std</th>
      <th>min</th>
      <th>25%</th>
      <th>50%</th>
      <th>75%</th>
      <th>max</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>crim</th>
      <td>506.0</td>
      <td>3.613524</td>
      <td>8.601545</td>
      <td>0.00632</td>
      <td>0.082045</td>
      <td>0.25651</td>
      <td>3.677083</td>
      <td>88.9762</td>
    </tr>
    <tr>
      <th>zn</th>
      <td>506.0</td>
      <td>11.363636</td>
      <td>23.322453</td>
      <td>0.00000</td>
      <td>0.000000</td>
      <td>0.00000</td>
      <td>12.500000</td>
      <td>100.0000</td>
    </tr>
    <tr>
      <th>indus</th>
      <td>506.0</td>
      <td>11.136779</td>
      <td>6.860353</td>
      <td>0.46000</td>
      <td>5.190000</td>
      <td>9.69000</td>
      <td>18.100000</td>
      <td>27.7400</td>
    </tr>
    <tr>
      <th>nox</th>
      <td>506.0</td>
      <td>0.554695</td>
      <td>0.115878</td>
      <td>0.38500</td>
      <td>0.449000</td>
      <td>0.53800</td>
      <td>0.624000</td>
      <td>0.8710</td>
    </tr>
    <tr>
      <th>rm</th>
      <td>506.0</td>
      <td>6.284634</td>
      <td>0.702617</td>
      <td>3.56100</td>
      <td>5.885500</td>
      <td>6.20850</td>
      <td>6.623500</td>
      <td>8.7800</td>
    </tr>
    <tr>
      <th>age</th>
      <td>506.0</td>
      <td>68.574901</td>
      <td>28.148861</td>
      <td>2.90000</td>
      <td>45.025000</td>
      <td>77.50000</td>
      <td>94.075000</td>
      <td>100.0000</td>
    </tr>
    <tr>
      <th>dis</th>
      <td>506.0</td>
      <td>3.795043</td>
      <td>2.105710</td>
      <td>1.12960</td>
      <td>2.100175</td>
      <td>3.20745</td>
      <td>5.188425</td>
      <td>12.1265</td>
    </tr>
    <tr>
      <th>rad</th>
      <td>506.0</td>
      <td>9.549407</td>
      <td>8.707259</td>
      <td>1.00000</td>
      <td>4.000000</td>
      <td>5.00000</td>
      <td>24.000000</td>
      <td>24.0000</td>
    </tr>
    <tr>
      <th>tax</th>
      <td>506.0</td>
      <td>408.237154</td>
      <td>168.537116</td>
      <td>187.00000</td>
      <td>279.000000</td>
      <td>330.00000</td>
      <td>666.000000</td>
      <td>711.0000</td>
    </tr>
    <tr>
      <th>ptratio</th>
      <td>506.0</td>
      <td>18.455534</td>
      <td>2.164946</td>
      <td>12.60000</td>
      <td>17.400000</td>
      <td>19.05000</td>
      <td>20.200000</td>
      <td>22.0000</td>
    </tr>
    <tr>
      <th>black</th>
      <td>506.0</td>
      <td>356.674032</td>
      <td>91.294864</td>
      <td>0.32000</td>
      <td>375.377500</td>
      <td>391.44000</td>
      <td>396.225000</td>
      <td>396.9000</td>
    </tr>
    <tr>
      <th>lstat</th>
      <td>506.0</td>
      <td>12.653063</td>
      <td>7.141062</td>
      <td>1.73000</td>
      <td>6.950000</td>
      <td>11.36000</td>
      <td>16.955000</td>
      <td>37.9700</td>
    </tr>
    <tr>
      <th>medv</th>
      <td>506.0</td>
      <td>22.532806</td>
      <td>9.197104</td>
      <td>5.00000</td>
      <td>17.025000</td>
      <td>21.20000</td>
      <td>25.000000</td>
      <td>50.0000</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cat_cols</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">select_dtypes</span><span class="p">(</span><span class="n">include</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;object&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">columns</span>
<span class="n">num_cols</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">select_dtypes</span><span class="p">(</span><span class="n">include</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">number</span><span class="p">)</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Categorical Variables:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">cat_cols</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Numerical Variables:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">num_cols</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Categorical Variables:
Index([&#39;chas&#39;], dtype=&#39;object&#39;)
Numerical Variables:
[&#39;crim&#39;, &#39;zn&#39;, &#39;indus&#39;, &#39;nox&#39;, &#39;rm&#39;, &#39;age&#39;, &#39;dis&#39;, &#39;rad&#39;, &#39;tax&#39;, &#39;ptratio&#39;, &#39;black&#39;, &#39;lstat&#39;, &#39;medv&#39;]
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p><strong><code class="docutils literal notranslate"><span class="pre">Análisis</span> <span class="pre">univariado</span></code></strong></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">kurtosis</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p><strong><code class="docutils literal notranslate"><span class="pre">Asimetría</span></code></strong></p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">skew</span> <span class="pre">=</span> <span class="pre">0</span></code>: Distribución <code class="docutils literal notranslate"><span class="pre">simétrica</span></code> (valores aceptables <code class="docutils literal notranslate"><span class="pre">skew</span></code><span class="math notranslate nohighlight">\(\in(-1, 1)\)</span>).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">skew</span> <span class="pre">&gt;</span> <span class="pre">0</span></code>: Mayor peso en la cola izquierda de la distribución (<code class="docutils literal notranslate"><span class="pre">sesgo</span> <span class="pre">positivo</span></code>).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">skew</span> <span class="pre">&lt;</span> <span class="pre">0</span></code>: Mayor peso en la cola derecha de la distribución (<code class="docutils literal notranslate"><span class="pre">sesgo</span> <span class="pre">negativo</span></code>).</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p><strong><code class="docutils literal notranslate"><span class="pre">Kurtosis</span></code></strong>: Determina si una distribución tiene <code class="docutils literal notranslate"><span class="pre">colas</span> <span class="pre">gruesas</span> <span class="pre">con</span> <span class="pre">respecto</span> <span class="pre">a</span> <span class="pre">la</span> <span class="pre">distribución</span> <span class="pre">normal</span></code>. Proporciona información sobre la <code class="docutils literal notranslate"><span class="pre">forma</span> <span class="pre">de</span> <span class="pre">una</span> <span class="pre">distribución</span> <span class="pre">de</span> <span class="pre">frecuencias</span></code>.</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">kurtosis=3</span></code>: se denomina <code class="docutils literal notranslate"><span class="pre">mesocúrtica</span></code> (distribución normal).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">kurtosis&lt;3</span></code>: se denomina <code class="docutils literal notranslate"><span class="pre">platicúrtica</span> <span class="pre">(distribución</span> <span class="pre">con</span> <span class="pre">colas</span> <span class="pre">menos</span> <span class="pre">gruesas</span> <span class="pre">que</span> <span class="pre">la</span> <span class="pre">normal)</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">kurtosis&gt;3</span></code>: se denomina <code class="docutils literal notranslate"><span class="pre">leptocúrtica</span> <span class="pre">(distribución</span> <span class="pre">con</span> <span class="pre">colas</span> <span class="pre">más</span> <span class="pre">gruesas</span> <span class="pre">que</span> <span class="pre">la</span> <span class="pre">normal)</span></code> y significa que trata de <code class="docutils literal notranslate"><span class="pre">producir</span> <span class="pre">más</span> <span class="pre">valores</span> <span class="pre">atípicos</span> <span class="pre">que</span> <span class="pre">la</span> <span class="pre">distribución</span> <span class="pre">normal</span></code>.</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p><strong><code class="docutils literal notranslate"><span class="pre">Variables</span> <span class="pre">numéricas</span></code></strong></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">font_scale</span><span class="o">=</span><span class="mf">1.4</span><span class="p">)</span>
<span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">num_cols</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Column: &#39;</span><span class="p">,</span> <span class="n">col</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Skew:&#39;</span><span class="p">,</span> <span class="nb">round</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">skew</span><span class="p">(),</span> <span class="mi">2</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Kurtosis: &#39;</span><span class="p">,</span> <span class="nb">round</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">kurtosis</span><span class="p">(),</span> <span class="mi">2</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">14</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">data</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">grid</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">data</span><span class="p">[</span><span class="n">col</span><span class="p">])</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Column:  crim
Skew: 5.22
Kurtosis:  37.13
</pre></div>
</div>
<img alt="_images/f57c99ee4a80524dedb3a827eb0532b4e366dfd68a2be5c5214770fc9b90312b.png" src="_images/f57c99ee4a80524dedb3a827eb0532b4e366dfd68a2be5c5214770fc9b90312b.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Column:  zn
Skew: 2.23
Kurtosis:  4.03
</pre></div>
</div>
<img alt="_images/9499ec2afb11f86a40dc65542451823c436abc067741adef4b2a244c197aedfa.png" src="_images/9499ec2afb11f86a40dc65542451823c436abc067741adef4b2a244c197aedfa.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Column:  indus
Skew: 0.3
Kurtosis:  -1.23
</pre></div>
</div>
<img alt="_images/7ca7c15defa0649036a8c0ff4d1ab74c702f3bbaafbb23a32c337b99b8b10b26.png" src="_images/7ca7c15defa0649036a8c0ff4d1ab74c702f3bbaafbb23a32c337b99b8b10b26.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Column:  nox
Skew: 0.73
Kurtosis:  -0.06
</pre></div>
</div>
<img alt="_images/0da124f08b23a3c2e6cc04c40fdd442269c13f7c94e712a4e0100c35f64b7402.png" src="_images/0da124f08b23a3c2e6cc04c40fdd442269c13f7c94e712a4e0100c35f64b7402.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Column:  rm
Skew: 0.4
Kurtosis:  1.89
</pre></div>
</div>
<img alt="_images/812d13e56f6f6a0f903e1c5d6b6a6d7145963961d9319d2795d0795def9d7fec.png" src="_images/812d13e56f6f6a0f903e1c5d6b6a6d7145963961d9319d2795d0795def9d7fec.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Column:  age
Skew: -0.6
Kurtosis:  -0.97
</pre></div>
</div>
<img alt="_images/d55ff077079f55879b161dc9abbc9ea9f6d260fe6608bcd51c97015289983075.png" src="_images/d55ff077079f55879b161dc9abbc9ea9f6d260fe6608bcd51c97015289983075.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Column:  dis
Skew: 1.01
Kurtosis:  0.49
</pre></div>
</div>
<img alt="_images/2a6d245d4d3bddf63e52a95342cd20be35c2e32afb8ed1679472a73e069c3f10.png" src="_images/2a6d245d4d3bddf63e52a95342cd20be35c2e32afb8ed1679472a73e069c3f10.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Column:  rad
Skew: 1.0
Kurtosis:  -0.87
</pre></div>
</div>
<img alt="_images/731121365781bb51f0cf6812901e58acfe8907eb041e7e28241858ceba84dcef.png" src="_images/731121365781bb51f0cf6812901e58acfe8907eb041e7e28241858ceba84dcef.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Column:  tax
Skew: 0.67
Kurtosis:  -1.14
</pre></div>
</div>
<img alt="_images/f41d5814a3421c3843565a9e4069e7b43cddddcca5cb9af6ba80edf5aef9d0e1.png" src="_images/f41d5814a3421c3843565a9e4069e7b43cddddcca5cb9af6ba80edf5aef9d0e1.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Column:  ptratio
Skew: -0.8
Kurtosis:  -0.29
</pre></div>
</div>
<img alt="_images/0e6d3a644c0956dfd7b22c1a697cffa924e42bfab94628a918b4208f2f1faa12.png" src="_images/0e6d3a644c0956dfd7b22c1a697cffa924e42bfab94628a918b4208f2f1faa12.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Column:  black
Skew: -2.89
Kurtosis:  7.23
</pre></div>
</div>
<img alt="_images/afee426106bd44c84670f53600b445dc94d322a8302f11895e73e7637912d4b5.png" src="_images/afee426106bd44c84670f53600b445dc94d322a8302f11895e73e7637912d4b5.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Column:  lstat
Skew: 0.91
Kurtosis:  0.49
</pre></div>
</div>
<img alt="_images/3218b467d2832e6ba1cec1a843d55b036b773f2deda325d436d280d7c4a64f88.png" src="_images/3218b467d2832e6ba1cec1a843d55b036b773f2deda325d436d280d7c4a64f88.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Column:  medv
Skew: 1.11
Kurtosis:  1.5
</pre></div>
</div>
<img alt="_images/a8beaafdc8ed5afab0b5460dc07cfbba478b95a3b2c841cd7490523800a95719.png" src="_images/a8beaafdc8ed5afab0b5460dc07cfbba478b95a3b2c841cd7490523800a95719.png" />
</div>
</div>
<ul class="simple">
<li><p><strong><code class="docutils literal notranslate"><span class="pre">Variables</span> <span class="pre">categóricas</span></code></strong>: Usando <code class="docutils literal notranslate"><span class="pre">diagramas</span> <span class="pre">de</span> <span class="pre">barras</span></code> representamos la variable dummy del <code class="docutils literal notranslate"><span class="pre">Río</span> <span class="pre">Charles</span> <span class="pre">(=</span> <span class="pre">1</span> <span class="pre">si</span> <span class="pre">el</span> <span class="pre">tramo</span> <span class="pre">limita</span> <span class="pre">con</span> <span class="pre">el</span> <span class="pre">río;</span> <span class="pre">0</span> <span class="pre">en</span> <span class="pre">caso</span> <span class="pre">contrario)</span></code></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">matplotlib</span><span class="o">.</span><span class="n">rc_file_defaults</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sns</span><span class="o">.</span><span class="n">countplot</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="s1">&#39;chas&#39;</span><span class="p">,</span> <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="n">order</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;chas&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span><span class="o">.</span><span class="n">index</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/931c70e626e8ec7040cbdc7dbd99699da391300e56057543797443924ba3ba8a.png" src="_images/931c70e626e8ec7040cbdc7dbd99699da391300e56057543797443924ba3ba8a.png" />
</div>
</div>
<ul class="simple">
<li><p><strong><code class="docutils literal notranslate"><span class="pre">Transformación</span> <span class="pre">de</span> <span class="pre">datos:</span></code></strong> Las variables por ejemplo <code class="docutils literal notranslate"><span class="pre">crime</span></code> y <code class="docutils literal notranslate"><span class="pre">black</span></code>, por ejemplo, están muy sesgadas y en una escala mayor. Hagamos una <code class="docutils literal notranslate"><span class="pre">transformación</span> <span class="pre">logarítmica</span></code>. La transformación logarítmica <code class="docutils literal notranslate"><span class="pre">puede</span> <span class="pre">ayudar</span> <span class="pre">en</span> <span class="pre">la</span> <span class="pre">normalización</span></code>, por lo que esta variable puede <code class="docutils literal notranslate"><span class="pre">mantener</span> <span class="pre">la</span> <span class="pre">escala</span> <span class="pre">estándar</span> <span class="pre">con</span> <span class="pre">otras</span> <span class="pre">variables</span></code></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">log_transform</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="n">col</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">colname</span> <span class="ow">in</span> <span class="n">col</span><span class="p">:</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">colname</span><span class="p">]</span> <span class="o">==</span> <span class="mf">1.0</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">():</span>
            <span class="n">data</span><span class="p">[</span><span class="n">colname</span> <span class="o">+</span> <span class="s1">&#39;_log&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">colname</span><span class="p">]</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">data</span><span class="p">[</span><span class="n">colname</span> <span class="o">+</span> <span class="s1">&#39;_log&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">colname</span><span class="p">])</span>
    <span class="n">data</span><span class="o">.</span><span class="n">info</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">log_transform</span><span class="p">(</span><span class="n">data</span><span class="p">,[</span><span class="s1">&#39;crim&#39;</span><span class="p">,</span><span class="s1">&#39;black&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
Index: 506 entries, 1 to 506
Data columns (total 16 columns):
 #   Column     Non-Null Count  Dtype  
---  ------     --------------  -----  
 0   crim       506 non-null    float64
 1   zn         506 non-null    float64
 2   indus      506 non-null    float64
 3   chas       506 non-null    object 
 4   nox        506 non-null    float64
 5   rm         506 non-null    float64
 6   age        506 non-null    float64
 7   dis        506 non-null    float64
 8   rad        506 non-null    int64  
 9   tax        506 non-null    int64  
 10  ptratio    506 non-null    float64
 11  black      506 non-null    float64
 12  lstat      506 non-null    float64
 13  medv       506 non-null    float64
 14  crim_log   506 non-null    float64
 15  black_log  506 non-null    float64
dtypes: float64(13), int64(2), object(1)
memory usage: 67.2+ KB
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sns</span><span class="o">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;crim_log&quot;</span><span class="p">],</span> <span class="n">axlabel</span><span class="o">=</span><span class="s2">&quot;crim_log&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/83ac1b8f312931b484bdcb074af6e3e085583d2bcb7dc7d8e3f1946a014b8059.png" src="_images/83ac1b8f312931b484bdcb074af6e3e085583d2bcb7dc7d8e3f1946a014b8059.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sns</span><span class="o">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;black_log&quot;</span><span class="p">],</span> <span class="n">axlabel</span><span class="o">=</span><span class="s2">&quot;black_log&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/ce3af9636303f02522d389721c5c21a35eb22cf3540b8720cb55c478086747a8.png" src="_images/ce3af9636303f02522d389721c5c21a35eb22cf3540b8720cb55c478086747a8.png" />
</div>
</div>
<ul class="simple">
<li><p><strong><code class="docutils literal notranslate"><span class="pre">Análisis</span> <span class="pre">bivariado</span></code></strong>: Pasemos ahora al análisis bivariado. El <code class="docutils literal notranslate"><span class="pre">análisis</span> <span class="pre">bivariado</span> <span class="pre">ayuda</span> <span class="pre">a</span> <span class="pre">comprender</span> <span class="pre">cómo</span> <span class="pre">se</span> <span class="pre">relacionan</span> <span class="pre">las</span> <span class="pre">variables</span> <span class="pre">entre</span> <span class="pre">sí</span></code> y la <code class="docutils literal notranslate"><span class="pre">relación</span> <span class="pre">entre</span> <span class="pre">las</span> <span class="pre">variables</span> <span class="pre">dependientes</span> <span class="pre">e</span> <span class="pre">independientes</span></code> presentes en el conjunto de datos. Puede utilizar el siguiente comando para <code class="docutils literal notranslate"><span class="pre">visualizar</span> <span class="pre">todos</span> <span class="pre">los</span> <span class="pre">scatter</span> <span class="pre">plots,</span> <span class="pre">para</span> <span class="pre">las</span> <span class="pre">posibles</span> <span class="pre">relaciones</span></code>:</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">sns</span><span class="o">.</span><span class="n">pairplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s1">&#39;chas&#39;</span><span class="p">,</span> <span class="s1">&#39;black_log&#39;</span><span class="p">,</span> <span class="s1">&#39;crim_log&#39;</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">));</span>
</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">scatter_regplot</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">strx</span><span class="p">,</span> <span class="n">stry</span><span class="p">):</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">font_scale</span><span class="o">=</span><span class="mf">1.4</span><span class="p">)</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">14</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span> <span class="n">sharey</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">strx</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">stry</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">regplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">strx</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">stry</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]);</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;Relación entre </span><span class="si">%s</span><span class="s1"> y medv&#39;</span><span class="o">%</span><span class="k">col</span>)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">num_cols</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="s1">&#39;medv&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">num_cols</span><span class="p">:</span>
    <span class="n">scatter_regplot</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">col</span><span class="p">,</span> <span class="s1">&#39;medv&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/07c71a28aa1d5c34eefa485334b47e56e374d60ab819ae912bb7ce822cb35677.png" src="_images/07c71a28aa1d5c34eefa485334b47e56e374d60ab819ae912bb7ce822cb35677.png" />
<img alt="_images/71f0989724c53c5672bf26c2f9b119e4ba54b2d4ba9fb9f87165ae4329f69594.png" src="_images/71f0989724c53c5672bf26c2f9b119e4ba54b2d4ba9fb9f87165ae4329f69594.png" />
<img alt="_images/eb874e57eede70be76a7ea764fc657ff30793dd06cb5c8be71ab7a6dc92f182f.png" src="_images/eb874e57eede70be76a7ea764fc657ff30793dd06cb5c8be71ab7a6dc92f182f.png" />
<img alt="_images/195349ed1a4e1e7a2c5a4d1733af34016808ef0693e7e5bf1157b7f912635f4d.png" src="_images/195349ed1a4e1e7a2c5a4d1733af34016808ef0693e7e5bf1157b7f912635f4d.png" />
<img alt="_images/b815c9414d48ed24edc8bc6e857cac35ffafd2b924f9354469305a8a75e561d5.png" src="_images/b815c9414d48ed24edc8bc6e857cac35ffafd2b924f9354469305a8a75e561d5.png" />
<img alt="_images/425eaa267037814b9df431a3b1c3b17019e2e9081f0ade58d3b730eab52d096d.png" src="_images/425eaa267037814b9df431a3b1c3b17019e2e9081f0ade58d3b730eab52d096d.png" />
<img alt="_images/0cddea2a72866e9ad2d60e5c6f5365b15186bb73954c5aa7c0d901acf66958ef.png" src="_images/0cddea2a72866e9ad2d60e5c6f5365b15186bb73954c5aa7c0d901acf66958ef.png" />
<img alt="_images/519e4a4b01159b37b98856415209320d9224d866d1aded6f743ea423cc3b5572.png" src="_images/519e4a4b01159b37b98856415209320d9224d866d1aded6f743ea423cc3b5572.png" />
<img alt="_images/b9fcc95a3b08cf78e9192775e33b59299c0b98220a723b42759018fabb1abb1b.png" src="_images/b9fcc95a3b08cf78e9192775e33b59299c0b98220a723b42759018fabb1abb1b.png" />
<img alt="_images/7c92b370bff43cb4b21d3c9f1b00a3e86a4f5ca1361294c9e194b046dac89d58.png" src="_images/7c92b370bff43cb4b21d3c9f1b00a3e86a4f5ca1361294c9e194b046dac89d58.png" />
<img alt="_images/6d8e6e2ec2244062962176c81b26a9964cffbdeb676cdd84c96f72ac5a19ea7a.png" src="_images/6d8e6e2ec2244062962176c81b26a9964cffbdeb676cdd84c96f72ac5a19ea7a.png" />
<img alt="_images/f5fda751b0e2ff71f793ce0764463007bd4c04a1098d3cc653758c8d38ac2760.png" src="_images/f5fda751b0e2ff71f793ce0764463007bd4c04a1098d3cc653758c8d38ac2760.png" />
</div>
</div>
<ul class="simple">
<li><p>Un <code class="docutils literal notranslate"><span class="pre">mapa</span> <span class="pre">de</span> <span class="pre">calor</span></code> se utiliza ampliamente para este tipo de análisis. El mapa de calor <code class="docutils literal notranslate"><span class="pre">muestra</span> <span class="pre">la</span> <span class="pre">correlación</span> <span class="pre">entre</span> <span class="pre">las</span> <span class="pre">variables,</span> <span class="pre">ya</span> <span class="pre">sea</span> <span class="pre">positiva</span> <span class="pre">o</span> <span class="pre">negativa</span></code>.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">matplotlib</span><span class="o">.</span><span class="n">rc_file_defaults</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">font_scale</span><span class="o">=</span><span class="mf">1.2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">7</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s1">&#39;chas&#39;</span><span class="p">,</span> <span class="s1">&#39;black_log&#39;</span><span class="p">,</span> <span class="s1">&#39;crim_log&#39;</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">corr</span><span class="p">(),</span> <span class="n">annot</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">vmin</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">vmax</span> <span class="o">=</span> <span class="mi">1</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/aa5a722f974aa3e4c2fe2006930b18cb2be4c827a528987eb5d1db6c8bd332e8.png" src="_images/aa5a722f974aa3e4c2fe2006930b18cb2be4c827a528987eb5d1db6c8bd332e8.png" />
</div>
</div>
<ul class="simple">
<li><p>A manera de ejemplo, <code class="docutils literal notranslate"><span class="pre">utilizaremos</span> <span class="pre">el</span> <span class="pre">dataset</span> <span class="pre">mglearn.datasets.load_extended_boston()</span> <span class="pre">de</span> <span class="pre">las</span> <span class="pre">104</span> <span class="pre">características</span></code> resultantes de las 13 características originales junto con las <code class="docutils literal notranslate"><span class="pre">91</span> <span class="pre">combinaciones</span> <span class="pre">posibles</span> <span class="pre">de</span> <span class="pre">dos</span> <span class="pre">características</span> <span class="pre">dentro</span> <span class="pre">de</span> <span class="pre">esas</span> <span class="pre">13</span></code>.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">mglearn</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">load_extended_boston</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">lr</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">lr</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Al comparar los <code class="docutils literal notranslate"><span class="pre">score</span></code> de los conjuntos de entrenamiento y de prueba, comprobamos que <code class="docutils literal notranslate"><span class="pre">predecimos</span> <span class="pre">con</span> <span class="pre">mucha</span> <span class="pre">precisión</span> <span class="pre">en</span> <span class="pre">el</span> <span class="pre">conjunto</span> <span class="pre">de</span> <span class="pre">entrenamiento,</span> <span class="pre">pero</span> <span class="pre">el</span></code> <span class="math notranslate nohighlight">\(R^2\)</span> <code class="docutils literal notranslate"><span class="pre">en</span> <span class="pre">el</span> <span class="pre">conjunto</span> <span class="pre">de</span> <span class="pre">prueba</span> <span class="pre">es</span> <span class="pre">mucho</span> <span class="pre">peor</span></code></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training set score: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">lr</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test set score: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">lr</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training set score: 0.95
Test set score: 0.61
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Esta <code class="docutils literal notranslate"><span class="pre">discrepancia</span> <span class="pre">entre</span> <span class="pre">el</span> <span class="pre">rendimiento</span> <span class="pre">en</span> <span class="pre">el</span> <span class="pre">conjunto</span> <span class="pre">de</span> <span class="pre">entrenamiento</span> <span class="pre">y</span> <span class="pre">el</span> <span class="pre">conjunto</span> <span class="pre">de</span> <span class="pre">prueba</span></code> es un claro signo de <code class="docutils literal notranslate"><span class="pre">overfitting</span></code>, y por lo tanto, debemos tratar de <code class="docutils literal notranslate"><span class="pre">encontrar</span> <span class="pre">un</span> <span class="pre">modelo</span> <span class="pre">que</span> <span class="pre">nos</span> <span class="pre">permita</span> <span class="pre">controlar</span> <span class="pre">la</span> <span class="pre">complejidad</span></code>. Usualmente, en este tipo de casos utilizamos <code class="docutils literal notranslate"><span class="pre">técnicas</span> <span class="pre">de</span> <span class="pre">regularización</span></code>. Una de las alternativas más utilizadas a la regresión lineal estándar es la <code class="docutils literal notranslate"><span class="pre">regresión</span> <span class="pre">ridge</span></code>, que estudiaremos a continuación.</p></li>
</ul>
</section>
</section>
<section id="regresion-ridge">
<h2>Regresión ridge<a class="headerlink" href="#regresion-ridge" title="Permalink to this heading">#</a></h2>
<section id="analisis">
<h3>Análisis<a class="headerlink" href="#analisis" title="Permalink to this heading">#</a></h3>
<div class="admonition-observacion admonition">
<p class="admonition-title">Observación</p>
<ul class="simple">
<li><p>En la regresión ridge, los coeficientes <span class="math notranslate nohighlight">\(\boldsymbol{\hat{\beta}}\)</span> se eligen no sólo para que predigan bien en los datos de entrenamiento, sino que también, para que se ajusten a una <code class="docutils literal notranslate"><span class="pre">restricción</span></code> adicional. <code class="docutils literal notranslate"><span class="pre">La</span> <span class="pre">regresión</span> <span class="pre">Ridge</span> <span class="pre">regulariza</span> <span class="pre">la</span> <span class="pre">regresión</span> <span class="pre">lineal</span> <span class="pre">imponiendo</span> <span class="pre">una</span> <span class="pre">penalización</span> <span class="pre">al</span> <span class="pre">tamaño</span> <span class="pre">de</span> <span class="pre">los</span> <span class="pre">coeficientes</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">La</span> <span class="pre">magnitud</span> <span class="pre">de</span> <span class="pre">los</span> <span class="pre">coeficientes</span> <span class="pre">se</span> <span class="pre">considera</span> <span class="pre">lo</span> <span class="pre">más</span> <span class="pre">pequeña</span> <span class="pre">posible</span></code>; en otras palabras, todas las entradas de <span class="math notranslate nohighlight">\(\boldsymbol{\hat{\beta}}\)</span> deben ser cercanas a cero. Intuitivamente, esto significa que <code class="docutils literal notranslate"><span class="pre">cada</span> <span class="pre">característica</span> <span class="pre">debe</span> <span class="pre">tener</span> <span class="pre">el</span> <span class="pre">menor</span> <span class="pre">efecto</span> <span class="pre">posible</span> <span class="pre">sobre</span> <span class="pre">el</span> <span class="pre">resultado</span></code> (lo que se traduce en tener una pendiente pequeña), <code class="docutils literal notranslate"><span class="pre">sin</span> <span class="pre">dejar</span> <span class="pre">de</span> <span class="pre">predecir</span> <span class="pre">bien</span></code>. Esta restricción es un ejemplo de lo que se llama <code class="docutils literal notranslate"><span class="pre">regularización</span></code>.</p></li>
<li><p>La <code class="docutils literal notranslate"><span class="pre">regularización</span></code> consiste en <code class="docutils literal notranslate"><span class="pre">restringir</span> <span class="pre">explícitamente</span> <span class="pre">un</span> <span class="pre">modelo</span> <span class="pre">para</span> <span class="pre">evitar</span> <span class="pre">el</span> <span class="pre">overfitting</span></code>. El tipo particular utilizado por la <code class="docutils literal notranslate"><span class="pre">regresión</span> <span class="pre">ridge</span></code> se conoce como <code class="docutils literal notranslate"><span class="pre">regularización</span></code> <span class="math notranslate nohighlight">\(L^2\)</span>.</p></li>
</ul>
</div>
<p><strong><code class="docutils literal notranslate"><span class="pre">Formulación</span></code></strong></p>
<ul>
<li><p>Consideremos el <code class="docutils literal notranslate"><span class="pre">modelo</span> <span class="pre">de</span> <span class="pre">regresión</span> <span class="pre">lineal</span></code></p>
<div class="math notranslate nohighlight" id="equation-linear-model-comp">
<span class="eqno">(7)<a class="headerlink" href="#equation-linear-model-comp" title="Permalink to this equation">#</a></span>\[
    y_{i}=\beta_{0}+\beta_{1}\cdot x_{i1}+\beta_{2}\cdot x_{i2}+\cdots+\beta_{p}\cdot x_{ip}+\varepsilon_{i},~i = 1,2,\dots, n,
    \]</div>
<p>basado en los datos observados <span class="math notranslate nohighlight">\(\{(y_{i}, x_{i1}, x_{i2},\dots, x_{ip}):~i=1,2,\dots,n\}\)</span> para la variable respuesta <span class="math notranslate nohighlight">\(y\)</span> y <span class="math notranslate nohighlight">\(p\)</span> variables predictoras <span class="math notranslate nohighlight">\(\boldsymbol{x}=(x_{1}, x_{2},\dots,x_{p})\)</span>. La <code class="docutils literal notranslate"><span class="pre">regresión</span> <span class="pre">ridge</span></code> propuesta por <code class="docutils literal notranslate"><span class="pre">Hoerl</span> <span class="pre">y</span> <span class="pre">Kennard</span> <span class="pre">(1970)</span></code> es un método para <code class="docutils literal notranslate"><span class="pre">evitar</span> <span class="pre">la</span> <span class="pre">inestabilidad</span> <span class="pre">de</span> <span class="pre">las</span> <span class="pre">estimaciones</span> <span class="pre">en</span> <span class="pre">los</span> <span class="pre">modelos</span> <span class="pre">de</span> <span class="pre">regresión</span> <span class="pre">lineal,</span> <span class="pre">causada</span> <span class="pre">por</span> <span class="pre">la</span> <span class="pre">multicolinealidad</span></code>, esto es, correlación alta entre más de dos variables predictoras.</p>
</li>
<li><p>Este método es una regularización, en la que la <code class="docutils literal notranslate"><span class="pre">suma</span> <span class="pre">de</span> <span class="pre">cuadrados</span> <span class="pre">de</span> <span class="pre">los</span> <span class="pre">coeficientes</span> <span class="pre">de</span> <span class="pre">regresión,</span> <span class="pre">excluyendo</span> <span class="pre">el</span> <span class="pre">intercepto,</span> <span class="pre">es</span> <span class="pre">el</span> <span class="pre">término</span> <span class="pre">de</span> <span class="pre">penalización</span></code>, y las estimaciones de coeficientes de regresión se obtienen de la siguiente manera.</p></li>
</ul>
<div class="tip dropdown admonition">
<p class="admonition-title">Problema de multicolinealidad</p>
<ul class="simple">
<li><p>Cuando las variables predictoras están correlacionadas, esto indica que los <code class="docutils literal notranslate"><span class="pre">cambios</span> <span class="pre">en</span> <span class="pre">una</span> <span class="pre">variable</span> <span class="pre">están</span> <span class="pre">asociados</span> <span class="pre">a</span> <span class="pre">cambios</span> <span class="pre">en</span> <span class="pre">otra</span></code>. Cuanto más fuerte sea la correlación, más difícil será cambiar una variable sin cambiar otra.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Resulta</span> <span class="pre">difícil</span> <span class="pre">para</span> <span class="pre">el</span> <span class="pre">modelo</span> <span class="pre">estimar</span> <span class="pre">la</span> <span class="pre">relación</span> <span class="pre">entre</span> <span class="pre">cada</span> <span class="pre">variable</span> <span class="pre">predictora</span> <span class="pre">y</span> <span class="pre">la</span> <span class="pre">variable</span> <span class="pre">respuesta</span> <span class="pre">de</span> <span class="pre">forma</span> <span class="pre">independiente</span></code> porque las variables predictoras tienden a cambiar al unísono.</p></li>
</ul>
</div>
<p>En primer lugar, obtenemos la <code class="docutils literal notranslate"><span class="pre">media</span></code> <span class="math notranslate nohighlight">\(\bar x_{j}=n^{-1}\sum_{i=1}^{n}x_{ij}\)</span> y la <code class="docutils literal notranslate"><span class="pre">varianza</span></code> <span class="math notranslate nohighlight">\(s_{j}^2=n^{-1}\sum_{i=1}^{n}(x_{ij}-\bar x_{j})^{2}\)</span>, <span class="math notranslate nohighlight">\(j=1,2,\dots,p\)</span> de los datos para las variables predictoras y <code class="docutils literal notranslate"><span class="pre">estandaricemos</span></code> los datos de la siguiente manera</p>
<div class="math notranslate nohighlight" id="equation-estand-ridge-reg">
<span class="eqno">(8)<a class="headerlink" href="#equation-estand-ridge-reg" title="Permalink to this equation">#</a></span>\[
z_{ij}=\frac{x_{ij}-\bar x_{j}}{s_{j}},~i=1,2,\dots,n,~j=1,2,\dots,p.
\]</div>
<div class="dropdown admonition">
<p class="admonition-title">¿Por qué estandarizar? </p>
<ul class="simple">
<li><p>La <code class="docutils literal notranslate"><span class="pre">regresión</span> <span class="pre">ridge</span></code> regulariza la <code class="docutils literal notranslate"><span class="pre">regresión</span> <span class="pre">lineal</span></code> imponiendo una <code class="docutils literal notranslate"><span class="pre">penalización</span> <span class="pre">al</span> <span class="pre">tamaño</span> <span class="pre">de</span> <span class="pre">los</span> <span class="pre">coeficientes</span></code>. Así, los coeficientes se contraen hacia cero y entre sí. Cuando esto ocurre, si las <code class="docutils literal notranslate"><span class="pre">variables</span> <span class="pre">independientes</span> <span class="pre">no</span> <span class="pre">tienen</span> <span class="pre">la</span> <span class="pre">misma</span> <span class="pre">escala,</span> <span class="pre">la</span> <span class="pre">contracción</span> <span class="pre">no</span> <span class="pre">es</span> <span class="pre">justa</span></code>.</p></li>
<li><p>Dos variables independientes con <code class="docutils literal notranslate"><span class="pre">diferentes</span> <span class="pre">escalas</span> <span class="pre">tendrán</span> <span class="pre">diferentes</span> <span class="pre">contribuciones</span> <span class="pre">a</span> <span class="pre">los</span> <span class="pre">términos</span> <span class="pre">penalizados</span></code>, porque el término penalizado es una suma de cuadrados de todos los coeficientes. Para evitar este tipo de problemas, muy a menudo, las <code class="docutils literal notranslate"><span class="pre">variables</span> <span class="pre">independientes</span> <span class="pre">se</span> <span class="pre">centran</span> <span class="pre">y</span> <span class="pre">se</span> <span class="pre">escalan</span></code> para que tengan varianza unitaria.</p></li>
</ul>
</div>
<p>El modelo de <code class="docutils literal notranslate"><span class="pre">regresión</span> <span class="pre">lineal</span> <span class="pre">basado</span> <span class="pre">en</span> <span class="pre">los</span> <span class="pre">datos</span> <span class="pre">estandarizados</span></code> puede expresarse entonces como</p>
<div class="math notranslate nohighlight" id="equation-eq-reg-li-z">
<span class="eqno">(9)<a class="headerlink" href="#equation-eq-reg-li-z" title="Permalink to this equation">#</a></span>\[\begin{split}
\begin{align*}
y_{i} &amp;= \beta_{0} + \beta_{1}\bar x_{1} + \beta_{2}\bar x_{2} + \cdots + \beta_{p}\bar x_{p} + 
\beta_{1}^{\star}z_{i1} + \beta_{2}^{\star}z_{i2} + \cdots + \beta_{p}^{\star}z_{ip} + \varepsilon_{i}\\
&amp;=\beta_{0}^{\star} + \beta_{1}^{\star}z_{i1} + \beta_{2}^{\star}z_{i2} + \cdots + \beta_{p}^{\star}z_{ip} + \varepsilon_{i},~ i = 1,2,\dots,n,
\end{align*}
\end{split}\]</div>
<p>donde <span class="math notranslate nohighlight">\(\beta_{0}^{\star}=\beta_{0}+\beta_{1}\bar x_{1}+\beta_{2}\bar x_{2}+\cdots+\beta_{p}\bar x_{p}~\text{y}~\beta_{j}^{\star}=s_{j}\beta_{j}\)</span>. Por lo tanto, podemos expresar el <code class="docutils literal notranslate"><span class="pre">modelo</span> <span class="pre">de</span> <span class="pre">regresión</span> <span class="pre">lineal</span> <span class="pre">basados</span> <span class="pre">en</span> <span class="pre">los</span> <span class="pre">datos</span> <span class="pre">estandarizados</span></code> para la variable predictora como</p>
<div class="math notranslate nohighlight" id="equation-reg-ridge-model">
<span class="eqno">(10)<a class="headerlink" href="#equation-reg-ridge-model" title="Permalink to this equation">#</a></span>\[
\boldsymbol{y}=\beta_{0}^{\star}\boldsymbol{1}+Z\boldsymbol{\beta}_{s}+\boldsymbol{\varepsilon},
\]</div>
<p>en <code class="docutils literal notranslate"><span class="pre">forma</span> <span class="pre">matricial</span></code></p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{pmatrix}
y_{1}\\
y_{2}\\
\vdots\\
y_{i}\\
\vdots\\
y_{n}
\end{pmatrix}
=
\beta_{0}^{\star}
\begin{pmatrix}
1\\
1\\
\vdots\\
1\\
\vdots\\
1
\end{pmatrix}
+
\begin{pmatrix}
z_{11} &amp; z_{12} &amp; \cdots &amp; z_{1p}\\
z_{21} &amp; z_{22} &amp; \cdots &amp; z_{2p}\\
\vdots &amp; \vdots &amp; &amp; \vdots\\
z_{31} &amp; z_{32} &amp; \cdots &amp; z_{3p}\\
\vdots &amp; \vdots &amp; &amp; \vdots\\
z_{n1} &amp; z_{n2} &amp; \cdots &amp; z_{np}
\end{pmatrix}
\begin{pmatrix}
\beta_{0}\\[2mm]
\beta_{1}\\[2mm]
\beta_{2}\\
\vdots\\[2mm]
\beta_{p}
\end{pmatrix}
+
\begin{pmatrix}
\varepsilon_{1}\\
\varepsilon_{2}\\
\vdots\\
\varepsilon_{i}\\
\vdots\\
\varepsilon_{n}
\end{pmatrix}
\end{split}\]</div>
<p>donde <span class="math notranslate nohighlight">\(\boldsymbol{1}\)</span> es un vector <span class="math notranslate nohighlight">\(n\)</span>-dimensional de unos, <span class="math notranslate nohighlight">\(\boldsymbol{\beta}_{s}=(s_{1}\beta_{1}, s_{2}\beta_{2},\dots,s_{p}\beta_{p})^{T}\)</span>, y <span class="math notranslate nohighlight">\(Z\)</span> es una matriz de <span class="math notranslate nohighlight">\(n\times p\)</span> que contiene los datos estandarizados <span class="math notranslate nohighlight">\(z_{ij}=(x_{ij}-\bar x_{j})/s_{j},~ i=1,2,\dots,n; j=1,2,\dots,p\)</span> en su posición <span class="math notranslate nohighlight">\((i,j)\)</span>.</p>
<p>El estimador <code class="docutils literal notranslate"><span class="pre">ridge</span></code> para el vector de coeficientes esta dado entonces por <code class="docutils literal notranslate"><span class="pre">minimización</span></code> de:</p>
<div class="math notranslate nohighlight" id="equation-ridge-coeff-stand">
<span class="eqno">(11)<a class="headerlink" href="#equation-ridge-coeff-stand" title="Permalink to this equation">#</a></span>\[
S_{\lambda}(\beta_{0}^{\star}, \boldsymbol{\beta}_{s})=(\boldsymbol{y}-\beta_{0}^{\star}\boldsymbol{1}-Z\boldsymbol{\beta}_{s})^{T}(\boldsymbol{y}-\beta_{0}^{\star}\boldsymbol{1}-Z\boldsymbol{\beta}_{s})+\lambda\boldsymbol{\beta}_{s}^{T}\boldsymbol{\beta}_{s}
\]</div>
<p>donde el <code class="docutils literal notranslate"><span class="pre">termino</span> <span class="pre">de</span> <span class="pre">regularización</span></code> <span class="math notranslate nohighlight">\(L^2\)</span>: (<span class="math notranslate nohighlight">\(\lambda\boldsymbol{\beta}_{s}^{T}\boldsymbol{\beta}_{s}\)</span>) con <code class="docutils literal notranslate"><span class="pre">parámetro</span> <span class="pre">de</span> <span class="pre">regularización</span></code> <span class="math notranslate nohighlight">\(\lambda\)</span> ha sido agregado al <code class="docutils literal notranslate"><span class="pre">vector</span> <span class="pre">de</span> <span class="pre">coeficientes</span> <span class="pre">de</span> <span class="pre">regresión,</span> <span class="pre">excepto</span> <span class="pre">el</span> <span class="pre">intercepto</span></code>. Este término es conocido como <code class="docutils literal notranslate"><span class="pre">weight</span> <span class="pre">decay</span></code>. Veamos una simulación de la <code class="docutils literal notranslate"><span class="pre">regularización</span> <span class="pre">ridge</span></code> usando a la <a class="reference external" href="https://es.wikipedia.org/wiki/Matriz_de_Hilbert">matriz de Hilbert</a> como input y un <code class="docutils literal notranslate"><span class="pre">vector</span> <span class="pre">unitario</span></code>, como output.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">linear_model</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">11</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">)[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n_alphas</span> <span class="o">=</span> <span class="mi">200</span>
<span class="n">alphas</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_alphas</span><span class="p">)</span>

<span class="n">coefs</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">alphas</span><span class="p">:</span>
    <span class="n">ridge</span> <span class="o">=</span> <span class="n">linear_model</span><span class="o">.</span><span class="n">Ridge</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="n">a</span><span class="p">,</span> <span class="n">fit_intercept</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">ridge</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">coefs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ridge</span><span class="o">.</span><span class="n">coef_</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">alphas</span><span class="p">,</span> <span class="n">coefs</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xscale</span><span class="p">(</span><span class="s2">&quot;log&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="n">ax</span><span class="o">.</span><span class="n">get_xlim</span><span class="p">()[::</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;alpha&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;weights&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Ridge coefficients as a function of the regularization&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">&quot;tight&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/f50d6aed9c507611edfa6c4cf66752632889d8ada237dbf33c3b87747ad6ee21.png" src="_images/f50d6aed9c507611edfa6c4cf66752632889d8ada237dbf33c3b87747ad6ee21.png" />
</div>
</div>
<p>La Eq. <a class="reference internal" href="#equation-ridge-coeff-stand">(11)</a> puede <code class="docutils literal notranslate"><span class="pre">reescribirse</span></code> de la siguiente forma al <code class="docutils literal notranslate"><span class="pre">desarrollar</span> <span class="pre">los</span> <span class="pre">productos</span> <span class="pre">asociados</span> <span class="pre">y</span> <span class="pre">aplicar</span> <span class="pre">propiedades</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">transpuesta</span></code></p>
<div class="math notranslate nohighlight">
\[
S_{\lambda}(\beta_{0}^{\star}, \boldsymbol{\beta}_{s})=\boldsymbol{y}^{T}\boldsymbol{y}-2\boldsymbol{y}^{T}\beta_{0}^{\star}\boldsymbol{1}-2\boldsymbol{y}^{T}Z\boldsymbol{\beta}_{s}+2\beta_{0}\textcolor{red}{\boldsymbol{1}^{T}Z}\boldsymbol{\beta}_{s}+n\beta_{0}^{\star^{2}}+\boldsymbol{\beta}_{s}^{T}Z^{T}Z\boldsymbol{\beta}_{s}+\lambda\boldsymbol{\beta}_{s}^{T}\boldsymbol{\beta}_{s}
\]</div>
<p>Diferenciando con respecto a <span class="math notranslate nohighlight">\(\beta_{0}^{\star}\)</span> y <span class="math notranslate nohighlight">\(\boldsymbol{\beta}_{s}\)</span> para resolver el <code class="docutils literal notranslate"><span class="pre">problema</span> <span class="pre">de</span> <span class="pre">minimización</span></code>, obtenemos las siguientes ecuaciones:</p>
<div class="math notranslate nohighlight" id="equation-eq-betaz">
<span class="eqno">(12)<a class="headerlink" href="#equation-eq-betaz" title="Permalink to this equation">#</a></span>\[
\begin{align*}
\frac{\partial S_{\lambda}(\beta_{0}^{\star}, \boldsymbol{\beta}_{s})}{\partial\beta_{0}^{\star}}&amp;=-2n\overline{y}+2n\beta_{0}^{\star}=0
\end{align*}
\]</div>
<p>Nótese que <span class="math notranslate nohighlight">\(Z^{T}\boldsymbol{1}=\boldsymbol{1}^{T}Z=0\)</span> <code class="docutils literal notranslate"><span class="pre">(verifíquelo)</span></code>. Para el caso de la derivada parcial con respecto a <span class="math notranslate nohighlight">\(\boldsymbol{\beta}_{s}\)</span> se requiere antes, estudiar la <code class="docutils literal notranslate"><span class="pre">derivada</span> <span class="pre">de</span> <span class="pre">una</span> <span class="pre">forma</span> <span class="pre">cuadrática</span></code> de la forma <span class="math notranslate nohighlight">\(\boldsymbol{x}^{T}A\boldsymbol{x}\)</span>. Nótese que</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\boldsymbol{x}^{T}A\boldsymbol{x}&amp;=(x_{1}, x_{2},\dots, x_{p})
\begin{pmatrix}
A_{11} &amp; A_{12} &amp; \cdots &amp; A_{1p}\\
A_{21} &amp; A_{22} &amp; \cdots &amp; A_{2p}\\
\vdots\\
A_{31} &amp; A_{32} &amp; \cdots &amp; A_{3p}\\
\vdots\\
A_{p1} &amp; A_{p2} &amp; \cdots &amp; A_{pp}
\end{pmatrix}
\begin{pmatrix}
x_{1}\\
x_{2}\\
\vdots\\
x_{p}
\end{pmatrix}
% &amp;=\left(\sum_{i=1}^{p}x_{i}A_{i1}, \sum_{i=1}^{p}x_{i}A_{i2},\dots, \sum_{i=1}^{p}x_{i}A_{ip}\right)
% \begin{pmatrix}
% x_{1}\\
% x_{2}\\
% \vdots\\
% x_{p}
% \end{pmatrix}\\
=\sum_{j=1}^{p}\left(\sum_{i=1}^{p}x_{i}A_{ij}\right)x_{j}
\end{align*}
\end{split}\]</div>
<p>Derivando con respecto a <span class="math notranslate nohighlight">\(x_{k}\)</span> para obtener la <span class="math notranslate nohighlight">\(k\)</span><code class="docutils literal notranslate"><span class="pre">-ésima</span> <span class="pre">componente</span> <span class="pre">del</span> <span class="pre">gradiente</span></code> <span class="math notranslate nohighlight">\(\nabla_{\boldsymbol{x}}(\boldsymbol{x}^{T}A\boldsymbol{x})\)</span></p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\frac{\partial(\boldsymbol{x}^{T}A\boldsymbol{x})}{\partial x_{k}}&amp;=
\frac{\partial}{\partial x_{k}}\left[\sum_{j=1}^{p}\left(\sum_{i=1}^{p}x_{i}A_{ij}\right)x_{j}\right]\\
&amp;=\sum_{j=1}^{p}\left(\sum_{i=1}^{p}\frac{\partial x_{i}}{\partial x_{k}}A_{ij}\right)x_{j}+
\sum_{j=1}^{p}\frac{\partial x_{j}}{\partial x_{k}}\left(\sum_{i=1}^{p}x_{i}A_{ij}\right)\\
&amp;=\sum_{j=1}^{p}A_{kj}x_{j}+\sum_{i=1}^{p}x_{i}A_{ik}
\end{align*}
\end{split}\]</div>
<p>Por lo tanto, para <span class="math notranslate nohighlight">\(k=1,2,\dots,p\)</span>, <code class="docutils literal notranslate"><span class="pre">bajo</span> <span class="pre">el</span> <span class="pre">supuesto</span> <span class="pre">de</span> <span class="pre">simetría</span></code> para <span class="math notranslate nohighlight">\(A\)</span> se tiene que</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\frac{\partial(\boldsymbol{x}^{T}A\boldsymbol{x})}{\partial\boldsymbol{x}}&amp;=
\begin{pmatrix}
\displaystyle{\sum_{j=1}^{p}A_{1j}x_{j}+\sum_{i=1}^{p}x_{i}A_{i1}}\\
\displaystyle{\sum_{j=1}^{p}A_{2j}x_{j}+\sum_{i=1}^{p}x_{i}A_{i2}}\\
\vdots\\
\displaystyle{\sum_{j=1}^{p}A_{pj}x_{j}+\sum_{i=1}^{p}x_{i}A_{ip}}
\end{pmatrix}\\
&amp;=A\boldsymbol{x}+A^{T}\boldsymbol{x}\\
&amp;=(A+A^{T})\boldsymbol{x}\\
&amp;=2A\boldsymbol{x}
\end{align*}
\end{split}\]</div>
<p><code class="docutils literal notranslate"><span class="pre">Nótese</span> <span class="pre">que</span></code> <span class="math notranslate nohighlight">\(A:=Z^{T}Z\)</span>, <code class="docutils literal notranslate"><span class="pre">es</span> <span class="pre">simétrica</span></code>, en efecto: <span class="math notranslate nohighlight">\(A^{T}=(Z^{T}Z)^{T}=Z^{T}(Z^{T})^{T}=Z^{T}Z=A\)</span>, entonces <span class="math notranslate nohighlight">\(\partial_{\boldsymbol{\beta}_{s}}(\boldsymbol{\beta}_{s}^{T}Z^{T}Z\boldsymbol{\beta}_{s})=2Z^{T}Z\boldsymbol{\beta}_{s}\)</span>, por lo tanto</p>
<div class="math notranslate nohighlight" id="equation-eq-betas">
<span class="eqno">(13)<a class="headerlink" href="#equation-eq-betas" title="Permalink to this equation">#</a></span>\[
\begin{align*}
\frac{\partial S_{\lambda}(\beta_{0}^{\star},\boldsymbol{\beta}_{s})}{\partial\boldsymbol{\beta}_{s}}=-2Z^{T}\boldsymbol{y}+2Z^{T}Z\boldsymbol{\beta}_{s}+2\lambda\boldsymbol{\beta}_{s}=\boldsymbol{0}
\end{align*}
\]</div>
<p><code class="docutils literal notranslate"><span class="pre">Resolviendo</span> <span class="pre">las</span> <span class="pre">ecuaciones</span></code> <a class="reference internal" href="#equation-eq-betaz">(12)</a> y <a class="reference internal" href="#equation-eq-betas">(13)</a> para <span class="math notranslate nohighlight">\(\beta_{0}^{\star}\)</span> y <span class="math notranslate nohighlight">\(\boldsymbol{\beta}_{s}\)</span>, se tienen <code class="docutils literal notranslate"><span class="pre">estimadores</span> <span class="pre">ridge</span></code> para el modelo de regresión <a class="reference internal" href="#equation-eq-reg-li-z">(9)</a></p>
<div class="math notranslate nohighlight">
\[
\hat{\beta}_{0}^{\star}=\overline{y}\quad\text{y}\quad\hat{\boldsymbol{\beta}}_{s}=(Z^{T}Z+\lambda I_{p})^{-1}Z^{T}\boldsymbol{y}
\]</div>
<p>Dado que <span class="math notranslate nohighlight">\(\beta_{0}^{\star}=\beta_{0}+\beta_{1}\bar x_{1}+\beta_{2}\bar x_{2}+\cdots+\beta_{p}\bar x_{p}\)</span> <code class="docutils literal notranslate"><span class="pre">usando</span> <span class="pre">la</span> <span class="pre">estimación</span> <span class="pre">obtenida</span></code> <span class="math notranslate nohighlight">\(\hat{\beta}_{0}^{\star}\)</span> se tiene que</p>
<div class="math notranslate nohighlight">
\[
\hat{\beta}_{0}=\overline{y}-\hat{\beta}_{1}\bar x_{1}-\hat{\beta}_{2}\bar x_{2}-\cdots-\hat{\beta}_{p}\bar x_{p}.
\]</div>
<p>Además, la <code class="docutils literal notranslate"><span class="pre">estimación</span> <span class="pre">ridge</span> <span class="pre">del</span> <span class="pre">vector</span> <span class="pre">de</span> <span class="pre">coeficientes</span> <span class="pre">de</span> <span class="pre">regresión</span></code>, está dada separadamente por la <code class="docutils literal notranslate"><span class="pre">minimización</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">función</span></code></p>
<div class="math notranslate nohighlight">
\[
S_{\lambda}(\boldsymbol{\beta}_{s})=(\boldsymbol{y}-Z\boldsymbol{\beta}_{s})^{T}(\boldsymbol{y}-Z\boldsymbol{\beta}_{s})+\lambda\boldsymbol{\beta}_{s}^{T}\boldsymbol{\beta}_{s}.
\]</div>
<p><code class="docutils literal notranslate"><span class="pre">En</span> <span class="pre">efecto</span></code>, para obtener <code class="docutils literal notranslate"><span class="pre">estimación</span> <span class="pre">ridge</span> <span class="pre">del</span> <span class="pre">vector</span> <span class="pre">de</span> <span class="pre">coeficientes</span></code> <span class="math notranslate nohighlight">\(\boldsymbol{\beta}_{s}=(\hat{\beta}_{1}, \hat{\beta}_{2},\dots, \hat{\beta}_{p})\)</span>, primero, nótese que al reemplazar <span class="math notranslate nohighlight">\(\hat{\beta}_{0}^{\star}=\overline{y}\)</span> en Eq. <a class="reference internal" href="#equation-reg-ridge-model">(10)</a> se tiene que <span class="math notranslate nohighlight">\(y=\overline{y}\boldsymbol{1}+Z\boldsymbol{\beta}_{s}+\varepsilon\)</span>, entonces <span class="math notranslate nohighlight">\(\boldsymbol{y}-\overline{y}\boldsymbol{1}\)</span> esta <code class="docutils literal notranslate"><span class="pre">centrando</span> <span class="pre">los</span> <span class="pre">datos</span> <span class="pre">en</span> <span class="pre">relación</span> <span class="pre">a</span> <span class="pre">la</span> <span class="pre">variable</span> <span class="pre">respuesta</span></code>.</p>
<p><code class="docutils literal notranslate"><span class="pre">Estandarizando</span> <span class="pre">las</span> <span class="pre">variables</span> <span class="pre">predictoras</span> <span class="pre">y</span> <span class="pre">respuesta</span></code> en nuestro modelo inicial Ecuación <a class="reference internal" href="#equation-linear-model-comp">(7)</a>, mediante <span class="math notranslate nohighlight">\(y_{i}-\overline{y}\)</span> y <span class="math notranslate nohighlight">\((x_{ij}-\bar x_{j})/s_{j}\)</span> se tienen las siguientes igualdades, <code class="docutils literal notranslate"><span class="pre">verifiquelas</span></code></p>
<div class="math notranslate nohighlight" id="equation-ridge-normalization">
<span class="eqno">(14)<a class="headerlink" href="#equation-ridge-normalization" title="Permalink to this equation">#</a></span>\[
\sum_{i=1}^{n}y_{i}=0,\quad\sum_{i=1}^{n}x_{ij}=0,~j=1,2,\dots,p,\quad\sum_{i=1}^{n}x_{ij}^{2}=n
\]</div>
<p>Entonces,</p>
<div class="math notranslate nohighlight">
\[
\beta_{0}^{\star}=\bar{y}=\frac{1}{n}\sum_{i=1}^{n}y_{i}=0.
\]</div>
<p><code class="docutils literal notranslate"><span class="pre">En</span> <span class="pre">virtud</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">implicación</span></code> de estas igualdades con respecto al parámetro <span class="math notranslate nohighlight">\(\beta_{0}^{\star}\)</span> y la Ecuación <a class="reference internal" href="#equation-eq-reg-li-z">(9)</a>, podemos <code class="docutils literal notranslate"><span class="pre">considerar</span> <span class="pre">sin</span> <span class="pre">perdida</span> <span class="pre">de</span> <span class="pre">generalidad</span></code>, el modelo de regresión</p>
<div class="math notranslate nohighlight">
\[
y=X\boldsymbol{\beta}+\boldsymbol{\varepsilon},
\]</div>
<p>donde <span class="math notranslate nohighlight">\(X\in\mathbb{R}^{n\times p},~\boldsymbol{\beta}\in\mathbb{R}^{p},~E(\boldsymbol{\varepsilon})=0\)</span> y <span class="math notranslate nohighlight">\(\textrm{cov}(\boldsymbol{\varepsilon})=\sigma^2\boldsymbol{I}\)</span>.</p>
<p>Por lo tanto <code class="docutils literal notranslate"><span class="pre">minimizando</span> <span class="pre">el</span> <span class="pre">operador</span></code> <span class="math notranslate nohighlight">\(S_{\lambda}(\boldsymbol{\beta})=(y-X\boldsymbol{\beta})^{T}(y-X\boldsymbol{\beta})+\lambda\boldsymbol{\beta}^{T}\boldsymbol{\beta}\)</span>, de <code class="docutils literal notranslate"><span class="pre">forma</span> <span class="pre">análoga</span> <span class="pre">al</span> <span class="pre">procedimiento</span> <span class="pre">de</span> <span class="pre">optimización</span> <span class="pre">para</span></code> Eq. <a class="reference internal" href="#equation-ridge-coeff-stand">(11)</a>, obtenemos el estimador de ridge:</p>
<div class="math notranslate nohighlight">
\[
\hat{\boldsymbol{\beta}}_{R}=(X^{T}X+\lambda\boldsymbol{I}_{p})^{-1}X^{T}\boldsymbol{y}.
\]</div>
<div class="admonition-propiedades-del-estimador-ridge admonition" id="prop-ridge-estimador">
<p class="admonition-title">Propiedades del estimador ridge</p>
<p>El <code class="docutils literal notranslate"><span class="pre">estimador</span> <span class="pre">ridge</span></code> satisface las siguientes propiedades:</p>
<div class="math notranslate nohighlight" id="equation-ridge-props">
<span class="eqno">(15)<a class="headerlink" href="#equation-ridge-props" title="Permalink to this equation">#</a></span>\[\begin{split}
\begin{align}
\text{E}(\hat{\boldsymbol{\beta}}_{R})&amp;=(X^{T}X+\lambda\boldsymbol{I}_{p})^{-1}X^{T}X\boldsymbol{\beta}\\
\text{Cov}(\boldsymbol{\beta}_{R})&amp;=\sigma^{2}(X^{T}X+\lambda\boldsymbol{I}_{p})^{-1}X^{T}X(X^{T}X+\lambda\boldsymbol{I}_{p})^{-1}\\
\text{E}(\hat{\boldsymbol{\beta}}_{R}-\boldsymbol{\beta})&amp;=-\lambda(X^{T}X+\lambda\boldsymbol{I}_{p})^{-1}\boldsymbol{\beta}\\
\text{E}[(\hat{\boldsymbol{\beta}}_{R}-\boldsymbol{\beta})^{T}(\hat{\boldsymbol{\beta}}_{R}-\boldsymbol{\beta})]&amp;=\displaystyle{\sigma^{2}\sum_{j=1}^{p}\frac{l_{j}}{(l_{j}+\lambda)^{2}}+\lambda^{2}\boldsymbol{\beta}^{T}(X^{T}X+\lambda\boldsymbol{I}_{p})^{-2}\boldsymbol{\beta}},
\end{align}
\end{split}\]</div>
<p>donde <span class="math notranslate nohighlight">\(l_{1}, l_{2},\dots, l_{p}\)</span> son los <code class="docutils literal notranslate"><span class="pre">autovalores</span> <span class="pre">ordenados</span></code> de <span class="math notranslate nohighlight">\(X^{T}X\)</span>. El primer término del lado derecho de la última ecuación en <a class="reference internal" href="#equation-ridge-props">(15)</a> representa la suma de las <code class="docutils literal notranslate"><span class="pre">varianzas</span> <span class="pre">de</span> <span class="pre">los</span> <span class="pre">componentes</span> <span class="pre">del</span> <span class="pre">estimador</span> <span class="pre">ridge</span></code>, y el segundo término es el <code class="docutils literal notranslate"><span class="pre">cuadrado</span> <span class="pre">del</span> <span class="pre">sesgo</span></code>.</p>
</div>
<div class="tip admonition">
<p class="admonition-title">Ejercicio para el lector</p>
<p>Queda como <code class="docutils literal notranslate"><span class="pre">ejercicio</span> <span class="pre">para</span> <span class="pre">el</span> <span class="pre">lector</span> <span class="pre">verificar</span> <span class="pre">las</span> <span class="pre">Propiedades</span></code> <a class="reference internal" href="#equation-ridge-props">(15)</a> del <code class="docutils literal notranslate"><span class="pre">estimador</span> <span class="pre">ridge</span></code>. <em>Sugerencia: Revisar el texto de Sadanori Konishi</em>, <code class="docutils literal notranslate"><span class="pre">Introduction</span> <span class="pre">to</span> <span class="pre">Multivariate</span> <span class="pre">Analysis:</span> <span class="pre">Linear</span> <span class="pre">and</span> <span class="pre">Nonlinear</span> <span class="pre">Modeling</span></code> <span id="id1">[<a class="reference internal" href="biblio.html#id20" title="S. Konishi. Introduction to Multivariate Analysis: Linear and Nonlinear Modeling. Chapman &amp; Hall/CRC Texts in Statistical Science. Taylor &amp; Francis, 2014. ISBN 9781466567283. URL: https://books.google.com.co/books?id=fcuuAwAAQBAJ.">Konishi, 2014</a>]</span>.</p>
</div>
</section>
<section id="implementacion">
<h3>Implementación<a class="headerlink" href="#implementacion" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>La <code class="docutils literal notranslate"><span class="pre">regresión</span> <span class="pre">ridge</span></code> se implementa en <code class="docutils literal notranslate"><span class="pre">linear_model.Ridge</span></code>. Veamos qué tal lo hace en el conjunto de datos ampliado de <code class="docutils literal notranslate"><span class="pre">Boston</span> <span class="pre">Housing</span></code>.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">Ridge</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ridge</span> <span class="o">=</span> <span class="n">Ridge</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training set score: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">ridge</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test set score: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">ridge</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training set score: 0.89
Test set score: 0.75
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Como puede ver, <code class="docutils literal notranslate"><span class="pre">el</span> <span class="pre">score</span> <span class="pre">en</span> <span class="pre">el</span> <span class="pre">conjunto</span> <span class="pre">de</span> <span class="pre">entrenamiento</span> <span class="pre">de</span> <span class="pre">Ridge</span> <span class="pre">es</span> <span class="pre">menor</span> <span class="pre">que</span> <span class="pre">el</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">regresión</span> <span class="pre">lineal</span></code>, cuyos scores fueron: <strong>Training set score: 0.95 and Test set score: 0.61</strong>. Además, <code class="docutils literal notranslate"><span class="pre">la</span> <span class="pre">puntuación</span> <span class="pre">en</span> <span class="pre">el</span> <span class="pre">conjunto</span> <span class="pre">de</span> <span class="pre">prueba</span> <span class="pre">es</span> <span class="pre">mayor</span></code>. En este caso, <code class="docutils literal notranslate"><span class="pre">Ridge</span></code>, usa <code class="docutils literal notranslate"><span class="pre">alpha=1.0</span></code> como parámetro por default (ver <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html">sklearn.linear_model.Ridge</a>). Esto es coherente con nuestras expectativas.</p></li>
<li><p>Con la regresión, nos ajustamos demasiado a los datos. <code class="docutils literal notranslate"><span class="pre">Ridge</span> <span class="pre">es</span> <span class="pre">un</span> <span class="pre">modelo</span> <span class="pre">más</span> <span class="pre">restringido,</span> <span class="pre">por</span> <span class="pre">lo</span> <span class="pre">que</span> <span class="pre">existe</span> <span class="pre">menos</span> <span class="pre">probabilidad</span> <span class="pre">de</span> <span class="pre">overfitting</span></code>. Un modelo <code class="docutils literal notranslate"><span class="pre">menos</span> <span class="pre">complejo</span></code> significa un <code class="docutils literal notranslate"><span class="pre">peor</span> <span class="pre">rendimiento</span> <span class="pre">en</span> <span class="pre">el</span> <span class="pre">conjunto</span> <span class="pre">de</span> <span class="pre">de</span> <span class="pre">entrenamiento,</span> <span class="pre">pero</span> <span class="pre">una</span> <span class="pre">mejor</span> <span class="pre">generalización</span></code>. Como sólo nos interesa el rendimiento de la generalización, deberíamos elegir el modelo Ridge en lugar del modelo de regresión lineal.</p></li>
</ul>
<ul class="simple">
<li><p>El modelo <code class="docutils literal notranslate"><span class="pre">Ridge</span></code> hace un <code class="docutils literal notranslate"><span class="pre">balance</span> <span class="pre">entre</span> <span class="pre">la</span> <span class="pre">simplicidad</span> <span class="pre">del</span> <span class="pre">modelo</span> <span class="pre">(coeficientes</span> <span class="pre">casi</span> <span class="pre">nulos)</span> <span class="pre">y</span> <span class="pre">su</span> <span class="pre">rendimiento</span> <span class="pre">en</span> <span class="pre">el</span> <span class="pre">conjunto</span> <span class="pre">de</span> <span class="pre">entrenamiento</span></code>. La importancia que el modelo da a la simplicidad frente al rendimiento del conjunto de entrenamiento, puede ser <code class="docutils literal notranslate"><span class="pre">especificada</span> <span class="pre">por</span> <span class="pre">el</span> <span class="pre">usuario</span></code>, utilizando el parámetro <code class="docutils literal notranslate"><span class="pre">alpha</span></code>.</p></li>
<li><p>En el ejemplo anterior, hemos utilizado el parámetro por defecto <code class="docutils literal notranslate"><span class="pre">alpha=1.0</span></code>. Sin embargo, no hay ninguna razón por la que este nos dió la mejor compensación. El ajuste óptimo de <code class="docutils literal notranslate"><span class="pre">alpha</span></code> depende del conjunto de datos concreto que estemos utilizando.</p></li>
</ul>
<div class="tip admonition">
<p class="admonition-title">Observación</p>
<ul class="simple">
<li><p>Aumentar <code class="docutils literal notranslate"><span class="pre">alpha</span></code> obliga a los coeficientes a acercarse más a cero, lo que <code class="docutils literal notranslate"><span class="pre">disminuye</span> <span class="pre">el</span> <span class="pre">rendimiento</span> <span class="pre">del</span> <span class="pre">conjunto</span> <span class="pre">de</span> <span class="pre">entrenamiento,</span> <span class="pre">pero</span> <span class="pre">puede</span> <span class="pre">ayudar</span> <span class="pre">a</span> <span class="pre">mejorar</span> <span class="pre">la</span> <span class="pre">generalización</span></code>.</p></li>
</ul>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ridge10</span> <span class="o">=</span> <span class="n">Ridge</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training set score: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">ridge10</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test set score: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">ridge10</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training set score: 0.79
Test set score: 0.64
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>La disminución de <code class="docutils literal notranslate"><span class="pre">alpha</span></code> permite que los coeficientes estén menos restringidos. <code class="docutils literal notranslate"><span class="pre">Para</span> <span class="pre">valores</span> <span class="pre">muy</span> <span class="pre">pequeños</span> <span class="pre">de</span> <span class="pre">alpha,</span> <span class="pre">los</span> <span class="pre">coeficientes</span> <span class="pre">apenas</span> <span class="pre">están</span> <span class="pre">restringidos,</span> <span class="pre">y</span> <span class="pre">terminamos</span> <span class="pre">con</span> <span class="pre">un</span> <span class="pre">modelo</span> <span class="pre">que</span> <span class="pre">se</span> <span class="pre">parece</span> <span class="pre">a</span> <span class="pre">LinearRegression</span></code></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ridge01</span> <span class="o">=</span> <span class="n">Ridge</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training set score: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">ridge01</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test set score: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">ridge01</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training set score: 0.93
Test set score: 0.77
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Observe cómo el parámetro <code class="docutils literal notranslate"><span class="pre">alpha</span></code> se corresponde con la complejidad del modelo. Discutiremos los <code class="docutils literal notranslate"><span class="pre">métodos</span> <span class="pre">para</span> <span class="pre">seleccionar</span> <span class="pre">adecuadamente</span> <span class="pre">los</span> <span class="pre">parámetros</span></code> en el capítulo de <code class="docutils literal notranslate"><span class="pre">evaluación</span> <span class="pre">de</span> <span class="pre">modelos</span></code>. También podemos obtener una visión más cualitativa de cómo el parámetro <code class="docutils literal notranslate"><span class="pre">alpha</span></code> cambia el modelo, inspeccionando el atributo <code class="docutils literal notranslate"><span class="pre">coef_</span></code> de los modelos con diferentes valores de <code class="docutils literal notranslate"><span class="pre">alpha</span></code>.</p></li>
<li><p>Un <code class="docutils literal notranslate"><span class="pre">alpha</span></code> más alto significa un modelo más restringido, por lo que esperamos que las entradas de <code class="docutils literal notranslate"><span class="pre">coef_</span></code> tengan una magnitud menor.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">font_scale</span><span class="o">=</span><span class="mf">1.2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ridge</span><span class="o">.</span><span class="n">coef_</span><span class="p">,</span> <span class="s1">&#39;s&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Ridge alpha=1&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ridge10</span><span class="o">.</span><span class="n">coef_</span><span class="p">,</span> <span class="s1">&#39;^&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Ridge alpha=10&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ridge01</span><span class="o">.</span><span class="n">coef_</span><span class="p">,</span> <span class="s1">&#39;v&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Ridge alpha=0.1&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lr</span><span class="o">.</span><span class="n">coef_</span><span class="p">,</span> <span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;LinearRegression&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Coefficient index&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Coefficient magnitude&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hlines</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">lr</span><span class="o">.</span><span class="n">coef_</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="o">-</span><span class="mi">25</span><span class="p">,</span> <span class="mi">25</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/6201dcc7554169547eeb452d97f5da5b94b893384a9f7ad0e4a9d472bf882f44.png" src="_images/6201dcc7554169547eeb452d97f5da5b94b893384a9f7ad0e4a9d472bf882f44.png" />
</div>
</div>
<ul class="simple">
<li><p>Aquí, el eje <span class="math notranslate nohighlight">\(x\)</span> enumera las entradas de <code class="docutils literal notranslate"><span class="pre">coef_</span></code>. <span class="math notranslate nohighlight">\(x=0\)</span> muestra el <code class="docutils literal notranslate"><span class="pre">coeficiente</span> <span class="pre">asociado</span> <span class="pre">a</span> <span class="pre">la</span> <span class="pre">primera</span> <span class="pre">característica</span></code>, <span class="math notranslate nohighlight">\(x=1\)</span> el <code class="docutils literal notranslate"><span class="pre">coeficiente</span> <span class="pre">asociado</span> <span class="pre">a</span> <span class="pre">la</span> <span class="pre">segunda</span> <span class="pre">característica</span></code>, y así sucesivamente hasta <span class="math notranslate nohighlight">\(x=100\)</span>. El eje <span class="math notranslate nohighlight">\(y\)</span> muestra los <code class="docutils literal notranslate"><span class="pre">valores</span> <span class="pre">numéricos</span> <span class="pre">de</span> <span class="pre">los</span> <span class="pre">valores</span> <span class="pre">correspondientes</span> <span class="pre">de</span> <span class="pre">los</span> <span class="pre">coeficientes</span></code>. La principal conclusión es que para <code class="docutils literal notranslate"><span class="pre">alpha=10</span></code>, los coeficientes se sitúan en su mayoría entre -3 y 3.</p></li>
<li><p>Los coeficientes del modelo <code class="docutils literal notranslate"><span class="pre">Ridge</span></code> con <code class="docutils literal notranslate"><span class="pre">alpha=1</span></code> son algo mayores. Los puntos correspondientes a <code class="docutils literal notranslate"><span class="pre">alpha=0,1</span></code> tienen una magnitud aún mayor, y muchos de los puntos correspondientes a la <code class="docutils literal notranslate"><span class="pre">regresión</span> <span class="pre">lineal</span> <span class="pre">sin</span> <span class="pre">ninguna</span> <span class="pre">regularización</span></code> (que sería <code class="docutils literal notranslate"><span class="pre">alpha=0</span></code>), son tan grandes que quedan fuera del gráfico.</p></li>
<li><p>Otra forma de entender la influencia de la regularización es fijar un valor de <code class="docutils literal notranslate"><span class="pre">alpha</span></code> pero variando la cantidad de datos de entrenamiento disponibles. Si submuestreamos el conjunto de datos de <code class="docutils literal notranslate"><span class="pre">Boston</span> <span class="pre">Housing</span></code> y evaluamos <code class="docutils literal notranslate"><span class="pre">LinearRegression</span></code> y <code class="docutils literal notranslate"><span class="pre">Ridge(alpha=1)</span></code> en subconjuntos de tamaño creciente, obtenemos la siguiente <code class="docutils literal notranslate"><span class="pre">curva</span> <span class="pre">de</span> <span class="pre">aprendizaje</span></code></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mglearn</span><span class="o">.</span><span class="n">plots</span><span class="o">.</span><span class="n">plot_ridge_n_samples</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/28eb4daa31d5fe05ea1ca41537ec212aeaa2df773b983131c17905ab35438690.png" src="_images/28eb4daa31d5fe05ea1ca41537ec212aeaa2df773b983131c17905ab35438690.png" />
</div>
</div>
<ul class="simple">
<li><p>Como era de esperarse, la <code class="docutils literal notranslate"><span class="pre">puntuación</span> <span class="pre">de</span> <span class="pre">entrenamiento</span> <span class="pre">es</span> <span class="pre">mayor</span> <span class="pre">que</span> <span class="pre">la</span> <span class="pre">de</span> <span class="pre">prueba</span> <span class="pre">para</span> <span class="pre">todos</span> <span class="pre">los</span> <span class="pre">tamaños</span> <span class="pre">de</span> <span class="pre">conjuntos</span> <span class="pre">de</span> <span class="pre">datos</span></code>, tanto para la <code class="docutils literal notranslate"><span class="pre">regresión</span> <span class="pre">lineal</span></code> como para la <code class="docutils literal notranslate"><span class="pre">ridge</span></code>. Debido a que la <code class="docutils literal notranslate"><span class="pre">regresión</span> <span class="pre">ridge</span> <span class="pre">está</span> <span class="pre">regularizada,</span> <span class="pre">la</span> <span class="pre">puntuación</span> <span class="pre">de</span> <span class="pre">entrenamiento</span> <span class="pre">es</span> <span class="pre">inferior</span> <span class="pre">a</span> <span class="pre">la</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">regresión</span> <span class="pre">lineal</span> <span class="pre">en</span> <span class="pre">todos</span> <span class="pre">los</span> <span class="pre">casos</span></code>.</p></li>
<li><p>La puntuación de la prueba de la regresión ridge es mejor, en particular, para los subconjuntos pequeños de datos. <code class="docutils literal notranslate"><span class="pre">Para</span> <span class="pre">menos</span> <span class="pre">de</span> <span class="pre">400</span> <span class="pre">puntos</span> <span class="pre">de</span> <span class="pre">datos,</span> <span class="pre">la</span> <span class="pre">regresión</span> <span class="pre">lineal</span> <span class="pre">no</span> <span class="pre">es</span> <span class="pre">capaz</span> <span class="pre">de</span> <span class="pre">aprender</span> <span class="pre">nada</span></code>. <code class="docutils literal notranslate"><span class="pre">A</span> <span class="pre">medida</span> <span class="pre">que</span> <span class="pre">el</span> <span class="pre">modelo</span> <span class="pre">dispone</span> <span class="pre">de</span> <span class="pre">más</span> <span class="pre">datos,</span> <span class="pre">ambos</span> <span class="pre">modelos</span> <span class="pre">mejoran,</span> <span class="pre">y</span> <span class="pre">la</span> <span class="pre">regresión</span> <span class="pre">lineal</span> <span class="pre">alcanza</span> <span class="pre">a</span> <span class="pre">la</span> <span class="pre">ridge.</span></code></p></li>
</ul>
</section>
</section>
<section id="lasso">
<h2>Lasso<a class="headerlink" href="#lasso" title="Permalink to this heading">#</a></h2>
<p><strong><code class="docutils literal notranslate"><span class="pre">Observación</span></code></strong></p>
<ul class="simple">
<li><p>Una alternativa a la <code class="docutils literal notranslate"><span class="pre">regresión</span> <span class="pre">ridge</span></code> para regularizar la <code class="docutils literal notranslate"><span class="pre">regresión</span> <span class="pre">lineal</span></code> es la <code class="docutils literal notranslate"><span class="pre">regresión</span> <span class="pre">lasso</span></code>. Al igual que con la regresión <code class="docutils literal notranslate"><span class="pre">ridge</span></code>, el uso de <code class="docutils literal notranslate"><span class="pre">lasso</span></code> también <code class="docutils literal notranslate"><span class="pre">restringe</span> <span class="pre">los</span> <span class="pre">coeficientes</span> <span class="pre">para</span> <span class="pre">que</span> <span class="pre">sean</span> <span class="pre">cercanos</span> <span class="pre">a</span> <span class="pre">cero,</span> <span class="pre">pero</span> <span class="pre">de</span> <span class="pre">una</span> <span class="pre">forma</span> <span class="pre">ligeramente</span> <span class="pre">diferente,</span> <span class="pre">llamada</span> <span class="pre">regularización</span></code> <span class="math notranslate nohighlight">\(L^1\)</span>.</p></li>
<li><p>La consecuencia de la regularización <span class="math notranslate nohighlight">\(L^1\)</span> es que <code class="docutils literal notranslate"><span class="pre">cuando</span> <span class="pre">se</span> <span class="pre">utiliza</span> <span class="pre">lasso,</span> <span class="pre">algunos</span> <span class="pre">coeficientes</span> <span class="pre">son</span> <span class="pre">exactamente</span> <span class="pre">cero</span></code>. Esto significa que, <code class="docutils literal notranslate"><span class="pre">algunas</span> <span class="pre">características</span> <span class="pre">son</span> <span class="pre">totalmente</span> <span class="pre">ignoradas</span> <span class="pre">por</span> <span class="pre">el</span> <span class="pre">modelo</span></code>. Esto puede verse como una forma de <strong><code class="docutils literal notranslate"><span class="pre">selección</span> <span class="pre">automática</span> <span class="pre">de</span> <span class="pre">características</span></code></strong>.</p></li>
<li><p>El hecho de que algunos coeficientes sean exactamente cero a menudo hace que un <code class="docutils literal notranslate"><span class="pre">modelo</span> <span class="pre">sea</span> <span class="pre">más</span> <span class="pre">fácil</span> <span class="pre">de</span> <span class="pre">interpretar,</span> <span class="pre">y</span> <span class="pre">puede</span> <span class="pre">revelar</span> <span class="pre">las</span> <span class="pre">características</span> <span class="pre">más</span> <span class="pre">importantes</span> <span class="pre">de</span> <span class="pre">un</span> <span class="pre">modelo</span></code>.</p></li>
</ul>
<p><strong><code class="docutils literal notranslate"><span class="pre">Formulación</span></code></strong></p>
<p>El método <code class="docutils literal notranslate"><span class="pre">Lasso</span></code> es un método de estimación de parámetros, mediante la <code class="docutils literal notranslate"><span class="pre">minimización</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">siguiente</span> <span class="pre">función</span> <span class="pre">objetivo</span></code>, que impone la suma de valores absolutos (normas <span class="math notranslate nohighlight">\(L^{1}\)</span>) de los coeficientes de regresión como una <code class="docutils literal notranslate"><span class="pre">restricción</span> <span class="pre">(penalización)</span> <span class="pre">a</span> <span class="pre">la</span> <span class="pre">suma</span> <span class="pre">de</span> <span class="pre">errores</span> <span class="pre">al</span> <span class="pre">cuadrado</span></code>:</p>
<div class="math notranslate nohighlight">
\[
S_{\lambda}(\boldsymbol{\beta})=(y-X\boldsymbol{\beta})^{T}(y-X\boldsymbol{\beta})+\lambda\sum_{i=1}^{p}|\beta_{j}|,
\]</div>
<p>donde los datos observados están normalizados como en la Ecuación <a class="reference internal" href="#equation-ridge-normalization">(14)</a>. A diferencia de la contracción de los coeficientes de regresión hacia cero, que se produce en la regresión de ridge, <code class="docutils literal notranslate"><span class="pre">lasso</span> <span class="pre">da</span> <span class="pre">lugar</span> <span class="pre">a</span> <span class="pre">una</span> <span class="pre">estimación</span> <span class="pre">exactamente</span> <span class="pre">igual</span> <span class="pre">a</span> <span class="pre">cero</span> <span class="pre">para</span> <span class="pre">algunos</span> <span class="pre">de</span> <span class="pre">los</span> <span class="pre">coeficientes.</span></code></p>
<div class="tip admonition">
<p class="admonition-title">Observación</p>
<ul class="simple">
<li><p>Una ventaja de la regresión <code class="docutils literal notranslate"><span class="pre">ridge</span></code> es que si <span class="math notranslate nohighlight">\(p &lt; n\)</span> (<code class="docutils literal notranslate"><span class="pre">número</span> <span class="pre">de</span> <span class="pre">variables</span> <span class="pre">predictoras</span> <span class="pre">menor</span> <span class="pre">que</span> <span class="pre">el</span> <span class="pre">número</span> <span class="pre">de</span> <span class="pre">observaciones</span></code>), entonces con una selección adecuada del parámetro de regularización <span class="math notranslate nohighlight">\(\lambda\)</span>, <code class="docutils literal notranslate"><span class="pre">es</span> <span class="pre">posible</span> <span class="pre">obtener</span> <span class="pre">estimaciones</span> <span class="pre">estables</span> <span class="pre">de</span> <span class="pre">los</span> <span class="pre">coeficientes</span> <span class="pre">de</span> <span class="pre">regresión,</span> <span class="pre">incluso</span> <span class="pre">en</span> <span class="pre">casos</span> <span class="pre">que</span> <span class="pre">impliquen</span> <span class="pre">multicolinealidad</span> <span class="pre">entre</span> <span class="pre">las</span> <span class="pre">variables</span> <span class="pre">predictoras</span></code> o en los que <span class="math notranslate nohighlight">\(X^{T}X\)</span> es aproximadamente singular para la matriz de diseño <span class="math notranslate nohighlight">\(X\)</span>.</p></li>
<li><p>Sin embargo, debido a que, a diferencia de <code class="docutils literal notranslate"><span class="pre">lasso</span></code>, la regresión <code class="docutils literal notranslate"><span class="pre">ridge</span> <span class="pre">no</span> <span class="pre">puede</span> <span class="pre">producir</span> <span class="pre">estimaciones</span> <span class="pre">exactamente</span> <span class="pre">iguales</span> <span class="pre">a</span> <span class="pre">cero</span></code>, entonces, la regresión <code class="docutils literal notranslate"><span class="pre">ridge</span> <span class="pre">no</span> <span class="pre">puede</span> <span class="pre">utilizarse</span> <span class="pre">como</span> <span class="pre">método</span> <span class="pre">de</span> <span class="pre">selección</span> <span class="pre">de</span> <span class="pre">variables</span></code>.</p></li>
</ul>
</div>
<figure class="align-center" id="fig-ridge-lasso">
<a class="reference internal image-reference" href="_images/ridge_lasso.png"><img alt="_images/ridge_lasso.png" src="_images/ridge_lasso.png" style="width: 618.75px; height: 377.7px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 6 </span><span class="caption-text">Estimación ridge (izquierda) y estimación lasso (derecha).</span><a class="headerlink" href="#fig-ridge-lasso" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>La diferencia entre la estimación lasso y la estimación ridge puede demostrarse, para simplificar, para el caso de sólo dos variables predictoras <span class="math notranslate nohighlight">\(x_{1}\)</span> y <span class="math notranslate nohighlight">\(x_{2}\)</span>. <code class="docutils literal notranslate"><span class="pre">En</span> <span class="pre">la</span> <span class="pre">estimación</span> <span class="pre">ridge,</span> <span class="pre">la</span> <span class="pre">solución</span> <span class="pre">se</span> <span class="pre">basa</span> <span class="pre">en</span> <span class="pre">la</span> <span class="pre">restricción</span></code> <span class="math notranslate nohighlight">\(\beta_{1}^{2}+\beta_{2}^{2}\leq c_{1}\)</span> de minimizar</p>
<div class="math notranslate nohighlight">
\[
S(\beta_{1}, \beta_{2})=\sum_{i=1}^{n}\left(y_{i}-\sum_{j=1}^{2}\beta_{j}x_{ij}\right)^{2},
\]</div>
<p>para datos centrados, mientras que <code class="docutils literal notranslate"><span class="pre">la</span> <span class="pre">estimación</span> <span class="pre">lasso</span> <span class="pre">se</span> <span class="pre">basa</span> <span class="pre">en</span> <span class="pre">la</span> <span class="pre">restricción</span></code> <span class="math notranslate nohighlight">\(|\beta_{1}|+|\beta_{2}|\leq c_{2}\)</span>.</p>
<ul class="simple">
<li><p>Dado que la <code class="docutils literal notranslate"><span class="pre">estimación</span> <span class="pre">por</span> <span class="pre">mínimos</span> <span class="pre">cuadrados</span> <span class="pre">es</span> <span class="pre">la</span> <span class="pre">solución</span> <span class="pre">que</span> <span class="pre">minimiza</span></code> <span class="math notranslate nohighlight">\(S(\beta_{1}, \beta_{2})\)</span>, <code class="docutils literal notranslate"><span class="pre">esta</span> <span class="pre">se</span> <span class="pre">produce</span> <span class="pre">en</span> <span class="pre">el</span> <span class="pre">centro</span> <span class="pre">de</span> <span class="pre">una</span> <span class="pre">elipse</span></code>. Sin embargo, como se muestra en la <a class="reference internal" href="#fig-ridge-lasso"><span class="std std-numref">Fig. 6</span></a>, las soluciones que satisfacen las restricciones en las <code class="docutils literal notranslate"><span class="pre">estimaciones</span> <span class="pre">ridge</span> <span class="pre">se</span> <span class="pre">encuentran</span> <span class="pre">en</span> <span class="pre">regiones</span> <span class="pre">diferentes</span> <span class="pre">de</span> <span class="pre">las</span> <span class="pre">que</span> <span class="pre">satisfacen</span> <span class="pre">las</span> <span class="pre">restricciones</span> <span class="pre">en</span> <span class="pre">las</span> <span class="pre">estimaciones</span> <span class="pre">lasso</span></code>.</p></li>
<li><p>La diferencia esencial entre la estimación ridge y la estimación lasso como se muestra en la <a class="reference internal" href="#fig-ridge-lasso"><span class="std std-numref">Fig. 6</span></a>, es que <code class="docutils literal notranslate"><span class="pre">la</span> <span class="pre">estimación</span> <span class="pre">ridge</span> <span class="pre">reduce</span> <span class="pre">todas</span> <span class="pre">las</span> <span class="pre">estimaciones</span> <span class="pre">del</span> <span class="pre">coeficiente</span> <span class="pre">de</span> <span class="pre">regresión</span> <span class="pre">hacia,</span> <span class="pre">pero</span> <span class="pre">no</span> <span class="pre">exactamente</span> <span class="pre">cero</span></code>, en relación con las correspondientes a los mínimos cuadrados, mientras que <code class="docutils literal notranslate"><span class="pre">la</span> <span class="pre">estimación</span> <span class="pre">lasso</span> <span class="pre">localiza</span> <span class="pre">algunas</span> <span class="pre">de</span> <span class="pre">las</span> <span class="pre">estimaciones</span> <span class="pre">del</span> <span class="pre">coeficiente</span> <span class="pre">de</span> <span class="pre">regresión</span> <span class="pre">exactamente</span> <span class="pre">iguales</span> <span class="pre">a</span> <span class="pre">cero</span></code>.</p></li>
<li><p>Debido a su característica de reducir algunos coeficientes a exactamente cero, <code class="docutils literal notranslate"><span class="pre">lasso</span> <span class="pre">también</span> <span class="pre">puede</span> <span class="pre">utilizarse</span> <span class="pre">para</span> <span class="pre">la</span> <span class="pre">selección</span> <span class="pre">de</span> <span class="pre">variables</span> <span class="pre">en</span> <span class="pre">modelos</span> <span class="pre">a</span> <span class="pre">gran</span> <span class="pre">escala</span> <span class="pre">con</span> <span class="pre">muchas</span> <span class="pre">variables</span> <span class="pre">predictoras</span></code>, para las que el parámetro de regularización <span class="math notranslate nohighlight">\(\lambda\)</span> afecta al grado de de esparcimiento de la solución.</p></li>
</ul>
<div class="tip admonition">
<p class="admonition-title">Ejercicio para el lector</p>
<p>Queda como <code class="docutils literal notranslate"><span class="pre">ejercicio</span> <span class="pre">para</span> <span class="pre">el</span> <span class="pre">lector,</span> <span class="pre">encontrar</span> <span class="pre">parámetros</span> <span class="pre">de</span> <span class="pre">estimación</span> <span class="pre">lasso</span></code>, tal como se realizó en el caso de la regresión ridge. Se sugiere investigar sobre el <code class="docutils literal notranslate"><span class="pre">algoritmo</span> <span class="pre">LARS</span> <span class="pre">(Least</span> <span class="pre">Angle</span> <span class="pre">Regression)</span> <span class="pre">de</span> <span class="pre">Efron</span> <span class="pre">et</span> <span class="pre">al.</span> <span class="pre">(2004)</span></code>.</p>
</div>
</section>
<section id="aplicacion-regresion-lasso">
<h2>Aplicación: Regresión Lasso<a class="headerlink" href="#aplicacion-regresion-lasso" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Apliquemos <code class="docutils literal notranslate"><span class="pre">lasso</span></code> al conjunto de datos ampliado de <code class="docutils literal notranslate"><span class="pre">Boston</span> <span class="pre">Housing</span></code></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">Lasso</span>
<span class="n">lasso</span> <span class="o">=</span> <span class="n">Lasso</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training set score: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">lasso</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test set score: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">lasso</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Number of features used: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">lasso</span><span class="o">.</span><span class="n">coef_</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training set score: 0.29
Test set score: 0.21
Number of features used: 4
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Como se puede ver, <code class="docutils literal notranslate"><span class="pre">Lasso</span></code> lo hace bastante mal, tanto en el conjunto de entrenamiento como en el de prueba. Esto indica <code class="docutils literal notranslate"><span class="pre">underfitting</span></code>, pero, nótese que sólo utilizó 4 de las 105 características (<code class="docutils literal notranslate"><span class="pre">feature</span> <span class="pre">selection</span></code>). De forma similar a <code class="docutils literal notranslate"><span class="pre">Ridge</span></code>, <code class="docutils literal notranslate"><span class="pre">Lasso</span></code> también tiene un parámetro de regularización, <code class="docutils literal notranslate"><span class="pre">alpha</span></code>, que <code class="docutils literal notranslate"><span class="pre">controla</span> <span class="pre">la</span> <span class="pre">fuerza</span> <span class="pre">con</span> <span class="pre">la</span> <span class="pre">que</span> <span class="pre">los</span> <span class="pre">coeficientes</span> <span class="pre">son</span> <span class="pre">empujados</span> <span class="pre">hacia</span> <span class="pre">cero</span></code>.</p></li>
<li><p>En el ejemplo anterior, utilizamos el valor por defecto de <code class="docutils literal notranslate"><span class="pre">alpha=1.0</span></code>. Para reducir <code class="docutils literal notranslate"><span class="pre">underfitting</span></code>, intentemos disminuir <code class="docutils literal notranslate"><span class="pre">alpha</span></code>. Cuando hacemos esto, también necesitamos aumentar el ajuste por defecto de <code class="docutils literal notranslate"><span class="pre">max_iter</span></code> (<code class="docutils literal notranslate"><span class="pre">número</span> <span class="pre">máximo</span> <span class="pre">de</span> <span class="pre">iteraciones</span> <span class="pre">a</span> <span class="pre">ejecutar</span></code>)</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">lasso001</span> <span class="o">=</span> <span class="n">Lasso</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">100000</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training set score: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">lasso001</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test set score: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">lasso001</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Number of features used: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">lasso001</span><span class="o">.</span><span class="n">coef_</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training set score: 0.90
Test set score: 0.77
Number of features used: 33
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Un</span> <span class="pre">alpha</span> <span class="pre">más</span> <span class="pre">bajo</span> <span class="pre">nos</span> <span class="pre">permitió</span> <span class="pre">ajustar</span> <span class="pre">un</span> <span class="pre">modelo</span> <span class="pre">más</span> <span class="pre">complejo</span></code>, que funcionó mejor en los datos de entrenamiento y de prueba. El rendimiento es ligeramente mejor que utilizando <code class="docutils literal notranslate"><span class="pre">Ridge</span></code>, y `estamos utilizando sólo 33 de las 105 características.</p></li>
<li><p>Esto hace que este modelo sea potencialmente más fácil de entender. Sin embargo, <code class="docutils literal notranslate"><span class="pre">si</span> <span class="pre">fijamos</span> <span class="pre">alpha</span> <span class="pre">demasiado</span> <span class="pre">bajo,</span> <span class="pre">volvemos</span> <span class="pre">a</span> <span class="pre">eliminar</span> <span class="pre">el</span> <span class="pre">efecto</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">regularización</span> <span class="pre">y</span> <span class="pre">acabamos</span> <span class="pre">en</span> <span class="pre">overfitting</span></code>, con un resultado similar al de <code class="docutils literal notranslate"><span class="pre">LinearRegression</span></code></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">lasso00001</span> <span class="o">=</span> <span class="n">Lasso</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">100000</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training set score: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">lasso00001</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test set score: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">lasso00001</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Number of features used: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">lasso00001</span><span class="o">.</span><span class="n">coef_</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training set score: 0.95
Test set score: 0.64
Number of features used: 96
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Una vez más, podemos <code class="docutils literal notranslate"><span class="pre">trazar</span> <span class="pre">los</span> <span class="pre">coeficientes</span> <span class="pre">de</span> <span class="pre">los</span> <span class="pre">diferentes</span> <span class="pre">modelos</span></code></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">font_scale</span><span class="o">=</span><span class="mf">1.2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lasso</span><span class="o">.</span><span class="n">coef_</span><span class="p">,</span> <span class="s1">&#39;s&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Lasso alpha=1&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lasso001</span><span class="o">.</span><span class="n">coef_</span><span class="p">,</span> <span class="s1">&#39;^&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Lasso alpha=0.01&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lasso00001</span><span class="o">.</span><span class="n">coef_</span><span class="p">,</span> <span class="s1">&#39;v&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Lasso alpha=0.0001&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ridge01</span><span class="o">.</span><span class="n">coef_</span><span class="p">,</span> <span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Ridge alpha=0.1&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">ncol</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">1.05</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="o">-</span><span class="mi">25</span><span class="p">,</span> <span class="mi">25</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Coefficient index&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Coefficient magnitude&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/c0c7e6b3fd341734dee6870102148608e29ddf4070208f0631699d16d1fed149.png" src="_images/c0c7e6b3fd341734dee6870102148608e29ddf4070208f0631699d16d1fed149.png" />
</div>
</div>
<ul class="simple">
<li><p>Para <code class="docutils literal notranslate"><span class="pre">alpha</span> <span class="pre">=</span> <span class="pre">1</span></code>, no sólo vemos que la mayoría de los coeficientes son cero (algo que ya sabíamos), sino que los coeficientes restantes también son de pequeña magnitud. Disminuyendo <code class="docutils literal notranslate"><span class="pre">alpha</span> <span class="pre">a</span> <span class="pre">0.01</span> <span class="pre">,</span> <span class="pre">obtenemos</span> <span class="pre">la</span> <span class="pre">solución</span> <span class="pre">mostrada</span> <span class="pre">en</span> <span class="pre">triángulos</span> <span class="pre">salmones,</span> <span class="pre">que</span> <span class="pre">hace</span> <span class="pre">que</span> <span class="pre">la</span> <span class="pre">mayoría</span> <span class="pre">de</span> <span class="pre">las</span> <span class="pre">características</span> <span class="pre">sean</span> <span class="pre">exactamente</span> <span class="pre">cero</span></code>.</p></li>
<li><p>Utilizando <code class="docutils literal notranslate"><span class="pre">alpha</span> <span class="pre">=</span> <span class="pre">0.0001,</span> <span class="pre">obtenemos</span> <span class="pre">un</span> <span class="pre">modelo</span> <span class="pre">bastante</span> <span class="pre">poco</span> <span class="pre">regularizado,</span> <span class="pre">con</span> <span class="pre">la</span> <span class="pre">mayoría</span> <span class="pre">de</span> <span class="pre">los</span> <span class="pre">coeficientes</span> <span class="pre">no</span> <span class="pre">nulos</span> <span class="pre">y</span> <span class="pre">de</span> <span class="pre">gran</span> <span class="pre">magnitud</span></code>. A modo de comparación, la mejor solución <code class="docutils literal notranslate"><span class="pre">Ridge</span></code> se muestra con puntos rojos. El modelo <code class="docutils literal notranslate"><span class="pre">Ridge</span> <span class="pre">con</span> <span class="pre">alpha</span> <span class="pre">=</span> <span class="pre">0.1</span> <span class="pre">tiene</span> <span class="pre">un</span> <span class="pre">rendimiento</span> <span class="pre">predictivo</span> <span class="pre">similar</span> <span class="pre">al</span> <span class="pre">del</span> <span class="pre">modelo</span> <span class="pre">lasso</span> <span class="pre">con</span> <span class="pre">alpha</span> <span class="pre">=</span> <span class="pre">0.01,</span> <span class="pre">pero</span> <span class="pre">utilizando</span> <span class="pre">Ridge,</span> <span class="pre">todos</span> <span class="pre">los</span> <span class="pre">coeficientes</span> <span class="pre">son</span> <span class="pre">distintos</span> <span class="pre">de</span> <span class="pre">cero</span></code>.</p></li>
</ul>
<div class="tip admonition">
<p class="admonition-title">Observación</p>
<ul class="simple">
<li><p>En la práctica, la regresión <code class="docutils literal notranslate"><span class="pre">Ridge</span> <span class="pre">suele</span> <span class="pre">ser</span> <span class="pre">la</span> <span class="pre">primera</span> <span class="pre">opción</span> <span class="pre">entre</span> <span class="pre">estos</span> <span class="pre">dos</span> <span class="pre">modelos</span></code>. Sin embargo, <code class="docutils literal notranslate"><span class="pre">si</span> <span class="pre">tiene</span> <span class="pre">una</span> <span class="pre">gran</span> <span class="pre">cantidad</span> <span class="pre">de</span> <span class="pre">características</span> <span class="pre">y</span> <span class="pre">espera</span> <span class="pre">que</span> <span class="pre">sólo</span> <span class="pre">unas</span> <span class="pre">pocas</span> <span class="pre">sean</span> <span class="pre">importantes,</span> <span class="pre">Lasso</span> <span class="pre">podría</span> <span class="pre">ser</span> <span class="pre">una</span> <span class="pre">mejor</span> <span class="pre">opción</span></code>. Del mismo modo, si desea tener un modelo que es fácil de interpretar, <code class="docutils literal notranslate"><span class="pre">Lasso</span> <span class="pre">proporcionará</span> <span class="pre">un</span> <span class="pre">modelo</span> <span class="pre">que</span> <span class="pre">es</span> <span class="pre">más</span> <span class="pre">fácil</span> <span class="pre">de</span> <span class="pre">entender,</span> <span class="pre">ya</span> <span class="pre">que</span> <span class="pre">seleccionará</span> <span class="pre">sólo</span> <span class="pre">un</span> <span class="pre">subconjunto</span> <span class="pre">de</span> <span class="pre">las</span> <span class="pre">características</span> <span class="pre">de</span> <span class="pre">entrada</span></code>.</p></li>
</ul>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code> también proporciona la clase <code class="docutils literal notranslate"><span class="pre">ElasticNet</span></code>, que combina las penalizaciones de <code class="docutils literal notranslate"><span class="pre">Lasso</span></code> y <code class="docutils literal notranslate"><span class="pre">Ridge</span></code>. En la práctica, esta combinación funciona mejor, aunque al precio de tener dos parámetros que ajustar: uno para la regularización <span class="math notranslate nohighlight">\(L^1\)</span>, y otro para la regularización <span class="math notranslate nohighlight">\(L^2\)</span>.</p></li>
</ul>
</section>
<section id="modelos-lineales-para-clasificacion">
<h2>Modelos lineales para clasificación<a class="headerlink" href="#modelos-lineales-para-clasificacion" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Los</span> <span class="pre">modelos</span> <span class="pre">lineales</span> <span class="pre">también</span> <span class="pre">se</span> <span class="pre">utilizan</span> <span class="pre">ampliamente</span> <span class="pre">para</span> <span class="pre">la</span> <span class="pre">clasificación</span></code>. Veamos primero la <code class="docutils literal notranslate"><span class="pre">clasificación</span> <span class="pre">binaria</span></code>. En este caso, la predicción se realiza mediante la siguiente fórmula</p></li>
</ul>
<div class="math notranslate nohighlight" id="equation-linear-class">
<span class="eqno">(16)<a class="headerlink" href="#equation-linear-class" title="Permalink to this equation">#</a></span>\[
\hat{y}=\beta_{0}+\beta_{1}\cdot x_{1}+\beta_{2}\cdot x_{2}+\cdots+\beta_{p}\cdot x_{p}
\]</div>
<ul class="simple">
<li><p>La fórmula es muy similar a la de la regresión lineal, pero <code class="docutils literal notranslate"><span class="pre">en</span> <span class="pre">lugar</span> <span class="pre">de</span> <span class="pre">devolver</span> <span class="pre">simplemente</span> <span class="pre">la</span> <span class="pre">suma</span> <span class="pre">ponderada</span> <span class="pre">de</span> <span class="pre">las</span> <span class="pre">características,</span> <span class="pre">ponemos</span> <span class="pre">un</span> <span class="pre">umbral</span> <span class="pre">al</span> <span class="pre">valor</span> <span class="pre">predicho</span> <span class="pre">en</span> <span class="pre">cero</span></code>. Si la función es menor que cero, predecimos la clase -1; si es mayor que cero, predecimos la clase +1. Esta regla de predicción es común a todos los modelos lineales de clasificación. De nuevo, hay muchas formas diferentes de encontrar los coeficientes <span class="math notranslate nohighlight">\(\boldsymbol{\beta}\)</span>.</p></li>
<li><p>En los modelos lineales de regresión, la salida, <span class="math notranslate nohighlight">\(\hat{y}\)</span>, <code class="docutils literal notranslate"><span class="pre">es</span> <span class="pre">una</span> <span class="pre">función</span> <span class="pre">lineal</span> <span class="pre">de</span> <span class="pre">las</span> <span class="pre">características</span></code>: una <code class="docutils literal notranslate"><span class="pre">línea</span></code>, un <code class="docutils literal notranslate"><span class="pre">plano</span></code> o un <code class="docutils literal notranslate"><span class="pre">hiperplano</span></code>. En los modelos lineales de clasificación, la frontera de decisión es una función lineal de la entrada. En otras palabras, un <code class="docutils literal notranslate"><span class="pre">clasificador</span> <span class="pre">lineal</span> <span class="pre">(binario)</span> <span class="pre">es</span> <span class="pre">un</span> <span class="pre">clasificador</span> <span class="pre">que</span> <span class="pre">separa</span> <span class="pre">dos</span> <span class="pre">clases</span> <span class="pre">utilizando</span> <span class="pre">una</span> <span class="pre">línea,</span> <span class="pre">un</span> <span class="pre">plano</span> <span class="pre">o</span> <span class="pre">un</span> <span class="pre">hiperplano</span></code>.</p></li>
<li><p>Hay muchos algoritmos para aprender modelos lineales. Todos estos algoritmos difieren en los dos aspectos siguientes:</p>
<ul>
<li><p>La forma en que miden <code class="docutils literal notranslate"><span class="pre">que</span> <span class="pre">tan</span> <span class="pre">bien</span> <span class="pre">una</span> <span class="pre">combinación</span> <span class="pre">particular</span> <span class="pre">de</span> <span class="pre">coeficientes</span> <span class="pre">se</span> <span class="pre">ajusta</span> <span class="pre">a</span> <span class="pre">los</span> <span class="pre">datos</span> <span class="pre">de</span> <span class="pre">entrenamiento.</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Si</span> <span class="pre">utilizan</span> <span class="pre">regularización,</span> <span class="pre">de</span> <span class="pre">que</span> <span class="pre">tipo</span> <span class="pre">utilizan</span></code></p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>Los distintos algoritmos eligen diferentes formas de medir lo que significa <code class="docutils literal notranslate"><span class="pre">&quot;ajustarse</span> <span class="pre">bien</span> <span class="pre">al</span> <span class="pre">conjunto</span> <span class="pre">de</span> <span class="pre">entrenamiento&quot;</span></code>. Los dos algoritmos de clasificación lineal más comunes son la <code class="docutils literal notranslate"><span class="pre">regresión</span> <span class="pre">logística</span></code>, implementada en <code class="docutils literal notranslate"><span class="pre">linear_model.LogisticRegression</span></code>, y las <code class="docutils literal notranslate"><span class="pre">máquinas</span> <span class="pre">de</span> <span class="pre">vectores</span> <span class="pre">de</span> <span class="pre">soporte</span> <span class="pre">lineales</span> <span class="pre">(SVMs</span> <span class="pre">lineales)</span></code>, implementadas en <code class="docutils literal notranslate"><span class="pre">svm.LinearSVC</span> <span class="pre">(SVC</span> <span class="pre">significa</span> <span class="pre">clasificador</span> <span class="pre">de</span> <span class="pre">vectores</span> <span class="pre">de</span> <span class="pre">soporte)</span></code>.</p></li>
<li><p>A pesar de su nombre, <code class="docutils literal notranslate"><span class="pre">LogisticRegression</span></code> es un algoritmo de clasificación y no de regresión, por lo tanto no debe confundirse con <code class="docutils literal notranslate"><span class="pre">LinearRegression</span></code>. Podemos aplicar los modelos <code class="docutils literal notranslate"><span class="pre">LogisticRegression</span></code> y <code class="docutils literal notranslate"><span class="pre">LinearSVC</span></code> al conjunto de datos <code class="docutils literal notranslate"><span class="pre">forge</span></code> y visualizar la frontera de decisión encontrada por los modelos lineales.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">LinearSVC</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set_style</span><span class="p">(</span><span class="s2">&quot;darkgrid&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">mglearn</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">make_forge</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>

<span class="k">for</span> <span class="n">model</span><span class="p">,</span> <span class="n">ax</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">([</span><span class="n">LinearSVC</span><span class="p">(),</span> <span class="n">LogisticRegression</span><span class="p">()],</span> <span class="n">axes</span><span class="p">):</span>
    <span class="n">clf</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">mglearn</span><span class="o">.</span><span class="n">plots</span><span class="o">.</span><span class="n">plot_2d_separator</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">fill</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">.7</span><span class="p">)</span>
    <span class="n">mglearn</span><span class="o">.</span><span class="n">discrete_scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">y</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">clf</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">))</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Feature 0&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Feature 1&quot;</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/508916006be05b74697bcd0caadaffdf256205846bccc84c9dc2aee0ed5812f9.png" src="_images/508916006be05b74697bcd0caadaffdf256205846bccc84c9dc2aee0ed5812f9.png" />
</div>
</div>
<ul class="simple">
<li><p>En esta figura, tenemos la primera característica del conjunto de datos <code class="docutils literal notranslate"><span class="pre">forge</span></code> en el eje <span class="math notranslate nohighlight">\(x\)</span> y la segunda característica en el eje <span class="math notranslate nohighlight">\(y\)</span>, como antes. Se muestran las <code class="docutils literal notranslate"><span class="pre">fronteras</span> <span class="pre">de</span> <span class="pre">decisión</span> <span class="pre">encontrados</span> <span class="pre">por</span> <span class="pre">LinearSVC</span> <span class="pre">y</span> <span class="pre">LogisticRegression</span></code> respectivamente como <code class="docutils literal notranslate"><span class="pre">líneas</span> <span class="pre">rectas,</span> <span class="pre">separando</span> <span class="pre">el</span> <span class="pre">área</span> <span class="pre">clasificada</span> <span class="pre">como</span> <span class="pre">clase</span> <span class="pre">1</span> <span class="pre">en</span> <span class="pre">la</span> <span class="pre">parte</span> <span class="pre">superior,</span> <span class="pre">del</span> <span class="pre">área</span> <span class="pre">clasificada</span> <span class="pre">como</span> <span class="pre">clase</span> <span class="pre">0</span> <span class="pre">en</span> <span class="pre">la</span> <span class="pre">parte</span> <span class="pre">inferior</span></code>.</p></li>
<li><p>En otras palabras, cualquier nuevo punto de datos que se encuentre por encima de la línea negra será clasificado como clase 1 por el clasificador respectivo, mientras que cualquier punto que se encuentre por debajo de la línea negra será clasificado como clase 0. Los dos modelos entregan fronteras de decisión similares. <code class="docutils literal notranslate"><span class="pre">Obsérvese</span> <span class="pre">que</span> <span class="pre">ambos</span> <span class="pre">clasifican</span> <span class="pre">erróneamente</span> <span class="pre">dos</span> <span class="pre">de</span> <span class="pre">los</span> <span class="pre">puntos</span></code>.</p></li>
</ul>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Por</span> <span class="pre">defecto,</span> <span class="pre">ambos</span> <span class="pre">modelos</span> <span class="pre">aplican</span> <span class="pre">una</span> <span class="pre">regularización</span></code> <span class="math notranslate nohighlight">\(L^{2}\)</span>, <code class="docutils literal notranslate"><span class="pre">de</span> <span class="pre">la</span> <span class="pre">misma</span> <span class="pre">manera</span> <span class="pre">que</span> <span class="pre">lo</span> <span class="pre">hace</span> <span class="pre">Ridge</span> <span class="pre">para</span> <span class="pre">la</span> <span class="pre">regresión</span></code>. Para <code class="docutils literal notranslate"><span class="pre">LogisticRegression</span></code> y <code class="docutils literal notranslate"><span class="pre">LinearSVC</span></code> el parámetro de compensación que determina la fuerza de la regularización se llama <code class="docutils literal notranslate"><span class="pre">C</span></code>, y <code class="docutils literal notranslate"><span class="pre">los</span> <span class="pre">valores</span> <span class="pre">más</span> <span class="pre">altos</span> <span class="pre">de</span> <span class="pre">C</span> <span class="pre">corresponden</span> <span class="pre">a</span> <span class="pre">menor</span> <span class="pre">regularización</span></code>.</p></li>
</ul>
<ul class="simple">
<li><p>Hay otro aspecto interesante de cómo actúa el parámetro <code class="docutils literal notranslate"><span class="pre">C</span></code>. El uso de <code class="docutils literal notranslate"><span class="pre">valores</span> <span class="pre">bajos</span> <span class="pre">de</span> <span class="pre">C</span> <span class="pre">harán</span> <span class="pre">que</span> <span class="pre">los</span> <span class="pre">algoritmos</span> <span class="pre">traten</span> <span class="pre">de</span> <span class="pre">ajustarse</span> <span class="pre">a</span> <span class="pre">la</span> <span class="pre">&quot;mayoría&quot;</span> <span class="pre">de</span> <span class="pre">los</span> <span class="pre">puntos</span> <span class="pre">de</span> <span class="pre">datos</span></code>, mientras que <code class="docutils literal notranslate"><span class="pre">el</span> <span class="pre">uso</span> <span class="pre">de</span> <span class="pre">valores</span> <span class="pre">más</span> <span class="pre">altos</span> <span class="pre">de</span> <span class="pre">C</span> <span class="pre">enfatiza</span> <span class="pre">la</span> <span class="pre">importancia</span> <span class="pre">de</span> <span class="pre">que</span> <span class="pre">cada</span> <span class="pre">punto</span> <span class="pre">de</span> <span class="pre">datos</span> <span class="pre">individual</span> <span class="pre">sea</span> <span class="pre">clasificado</span> <span class="pre">correctamente</span></code>. Veamos una ilustración utilizando <code class="docutils literal notranslate"><span class="pre">LinearSVC</span></code>.</p></li>
</ul>
<ul class="simple">
<li><p>En otras palabras, cuando se utiliza un valor alto para el parámetro <code class="docutils literal notranslate"><span class="pre">C</span></code>, <code class="docutils literal notranslate"><span class="pre">LogisticRegression</span></code> y <code class="docutils literal notranslate"><span class="pre">LinearSVC</span></code> intentan ajustarse al conjunto de entrenamiento lo mejor posible, mientras que con valores bajos del parámetro <code class="docutils literal notranslate"><span class="pre">C</span></code>, los modelos ponen más énfasis en encontrar un vector de coeficientes <span class="math notranslate nohighlight">\(\boldsymbol{\beta}\)</span> que se acerque a cero.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mglearn</span><span class="o">.</span><span class="n">plots</span><span class="o">.</span><span class="n">plot_linear_svc_regularization</span><span class="p">();</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/f1e9bfee555c8ef83f9f65bc2ce154b22607fd77531a97fb21d1c1671b96d5d3.png" src="_images/f1e9bfee555c8ef83f9f65bc2ce154b22607fd77531a97fb21d1c1671b96d5d3.png" />
</div>
</div>
<ul class="simple">
<li><p>En el lado izquierdo, tenemos un <code class="docutils literal notranslate"><span class="pre">valor</span> <span class="pre">de</span></code> <span class="math notranslate nohighlight">\(C\)</span> <code class="docutils literal notranslate"><span class="pre">muy</span> <span class="pre">pequeño</span></code> (<span class="math notranslate nohighlight">\(C=0.01\)</span>) <code class="docutils literal notranslate"><span class="pre">que</span> <span class="pre">corresponde</span> <span class="pre">a</span> <span class="pre">una</span> <span class="pre">gran</span> <span class="pre">regularización</span></code>. La mayoría de los puntos de la clase 0 están en la parte superior, y la mayoría de los puntos de la clase 1 están en la parte inferior. <code class="docutils literal notranslate"><span class="pre">El</span> <span class="pre">modelo</span> <span class="pre">fuertemente</span> <span class="pre">regularizado</span> <span class="pre">elige</span> <span class="pre">una</span> <span class="pre">línea</span> <span class="pre">relativamente</span> <span class="pre">horizontal,</span> <span class="pre">clasificando</span> <span class="pre">erróneamente</span> <span class="pre">dos</span> <span class="pre">puntos</span></code>.</p></li>
<li><p>En el gráfico central, <span class="math notranslate nohighlight">\(C\)</span> es ligeramente más alto (<span class="math notranslate nohighlight">\(C=10\)</span>), y <code class="docutils literal notranslate"><span class="pre">el</span> <span class="pre">modelo</span> <span class="pre">se</span> <span class="pre">centra</span> <span class="pre">más</span> <span class="pre">en</span> <span class="pre">las</span> <span class="pre">dos</span> <span class="pre">muestras</span> <span class="pre">mal</span> <span class="pre">clasificadas,</span> <span class="pre">inclinando</span> <span class="pre">el</span> <span class="pre">límite</span> <span class="pre">de</span> <span class="pre">decisión</span></code>. Por último, en el lado derecho, correspondiente al <code class="docutils literal notranslate"><span class="pre">valor</span> <span class="pre">mas</span> <span class="pre">alto</span> <span class="pre">de</span></code> <span class="math notranslate nohighlight">\(C\)</span> (<span class="math notranslate nohighlight">\(C=1000\)</span>), <code class="docutils literal notranslate"><span class="pre">el</span> <span class="pre">modelo</span> <span class="pre">inclina</span> <span class="pre">mucho</span> <span class="pre">mas</span> <span class="pre">la</span> <span class="pre">frontera</span> <span class="pre">de</span> <span class="pre">decisión,</span> <span class="pre">clasificando</span> <span class="pre">ahora</span> <span class="pre">correctamente</span> <span class="pre">todos</span> <span class="pre">los</span> <span class="pre">puntos</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">clase</span> <span class="pre">0</span></code>. Solo <code class="docutils literal notranslate"><span class="pre">uno</span> <span class="pre">de</span> <span class="pre">los</span> <span class="pre">puntos</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">clase</span> <span class="pre">1</span> <span class="pre">sigue</span> <span class="pre">estando</span> <span class="pre">mal</span> <span class="pre">clasificado</span></code>, ya que no es posible clasificar correctamente todos los puntos de este conjunto de datos utilizando una línea recta.</p></li>
<li><p>El modelo ilustrado en la parte derecha se esfuerza por clasificar correctamente todos los puntos, pero puede que no capte bien la disposición general de las clases. En otras palabras, <code class="docutils literal notranslate"><span class="pre">es</span> <span class="pre">probable</span> <span class="pre">que</span> <span class="pre">el</span> <span class="pre">modelo</span> <span class="pre">ilustrado</span> <span class="pre">en</span> <span class="pre">la</span> <span class="pre">derecha</span> <span class="pre">presente</span> <span class="pre">overfitting</span></code>. Al igual que en el caso de la regresión, los modelos lineales de clasificación pueden parecer muy restrictivos en espacios de baja dimensión, ya que sólo permiten límites de decisión que sean líneas rectas o planos.</p></li>
<li><p>De nuevo, <code class="docutils literal notranslate"><span class="pre">en</span> <span class="pre">dimensiones</span> <span class="pre">altas,</span> <span class="pre">los</span> <span class="pre">modelos</span> <span class="pre">lineales</span> <span class="pre">de</span> <span class="pre">clasificación</span> <span class="pre">se</span> <span class="pre">vuelven</span> <span class="pre">muy</span> <span class="pre">potentes,</span> <span class="pre">y</span> <span class="pre">la</span> <span class="pre">protección</span> <span class="pre">contra</span> <span class="pre">el</span> <span class="pre">overfitting</span> <span class="pre">es</span> <span class="pre">cada</span> <span class="pre">vez</span> <span class="pre">más</span> <span class="pre">importante</span> <span class="pre">cuando</span> <span class="pre">se</span> <span class="pre">consideran</span> <span class="pre">más</span> <span class="pre">características</span></code>.</p></li>
</ul>
<ul class="simple">
<li><p>Analicemos <code class="docutils literal notranslate"><span class="pre">LinearLogistic</span></code> con más detalle en el conjunto de datos de <code class="docutils literal notranslate"><span class="pre">cáncer</span> <span class="pre">de</span> <span class="pre">mama</span></code>:</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_breast_cancer</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cancer</span> <span class="o">=</span> <span class="n">load_breast_cancer</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">cancer</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> 
                                                    <span class="n">cancer</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> 
                                                    <span class="n">stratify</span><span class="o">=</span><span class="n">cancer</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> 
                                                    <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">logreg</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training set score: </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">logreg</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test set score: </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">logreg</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training set score: 0.955
Test set score: 0.951
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>El valor por defecto de <span class="math notranslate nohighlight">\(C=1\)</span> proporciona un rendimiento bastante bueno, con una <code class="docutils literal notranslate"><span class="pre">precisión</span> <span class="pre">del</span> <span class="pre">95%</span> <span class="pre">tanto</span> <span class="pre">en</span> <span class="pre">el</span> <span class="pre">conjunto</span> <span class="pre">de</span> <span class="pre">entrenamiento</span> <span class="pre">como</span> <span class="pre">en</span> <span class="pre">el</span> <span class="pre">de</span> <span class="pre">prueba</span></code>. Si intentamos aumentar <span class="math notranslate nohighlight">\(C\)</span> obtenemos un modelo más complejo</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">logreg100</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">C</span><span class="o">=</span><span class="mi">1000000</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training set score: </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">logreg100</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test set score: </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">logreg100</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training set score: 0.960
Test set score: 0.958
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>El uso de <span class="math notranslate nohighlight">\(C=1000000\)</span> da lugar a una <code class="docutils literal notranslate"><span class="pre">mayor</span> <span class="pre">precisión</span> <span class="pre">en</span> <span class="pre">el</span> <span class="pre">conjunto</span> <span class="pre">de</span> <span class="pre">entrenamiento</span></code>. También podemos investigar qué ocurre si utilizamos un modelo aún más regularizado que el predeterminado de <span class="math notranslate nohighlight">\(C=1\)</span>, estableciendo <span class="math notranslate nohighlight">\(C=0.01\)</span></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">logreg001</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">C</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training set score: </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">logreg001</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test set score: </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">logreg001</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training set score: 0.934
Test set score: 0.930
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Cuando se desplaza más hacia la izquierda en la escala mostrada en la <a class="reference internal" href="supervised_intro.html#fig-sweet-spot"><span class="std std-numref">Fig. 3</span></a> e obtiene un <code class="docutils literal notranslate"><span class="pre">modelo</span> <span class="pre">subjustado,</span> <span class="pre">tanto</span> <span class="pre">la</span> <span class="pre">precisión</span> <span class="pre">del</span> <span class="pre">conjunto</span> <span class="pre">de</span> <span class="pre">entrenamiento</span> <span class="pre">como</span> <span class="pre">la</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">prueba</span> <span class="pre">disminuyen</span> <span class="pre">en</span> <span class="pre">relación</span> <span class="pre">con</span> <span class="pre">los</span> <span class="pre">parámetros</span> <span class="pre">por</span> <span class="pre">defecto</span></code>. Por último, veamos los coeficientes aprendidos por los modelos con las tres configuraciones diferentes de los parámetros de regularización <span class="math notranslate nohighlight">\(C\)</span></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">font_scale</span><span class="o">=</span><span class="mf">1.4</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">logreg</span><span class="o">.</span><span class="n">coef_</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;C=1&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">logreg100</span><span class="o">.</span><span class="n">coef_</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="s1">&#39;^&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;C=100&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">logreg001</span><span class="o">.</span><span class="n">coef_</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="s1">&#39;v&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;C=0.001&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">cancer</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="n">cancer</span><span class="o">.</span><span class="n">feature_names</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">90</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hlines</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">cancer</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Coefficient index&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Coefficient magnitude&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/05ebde705c2710e39267f82d9458fb6b69fa207b9d8539f698774fcdbf6d793b.png" src="_images/05ebde705c2710e39267f82d9458fb6b69fa207b9d8539f698774fcdbf6d793b.png" />
</div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Si</span> <span class="pre">deseamos</span> <span class="pre">un</span> <span class="pre">modelo</span> <span class="pre">más</span> <span class="pre">interpretable,</span> <span class="pre">el</span> <span class="pre">uso</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">regularización</span></code> <span class="math notranslate nohighlight">\(L^{1}\)</span> <code class="docutils literal notranslate"><span class="pre">podría</span> <span class="pre">ayudar,</span> <span class="pre">ya</span> <span class="pre">que</span> <span class="pre">limita</span> <span class="pre">el</span> <span class="pre">modelo</span> <span class="pre">a</span> <span class="pre">utilizar</span> <span class="pre">sólo</span> <span class="pre">unas</span> <span class="pre">pocas</span> <span class="pre">características</span></code>. El siguiente es el gráfico de coeficientes y las precisiones de clasificación para la regularización <span class="math notranslate nohighlight">\(L^{1}\)</span></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">font_scale</span><span class="o">=</span><span class="mf">1.4</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="k">for</span> <span class="n">C</span><span class="p">,</span> <span class="n">marker</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">([</span><span class="mf">0.001</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">100</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="s1">&#39;^&#39;</span><span class="p">,</span> <span class="s1">&#39;v&#39;</span><span class="p">]):</span>
    <span class="n">lr_l1</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">C</span><span class="o">=</span><span class="n">C</span><span class="p">,</span> 
                               <span class="n">penalty</span><span class="o">=</span><span class="s2">&quot;l1&quot;</span><span class="p">,</span> 
                               <span class="n">solver</span><span class="o">=</span><span class="s1">&#39;liblinear&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training accuracy of l1 logreg with C=</span><span class="si">{:.3f}</span><span class="s2">: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
        <span class="n">C</span><span class="p">,</span> <span class="n">lr_l1</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test accuracy of l1 logreg with C=</span><span class="si">{:.3f}</span><span class="s2">: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
        <span class="n">C</span><span class="p">,</span> <span class="n">lr_l1</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lr_l1</span><span class="o">.</span><span class="n">coef_</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">marker</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;C=</span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">C</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">cancer</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="n">cancer</span><span class="o">.</span><span class="n">feature_names</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">90</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hlines</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">cancer</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Coefficient index&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Coefficient magnitude&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">3</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training accuracy of l1 logreg with C=0.001: 0.91
Test accuracy of l1 logreg with C=0.001: 0.92
Training accuracy of l1 logreg with C=1.000: 0.96
Test accuracy of l1 logreg with C=1.000: 0.96
Training accuracy of l1 logreg with C=100.000: 0.99
Test accuracy of l1 logreg with C=100.000: 0.98
</pre></div>
</div>
<img alt="_images/6f6bd1a32c69c7108c566b002beb43caa9229244e19aa4a93de2406b5a7407e6.png" src="_images/6f6bd1a32c69c7108c566b002beb43caa9229244e19aa4a93de2406b5a7407e6.png" />
</div>
</div>
<ul class="simple">
<li><p>Como puede ver, <code class="docutils literal notranslate"><span class="pre">hay</span> <span class="pre">mucha</span> <span class="pre">similitud</span> <span class="pre">entre</span> <span class="pre">los</span> <span class="pre">modelos</span> <span class="pre">lineales</span> <span class="pre">de</span> <span class="pre">clasificación</span> <span class="pre">binaria</span> <span class="pre">y</span> <span class="pre">los</span> <span class="pre">modelos</span> <span class="pre">lineales</span> <span class="pre">de</span> <span class="pre">regresión</span></code>. Como en la regresión, la principal diferencia entre los modelos es el parámetro de penalización, que influye en la regularización, <code class="docutils literal notranslate"><span class="pre">en</span> <span class="pre">si</span> <span class="pre">el</span> <span class="pre">modelo</span> <span class="pre">utilizará</span> <span class="pre">todas</span> <span class="pre">las</span> <span class="pre">características</span> <span class="pre">disponibles</span> <span class="pre">o</span> <span class="pre">seleccionará</span> <span class="pre">sólo</span> <span class="pre">un</span> <span class="pre">subconjunto.</span></code></p></li>
</ul>
</section>
<section id="modelos-lineales-para-la-clasificacion-multiclase">
<h2>Modelos lineales para la clasificación multiclase<a class="headerlink" href="#modelos-lineales-para-la-clasificacion-multiclase" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Muchos modelos de clasificación lineal sólo sirven para la clasificación binaria y no se extienden de forma natural al caso multiclase (con la excepción de la <code class="docutils literal notranslate"><span class="pre">regresión</span> <span class="pre">logística</span></code>). Una técnica común para extender un algoritmo de clasificación binaria a un <code class="docutils literal notranslate"><span class="pre">algoritmo</span> <span class="pre">de</span> <span class="pre">clasificación</span> <span class="pre">multiclase</span></code> es el enfoque <code class="docutils literal notranslate"><span class="pre">one-vs.-rest</span></code>. En el enfoque <code class="docutils literal notranslate"><span class="pre">one-vs.-rest</span></code>, <code class="docutils literal notranslate"><span class="pre">se</span> <span class="pre">aprende</span> <span class="pre">un</span> <span class="pre">modelo</span> <span class="pre">binario</span> <span class="pre">para</span> <span class="pre">cada</span> <span class="pre">clase</span> <span class="pre">fija,</span> <span class="pre">el</span> <span class="pre">cual</span> <span class="pre">intenta</span> <span class="pre">separar</span> <span class="pre">esa</span> <span class="pre">clase</span> <span class="pre">de</span> <span class="pre">todas</span> <span class="pre">las</span> <span class="pre">demás,</span> <span class="pre">lo</span> <span class="pre">cual</span> <span class="pre">da</span> <span class="pre">lugar</span> <span class="pre">a</span> <span class="pre">tantos</span> <span class="pre">modelos</span> <span class="pre">binarios</span> <span class="pre">como</span> <span class="pre">clases</span> <span class="pre">exista</span></code>.</p></li>
<li><p>Para hacer una predicción, se ejecutan todos los clasificadores binarios en un punto de prueba. <code class="docutils literal notranslate"><span class="pre">El</span> <span class="pre">clasificador</span> <span class="pre">que</span> <span class="pre">tenga</span> <span class="pre">la</span> <span class="pre">mayor</span> <span class="pre">puntuación</span> <span class="pre">en</span> <span class="pre">su</span> <span class="pre">clase</span> <span class="pre">&quot;gana&quot;,</span> <span class="pre">y</span> <span class="pre">esta</span> <span class="pre">etiqueta</span> <span class="pre">de</span> <span class="pre">clase</span> <span class="pre">se</span> <span class="pre">devuelve</span> <span class="pre">como</span> <span class="pre">predicción</span></code>. Al tener un clasificador binario por clase, se tiene un vector de coeficientes <span class="math notranslate nohighlight">\(\boldsymbol{\beta}\)</span> para cada clase. La clase para la que el resultado de la fórmula de clasificación dada aquí, es la más alta, es la etiqueta de clase asignada:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\beta_{0}+\beta_{1}\cdot x_{1}+\beta_{2}\cdot x_{2}+\cdots+\beta_{p}\cdot x_{p}
\]</div>
<ul class="simple">
<li><p>Las matemáticas que subyacen a la <code class="docutils literal notranslate"><span class="pre">regresión</span> <span class="pre">logística</span> <span class="pre">multiclase</span></code> difieren en cierta medida del enfoque de una sola clase, pero también dan como resultado un <code class="docutils literal notranslate"><span class="pre">vector</span> <span class="pre">de</span> <span class="pre">coeficientes</span> <span class="pre">y</span> <span class="pre">un</span> <span class="pre">intercepto</span> <span class="pre">por</span> <span class="pre">clase,</span> <span class="pre">y</span> <span class="pre">se</span> <span class="pre">aplica</span> <span class="pre">el</span> <span class="pre">mismo</span> <span class="pre">método</span> <span class="pre">para</span> <span class="pre">hacer</span> <span class="pre">una</span> <span class="pre">predicción</span></code>. Apliquemos el método de <code class="docutils literal notranslate"><span class="pre">one-vs.-rest</span></code> a un conjunto de datos de clasificación de tres clases. Utilizamos un <code class="docutils literal notranslate"><span class="pre">conjunto</span> <span class="pre">de</span> <span class="pre">datos</span> <span class="pre">bidimensional,</span> <span class="pre">en</span> <span class="pre">el</span> <span class="pre">que</span> <span class="pre">cada</span> <span class="pre">clase</span> <span class="pre">viene</span> <span class="pre">dada</span> <span class="pre">por</span> <span class="pre">datos</span> <span class="pre">muestreados</span> <span class="pre">de</span> <span class="pre">una</span> <span class="pre">distribución</span> <span class="pre">gaussiana.</span></code></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_blobs</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_blobs</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">mglearn</span><span class="o">.</span><span class="n">discrete_scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">y</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Feature 0&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Feature 1&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s2">&quot;Class 0&quot;</span><span class="p">,</span> <span class="s2">&quot;Class 1&quot;</span><span class="p">,</span> <span class="s2">&quot;Class 2&quot;</span><span class="p">]);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/53c04a4c01f06a4e7490bdb5135467da9e7500ef870d821ddf339e0665e5d7e9.png" src="_images/53c04a4c01f06a4e7490bdb5135467da9e7500ef870d821ddf339e0665e5d7e9.png" />
</div>
</div>
<ul class="simple">
<li><p>Ahora, entrenamos un clasificador <code class="docutils literal notranslate"><span class="pre">LinearSVC</span></code> en el conjunto de datos</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">linear_svm</span> <span class="o">=</span> <span class="n">LinearSVC</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Coefficient shape: &quot;</span><span class="p">,</span> <span class="n">linear_svm</span><span class="o">.</span><span class="n">coef_</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Intercept shape: &quot;</span><span class="p">,</span> <span class="n">linear_svm</span><span class="o">.</span><span class="n">intercept_</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Coefficient shape:  (3, 2)
Intercept shape:  (3,)
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Vemos que la dimensión (<code class="docutils literal notranslate"><span class="pre">shape</span></code>) de <code class="docutils literal notranslate"><span class="pre">coef_</span></code> es <code class="docutils literal notranslate"><span class="pre">(3,</span> <span class="pre">2)</span></code>, lo que significa que <code class="docutils literal notranslate"><span class="pre">cada</span> <span class="pre">fila</span> <span class="pre">de</span> <span class="pre">coef_</span> <span class="pre">contiene</span> <span class="pre">el</span> <span class="pre">vector</span> <span class="pre">de</span> <span class="pre">coeficientes</span> <span class="pre">para</span> <span class="pre">cada</span> <span class="pre">una</span> <span class="pre">de</span> <span class="pre">las</span> <span class="pre">tres</span> <span class="pre">clases</span></code> y <code class="docutils literal notranslate"><span class="pre">cada</span> <span class="pre">columna</span> <span class="pre">contiene</span> <span class="pre">el</span> <span class="pre">valor</span> <span class="pre">del</span> <span class="pre">coeficiente</span> <span class="pre">para</span> <span class="pre">cada</span> <span class="pre">característica</span> <span class="pre">específica</span></code> (hay dos en este conjunto de datos).</p></li>
<li><p>La matriz <code class="docutils literal notranslate"><span class="pre">intercept_</span> <span class="pre">es</span> <span class="pre">ahora</span> <span class="pre">una</span> <span class="pre">matriz</span> <span class="pre">unidimensional</span> <span class="pre">que</span> <span class="pre">almacena</span> <span class="pre">los</span> <span class="pre">interceptos</span> <span class="pre">de</span> <span class="pre">cada</span> <span class="pre">clase</span></code>. Visualicemos las líneas dadas por los tres clasificadores binarios. En este caso <code class="docutils literal notranslate"><span class="pre">line=x</span></code>, para el clasificador separador <code class="docutils literal notranslate"><span class="pre">ax+by+c=0</span></code>.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mglearn</span><span class="o">.</span><span class="n">discrete_scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">y</span><span class="p">)</span>
<span class="n">line</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">15</span><span class="p">,</span> <span class="mi">15</span><span class="p">)</span>

<span class="k">for</span> <span class="n">coef</span><span class="p">,</span> <span class="n">intercept</span><span class="p">,</span> <span class="n">color</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">linear_svm</span><span class="o">.</span><span class="n">coef_</span><span class="p">,</span> <span class="n">linear_svm</span><span class="o">.</span><span class="n">intercept_</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="s1">&#39;g&#39;</span><span class="p">]):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">line</span><span class="p">,</span> <span class="o">-</span><span class="p">(</span><span class="n">line</span> <span class="o">*</span> <span class="n">coef</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">intercept</span><span class="p">)</span> <span class="o">/</span> <span class="n">coef</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">color</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="mi">15</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Feature 0&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Feature 1&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">&#39;Class 0&#39;</span><span class="p">,</span> <span class="s1">&#39;Class 1&#39;</span><span class="p">,</span> <span class="s1">&#39;Class 2&#39;</span><span class="p">,</span> <span class="s1">&#39;Line class 0&#39;</span><span class="p">,</span> <span class="s1">&#39;Line class 1&#39;</span><span class="p">,</span> 
                <span class="s1">&#39;Line class 2&#39;</span><span class="p">],</span> <span class="n">loc</span><span class="o">=</span><span class="p">(</span><span class="mf">1.01</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/b3fc909542e9daab34e489446af86a9ac474473a5558d00865f975833ee4ef6b.png" src="_images/b3fc909542e9daab34e489446af86a9ac474473a5558d00865f975833ee4ef6b.png" />
</div>
</div>
<ul class="simple">
<li><p>Se puede ver que <code class="docutils literal notranslate"><span class="pre">todos</span> <span class="pre">los</span> <span class="pre">puntos</span> <span class="pre">que</span> <span class="pre">pertenecen</span> <span class="pre">a</span> <span class="pre">la</span> <span class="pre">clase</span> <span class="pre">0</span> <span class="pre">en</span> <span class="pre">los</span> <span class="pre">datos</span> <span class="pre">de</span> <span class="pre">entrenamiento</span> <span class="pre">están</span> <span class="pre">por</span> <span class="pre">encima</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">línea</span> <span class="pre">correspondiente</span> <span class="pre">a</span> <span class="pre">la</span> <span class="pre">clase</span> <span class="pre">0</span></code>, lo que significa que están en el lado de la “clase 0” de este clasificador binario. Además, <code class="docutils literal notranslate"><span class="pre">los</span> <span class="pre">puntos</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">clase</span> <span class="pre">0</span> <span class="pre">están</span> <span class="pre">por</span> <span class="pre">encima</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">línea</span> <span class="pre">correspondiente</span> <span class="pre">a</span> <span class="pre">la</span> <span class="pre">clase</span> <span class="pre">2,</span> <span class="pre">lo</span> <span class="pre">que</span> <span class="pre">significa</span> <span class="pre">que</span> <span class="pre">son</span> <span class="pre">clasificados</span> <span class="pre">como</span> <span class="pre">&quot;resto&quot;</span> <span class="pre">por</span> <span class="pre">el</span> <span class="pre">clasificador</span> <span class="pre">binario</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">clase</span> <span class="pre">2</span></code>.</p></li>
<li><p>Los puntos que pertenecen a la clase 0 están a la izquierda de la línea correspondiente a la clase 1, lo que significa que el clasificador binario para la clase 1 también los clasifica como “resto”. Por tanto, cualquier punto de esta zona será clasificado como clase 0 por el clasificador final (<code class="docutils literal notranslate"><span class="pre">el</span> <span class="pre">resultado</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">fórmula</span> <span class="pre">de</span> <span class="pre">confianza</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">clasificación</span> <span class="pre">para</span> <span class="pre">el</span> <span class="pre">clasificador</span> <span class="pre">0</span> <span class="pre">es</span> <span class="pre">mayor</span> <span class="pre">que</span> <span class="pre">cero,</span> <span class="pre">mientras</span> <span class="pre">que</span> <span class="pre">es</span> <span class="pre">menor</span> <span class="pre">que</span> <span class="pre">cero</span> <span class="pre">para</span> <span class="pre">las</span> <span class="pre">otras</span> <span class="pre">dos</span> <span class="pre">clases</span></code>).</p></li>
<li><p>Pero, <code class="docutils literal notranslate"><span class="pre">¿qué</span> <span class="pre">ocurre</span> <span class="pre">con</span> <span class="pre">el</span> <span class="pre">triángulo</span> <span class="pre">del</span> <span class="pre">centro</span> <span class="pre">del</span> <span class="pre">gráfico?</span> <span class="pre">Los</span> <span class="pre">tres</span> <span class="pre">clasificadores</span> <span class="pre">binarios</span> <span class="pre">clasifican</span> <span class="pre">los</span> <span class="pre">puntos</span> <span class="pre">allí</span> <span class="pre">como</span> <span class="pre">&quot;resto&quot;</span></code>. <code class="docutils literal notranslate"><span class="pre">¿A</span> <span class="pre">qué</span> <span class="pre">clase</span> <span class="pre">se</span> <span class="pre">asignaría</span> <span class="pre">un</span> <span class="pre">punto</span> <span class="pre">allí?</span></code> La respuesta es, la que tiene el valor más alto de la fórmula de clasificación: <code class="docutils literal notranslate"><span class="pre">la</span> <span class="pre">clase</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">línea</span> <span class="pre">más</span> <span class="pre">cercana</span></code>.</p></li>
<li><p>El siguiente ejemplo muestra las <code class="docutils literal notranslate"><span class="pre">predicciones</span> <span class="pre">para</span> <span class="pre">todas</span> <span class="pre">las</span> <span class="pre">regiones</span> <span class="pre">del</span> <span class="pre">espacio</span> <span class="pre">2D</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">zona</span></code></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mglearn</span><span class="o">.</span><span class="n">plots</span><span class="o">.</span><span class="n">plot_2d_classification</span><span class="p">(</span><span class="n">linear_svm</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">fill</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">.7</span><span class="p">)</span>
<span class="n">mglearn</span><span class="o">.</span><span class="n">discrete_scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">y</span><span class="p">)</span>
<span class="n">line</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">15</span><span class="p">,</span> <span class="mi">15</span><span class="p">)</span>

<span class="k">for</span> <span class="n">coef</span><span class="p">,</span> <span class="n">intercept</span><span class="p">,</span> <span class="n">color</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">linear_svm</span><span class="o">.</span><span class="n">coef_</span><span class="p">,</span> <span class="n">linear_svm</span><span class="o">.</span><span class="n">intercept_</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="s1">&#39;g&#39;</span><span class="p">]):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">line</span><span class="p">,</span> <span class="o">-</span><span class="p">(</span><span class="n">line</span> <span class="o">*</span> <span class="n">coef</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">intercept</span><span class="p">)</span> <span class="o">/</span> <span class="n">coef</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">color</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">&#39;Class 0&#39;</span><span class="p">,</span> <span class="s1">&#39;Class 1&#39;</span><span class="p">,</span> <span class="s1">&#39;Class 2&#39;</span><span class="p">,</span> <span class="s1">&#39;Line class 0&#39;</span><span class="p">,</span> <span class="s1">&#39;Line class 1&#39;</span><span class="p">,</span>
                <span class="s1">&#39;Line class 2&#39;</span><span class="p">],</span> <span class="n">loc</span><span class="o">=</span><span class="p">(</span><span class="mf">1.01</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Feature 0&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Feature 1&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/e707b6086af7bb86483c3a5daa2f82a299ea6cd5dee33c659a0c0dc9ac66e566.png" src="_images/e707b6086af7bb86483c3a5daa2f82a299ea6cd5dee33c659a0c0dc9ac66e566.png" />
</div>
</div>
<div class="tip admonition">
<p class="admonition-title">Puntos fuertes, puntos débiles y parámetros</p>
<ul class="simple">
<li><p>El parámetro principal de los modelos lineales es el parámetro de regularización, llamado <code class="docutils literal notranslate"><span class="pre">alpha</span></code> en los modelos de regresión y <code class="docutils literal notranslate"><span class="pre">C</span></code> en <code class="docutils literal notranslate"><span class="pre">LinearSVC</span></code> y <code class="docutils literal notranslate"><span class="pre">LogisticRegression</span></code>. Los <code class="docutils literal notranslate"><span class="pre">valores</span> <span class="pre">grandes</span> <span class="pre">de</span> <span class="pre">alpha</span> <span class="pre">o</span> <span class="pre">valores</span> <span class="pre">pequeños</span> <span class="pre">de</span> <span class="pre">C</span> <span class="pre">están</span> <span class="pre">asociados</span> <span class="pre">con</span> <span class="pre">modelos</span> <span class="pre">simples</span></code>. En particular, para los modelos de regresión, el ajuste de estos parámetros es bastante importante. Normalmente, <code class="docutils literal notranslate"><span class="pre">C</span></code> y <code class="docutils literal notranslate"><span class="pre">alpha</span></code> se buscan en una escala logarítmica.</p></li>
<li><p>La otra decisión que hay que tomar es si se quiere utilizar la regularización <span class="math notranslate nohighlight">\(L^1\)</span> o la regularización <span class="math notranslate nohighlight">\(L^2\)</span>. <code class="docutils literal notranslate"><span class="pre">Si</span> <span class="pre">se</span> <span class="pre">supone</span> <span class="pre">que</span> <span class="pre">sólo</span> <span class="pre">unas</span> <span class="pre">pocas</span> <span class="pre">características</span> <span class="pre">son</span> <span class="pre">realmente</span> <span class="pre">importantes,</span> <span class="pre">se</span> <span class="pre">debería</span> <span class="pre">utilizar</span> <span class="pre">la</span> <span class="pre">regularización</span></code> <span class="math notranslate nohighlight">\(L^1\)</span>, <code class="docutils literal notranslate"><span class="pre">de</span> <span class="pre">lo</span> <span class="pre">contrario,</span> <span class="pre">debería</span> <span class="pre">utilizar</span></code> <span class="math notranslate nohighlight">\(L^2\)</span> <code class="docutils literal notranslate"><span class="pre">por</span> <span class="pre">defecto</span></code>. <span class="math notranslate nohighlight">\(L^1\)</span> <code class="docutils literal notranslate"><span class="pre">también</span> <span class="pre">puede</span> <span class="pre">ser</span> <span class="pre">útil</span> <span class="pre">si</span> <span class="pre">la</span> <span class="pre">interpretabilidad</span> <span class="pre">del</span> <span class="pre">modelo</span> <span class="pre">es</span> <span class="pre">importante</span></code>. Como <span class="math notranslate nohighlight">\(L^1\)</span> utilizará sólo unas pocas características, es más fácil explicar qué características son importantes para el modelo, y cuáles son los efectos de esas características.</p></li>
<li><p>Los <code class="docutils literal notranslate"><span class="pre">modelos</span> <span class="pre">lineales</span> <span class="pre">son</span> <span class="pre">muy</span> <span class="pre">rápidos</span> <span class="pre">de</span> <span class="pre">entrenar</span> <span class="pre">y</span> <span class="pre">de</span> <span class="pre">predecir</span></code>. Se adaptan a conjuntos de datos muy grandes y funcionan bien con datos dispersos. Si sus datos constan de cientos de miles o millones de muestras, es posible que desee investigar el uso de la opción <code class="docutils literal notranslate"><span class="pre">solver='sag'</span></code> en <code class="docutils literal notranslate"><span class="pre">LogisticRegression</span></code> y <code class="docutils literal notranslate"><span class="pre">Ridge</span></code>, que puede ser más rápida que la predeterminada en grandes conjuntos de datos. Otras opciones son la clase <code class="docutils literal notranslate"><span class="pre">SGDClassifier</span> <span class="pre">y</span> <span class="pre">la</span> <span class="pre">clase</span> <span class="pre">SGDRegressor</span> <span class="pre">que</span> <span class="pre">implementan</span> <span class="pre">versiones</span> <span class="pre">aún</span> <span class="pre">más</span> <span class="pre">escalables</span> <span class="pre">de</span> <span class="pre">los</span> <span class="pre">modelos</span> <span class="pre">lineales</span> <span class="pre">descritos</span> <span class="pre">aquí</span></code>.</p></li>
<li><p>Otro punto fuerte de los modelos lineales es que <code class="docutils literal notranslate"><span class="pre">permiten</span> <span class="pre">entender</span> <span class="pre">con</span> <span class="pre">relativa</span> <span class="pre">facilidad</span> <span class="pre">cómo</span> <span class="pre">se</span> <span class="pre">realiza</span> <span class="pre">una</span> <span class="pre">predicción,</span> <span class="pre">utilizando</span> <span class="pre">las</span> <span class="pre">fórmulas</span> <span class="pre">que</span> <span class="pre">vimos</span> <span class="pre">antes</span> <span class="pre">para</span> <span class="pre">la</span> <span class="pre">regresión</span> <span class="pre">y</span> <span class="pre">la</span> <span class="pre">clasificación</span></code>. Por desgracia, a menudo, no está del todo claro por qué los coeficientes son como son. Esto es particularmente cierto si su conjunto de datos tiene características altamente correlacionadas; en estos casos, los coeficientes pueden ser difíciles de interpretar.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Los</span> <span class="pre">modelos</span> <span class="pre">lineales</span> <span class="pre">suelen</span> <span class="pre">funcionar</span> <span class="pre">bien</span> <span class="pre">cuando</span> <span class="pre">el</span> <span class="pre">número</span> <span class="pre">de</span> <span class="pre">características</span> <span class="pre">es</span> <span class="pre">grande</span> <span class="pre">en</span> <span class="pre">comparación</span> <span class="pre">con</span> <span class="pre">el</span> <span class="pre">número</span> <span class="pre">de</span> <span class="pre">muestras</span></code>. También se utilizan a menudo en conjuntos de datos muy grandes, simplemente porque no es factible entrenar otros modelos. Sin embargo, <code class="docutils literal notranslate"><span class="pre">en</span> <span class="pre">espacios</span> <span class="pre">de</span> <span class="pre">menor</span> <span class="pre">dimensión</span> <span class="pre">otros</span> <span class="pre">modelos</span> <span class="pre">pueden</span> <span class="pre">ofrecer</span> <span class="pre">un</span> <span class="pre">mejor</span> <span class="pre">rendimiento</span> <span class="pre">de</span> <span class="pre">generalización</span></code>. Veremos algunos ejemplos en los que los modelos lineales fallan cuando abordemos <strong><code class="docutils literal notranslate"><span class="pre">máquinas</span> <span class="pre">de</span> <span class="pre">vectores</span> <span class="pre">de</span> <span class="pre">soporte</span> <span class="pre">kernelizadas</span></code></strong></p></li>
</ul>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="knn_model.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="math notranslate nohighlight">\(k\)</span>-Vecinos más cercanos</p>
      </div>
    </a>
    <a class="right-next"
       href="bayes_model.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Clasificadores Naive Bayes</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#modelo-de-regresion-lineal">Modelo de regresión lineal</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#minimos-cuadrados-ordinarios">Mínimos Cuadrados Ordinarios</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#aplicacion-regresion-ridge-y-ols">Aplicación: Regresión Ridge y OLS</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#analisis-exploratorio-de-datos">Análisis Exploratorio de Datos</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#regresion-ridge">Regresión ridge</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#analisis">Análisis</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#implementacion">Implementación</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lasso">Lasso</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#aplicacion-regresion-lasso">Aplicación: Regresión Lasso</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#modelos-lineales-para-clasificacion">Modelos lineales para clasificación</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#modelos-lineales-para-la-clasificacion-multiclase">Modelos lineales para la clasificación multiclase</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Lihki Rubio PhD in Mathematical Engineering
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright Department of Mathematics and Statistics.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>