
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>\(k\)-Vecinos más cercanos &#8212; Machine Learning</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.1/css/all.min.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.1/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.1/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.1/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=384b581d" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/proof.css?v=ca93fcec" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css?v=0a3b3ea7" />
    <link rel="stylesheet" type="text/css" href="_static/custom.css?v=530fe47d" />
    <link rel="stylesheet" type="text/css" href="_static/.ipynb_checkpoints/custom-checkpoint.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae" />
  <script src="_static/vendor/fontawesome/6.5.1/js/all.min.js?digest=8d27b9dea8ad943066ae"></script>

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=efea14e4"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=36754332"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'knn_model';</script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="_static/custom.js?v=14184634"></script>
    <script src="_static/.ipynb_checkpoints/custom-checkpoint.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Modelos lineales" href="linear_model.html" />
    <link rel="prev" title="Aprendizaje supervisado" href="supervised_intro.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a id="pst-skip-link" class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <header class="bd-header navbar navbar-expand-lg bd-navbar">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/fotolihki.jpg" class="logo__image only-light" alt="Machine Learning - Home"/>
    <script>document.write(`<img src="_static/fotolihki.jpg" class="logo__image only-dark" alt="Machine Learning - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn navbar-btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Profesor: Dr. Lihki Rubio
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="supervised_intro.html">Aprendizaje supervisado</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#"><span class="math notranslate nohighlight">\(k\)</span>-Vecinos más cercanos</a></li>
<li class="toctree-l1"><a class="reference internal" href="linear_model.html">Modelos lineales</a></li>
<li class="toctree-l1"><a class="reference internal" href="bayes_model.html">Clasificadores Naive Bayes</a></li>
<li class="toctree-l1"><a class="reference internal" href="decisiontree_model.html">Árboles de decisión</a></li>

<li class="toctree-l1"><a class="reference internal" href="svm_model.html">Máquinas de vectores de soporte</a></li>
<li class="toctree-l1"><a class="reference internal" href="ann_model.html">Redes Neuronales y Deep Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="practical_pca.html">Análisis de Componentes Principales</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_evaluation.html">Evaluación de modelos</a></li>
<li class="toctree-l1"><a class="reference internal" href="chains_pipelines.html">Cadenas de Algoritmos y Pipelines</a></li>
<li class="toctree-l1"><a class="reference internal" href="appendix.html">Apéndice</a></li>
<li class="toctree-l1"><a class="reference internal" href="biblio.html">Bibliografía</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/knn_model.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>k-Vecinos más cercanos</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#analisis">Análisis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#implementacion">Implementación</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#analisis-de-kneighborsclassifier">Análisis de <code class="docutils literal notranslate"><span class="pre">KNeighborsClassifier</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#aplicacion-breast-cancer-dataset">Aplicación: Breast Cancer Dataset</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#analisis-exploratorio-de-datos">Análisis Exploratorio de Datos</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#multicolinealidad">Multicolinealidad</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#factor-de-inflacion-de-la-varianza-vif">Factor de Inflación de la Varianza (VIF)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#seleccion-del-modelo-k-nn">Selección del modelo K-NN</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#regresion-por-k-vecinos">Regresión por <span class="math notranslate nohighlight">\(k\)</span>-vecinos</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#analisis-de-kneighborsregressor">Análisis de <code class="docutils literal notranslate"><span class="pre">KNeighborsRegressor</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#aplicacion-world-hydropower-generation">Aplicación: World Hydropower Generation</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="k-vecinos-mas-cercanos">
<h1><span class="math notranslate nohighlight">\(k\)</span>-Vecinos más cercanos<a class="headerlink" href="#k-vecinos-mas-cercanos" title="Link to this heading">#</a></h1>
<ul class="simple">
<li><p>El algoritmo <code class="docutils literal notranslate"><span class="pre">vecino</span> <span class="pre">más</span> <span class="pre">cercano</span></code> es considerado uno de los <code class="docutils literal notranslate"><span class="pre">más</span> <span class="pre">simples</span> <span class="pre">dentro</span> <span class="pre">del</span> <span class="pre">aprendizaje</span> <span class="pre">automático</span></code>. Su enfoque consiste en <code class="docutils literal notranslate"><span class="pre">memorizar</span> <span class="pre">el</span> <span class="pre">conjunto</span> <span class="pre">de</span> <span class="pre">entrenamiento</span> <span class="pre">y</span> <span class="pre">luego</span> <span class="pre">predecir</span> <span class="pre">la</span> <span class="pre">etiqueta</span> <span class="pre">del</span> <span class="pre">vecino</span> <span class="pre">más</span> <span class="pre">cercano</span> <span class="pre">en</span> <span class="pre">dicho</span> <span class="pre">conjunto</span></code>. Este método se basa en la idea de que las <code class="docutils literal notranslate"><span class="pre">características</span> <span class="pre">utilizadas</span> <span class="pre">para</span> <span class="pre">describir</span> <span class="pre">los</span> <span class="pre">puntos</span> <span class="pre">en</span> <span class="pre">el</span> <span class="pre">dominio</span> <span class="pre">son</span> <span class="pre">relevantes</span> <span class="pre">para</span> <span class="pre">determinar</span> <span class="pre">sus</span> <span class="pre">etiquetas</span></code>, de manera que es probable que <code class="docutils literal notranslate"><span class="pre">puntos</span> <span class="pre">cercanos</span> <span class="pre">tengan</span> <span class="pre">la</span> <span class="pre">misma</span> <span class="pre">etiqueta</span></code>. Incluso en situaciones donde el conjunto de entrenamiento es muy grande, es posible encontrar un vecino más cercano, como por ejemplo cuando el <code class="docutils literal notranslate"><span class="pre">conjunto</span> <span class="pre">de</span> <span class="pre">entrenamiento</span> <span class="pre">abarca</span> <span class="pre">toda</span> <span class="pre">la</span> <span class="pre">Web</span> <span class="pre">y</span> <span class="pre">las</span> <span class="pre">distancias</span> <span class="pre">se</span> <span class="pre">basan</span> <span class="pre">en</span> <span class="pre">enlaces</span></code>.</p></li>
<li><p>A diferencia de otros paradigmas algorítmicos que requieren hipótesis predefinidas, el método del <code class="docutils literal notranslate"><span class="pre">vecino</span> <span class="pre">más</span> <span class="pre">cercano</span> <span class="pre">calcula</span> <span class="pre">una</span> <span class="pre">etiqueta</span> <span class="pre">para</span> <span class="pre">cualquier</span> <span class="pre">punto</span> <span class="pre">de</span> <span class="pre">prueba</span> <span class="pre">sin</span> <span class="pre">buscar</span> <span class="pre">un</span> <span class="pre">predictor</span> <span class="pre">dentro</span> <span class="pre">de</span> <span class="pre">una</span> <span class="pre">clase</span> <span class="pre">de</span> <span class="pre">funciones</span> <span class="pre">predefinida</span></code>. En este capítulo, se describen los métodos del <code class="docutils literal notranslate"><span class="pre">vecino</span> <span class="pre">más</span> <span class="pre">cercano</span></code> tanto para problemas de <code class="docutils literal notranslate"><span class="pre">clasificación</span></code> como de <code class="docutils literal notranslate"><span class="pre">regresión</span></code>, se analiza su rendimiento en clasificación binaria y se discute la eficacia de su aplicación.</p></li>
</ul>
<section id="analisis">
<h2>Análisis<a class="headerlink" href="#analisis" title="Link to this heading">#</a></h2>
<div class="proof definition admonition" id="def_knn">
<p class="admonition-title"><span class="caption-number">Definition 1 </span> (<span class="math notranslate nohighlight">\(k\)</span>-NN (Clasificación))</p>
<section class="definition-content" id="proof-content">
<ul class="simple">
<li><p>Sea <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> nuestro <code class="docutils literal notranslate"><span class="pre">dominio</span> <span class="pre">de</span> <span class="pre">instancia</span></code> (<code class="docutils literal notranslate"><span class="pre">conjunto</span> <span class="pre">de</span> <span class="pre">objetos</span> <span class="pre">que</span> <span class="pre">se</span> <span class="pre">desea</span> <span class="pre">etiquetar</span></code>), dotado con una métrica <span class="math notranslate nohighlight">\(\rho\)</span>. Es decir, <span class="math notranslate nohighlight">\(\rho:\mathcal{X}\times\mathcal{X}\longrightarrow\mathbb{R}\)</span> es una  función que retorna la <code class="docutils literal notranslate"><span class="pre">distancia</span> <span class="pre">entre</span> <span class="pre">cualquier</span> <span class="pre">par</span> <span class="pre">de</span> <span class="pre">elementos</span></code> de <span class="math notranslate nohighlight">\(\mathcal{X}\)</span>. Por ejemplo, si <span class="math notranslate nohighlight">\(\mathcal{X}=\mathbb{R}^{d}\)</span>, entonces <span class="math notranslate nohighlight">\(\rho\)</span> puede ser la <code class="docutils literal notranslate"><span class="pre">distancia</span> <span class="pre">Euclidiana</span></code>,</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\rho(\boldsymbol{x}, \boldsymbol{x}')=\|\boldsymbol{x}-\boldsymbol{x}'\|=\sqrt{\sum_{i=1}^{d}(x_{i}-x_{i}')^{2}}.
\]</div>
<ul class="simple">
<li><p>Sea <span class="math notranslate nohighlight">\(S=(\boldsymbol{x}_{1}, y_{1}),\dots,(\boldsymbol{x}_{m}, y_{m})\)</span> una secuencia de <code class="docutils literal notranslate"><span class="pre">ejemplos</span> <span class="pre">de</span> <span class="pre">entrenamiento</span></code> y <span class="math notranslate nohighlight">\(\mathcal{Y}\)</span>, el <code class="docutils literal notranslate"><span class="pre">conjunto</span> <span class="pre">de</span> <span class="pre">etiquetas</span></code>, usualmente: <span class="math notranslate nohighlight">\(\{0, 1\},~\{-1, +1\}\)</span> o <span class="math notranslate nohighlight">\(\mathbb{R}\)</span>. Para cada <span class="math notranslate nohighlight">\(\boldsymbol{x}\in\mathcal{X}\)</span>, sea <span class="math notranslate nohighlight">\(\pi_{1}(\boldsymbol{x}),\dots,\pi_{m}(\boldsymbol{x})\)</span> una <code class="docutils literal notranslate"><span class="pre">reordenación</span></code> de <span class="math notranslate nohighlight">\(\{1,\dots,m\}\)</span> en función de su distancia a <span class="math notranslate nohighlight">\(\boldsymbol{x}\)</span>, <span class="math notranslate nohighlight">\(\rho(\boldsymbol{x}, \boldsymbol{x}_{i})\)</span>. Esto es, para todo <span class="math notranslate nohighlight">\(i&lt;m\)</span>,</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\rho(\boldsymbol{x}, \boldsymbol{x}_{\pi_{i}(\boldsymbol{x})})\leq\rho(\boldsymbol{x}, \boldsymbol{x}_{\pi_{i+1}(\boldsymbol{x})}).
\]</div>
<ul class="simple">
<li><p>Para un número <span class="math notranslate nohighlight">\(k\)</span>, la regla <span class="math notranslate nohighlight">\(k\)</span>-NN para la <code class="docutils literal notranslate"><span class="pre">clasificación</span> <span class="pre">binaria</span></code> se define del siguiente modo:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">input</span></code>: muestra de <code class="docutils literal notranslate"><span class="pre">entrenamiento</span></code> <span class="math notranslate nohighlight">\(S=(\boldsymbol{x}_{1}, y_{1}),\dots,(\boldsymbol{x}_{m}, y_{m})\)</span></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">output</span></code>: <span class="math notranslate nohighlight">\(\forall~\boldsymbol{x}\in\mathcal{X}\)</span>, <code class="docutils literal notranslate"><span class="pre">etiqueta</span> <span class="pre">mayoritaria</span></code> en <span class="math notranslate nohighlight">\(\{y_{\pi_{i}(\boldsymbol{x})}:~i\leq k\}\)</span></p></li>
</ul>
</li>
</ul>
</section>
</div><figure class="align-center" id="knn-classification-fig">
<a class="reference internal image-reference" href="_images/knn_classification.png"><img alt="_images/knn_classification.png" src="_images/knn_classification.png" style="width: 531.9px; height: 463.5px;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 4 </span><span class="caption-text">Clasificación usando <span class="math notranslate nohighlight">\(k\)</span>-NN para <span class="math notranslate nohighlight">\(k=3\)</span>. Source: <a class="reference external" href="http://kdnuggets.com">kdnuggets.com</a>.</span><a class="headerlink" href="#knn-classification-fig" title="Link to this image">#</a></p>
</figcaption>
</figure>
<div class="tip admonition">
<p class="admonition-title">Desempate en la clasificación <span class="math notranslate nohighlight">\(k\)</span>-NN</p>
<p>En ocasiones ocurren empates a la hora de seleccionar la clase mayoritaria. Existen varias formas de abordar este problema, las siguientes son las tres mas frecuentes</p>
<ol class="arabic simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Elija</span> <span class="pre">un</span> </code><span class="math notranslate nohighlight">\(k\)</span><code class="docutils literal notranslate"> <span class="pre">diferente</span></code></p>
<ul class="simple">
<li><p>Aunque un método de clasificación de tres vecinos más cercanos soluciona el problema de la selección de vecinos en las Figuras i) y ii), no resuelve el problema de la Figura iii).</p></li>
<li><p>De hecho, sigue existiendo la posibilidad de que se produzcan empates de selección en el conjunto de datos mayor independientemente del valor de <span class="math notranslate nohighlight">\(k\)</span>.</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">Elija</span> <span class="pre">al</span> <span class="pre">azar</span> <span class="pre">entre</span> <span class="pre">los</span> <span class="pre">valores</span> <span class="pre">empatados</span></code></p>
<ul class="simple">
<li><p>Aplicando este enfoque a la Figura ii), cada una de las tres observaciones tendría la misma probabilidad de ser seleccionada como uno de los dos vecinos.</p></li>
<li><p>En la Figura iii), se seleccionaría el <span class="math notranslate nohighlight">\(A\)</span> más cercano a <span class="math notranslate nohighlight">\(N\)</span>, y uno de los tres puntos observados restantes se seleccionaría al azar.</p></li>
<li><p>Dependiendo de cuáles de los valores empatados se permitan en el modelo, podría tener un efecto significativo en cómo se clasifica <span class="math notranslate nohighlight">\(N\)</span>.</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">Permitir</span> <span class="pre">observaciones</span> <span class="pre">hasta</span> <span class="pre">el</span> <span class="pre">punto</span> <span class="pre">de</span> <span class="pre">parada</span> <span class="pre">natural</span></code> La idea aquí es <em>elegir el número más pequeño tal que <span class="math notranslate nohighlight">\(k\)</span> sea mayor o igual que dos, y que no existan empates</em></p>
<ul class="simple">
<li><p>Para la Figura i), se seleccionarían las dos observaciones más cercanas (igual que en los dos métodos anteriores).</p></li>
<li><p>Para la Figura ii), como hay un empate a tres, se consideran los tres vecinos. La restricción de sólo dos vecinos se elimina para esta observación en particular.</p></li>
<li><p>Del mismo modo, en la Figura iii) se seleccionan las cuatro observaciones. Observe que este método elegiría tantos valores como fuera necesario para evitar el empate. Si en la Figura ii) hubiera ocho puntos equidistantes, se incluirían los ocho en el modelo.</p></li>
</ul>
</li>
<li><p>Supongamos que nos hemos decidido por el tercer método y que ya tenemos nuestros vecinos seleccionados</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Elegir</span> <span class="pre">un</span> </code><span class="math notranslate nohighlight">\(k\)</span><code class="docutils literal notranslate"> <span class="pre">impar</span></code>: Algunos sugieren simplemente elegir un valor impar para <span class="math notranslate nohighlight">\(k\)</span>. Este método no siempre funciona, ya que los estados de clasificación también podrían ser impares <span class="math notranslate nohighlight">\((A, B, C)\)</span>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Elegir</span> <span class="pre">al</span> <span class="pre">azar</span> <span class="pre">entre</span> <span class="pre">vecinos</span> <span class="pre">empatados</span></code>. Con este método, <span class="math notranslate nohighlight">\(L\)</span> y <span class="math notranslate nohighlight">\(N\)</span> tienen la misma probabilidad de ser clasificados como <span class="math notranslate nohighlight">\(A\)</span> o <span class="math notranslate nohighlight">\(B\)</span>. Pero, ¿es justo el azar? ¿tiene sentido que <span class="math notranslate nohighlight">\(N\)</span>, que está muy cerca de <span class="math notranslate nohighlight">\(A\)</span>, tenga la misma probabilidad de ser <span class="math notranslate nohighlight">\(B\)</span>?</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Ponderación</span> <span class="pre">por</span> <span class="pre">distancia</span></code>. Para resolver el problema planteado por el método anterior, es posible ponderar los vecinos de modo que los más cercanos al punto no observado tengan un “mayor voto”. Este método daría lugar a que tanto <span class="math notranslate nohighlight">\(L\)</span> como <span class="math notranslate nohighlight">\(N\)</span> se clasificaran como <span class="math notranslate nohighlight">\(A\)</span>, ya que los vecinos <span class="math notranslate nohighlight">\(A\)</span> están más cerca que los demás en comparación.</p></li>
</ul>
</li>
</ol>
</div>
<figure class="align-center" id="knn-ties">
<a class="reference internal image-reference" href="_images/knn_ties.png"><img alt="_images/knn_ties.png" src="_images/knn_ties.png" style="width: 702.0px; height: 197.4px;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 5 </span><span class="caption-text">k-NN: Empates en la selección de clase con mayor frecuencia.</span><a class="headerlink" href="#knn-ties" title="Link to this image">#</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p>Definamos por <span class="math notranslate nohighlight">\(h_{S}(\boldsymbol{x})\)</span> la <code class="docutils literal notranslate"><span class="pre">regla</span> <span class="pre">de</span> <span class="pre">predicción</span></code> (el subíndice <span class="math notranslate nohighlight">\(S\)</span> hace hincapié en el hecho de que <code class="docutils literal notranslate"><span class="pre">el</span> <span class="pre">predictor</span> <span class="pre">de</span> <span class="pre">salida</span> <span class="pre">depende</span> <span class="pre">de</span></code> <span class="math notranslate nohighlight">\(S\)</span>). Esta función también se denomina <code class="docutils literal notranslate"><span class="pre">predictor,</span> <span class="pre">hipótesis</span> <span class="pre">o</span> <span class="pre">clasificador</span></code>. El <code class="docutils literal notranslate"><span class="pre">predictor</span></code> puede utilizarse para predecir la etiqueta de nuevos puntos de dominio. Cuando <span class="math notranslate nohighlight">\(k=1\)</span> (ver <a class="reference internal" href="#def_knn">Definition 1</a>), tenemos la regla <span class="math notranslate nohighlight">\(1\)</span>-NN:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
h_{S}(\boldsymbol{x})=y_{\pi_{1}(\boldsymbol{x})}.
\]</div>
<ul class="simple">
<li><p>Nótese que hemos considerado la <code class="docutils literal notranslate"><span class="pre">métrica</span> <span class="pre">Euclideana</span></code> en esta definición, pero, <code class="docutils literal notranslate"><span class="pre">dependiendo</span> <span class="pre">del</span> <span class="pre">conjunto</span> <span class="pre">de</span> <span class="pre">datos,</span> <span class="pre">podría</span> <span class="pre">ser</span> <span class="pre">mas</span> <span class="pre">adecuado</span> <span class="pre">utilizar</span> <span class="pre">una</span> <span class="pre">métrica</span> <span class="pre">diferente</span></code> (ver <a class="reference external" href="https://es.wikipedia.org/wiki/Geometr%C3%ADa_del_taxista">Manhatan</a>, <a class="reference external" href="https://en.wikipedia.org/wiki/Minkowski_distance">Minkowski</a>). Esto es, una métrica alternativa, podría <code class="docutils literal notranslate"><span class="pre">mejorar</span> <span class="pre">los</span> <span class="pre">errores</span> <span class="pre">cometidos</span> <span class="pre">por</span> <span class="pre">el</span> <span class="pre">clasificador</span></code>.</p></li>
</ul>
<div class="proof definition admonition" id="def_knn_reg">
<p class="admonition-title"><span class="caption-number">Definition 2 </span> (<span class="math notranslate nohighlight">\(k\)</span>-NN (Regresión))</p>
<section class="definition-content" id="proof-content">
<ul class="simple">
<li><p>Para <code class="docutils literal notranslate"><span class="pre">problemas</span> <span class="pre">de</span> <span class="pre">regresión</span></code>, a saber, <span class="math notranslate nohighlight">\(\mathcal{Y}=\mathbb{R}\)</span>, se puede definir la <code class="docutils literal notranslate"><span class="pre">regla</span> <span class="pre">de</span> <span class="pre">predicción</span></code> como la <code class="docutils literal notranslate"><span class="pre">media</span> <span class="pre">objetivo</span></code> de los <span class="math notranslate nohighlight">\(k\)</span> vecinos más cercanos. Esto es,</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
h_{S}(\boldsymbol{x})=\frac{1}{k}\sum_{i=1}^{k}y_{\pi_{i}(\boldsymbol{x})}.
\]</div>
<ul class="simple">
<li><p>Más en general, para alguna función <span class="math notranslate nohighlight">\(\phi:~(\mathcal{X}, \mathcal{Y})^{k}\rightarrow\mathcal{Y}\)</span>, la regla <span class="math notranslate nohighlight">\(k\)</span>-NN con respecto a <span class="math notranslate nohighlight">\(\phi\)</span> es:</p></li>
</ul>
<div class="math notranslate nohighlight" id="equation-knn-regeq">
<span class="eqno">(1)<a class="headerlink" href="#equation-knn-regeq" title="Link to this equation">#</a></span>\[
h_{S}(\boldsymbol{x})=\phi((\boldsymbol{x}_{\pi_{1}(\boldsymbol{x})}, y_{\pi_{1}(\boldsymbol{x})}),\dots,(\boldsymbol{x}_{\pi_{k}(\boldsymbol{x})}, y_{\pi_{k}(\boldsymbol{x})})).
\]</div>
<ul class="simple">
<li><p>Se puede verificar que podemos lanzar la predicción por mayoría de etiquetas (<code class="docutils literal notranslate"><span class="pre">clasificación</span></code>) o por el objetivo promediado (<code class="docutils literal notranslate"><span class="pre">regresión</span></code>) como en la Ecuación <a class="reference internal" href="#equation-knn-regeq">(1)</a> mediante una <code class="docutils literal notranslate"><span class="pre">elección</span> <span class="pre">adecuada</span> <span class="pre">de</span></code> <span class="math notranslate nohighlight">\(\phi\)</span>.</p></li>
<li><p>La generalidad puede llevar a otras reglas, por ejemplo, si <span class="math notranslate nohighlight">\(\mathcal{Y}=\mathbb{R}\)</span>, podemos tomar una <code class="docutils literal notranslate"><span class="pre">media</span> <span class="pre">ponderada</span> <span class="pre">de</span> <span class="pre">los</span> <span class="pre">objetivos</span> <span class="pre">según</span> <span class="pre">la</span> <span class="pre">distancia</span> <span class="pre">a</span></code> <span class="math notranslate nohighlight">\(x\)</span></p></li>
</ul>
<div class="math notranslate nohighlight">
\[
h_{S}(\boldsymbol{x})=\sum_{i=1}^{k}\frac{\rho(\boldsymbol{x}, \boldsymbol{x}_{\pi_{i}(\boldsymbol{x})})}{\sum_{j=1}^{k}\rho(\boldsymbol{x}, \boldsymbol{x}_{\pi_{j}(\boldsymbol{x})})}y_{\pi_{i}(\boldsymbol{x})}.
\]</div>
</section>
</div><div class="proof definition admonition" id="def_emp_error">
<p class="admonition-title"><span class="caption-number">Definition 3 </span> (Error empírico y verdadero revisado)</p>
<section class="definition-content" id="proof-content">
<ul class="simple">
<li><p>Para una <code class="docutils literal notranslate"><span class="pre">distribución</span> <span class="pre">de</span> <span class="pre">probabilidad</span></code>, <span class="math notranslate nohighlight">\(\mathcal{D}\)</span>, sobre <span class="math notranslate nohighlight">\(\mathcal{X}\times\mathcal{Y}\)</span>, se puede medir la probabilidad de que <span class="math notranslate nohighlight">\(h\)</span> <code class="docutils literal notranslate"><span class="pre">cometa</span> <span class="pre">un</span> <span class="pre">error</span></code> cuando los puntos etiquetados se extraen aleatoriamente según <span class="math notranslate nohighlight">\(\mathcal{D}\)</span>. Redefinimos el <code class="docutils literal notranslate"><span class="pre">error</span> <span class="pre">verdadero</span> <span class="pre">(o</span> <span class="pre">riesgo)</span></code> de una regla de predicción <span class="math notranslate nohighlight">\(h\)</span> como</p></li>
</ul>
<div class="math notranslate nohighlight" id="equation-real-error">
<span class="eqno">(2)<a class="headerlink" href="#equation-real-error" title="Link to this equation">#</a></span>\[
L_{\mathcal{D}}(h):=\underset{(\boldsymbol{x},y)\sim\mathcal{D}}{\mathbb{P}}[h(\boldsymbol{x})\neq y]:=\mathcal{D}(\{(\boldsymbol{x},y):~h(\boldsymbol{x})\neq y\}).
\]</div>
<ul class="simple">
<li><p><strong><code class="docutils literal notranslate"><span class="pre">Minimización</span> <span class="pre">Empírica</span> <span class="pre">de</span> <span class="pre">Riesgo</span> <span class="pre">(ERM)</span></code></strong>. Nos gustaría encontrar un <code class="docutils literal notranslate"><span class="pre">predictor</span></code>, <span class="math notranslate nohighlight">\(h\)</span>, para el que se <code class="docutils literal notranslate"><span class="pre">minimizara</span> <span class="pre">el</span> <span class="pre">error</span></code> <span class="math notranslate nohighlight">\(L_{\mathcal{D}}(h)\)</span> sobre una <code class="docutils literal notranslate"><span class="pre">clase</span> <span class="pre">de</span> <span class="pre">hipótesis</span></code> denota por <span class="math notranslate nohighlight">\(\mathcal{H}\)</span>, esto es: <span class="math notranslate nohighlight">\(ERM_{\mathcal{H}}(S)\in\underset{h\in\mathcal{H}}{\text{argmin}}L_{S}(h)\)</span>. Cada <span class="math notranslate nohighlight">\(h\in\mathcal{H}\)</span> es una función de <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> a <span class="math notranslate nohighlight">\(\mathcal{Y}\)</span>.</p></li>
<li><p>Sin embargo, no se conocen los datos que generan <span class="math notranslate nohighlight">\(\mathcal{D}\)</span>. A lo que sí se tiene acceso es a los <code class="docutils literal notranslate"><span class="pre">datos</span> <span class="pre">de</span> <span class="pre">entrenamiento</span></code>, <span class="math notranslate nohighlight">\(S\)</span>. Una noción útil de error que puede calcular es el <code class="docutils literal notranslate"><span class="pre">error</span> <span class="pre">de</span> <span class="pre">entrenamiento</span> <span class="pre">(riesgo</span> <span class="pre">empírico)</span></code>, es decir, el <code class="docutils literal notranslate"><span class="pre">error</span> <span class="pre">en</span> <span class="pre">el</span> <span class="pre">que</span> <span class="pre">incurre</span> <span class="pre">el</span> <span class="pre">clasificador</span> <span class="pre">sobre</span> <span class="pre">la</span> <span class="pre">muestra</span> <span class="pre">de</span> <span class="pre">entrenamiento</span></code>:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
L_{S}(h):=\frac{|\{i\in\left[m\right]:~h(\boldsymbol{x}_{i})\neq y_{i}\}|}{m},~\left[m\right]=\{1,\dots,m\}.
\]</div>
<ul class="simple">
<li><p>Dado <span class="math notranslate nohighlight">\(S\)</span>, y un <code class="docutils literal notranslate"><span class="pre">aprendizaje</span></code>, se puede calcular <span class="math notranslate nohighlight">\(L_{S}(h)\)</span> para cualquier función <span class="math notranslate nohighlight">\(h:X\rightarrow\{0,1\}\)</span>.</p></li>
<li><p>Deseamos encontrar alguna hipótesis, <span class="math notranslate nohighlight">\(h : X\rightarrow Y\)</span>, que (probablemente de forma aproximada) <code class="docutils literal notranslate"><span class="pre">minimice</span> <span class="pre">el</span> <span class="pre">riesgo</span> <span class="pre">verdadero</span></code>,<span class="math notranslate nohighlight">\(L_{D}(h)\)</span>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Predictor</span> <span class="pre">óptimo</span> <span class="pre">de</span> <span class="pre">Bayes.</span></code> Dada cualquier distribución de probabilidad <span class="math notranslate nohighlight">\(\mathcal{D}\)</span> sobre <span class="math notranslate nohighlight">\(\mathcal{X}\times\{0, 1\}\)</span>, la <code class="docutils literal notranslate"><span class="pre">mejor</span> <span class="pre">función</span> <span class="pre">de</span> <span class="pre">predicción</span> <span class="pre">de</span> <span class="pre">etiquetas</span></code> de <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> a <span class="math notranslate nohighlight">\(\{0, 1\}\)</span> será</p></li>
</ul>
<div class="math notranslate nohighlight" id="equation-bayes-opt-pred">
<span class="eqno">(3)<a class="headerlink" href="#equation-bayes-opt-pred" title="Link to this equation">#</a></span>\[\begin{split}
f_{\mathcal{D}}(x)=
\begin{cases}
1,&amp;\text{si}~\mathbb{P}[y=1|x]\geq1/2\\
0,&amp;\text{otro caso}
\end{cases}
\end{split}\]</div>
<ul class="simple">
<li><p>Se puede verificar que <code class="docutils literal notranslate"><span class="pre">para</span> <span class="pre">toda</span> <span class="pre">distribución</span> <span class="pre">de</span> <span class="pre">probabilidad</span></code> <span class="math notranslate nohighlight">\(\mathcal{D}\)</span>, <code class="docutils literal notranslate"><span class="pre">el</span> <span class="pre">predictor</span> <span class="pre">óptimo</span> <span class="pre">de</span> <span class="pre">Bayes</span></code> <span class="math notranslate nohighlight">\(f_{D}\)</span> <code class="docutils literal notranslate"><span class="pre">es</span> <span class="pre">óptimo</span></code>, en el sentido de que <code class="docutils literal notranslate"><span class="pre">ningún</span> <span class="pre">otro</span> <span class="pre">clasificador</span></code>, <span class="math notranslate nohighlight">\(g : \mathcal \rightarrow\{0, 1\}\)</span>, <code class="docutils literal notranslate"><span class="pre">tiene</span> <span class="pre">un</span> <span class="pre">error</span> <span class="pre">menor</span></code>. Es decir, para cada clasificador <span class="math notranslate nohighlight">\(g, L_{\mathcal{D}}(f_{\mathcal{D}}) \leq L_{\mathcal{D}}(g)\)</span>.</p></li>
</ul>
</section>
</div><div class="proof definition admonition" id="gen_loss_fun">
<p class="admonition-title"><span class="caption-number">Definition 4 </span> (Funciones de pérdidas generalizadas)</p>
<section class="definition-content" id="proof-content">
<ul class="simple">
<li><p>Dado cualquier conjunto <span class="math notranslate nohighlight">\(\mathcal{H}\)</span> (que desempeña el papel de nuestras <code class="docutils literal notranslate"><span class="pre">hipótesis,</span> <span class="pre">o</span> <span class="pre">modelos</span></code>) y algún <code class="docutils literal notranslate"><span class="pre">dominio</span></code> <span class="math notranslate nohighlight">\(Z\)</span> sea <span class="math notranslate nohighlight">\(\ell\)</span> cualquier función de <span class="math notranslate nohighlight">\(\mathcal{H}\times Z\)</span> al conjunto de los números reales no negativos, <span class="math notranslate nohighlight">\(\ell: \mathcal{H}\times Z\rightarrow\mathbb{R}^{+}\)</span>. Llamamos a estas funciones, <code class="docutils literal notranslate"><span class="pre">funciones</span> <span class="pre">de</span> <span class="pre">pérdida</span></code>.</p></li>
<li><p>Nótese que para los problemas de predicción, tenemos que <span class="math notranslate nohighlight">\(Z = \mathcal{X}\times\mathcal{Y}\)</span>. Sin embargo, nuestra noción de la <code class="docutils literal notranslate"><span class="pre">función</span> <span class="pre">de</span> <span class="pre">pérdida</span></code> se generaliza más allá de las tareas de predicción y, por tanto, permite que <span class="math notranslate nohighlight">\(Z\)</span> sea <code class="docutils literal notranslate"><span class="pre">cualquier</span> <span class="pre">dominio</span> <span class="pre">de</span> <span class="pre">ejemplos</span></code>.</p></li>
<li><p>Definimos ahora la <code class="docutils literal notranslate"><span class="pre">función</span> <span class="pre">de</span> <span class="pre">riesgo</span></code> como la <code class="docutils literal notranslate"><span class="pre">pérdida</span> <span class="pre">esperada</span> <span class="pre">de</span> <span class="pre">un</span> <span class="pre">clasificador</span></code>, <span class="math notranslate nohighlight">\(h\in\mathcal{H}\)</span>, con respecto a la distribución de probabilidad <span class="math notranslate nohighlight">\(\mathcal{D}\)</span> sobre <span class="math notranslate nohighlight">\(Z\)</span>, a saber,</p></li>
</ul>
<div class="math notranslate nohighlight" id="equation-risk-function">
<span class="eqno">(4)<a class="headerlink" href="#equation-risk-function" title="Link to this equation">#</a></span>\[
L_{\mathcal{D}}(h):=\underset{z\sim\mathcal{D}}{\mathbb{E}}[\ell(h, z)].
\]</div>
<ul class="simple">
<li><p>Es decir, consideramos la <code class="docutils literal notranslate"><span class="pre">esperanza</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">pérdida</span> <span class="pre">de</span></code> <span class="math notranslate nohighlight">\(h\)</span> <code class="docutils literal notranslate"><span class="pre">sobre</span> <span class="pre">los</span> <span class="pre">objetos</span></code> <span class="math notranslate nohighlight">\(z\)</span> <code class="docutils literal notranslate"><span class="pre">elegidos</span> <span class="pre">aleatoriamente</span> <span class="pre">de</span> <span class="pre">acuerdo</span> <span class="pre">con</span></code> <span class="math notranslate nohighlight">\(\mathcal{D}\)</span>. Del mismo modo, definimos el <code class="docutils literal notranslate"><span class="pre">riesgo</span> <span class="pre">empírico</span></code> como la pérdida esperada sobre una muestra dada <span class="math notranslate nohighlight">\(S=(z_{1},\dots,z_{m})\in Z^{m}\)</span>, a saber</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
L_{S}(h):=\frac{1}{m}\sum_{i=1}^{m}\ell(h, z_{i}).
\]</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Ejemplos</span></code>: Dada una variable aleatoria <span class="math notranslate nohighlight">\(z\)</span> que abarca el conjunto de pares <span class="math notranslate nohighlight">\(\mathcal{X}\times\mathcal{Y}\)</span>, definimos las siguientes <code class="docutils literal notranslate"><span class="pre">funciones</span> <span class="pre">de</span> <span class="pre">pérdida</span></code></p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
\text{0-1 Loss}:&amp;~\ell_{\text{0-1}}(h, (x,y)):=
\begin{cases}
0, &amp; \text{si}~ h(x)=y\\[2mm]
1, &amp; \text{si}~ h(x)\neq y
\end{cases}\\
\text{Square Loss}:&amp;~\ell_{\text{sq}}(h, (x,y)):=(h(x)-y)^{2}.
\end{align}
\end{split}\]</div>
<ul>
<li><p><span class="math notranslate nohighlight">\(\ell_{\text{0-1}}(h, (x,y))\)</span> se utiliza en <code class="docutils literal notranslate"><span class="pre">problemas</span> <span class="pre">de</span> <span class="pre">clasificación</span> <span class="pre">binaria</span> <span class="pre">o</span> <span class="pre">multiclase</span></code>. Hay que tener en cuenta que, para una variable aleatoria, <span class="math notranslate nohighlight">\(\alpha\)</span>, que toma los valores <span class="math notranslate nohighlight">\(\{0,1\}\)</span>,</p>
<div class="math notranslate nohighlight">
\[\mathbb{E}_{\alpha\sim\mathcal{D}}[\alpha] = \mathbb{P}_{\alpha\sim\mathcal{D}}[\alpha = 1].\]</div>
<p>Por lo tanto, las funciones de pérdida definidas en Eq. <a class="reference internal" href="#equation-risk-function">(4)</a> y Eq. <a class="reference internal" href="#equation-real-error">(2)</a> son equivalentes.</p>
</li>
</ul>
</section>
</div><div class="proof observation admonition" id="knn_analysis">
<p class="admonition-title"><span class="caption-number">Observation 1 </span> (<span class="math notranslate nohighlight">\(1\)</span>-NN)</p>
<section class="observation-content" id="proof-content">
<ul class="simple">
<li><p>Dado que las reglas NN son <code class="docutils literal notranslate"><span class="pre">métodos</span> <span class="pre">de</span> <span class="pre">aprendizaje</span> <span class="pre">tan</span> <span class="pre">naturales</span></code>, sus propiedades de generalización han sido ampliamente estudiadas. La mayoría de los resultados anteriores son resultados de <code class="docutils literal notranslate"><span class="pre">consistencia</span> <span class="pre">asintótica</span></code>, que analizan el rendimiento de las reglas NN cuando el tamaño de la muestra, <span class="math notranslate nohighlight">\(m\)</span>, tiende a <span class="math notranslate nohighlight">\(\infty\)</span>, y la <code class="docutils literal notranslate"><span class="pre">tasa</span> <span class="pre">de</span> <span class="pre">convergencia</span> <span class="pre">depende</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">distribución</span> <span class="pre">subyacente</span></code>.</p></li>
<li><p>Estamos interesados en <code class="docutils literal notranslate"><span class="pre">aprendizajes</span> <span class="pre">de</span> <span class="pre">muestras</span> <span class="pre">de</span> <span class="pre">entrenamiento</span> <span class="pre">finitas</span></code> y entender el <code class="docutils literal notranslate"><span class="pre">rendimiento</span> <span class="pre">de</span> <span class="pre">generalización</span></code> en función del <code class="docutils literal notranslate"><span class="pre">tamaño</span> <span class="pre">de</span> <span class="pre">esos</span> <span class="pre">conjuntos</span> <span class="pre">de</span> <span class="pre">entrenamiento</span> <span class="pre">finitos</span></code> y de <code class="docutils literal notranslate"><span class="pre">supuestos</span> <span class="pre">previos</span> <span class="pre">claros</span> <span class="pre">sobre</span> <span class="pre">la</span> <span class="pre">distribución</span> <span class="pre">de</span> <span class="pre">los</span> <span class="pre">datos</span></code>. Por lo tanto, presentamos un análisis de <code class="docutils literal notranslate"><span class="pre">muestras</span> <span class="pre">finitas</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">regla</span> <span class="pre">1-NN</span></code>.</p></li>
</ul>
</section>
</div><div class="admonition-generalizacion-de-la-regla-1-nn admonition">
<p class="admonition-title">Generalización de la regla <span class="math notranslate nohighlight">\(1\)</span>-NN</p>
<ul class="simple">
<li><p>Ahora analizamos el <code class="docutils literal notranslate"><span class="pre">error</span> <span class="pre">verdadero</span></code> de la regla <span class="math notranslate nohighlight">\(1\)</span>-NN para la <code class="docutils literal notranslate"><span class="pre">clasificación</span> <span class="pre">binaria</span></code> con <code class="docutils literal notranslate"><span class="pre">función</span> <span class="pre">pérdida</span></code> <span class="math notranslate nohighlight">\(0-1\)</span> a saber, <span class="math notranslate nohighlight">\(\mathcal{Y}=\{0, 1\}\)</span> y <span class="math notranslate nohighlight">\(\ell(h, (\boldsymbol{x}, y))=\mathbb{1}_{[h(\boldsymbol{x})\neq y]}\)</span>. También supondremos en todo el análisis que <span class="math notranslate nohighlight">\(\mathcal{X} = [0,1]^{d}\)</span> y <span class="math notranslate nohighlight">\(\rho\)</span> es la <code class="docutils literal notranslate"><span class="pre">distancia</span> <span class="pre">euclidiana</span></code>.</p></li>
<li><p>Empezaremos introduciendo algunos notaciones. Sea <span class="math notranslate nohighlight">\(\mathcal{D}\)</span> una distribución sobre <span class="math notranslate nohighlight">\(\mathcal{X}\times\mathcal{Y}\)</span>. Denotemos por <span class="math notranslate nohighlight">\(\mathcal{D}_{\mathcal{X}}\)</span> la <code class="docutils literal notranslate"><span class="pre">distribución</span> <span class="pre">marginal</span> <span class="pre">inducida</span> <span class="pre">por</span></code> <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> y sea <span class="math notranslate nohighlight">\(\eta:\mathbb{R}^{d}\rightarrow\mathbb{R}\)</span> la <code class="docutils literal notranslate"><span class="pre">probabilidad</span> <span class="pre">condicional</span> <span class="pre">sobre</span> <span class="pre">las</span> <span class="pre">etiquetas</span></code>, esto es,</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\eta(\boldsymbol{x})=\mathbb{P}[y=1|\boldsymbol{x}].
\]</div>
<ul class="simple">
<li><p>La <code class="docutils literal notranslate"><span class="pre">regla</span> <span class="pre">óptima</span> <span class="pre">de</span> <span class="pre">Bayes</span></code> (es decir, la hipótesis que minimiza <span class="math notranslate nohighlight">\(L_{\mathcal{D}}(h)\)</span> sobre todas las funciones <span class="math notranslate nohighlight">\(h\in\mathcal{H}\)</span>, ver Eq. <a class="reference internal" href="#equation-bayes-opt-pred">(3)</a>) es</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
h^{\star}(\boldsymbol{x})=\mathbb{1}_{\left[\eta(\boldsymbol{x})&gt;1/2\right]}.
\]</div>
<ul class="simple">
<li><p>Suponemos que la función de <code class="docutils literal notranslate"><span class="pre">probabilidad</span> <span class="pre">condicional</span></code> <span class="math notranslate nohighlight">\(\eta\)</span> es <span class="math notranslate nohighlight">\(c\)</span>-Lipschitz (ver <a class="reference external" href="https://en.wikipedia.org/wiki/Lipschitz_continuity">Lipschitz continuity</a>) para algún valor de <span class="math notranslate nohighlight">\(c&gt;0\)</span>. Es decir, <span class="math notranslate nohighlight">\(\forall~\boldsymbol{x}, \boldsymbol{x}'\in\mathcal{X},~|\eta(\boldsymbol{x})-\eta(\boldsymbol{x}')|\leq c\|\boldsymbol{x}-\boldsymbol{x}'\|\)</span>. En otras palabras, esto significa que <code class="docutils literal notranslate"><span class="pre">si</span> <span class="pre">dos</span> <span class="pre">vectores</span> <span class="pre">están</span> <span class="pre">próximos,</span> <span class="pre">es</span> <span class="pre">probable</span> <span class="pre">que</span> <span class="pre">sus</span> <span class="pre">etiquetas</span> <span class="pre">sean</span> <span class="pre">las</span> <span class="pre">mismas</span></code>.</p></li>
</ul>
</div>
<div class="tip admonition">
<p class="admonition-title">Nota</p>
<p>El siguiente lema aplica la <code class="docutils literal notranslate"><span class="pre">Lipschitzness</span></code> de la función de <code class="docutils literal notranslate"><span class="pre">probabilidad</span> <span class="pre">condicional</span></code> para acotar el <code class="docutils literal notranslate"><span class="pre">error</span> <span class="pre">verdadero</span></code> de la regla <code class="docutils literal notranslate"><span class="pre">1-NN</span></code> en función de la distancia entre cada <code class="docutils literal notranslate"><span class="pre">instancia</span> <span class="pre">de</span> <span class="pre">prueba</span></code> y su <code class="docutils literal notranslate"><span class="pre">vecino</span> <span class="pre">más</span> <span class="pre">cercano</span> <span class="pre">en</span> <span class="pre">el</span> <span class="pre">conjunto</span> <span class="pre">de</span> <span class="pre">entrenamiento</span></code>.</p>
</div>
<div class="proof lemma admonition" id="knn_lemma1">
<p class="admonition-title"><span class="caption-number">Lemma 1 </span></p>
<section class="lemma-content" id="proof-content">
<p>Sea <span class="math notranslate nohighlight">\(\mathcal{X}=[0,1]^{d},~ \mathcal{Y}=\{0,1\}\)</span>, y <span class="math notranslate nohighlight">\(\mathcal{D}\)</span> una distribución sobre <span class="math notranslate nohighlight">\(\mathcal{X}\times\mathcal{Y}\)</span>, para la cual, la <code class="docutils literal notranslate"><span class="pre">función</span> <span class="pre">de</span> <span class="pre">probabilidad</span> <span class="pre">condicional</span></code>, <span class="math notranslate nohighlight">\(\eta\)</span>, es una <code class="docutils literal notranslate"><span class="pre">función</span></code> <span class="math notranslate nohighlight">\(c\)</span><code class="docutils literal notranslate"><span class="pre">-Lipschitz</span></code>. Sea <span class="math notranslate nohighlight">\(S=(\boldsymbol{x}_{1}, y_{1}),\dots,(\boldsymbol{x}_{m}, y_{m})\)</span> una muestra <code class="docutils literal notranslate"><span class="pre">iid</span></code> y sea <span class="math notranslate nohighlight">\(h_{S}\)</span> su correspondiente <code class="docutils literal notranslate"><span class="pre">hipótesis</span></code> <span class="math notranslate nohighlight">\(1\)</span>-NN. Sea <span class="math notranslate nohighlight">\(h^{\star}\)</span> la <code class="docutils literal notranslate"><span class="pre">regla</span> <span class="pre">óptima</span> <span class="pre">de</span> <span class="pre">Bayes</span></code> para <span class="math notranslate nohighlight">\(\eta\)</span>. Entonces,</p>
<div class="math notranslate nohighlight">
\[
\underset{S\sim\mathcal{D}^{m}}{\mathbb{E}}[L_{\mathcal{D}}(h_{S})]\leq 2 L_{\mathcal{D}}(h^{\star})+c\underset{S\sim\mathcal{D}^{m}, \boldsymbol{x}\sim\mathcal{D}}{\mathbb{E}}[\|\boldsymbol{x}-\boldsymbol{x}_{\pi_{1}(\boldsymbol{x})}\|].
\]</div>
</section>
</div><p><strong><code class="docutils literal notranslate"><span class="pre">Demostración</span></code></strong></p>
<ul class="simple">
<li><p>Dado que <span class="math notranslate nohighlight">\(L_{\mathcal{D}}(h_{S}):=\mathbb{E}_{(\boldsymbol{x}, y)\sim\mathcal{D}}(\ell(h, (\boldsymbol{x}, y)))=\mathbb{E}_{(\boldsymbol{x}, y)\sim\mathcal{D}}(\mathbb{1}_{[h(\boldsymbol{x})\neq y]})\)</span>, entonces <span class="math notranslate nohighlight">\(\mathbb{E}(L_{\mathcal{D}}(h_{S})))\)</span> es la <code class="docutils literal notranslate"><span class="pre">probabilidad</span> <span class="pre">de</span> <span class="pre">muestrear</span> <span class="pre">un</span> <span class="pre">conjunto</span> <span class="pre">de</span> <span class="pre">entrenamiento</span></code> <span class="math notranslate nohighlight">\(S\)</span> y un <code class="docutils literal notranslate"><span class="pre">ejemplo</span> <span class="pre">adicional</span></code> <span class="math notranslate nohighlight">\((\boldsymbol{x}, y)\)</span> tal que, la etiqueta de <span class="math notranslate nohighlight">\(\boldsymbol{x}_{\pi_{1}(\boldsymbol{x})}\)</span> es diferente de <span class="math notranslate nohighlight">\(y\)</span>.</p></li>
</ul>
<ul class="simple">
<li><p>En otras palabras, podemos primero <code class="docutils literal notranslate"><span class="pre">muestrear</span></code> <span class="math notranslate nohighlight">\(m\)</span> <code class="docutils literal notranslate"><span class="pre">ejemplos</span> <span class="pre">no</span> <span class="pre">etiquetados</span></code>, <span class="math notranslate nohighlight">\(S_{x}=(x_{1}, x_{2},\dots,x_{m})\)</span>, de acuerdo a <span class="math notranslate nohighlight">\(\mathcal{D}_{x}\)</span>, <code class="docutils literal notranslate"><span class="pre">y</span> <span class="pre">un</span> <span class="pre">nuevo</span> <span class="pre">ejemplo</span> <span class="pre">no</span> <span class="pre">etiquetado</span> <span class="pre">adicional</span></code>, <span class="math notranslate nohighlight">\(\boldsymbol{x}\sim\mathcal{D}_{x}\)</span>. Luego encontramos <span class="math notranslate nohighlight">\(\boldsymbol{x}_{\pi_{1}(\boldsymbol{x})}\)</span> que es el <code class="docutils literal notranslate"><span class="pre">vecino</span> <span class="pre">mas</span> <span class="pre">cercano</span> <span class="pre">a</span></code> <span class="math notranslate nohighlight">\(\boldsymbol{x}\)</span> en <span class="math notranslate nohighlight">\(S_{\boldsymbol{x}}\)</span>, y finalmente muestrear: <span class="math notranslate nohighlight">\(y\sim\eta(\boldsymbol{x})\)</span> y <span class="math notranslate nohighlight">\(y_{\pi_{1}(\boldsymbol{x})}\sim\eta(\boldsymbol{x}_{\pi_{1}(\boldsymbol{x})})\)</span>, donde <span class="math notranslate nohighlight">\(\eta\)</span> es la <code class="docutils literal notranslate"><span class="pre">probabilidad</span> <span class="pre">condicional</span> <span class="pre">asociada</span> <span class="pre">a</span> <span class="pre">la</span> <span class="pre">distribución</span> <span class="pre">marginal</span></code> sobre <span class="math notranslate nohighlight">\(\mathcal{X},~\mathcal{D}_{x}\)</span>.</p></li>
</ul>
<ul class="simple">
<li><p>Entonces</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\mathbb{E}_{S\sim\mathcal{D}^{m}}(L_{\mathcal{D}}(h_{S}))&amp;=\underset{S_{x}\sim\mathcal{D}_{x}^{m}, x\sim\mathcal{D}_{x}, y\sim\eta(x), y_{\pi_{1}(x)}\sim\eta(\boldsymbol{x}_{\pi_{1}(\boldsymbol{x})})}{\mathbb{E}}(\mathbb{1}_{[h(\boldsymbol{x})\neq y\cap h(\boldsymbol{x})\neq y_{\pi_{1}(\boldsymbol{x})}]})\\
&amp;=\underset{S_{x}\sim\mathcal{D}_{x}^{m}, x\sim\mathcal{D}_{x}, y\sim\eta(x), y_{\pi_{1}(x)}\sim\eta(\boldsymbol{x}_{\pi_{1}(\boldsymbol{x})})}{\mathbb{E}}(\mathbb{1}_{[y\neq y_{\pi_{1}(\boldsymbol{x})}]})\\
&amp;=\underset{S_{x}\sim\mathcal{D}_{x}^{m}, x\sim\mathcal{D}_{x}}{\mathbb{E}}\left(\underset{y\sim\eta(x), y_{\pi_{1}(x)}\sim\eta(\boldsymbol{x}_{\pi_{1}(\boldsymbol{x})})}{\mathbb{E}}(\mathbb{1}_{[y\neq y_{\pi_{1}(\boldsymbol{x})}]})\right)\\
&amp;=\underset{S_{x}\sim\mathcal{D}_{x}^{m}, x\sim\mathcal{D}_{x}}{\mathbb{E}}\left(\underset{y\sim\eta(x), y_{\pi_{1}(x)}\sim\eta(\boldsymbol{x}_{\pi_{1}(\boldsymbol{x})})}{\mathbb{P}}(y\neq y_{\pi_{1}(\boldsymbol{x})})\right)\tag{$\star$}
\end{align*}
\end{split}\]</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Acotamos</span> <span class="pre">superiormente</span></code> a: <span class="math notranslate nohighlight">\(\underset{y\sim\eta(x), y_{\pi_{1}(x)}\sim\eta(\boldsymbol{x}_{\pi_{1}(\boldsymbol{x})})}{\mathbb{P}}(y\neq y_{\pi_{1}(\boldsymbol{x})}),~\forall~\boldsymbol{x}, \pi_{1}(\boldsymbol{x})\in\mathcal{D}\)</span></p></li>
</ul>
<ul class="simple">
<li><p>Definamos <span class="math notranslate nohighlight">\(y':=y_{\pi_{1}(\boldsymbol{x})},~x':=\boldsymbol{x}_{\pi_{1}(\boldsymbol{x})}\)</span></p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\underset{y\sim\eta(x), y_{\pi_{1}(x)}\sim\eta(\boldsymbol{x}_{\pi_{1}(\boldsymbol{x})})}{\mathbb{P}}(y\neq y_{\pi_{1}(\boldsymbol{x})})&amp;=\mathbb{P}(y'=1|\boldsymbol{x}')\mathbb{P}(y=0|\boldsymbol{x})+\mathbb{P}(y'=0|\boldsymbol{x}')\mathbb{P}(y=1|\boldsymbol{x})\\
&amp;=\mathbb{P}(y'=1|\boldsymbol{x}')(1-\mathbb{P}(y=1|\boldsymbol{x}))+(1-\mathbb{P}(y'=1|\boldsymbol{x}'))\mathbb{P}(y=1|\boldsymbol{x})\\[3mm]
&amp;=\eta(\boldsymbol{x}')(1-\eta(\boldsymbol{x}))+(1-\eta(\boldsymbol{x}')\eta(\boldsymbol{x}))\\[3mm]
&amp;=(\textcolor{red}{\eta(\boldsymbol{x})-\eta(\boldsymbol{x})}+\eta(\boldsymbol{x}'))(1-\eta(\boldsymbol{x}))+(1\textcolor{red}{-\eta(\boldsymbol{x})+\eta(\boldsymbol{x})}-\eta(\boldsymbol{x}'))\eta(\boldsymbol{x})\\[3mm]
&amp;=2\eta(\boldsymbol{x})(1-\eta(\boldsymbol{x}))+(\eta(\boldsymbol{x})-\eta(\boldsymbol{x}'))(2\eta(\boldsymbol{x})-1)
\end{align*}
\end{split}\]</div>
<ul class="simple">
<li><p>Dado que <span class="math notranslate nohighlight">\(\eta(\boldsymbol{x})=\mathbb{P}(y=1|\boldsymbol{x})\in[0, 1]\)</span>, entonces <span class="math notranslate nohighlight">\(|2\eta(\boldsymbol{x})-1|\leq 1\)</span>. En efecto:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
0\leq\eta(\boldsymbol{x})\leq 1\leq\Leftrightarrow 0\leq 2\eta(\boldsymbol{x})\leq 2\Leftrightarrow-1\leq 2\eta(\boldsymbol{x})-1\leq 1\Leftrightarrow|2\eta(\boldsymbol{x})-1|\leq1.
\]</div>
<ul class="simple">
<li><p>Dado que <span class="math notranslate nohighlight">\(\eta(\boldsymbol{x})\)</span> es <span class="math notranslate nohighlight">\(c\)</span><code class="docutils literal notranslate"><span class="pre">-Lipschitz</span></code>, entonces, <span class="math notranslate nohighlight">\(\forall~\boldsymbol{x},\boldsymbol{x}'\in\mathcal{X},~ |\eta(\boldsymbol{x})-\eta(\boldsymbol{x}')|\leq c\|\boldsymbol{x}-\boldsymbol{x}'\|\)</span>. Por lo tanto,</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\underset{y\sim\eta(x), y_{\pi_{1}(x)}\sim\eta(\boldsymbol{x}_{\pi_{1}(\boldsymbol{x})})}{\mathbb{P}}(y\neq y_{\pi_{1}(\boldsymbol{x})})&amp;=|2\eta(\boldsymbol{x})(1-\eta(\boldsymbol{x}))+(\eta(\boldsymbol{x})-\eta(\boldsymbol{x}'))(2\eta(\boldsymbol{x})-1)|\\
&amp;\leq|2\eta(\boldsymbol{x})(1-\eta(\boldsymbol{x}))|+|(\eta(\boldsymbol{x})-\eta(\boldsymbol{x}'))(2\eta(\boldsymbol{x})-1)|\\[3mm]
&amp;\leq 2\eta(\boldsymbol{x})(1-\eta(\boldsymbol{x}))+|\eta(\boldsymbol{x})-\eta(\boldsymbol{x}')|\textcolor{red}{|2\eta(\boldsymbol{x})-1|}\\[3mm]
&amp;\leq 2\eta(\boldsymbol{x})(1-\eta(\boldsymbol{x}))+c\|\boldsymbol{x}-\boldsymbol{x}'\|
\end{align*}
\end{split}\]</div>
<ul class="simple">
<li><p>Reemplazando esta última desigualdad en (<span class="math notranslate nohighlight">\(\star\)</span>) se tiene que</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\underset{S_{x}\sim\mathcal{D}_{x}^{m}, x\sim\mathcal{D}_{x}}{\mathbb{E}}\left(\underset{y\sim\eta(x), y_{\pi_{1}(x)}\sim\eta(\boldsymbol{x}_{\pi_{1}(\boldsymbol{x})})}{\mathbb{P}}(y\neq y_{\pi_{1}(\boldsymbol{x})})\right)&amp;\leq\underset{\mathcal{X}\sim\mathcal{D}_{x}}{\mathbb{E}}(2\eta(\boldsymbol{x})(1-\eta(\boldsymbol{x})))\\
&amp;+c\underset{\boldsymbol{x}\sim\mathcal{D}_{x},~\mathcal{D}_{x}\sim\mathcal{D}_{x}^{m}}{\mathbb{E}}(\|\boldsymbol{x}-\boldsymbol{x}'\|)
\end{align*}
\end{split}\]</div>
<ul class="simple">
<li><p>Entonces</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\mathbb{E}_{S}(L_{\mathcal{D}}(h_{S}))\leq\underset{\mathcal{X}\sim\mathcal{D}_{x}}{\mathbb{E}}(2\eta(\boldsymbol{x})(1-\eta(\boldsymbol{x})))+c\underset{\boldsymbol{x}\sim\mathcal{D}_{x},~\mathcal{D}_{x}\sim\mathcal{D}_{x}^{m}}{\mathbb{E}}(\|\boldsymbol{x}-\boldsymbol{x}'\|)
\]</div>
<ul class="simple">
<li><p>Dado que <span class="math notranslate nohighlight">\(h^{\star}\)</span> es la <code class="docutils literal notranslate"><span class="pre">regla</span> <span class="pre">óptima</span> <span class="pre">de</span> <span class="pre">Bayes</span></code> para <span class="math notranslate nohighlight">\(\eta\)</span>, entonces <span class="math notranslate nohighlight">\(h^{\star}\)</span> minimiza la pérdida esperada del clasificador, esto es:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\mathbb{E}_{x}(2\eta(\boldsymbol{x})(1-\eta(\boldsymbol{x})))\leq 2\mathbb{E}_{\boldsymbol{x}}(\min\{\eta(\boldsymbol{x}), 1-\eta(\boldsymbol{x})\})=2 L_{\mathcal{D}}(h^{\star})
\]</div>
<ul class="simple">
<li><p>Nótese que la desigualdad anterior, que involucra el mínimo <span class="math notranslate nohighlight">\(\min\{\eta(\boldsymbol{x}), 1-\eta(\boldsymbol{x})\}\)</span>, es valida. En efecto, si <span class="math notranslate nohighlight">\(\eta(\boldsymbol{x})\in[0, 1]\)</span> y <span class="math notranslate nohighlight">\(\min\{\eta(\boldsymbol{x}), 1-\eta(\boldsymbol{x})\}=\eta(\boldsymbol{x})\)</span>, entonces <span class="math notranslate nohighlight">\(\eta(\boldsymbol{x})\leq 1-\eta(\boldsymbol{x})\)</span>, por lo tanto:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
2\eta(\boldsymbol{x})(1-\eta(\boldsymbol{x}))\leq2(1-\eta(\boldsymbol{x}))^{2}\leq 2\min\{\eta(\boldsymbol{x}), 1-\eta(\boldsymbol{x})\}
\]</div>
<ul class="simple">
<li><p>Por lo tanto:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\underset{S\sim\mathcal{D}^{m}}{\mathbb{E}}[L_{\mathcal{D}}(h_{S})]\leq 2 L_{\mathcal{D}}(h^{\star})+c\underset{\boldsymbol{x}\sim\mathcal{D}_{x},~\mathcal{D}_{x}\sim\mathcal{D}_{x}^{m}}{\mathbb{E}}(\|\boldsymbol{x}-\boldsymbol{x}'\|).
\]</div>
<div class="tip admonition">
<p class="admonition-title">Observation</p>
<p>El siguiente paso es <code class="docutils literal notranslate"><span class="pre">acotar</span> <span class="pre">la</span> <span class="pre">distancia</span> <span class="pre">entre</span> <span class="pre">una</span> <span class="pre">variable</span> <span class="pre">aleatoria</span></code> <span class="math notranslate nohighlight">\(\boldsymbol{x}\)</span> <code class="docutils literal notranslate"><span class="pre">y</span> <span class="pre">su</span> <span class="pre">vecino</span> <span class="pre">mas</span> <span class="pre">cercano</span> <span class="pre">en</span></code> <span class="math notranslate nohighlight">\(S\)</span>. Primero necesitaremos el siguiente Teorema, el cual <code class="docutils literal notranslate"><span class="pre">acota</span> <span class="pre">el</span> <span class="pre">peso</span> <span class="pre">probabilístico</span> <span class="pre">de</span> <span class="pre">subconjuntos</span> <span class="pre">que</span> <span class="pre">no</span> <span class="pre">son</span> <span class="pre">alcanzados</span> <span class="pre">por</span> <span class="pre">una</span> <span class="pre">muestra</span> <span class="pre">aleatoria,</span> <span class="pre">como</span> <span class="pre">una</span> <span class="pre">función</span> <span class="pre">del</span> <span class="pre">tamaño</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">muestra</span></code>.</p>
</div>
<div class="proof lemma admonition" id="knn_lemma2">
<p class="admonition-title"><span class="caption-number">Lemma 2 </span></p>
<section class="lemma-content" id="proof-content">
<p>Sea <span class="math notranslate nohighlight">\(C_{1}, C_{2},\dots,C_{r}\)</span> una colección de <code class="docutils literal notranslate"><span class="pre">subconjuntos</span> <span class="pre">de</span> <span class="pre">algún</span> <span class="pre">dominio</span></code> <span class="math notranslate nohighlight">\(\mathcal{X}\)</span>. Sea <span class="math notranslate nohighlight">\(S\)</span> una sucesión de <span class="math notranslate nohighlight">\(m\)</span> <code class="docutils literal notranslate"><span class="pre">puntos</span> <span class="pre">iid</span> <span class="pre">muestreados</span> <span class="pre">de</span> <span class="pre">acuerdo</span> <span class="pre">a</span> <span class="pre">una</span> <span class="pre">distribución</span> <span class="pre">de</span> <span class="pre">probabilidad</span></code> <span class="math notranslate nohighlight">\(\mathcal{D}\)</span> sobre <span class="math notranslate nohighlight">\(\mathcal{X}\)</span>. Entonces:</p>
<div class="math notranslate nohighlight">
\[
\mathbb{E}_{S\sim\mathcal{D}^{m}}\left(\sum_{i:C_{i}\cap S=\emptyset}\mathbb{P}(C_{i})\right)\leq\frac{r}{me}.
\]</div>
</section>
</div><p><strong><code class="docutils literal notranslate"><span class="pre">Demostración</span></code></strong></p>
<ul class="simple">
<li><p>Por <code class="docutils literal notranslate"><span class="pre">linealidad</span> <span class="pre">del</span> <span class="pre">valor</span> <span class="pre">esperado</span></code> se tiene que:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\mathbb{E}_{S}\left(\sum_{i:C_{i}\cap S=\emptyset}\mathbb{P}(C_{i})\right)&amp;=\sum_{i:C_{i}\cap S=\emptyset}\mathbb{E}_{S}(\mathbb{P}(C_{i}))\\
&amp;=\sum_{i=1}^{r}\mathbb{E}_{S}(\mathbb{P}(C_{i})\mathbb{1}_{C_{i}\cap S=\emptyset})\\
&amp;=\sum_{i=1}^{r}\mathbb{P}(C_{i})\mathbb{E}_{S}(\mathbb{1}_{C_{i}\cap S=\emptyset})
\end{align*}
\end{split}\]</div>
<ul class="simple">
<li><p>Entonces para cada <span class="math notranslate nohighlight">\(i\)</span>, usando <code class="docutils literal notranslate"><span class="pre">propiedades</span> <span class="pre">de</span> <span class="pre">independencia</span> <span class="pre">y</span> <span class="pre">complemento</span></code>, dado que <span class="math notranslate nohighlight">\(S\)</span> es una <code class="docutils literal notranslate"><span class="pre">sucesión</span> <span class="pre">de</span></code> <span class="math notranslate nohighlight">\(m\)</span> <code class="docutils literal notranslate"><span class="pre">puntos</span> <span class="pre">iid</span></code> tenemos</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\mathbb{E}_{S}(\mathbb{1}_{C_{i}\cap S=\emptyset})=\mathbb{P}_{S}(C_{i}\cap S=\emptyset)=\prod_{S}\mathbb{P}(C_{i}\setminus S)=(1-\mathbb{P}(C_{i}))^{m}.
\]</div>
<ul>
<li><p>Definamos <span class="math notranslate nohighlight">\(\varepsilon=-\mathbb{P}(C_{i})\)</span>. <code class="docutils literal notranslate"><span class="pre">Verifiquemos</span> <span class="pre">que</span></code> <span class="math notranslate nohighlight">\(e^{\varepsilon}\ge 1+\varepsilon,~\forall\varepsilon\in\mathbb{R}\)</span>. En efecto. Si <span class="math notranslate nohighlight">\(~\varepsilon\leq-1\Rightarrow e^{\varepsilon}&gt;0~\)</span> y <span class="math notranslate nohighlight">\(~1+\varepsilon\leq 0\Rightarrow 1+\varepsilon\leq0&lt;e^{\varepsilon}\Rightarrow1+\varepsilon\leq e^{\varepsilon}\)</span>.</p>
<div class="math notranslate nohighlight">
\[
    \begin{align*}
    \text{Si}~\varepsilon&gt;-1\Rightarrow e^{\varepsilon}&amp;=\lim_{n\rightarrow\infty}\left(1+\frac{\varepsilon}{n}\right)^{n}\underset{\text{Bernoulli}}{\geq}\lim_{n\rightarrow\infty}1+n\frac{\varepsilon}{n}=1+\varepsilon.
    \end{align*}
    \]</div>
<p>Entonces <span class="math notranslate nohighlight">\(1+\varepsilon\leq e^{\varepsilon},~\forall\varepsilon\in\mathbb{R}\)</span>.</p>
</li>
</ul>
<div class="proof definition admonition" id="des_bernoulli">
<p class="admonition-title"><span class="caption-number">Definition 5 </span> (Desigualdad de Bernoulli)</p>
<section class="definition-content" id="proof-content">
<p><code class="docutils literal notranslate"><span class="pre">Desigualdad</span> <span class="pre">de</span> <span class="pre">Bernoulli</span></code>: Sea <span class="math notranslate nohighlight">\(x\in\mathbb{R}\)</span> tal que <span class="math notranslate nohighlight">\(x&gt;-1\)</span> y <span class="math notranslate nohighlight">\(n\in\mathbb{Z}^{+}\)</span>, entonces, <span class="math notranslate nohighlight">\((1+x)^{n}\geq1+nx\)</span>.</p>
</section>
</div><ul class="simple">
<li><p>Dado que <span class="math notranslate nohighlight">\(\varepsilon=-\mathbb{P}(C_{i})\)</span>, entonces</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
(1-\mathbb{P}(C_{i}))^{m}\leq e^{-m \mathbb{P}(C_{i})}\Rightarrow\mathbb{E}_{S}(\mathbb{1}_{C_{i}\cap S=\emptyset})\leq e^{-m \mathbb{P}(C_{i})}
\]</div>
<ul class="simple">
<li><p>De este modo,</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\mathbb{E}_{S}\left(\sum_{i:C_{i}\cap S=\emptyset}\mathbb{P}(C_{i})\right)&amp;=\sum_{i=1}^{r}\mathbb{P}(C_{i})\mathbb{E}_{S}(\mathbb{1}_{C_{i}\cap S=\emptyset})\\
&amp;\leq\sum_{i=1}^{r}\mathbb{P}(C_{i})e^{-\mathbb{P}(C_{i})m}\\[3mm]
&amp;\leq r\max_{i}\mathbb{P}(C_{i})e^{-\mathbb{P}(C_{i})m},\quad f'(a)=0, a=\mathbb{P}(C_{i})\\
&amp;=r\frac{1}{m}e^{-m(1/m)}\\
&amp;=\frac{r}{me}
\end{align*}
\end{split}\]</div>
<div class="proof theorem admonition" id="knn_theorem1">
<p class="admonition-title"><span class="caption-number">Theorem 1 </span></p>
<section class="theorem-content" id="proof-content">
<p>Sea <span class="math notranslate nohighlight">\(\mathcal{X}=[0, 1]^{d},~\mathcal{Y}=\{0, 1\}\)</span> y <span class="math notranslate nohighlight">\(\mathcal{D}\)</span> una distribución sobre <span class="math notranslate nohighlight">\(\mathcal{X}\times\mathcal{Y}\)</span> para la cual la <code class="docutils literal notranslate"><span class="pre">función</span> <span class="pre">de</span> <span class="pre">probabilidad</span> <span class="pre">condicional</span></code>, <span class="math notranslate nohighlight">\(\eta\)</span>, es una función <span class="math notranslate nohighlight">\(c\)</span><code class="docutils literal notranslate"><span class="pre">-Lipschitz</span></code>. Denotamos con <span class="math notranslate nohighlight">\(h_{S}\)</span> el resultado de aplicar la regla <span class="math notranslate nohighlight">\(1\)</span>-NN a una muestra <span class="math notranslate nohighlight">\(S\sim\mathcal{D}^{m}\)</span>. Entonces</p>
<div class="math notranslate nohighlight">
\[
\mathbb{E}_{S\sim\mathcal{D}^{m}}(L_{\mathcal{D}}(h_{S}))\leq 2 L_{\mathcal{D}}(h^{\star})+4 c\sqrt{d} m^{-1/(d+1)}.
\]</div>
</section>
</div><p><strong><code class="docutils literal notranslate"><span class="pre">Demostración</span></code></strong></p>
<figure class="align-center" id="box-neigh-knn-fig">
<a class="reference internal image-reference" href="_images/box_neigh_knn.png"><img alt="_images/box_neigh_knn.png" src="_images/box_neigh_knn.png" style="width: 227.70000000000002px; height: 234.9px;" />
</a>
</figure>
<ul class="simple">
<li><p>Fijemos <span class="math notranslate nohighlight">\(\varepsilon=1/T\)</span>, para algún entero <span class="math notranslate nohighlight">\(T\)</span>, sea <span class="math notranslate nohighlight">\(r=T^{d}\)</span>, y sea <span class="math notranslate nohighlight">\(C_{1}, C_{2}, \dots, C_{m}\)</span> un <code class="docutils literal notranslate"><span class="pre">cubrimiento</span> <span class="pre">del</span> <span class="pre">conjunto</span></code> <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> usando <code class="docutils literal notranslate"><span class="pre">cajas</span> <span class="pre">de</span> <span class="pre">longitud</span></code> <span class="math notranslate nohighlight">\(\varepsilon\)</span>. Es decir, para cada <span class="math notranslate nohighlight">\((\alpha_{1}, \alpha_{2},\dots,\alpha_{d})\in [T]^{d}\)</span>, existe un conjunto <span class="math notranslate nohighlight">\(C_{i}\)</span> de la forma</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\mathcal{B}_{x}=\{\boldsymbol{x}:~\forall~j,~ x_{j}\in [(\alpha_{j}-1)/T, \alpha_{j}/T]\}
\]</div>
<ul class="simple">
<li><p>Entonces, <span class="math notranslate nohighlight">\(\forall~\boldsymbol{x}, \boldsymbol{x}'\)</span> en la <code class="docutils literal notranslate"><span class="pre">misma</span> <span class="pre">caja</span></code> <span class="math notranslate nohighlight">\(\mathcal{B}_{x}\)</span>, se tiene que, <span class="math notranslate nohighlight">\(x_{i}-x_{i}'\leq 1/T=\varepsilon\)</span></p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\|\boldsymbol{x}-\boldsymbol{x}'\|=\left(\sum_{i=1}^{d}(x_{i}-x_{i}')^{2}\right)^{1/2}\hspace{-4mm}\leq\left(\sum_{i=1}^{d}\varepsilon^{2}\right)^{1/2}\hspace{-4mm}=\sqrt{d\varepsilon^{2}}=\sqrt{d}\varepsilon.
\]</div>
<ul class="simple">
<li><p>Si <span class="math notranslate nohighlight">\(\boldsymbol{x}, \boldsymbol{x}'\)</span> <code class="docutils literal notranslate"><span class="pre">no</span> <span class="pre">caen</span> <span class="pre">en</span> <span class="pre">la</span> <span class="pre">misma</span> <span class="pre">caja</span></code> <span class="math notranslate nohighlight">\(\mathcal{B}_{x}\)</span> entonces <span class="math notranslate nohighlight">\(x_{i}-x_{i}'\leq 1,~\forall~i\)</span>, entonces <span class="math notranslate nohighlight">\(\|\boldsymbol{x}-\boldsymbol{x}'\|\leq\sqrt{d}\)</span>.</p></li>
</ul>
<ul class="simple">
<li><p>Entonces, dado que <span class="math notranslate nohighlight">\(\mathbb{P}\left(\bigcup_{C_{i}\cap S\neq\emptyset}C_{i}\right)\leq1\)</span> y <span class="math notranslate nohighlight">\(\boldsymbol{x}_{\pi_{1}(x)}\in S\)</span></p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\mathbb{E}_{\boldsymbol{x}, S}(\|\boldsymbol{x}-\boldsymbol{x}'\|)&amp;=\mathbb{E}_{S}(\mathbb{E}_{\boldsymbol{x}}(\|\boldsymbol{x}-\boldsymbol{x}'\|))\\[3mm]
&amp;=\mathbb{E}_{S}\left(\mathbb{E}_{\underset{\boldsymbol{x}\in C_{i}}{i:C_{i}\cap S=\emptyset}}(\|\boldsymbol{x}-\boldsymbol{x}_{\pi_{1}(x)}\|)+\mathbb{E}_{\underset{\boldsymbol{x}\in C_{i}}{i:C_{i}\cap S\neq\emptyset}}(\|\boldsymbol{x}-\boldsymbol{x}_{\pi_{1}(x)}\|)\right)\\
&amp;\leq\mathbb{E}_{S}\left(P\left(\bigcup_{C_{i}\cap S=\emptyset}C_{i}\right)\sqrt{d}+P\left(\bigcup_{C_{i}\cap S\neq\emptyset}C_{i}\right)\sqrt{d}\varepsilon\right)\\
&amp;\leq\mathbb{E}_{S}\left(\frac{r}{me}\sqrt{d}+1\sqrt{d}\varepsilon\right)\\[3mm]
&amp;=\sqrt{d}\left(\frac{r}{me}+\varepsilon\right)
\end{align*}
\end{split}\]</div>
<ul class="simple">
<li><p>Dado que <span class="math notranslate nohighlight">\(r=T^{d}=(1/\varepsilon)^{d}=1/\varepsilon^{d}\)</span>, entonces:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\mathbb{E}_{\boldsymbol{x}, S}(\|\boldsymbol{x}-\boldsymbol{x}_{\pi_{1}(\boldsymbol{x})}\|)\leq\sqrt{d}\left(\frac{1/\varepsilon^{d}}{me}+\varepsilon\right)=\sqrt{d}\left(\frac{\varepsilon^{-d}}{me}+\varepsilon\right)\leq\sqrt{d}\left(\frac{2^{d}\varepsilon^{-d}}{me}+\varepsilon\right).
\]</div>
<ul class="simple">
<li><p>Usando el <a class="reference internal" href="#knn_lemma1">Lemma 1</a> se tiene que</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\underset{S\sim\mathcal{D}^{m}}{\mathbb{E}}[L_{\mathcal{D}}(h_{S})]&amp;\leq 2 L_{\mathcal{D}}(h^{\star})+c\underset{S\sim\mathcal{D}^{m}, \boldsymbol{x}\sim\mathcal{D}}{\mathbb{E}}[\|\boldsymbol{x}-\boldsymbol{x}_{\pi_{1}(\boldsymbol{x})}\|]\\
&amp;\leq 2 L_{\mathcal{D}}(h^{\star})+c\sqrt{d}\left(\frac{2^{d}\varepsilon^{-d}}{me}+\varepsilon\right)
\end{align*}
\end{split}\]</div>
<ul class="simple">
<li><p>Finalmente, fijando <span class="math notranslate nohighlight">\(\varepsilon=2m^{-1/(d+1)}\)</span> se tiene que:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\frac{2^{d}\varepsilon^{-d}}{me}+\varepsilon&amp;=\frac{2^{d}2^{-d}m^{d/(d+1)}}{me}+2m^{-1/(d+1)}\\
&amp;=m^{[d/(d+1)]-1}(1/e)+2m^{-1/(d+1)}\\
&amp;=m^{-1/(d+1)}(1/e+2)\\
&amp;\leq4m^{-1/(d+1)}
\end{align*}
\end{split}\]</div>
<ul class="simple">
<li><p>Entonces</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\begin{align*}
\underset{S\sim\mathcal{D}^{m}}{\mathbb{E}}[L_{\mathcal{D}}(h_{S})]&amp;\leq 2 L_{\mathcal{D}}(h^{\star})+4c\sqrt{d}m^{-1/(d+1)}.
\end{align*}
\]</div>
<div class="proof observation admonition" id="observation-9">
<p class="admonition-title"><span class="caption-number">Observation 2 </span></p>
<section class="observation-content" id="proof-content">
<p>El Teorema implica que si <code class="docutils literal notranslate"><span class="pre">primero</span> <span class="pre">fijamos</span> <span class="pre">la</span> <span class="pre">distribución</span> <span class="pre">generadora</span> <span class="pre">de</span> <span class="pre">datos</span> <span class="pre">y</span> <span class="pre">luego</span> <span class="pre">hacemos</span> <span class="pre">tender</span></code> <span class="math notranslate nohighlight">\(m\)</span> <code class="docutils literal notranslate"><span class="pre">a</span> <span class="pre">infinito</span></code>, entonces <code class="docutils literal notranslate"><span class="pre">el</span> <span class="pre">error</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">regla</span></code> <span class="math notranslate nohighlight">\(1\)</span>-NN <code class="docutils literal notranslate"><span class="pre">converge</span> <span class="pre">al</span> <span class="pre">doble</span> <span class="pre">del</span> <span class="pre">error</span> <span class="pre">de</span> <span class="pre">Bayes</span></code>. El análisis puede generalizarse a valores mayores que <span class="math notranslate nohighlight">\(k\)</span>, demostrando que el error esperado de la regla <span class="math notranslate nohighlight">\(k\)</span>-NN converge a <span class="math notranslate nohighlight">\((1+\sqrt{8/k})\)</span> veces el error del <code class="docutils literal notranslate"><span class="pre">clasificador</span> <span class="pre">de</span> <span class="pre">Bayes</span></code>.</p>
</section>
</div></section>
<section id="implementacion">
<h2>Implementación<a class="headerlink" href="#implementacion" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p><strong><code class="docutils literal notranslate"><span class="pre">Clasificación</span> <span class="pre">k-vecinos</span></code></strong>. Como ya se estudió anteriormente, en su versión más sencilla, el algoritmo <code class="docutils literal notranslate"><span class="pre">k-NN</span></code> solo considera exactamente un vecino más cercano, que es el <code class="docutils literal notranslate"><span class="pre">dato</span> <span class="pre">de</span> <span class="pre">entrenamiento</span> <span class="pre">más</span> <span class="pre">cercano</span> <span class="pre">al</span> <span class="pre">punto</span> <span class="pre">para</span> <span class="pre">el</span> <span class="pre">que</span> <span class="pre">queremos</span> <span class="pre">hacer</span> <span class="pre">una</span> <span class="pre">predicción</span></code>. La predicción es entonces simplemente la etiqueta conocida para este punto de entrenamiento.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>
<span class="kn">import</span> <span class="nn">mglearn</span>
<span class="kn">import</span> <span class="nn">matplotlib</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mglearn</span><span class="o">.</span><span class="n">plots</span><span class="o">.</span><span class="n">plot_knn_classification</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/b4d74671fd0e1aa188142c12cf0c01df4a18195ff3e98ad70cbf2b6c633265b1.png" src="_images/b4d74671fd0e1aa188142c12cf0c01df4a18195ff3e98ad70cbf2b6c633265b1.png" />
</div>
</div>
<ul class="simple">
<li><p>Se han añadido <code class="docutils literal notranslate"><span class="pre">tres</span> <span class="pre">nuevos</span> <span class="pre">puntos</span> <span class="pre">de</span> <span class="pre">datos,</span> <span class="pre">mostrados</span> <span class="pre">como</span> <span class="pre">estrellas</span></code>. Para cada uno de ellos, marcamos el punto más cercano en el conjunto de entrenamiento. La predicción del algoritmo del <code class="docutils literal notranslate"><span class="pre">vecino</span> <span class="pre">más</span> <span class="pre">cercano</span> <span class="pre">es</span> <span class="pre">la</span> <span class="pre">etiqueta</span> <span class="pre">de</span> <span class="pre">ese</span> <span class="pre">punto</span> <span class="pre">(mostrada</span> <span class="pre">por</span> <span class="pre">el</span> <span class="pre">color</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">cruz)</span></code>.</p></li>
<li><p>En lugar de considerar sólo al vecino más cercano, también <code class="docutils literal notranslate"><span class="pre">podemos</span> <span class="pre">considerar</span> <span class="pre">un</span> <span class="pre">número</span> <span class="pre">arbitrario</span></code> <span class="math notranslate nohighlight">\(k\)</span>, de vecinos. De ahí viene el nombre del algoritmo <span class="math notranslate nohighlight">\(k\)</span>-vecinos más cercanos. Cuando se considera <code class="docutils literal notranslate"><span class="pre">más</span> <span class="pre">de</span> <span class="pre">un</span> <span class="pre">vecino,</span> <span class="pre">se</span> <span class="pre">utiliza</span> <span class="pre">la</span> <span class="pre">votación</span> <span class="pre">para</span> <span class="pre">asignar</span> <span class="pre">una</span> <span class="pre">etiqueta</span></code>. Esto significa que, para cada punto de prueba, contamos <code class="docutils literal notranslate"><span class="pre">cuántos</span> <span class="pre">vecinos</span> <span class="pre">pertenecen</span> <span class="pre">a</span> <span class="pre">clase</span> <span class="pre">0</span> <span class="pre">y</span> <span class="pre">cuántos</span> <span class="pre">vecinos</span> <span class="pre">pertenecen</span> <span class="pre">a</span> <span class="pre">la</span> <span class="pre">clase</span> <span class="pre">1</span></code>. A continuación, <code class="docutils literal notranslate"><span class="pre">asignamos</span> <span class="pre">la</span> <span class="pre">clase</span> <span class="pre">que</span> <span class="pre">es</span> <span class="pre">más</span> <span class="pre">frecuente</span></code>: es decir, la clase mayoritaria entre los <span class="math notranslate nohighlight">\(k\)</span> <code class="docutils literal notranslate"><span class="pre">vecinos</span> <span class="pre">más</span> <span class="pre">cercanos</span></code>.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mglearn</span><span class="o">.</span><span class="n">plots</span><span class="o">.</span><span class="n">plot_knn_classification</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/7ee0ca32acdbea5dedd37a11c58de176094f0da7652cbd945e8005a4ef4c7f89.png" src="_images/7ee0ca32acdbea5dedd37a11c58de176094f0da7652cbd945e8005a4ef4c7f89.png" />
</div>
</div>
<ul class="simple">
<li><p>Aunque esta ilustración se refiere a un <code class="docutils literal notranslate"><span class="pre">problema</span> <span class="pre">de</span> <span class="pre">clasificación</span> <span class="pre">binaria</span></code>, este método <code class="docutils literal notranslate"><span class="pre">puede</span> <span class="pre">aplicarse</span> <span class="pre">a</span> <span class="pre">conjuntos</span> <span class="pre">de</span> <span class="pre">datos</span> <span class="pre">con</span> <span class="pre">cualquier</span> <span class="pre">número</span> <span class="pre">de</span> <span class="pre">clases</span></code>. Para más clases, <code class="docutils literal notranslate"><span class="pre">contamos</span> <span class="pre">cuántos</span> <span class="pre">vecinos</span> <span class="pre">pertenecen</span> <span class="pre">a</span> <span class="pre">cada</span> <span class="pre">clase</span> <span class="pre">y</span> <span class="pre">volvemos</span> <span class="pre">a</span> <span class="pre">predecir</span> <span class="pre">la</span> <span class="pre">clase</span> <span class="pre">más</span> <span class="pre">común</span></code>. Ahora veamos cómo podemos aplicar el algoritmo de los <code class="docutils literal notranslate"><span class="pre">vecinos</span> <span class="pre">más</span> <span class="pre">cercanos</span></code> utilizando <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code>.</p></li>
<li><p>En primer lugar, dividimos nuestros datos en un conjunto de <code class="docutils literal notranslate"><span class="pre">entrenamiento</span></code> y otro de <code class="docutils literal notranslate"><span class="pre">prueba</span></code> para poder evaluar el rendimiento de la <code class="docutils literal notranslate"><span class="pre">generalización</span></code>. <code class="docutils literal notranslate"><span class="pre">random_state=0</span></code> nos asegura que obtendremos los <code class="docutils literal notranslate"><span class="pre">mismos</span> <span class="pre">conjuntos</span> <span class="pre">de</span> <span class="pre">training</span> <span class="pre">y</span> <span class="pre">test</span> <span class="pre">para</span> <span class="pre">diferentes</span> <span class="pre">ejecuciones</span></code>. Para mas información sobre <code class="docutils literal notranslate"><span class="pre">sklearn.model_selection.train_test_split</span></code> (ver documentación <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html">train_test_split</a>). Por defecto, cuando no es suministrado el porcentaje de entrenamiento <code class="docutils literal notranslate"><span class="pre">train_test_split</span></code> considera este porcentaje para el test como el 25%, esto es <code class="docutils literal notranslate"><span class="pre">test_size=0.25</span></code></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">mglearn</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">make_forge</span><span class="p">()</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>A continuación, <code class="docutils literal notranslate"><span class="pre">importamos</span> <span class="pre">e</span> <span class="pre">instanciamos</span></code> la clase <code class="docutils literal notranslate"><span class="pre">KNeighborsClassifier</span></code> de <code class="docutils literal notranslate"><span class="pre">sklearn</span></code> encargada de la tarea de clasificación. Aquí es cuando podemos <code class="docutils literal notranslate"><span class="pre">establecer</span> <span class="pre">parámetros,</span> <span class="pre">como</span> <span class="pre">el</span> <span class="pre">número</span> <span class="pre">de</span> <span class="pre">vecinos</span> <span class="pre">a</span> <span class="pre">utilizar</span></code>, el cual consideramos como 3 para este ejemplo <code class="docutils literal notranslate"><span class="pre">n_neighbors=3</span></code></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">clf</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Ahora, <code class="docutils literal notranslate"><span class="pre">ajustamos</span> <span class="pre">el</span> <span class="pre">clasificador</span> <span class="pre">utilizando</span> <span class="pre">el</span> <span class="pre">conjunto</span> <span class="pre">de</span> <span class="pre">entrenamiento</span></code>. Para la clase <code class="docutils literal notranslate"><span class="pre">KNeighborsClassifier</span></code> esto significa <code class="docutils literal notranslate"><span class="pre">almacenar</span> <span class="pre">el</span> <span class="pre">conjunto</span> <span class="pre">de</span> <span class="pre">datos,</span> <span class="pre">para</span> <span class="pre">poder</span> <span class="pre">calcular</span> <span class="pre">los</span> <span class="pre">vecinos</span> <span class="pre">durante</span> <span class="pre">la</span> <span class="pre">predicción</span></code>, teniendo en cuenta la asignación de la clase más frecuente, explicada anteriormente</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-1" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>KNeighborsClassifier(n_neighbors=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-1" type="checkbox" checked><label for="sk-estimator-id-1" class="sk-toggleable__label sk-toggleable__label-arrow">KNeighborsClassifier</label><div class="sk-toggleable__content"><pre>KNeighborsClassifier(n_neighbors=3)</pre></div></div></div></div></div></div></div>
</div>
<ul class="simple">
<li><p>Para hacer <code class="docutils literal notranslate"><span class="pre">predicciones</span> <span class="pre">sobre</span> <span class="pre">los</span> <span class="pre">datos</span> <span class="pre">de</span> <span class="pre">prueba</span></code>, llamamos al método de predicción <code class="docutils literal notranslate"><span class="pre">predict()</span></code>. Para cada punto de datos en el conjunto de prueba, éste <code class="docutils literal notranslate"><span class="pre">calcula</span> <span class="pre">sus</span> <span class="pre">vecinos</span> <span class="pre">más</span> <span class="pre">cercanos</span> <span class="pre">en</span> <span class="pre">el</span> <span class="pre">conjunto</span> <span class="pre">de</span> <span class="pre">entrenamiento</span> <span class="pre">y</span> <span class="pre">encuentra</span> <span class="pre">la</span> <span class="pre">clase</span> <span class="pre">más</span> <span class="pre">común</span> <span class="pre">entre</span> <span class="pre">ellos</span></code>. Para mas información sobre el cálculo del <code class="docutils literal notranslate"><span class="pre">score</span></code> (ver documentación <a class="reference external" href="https://scikit-learn.org/stable/modules/model_evaluation.html#accuracy-score">accuracy score</a>)</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_test</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[11.54155807,  5.21116083],
       [10.06393839,  0.99078055],
       [ 9.49123469,  4.33224792],
       [ 8.18378052,  1.29564214],
       [ 8.30988863,  4.80623966],
       [10.24028948,  2.45544401],
       [ 8.34468785,  1.63824349]])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test set predictions: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Test set predictions: [1 0 1 0 1 0 0]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test set: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">y_test</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Test set: [1 0 1 0 1 1 0]
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Para evaluar <code class="docutils literal notranslate"><span class="pre">lo</span> <span class="pre">bien</span> <span class="pre">que</span> <span class="pre">generaliza</span></code> nuestro modelo, podemos llamar al método <code class="docutils literal notranslate"><span class="pre">score()</span></code> con los datos de prueba junto con las etiquetas de prueba <code class="docutils literal notranslate"><span class="pre">X_text,</span> <span class="pre">y_test</span></code>.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test set accuracy: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Test set accuracy: 0.86
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Vemos que nuestro modelo tiene una <code class="docutils literal notranslate"><span class="pre">precisión</span></code> del 86%, lo que significa que <code class="docutils literal notranslate"><span class="pre">el</span> <span class="pre">modelo</span> <span class="pre">predijo</span> <span class="pre">la</span> <span class="pre">clase</span> <span class="pre">correctamente</span> <span class="pre">para</span> <span class="pre">el</span> <span class="pre">86%</span> <span class="pre">de</span> <span class="pre">las</span> <span class="pre">muestras</span> <span class="pre">del</span> <span class="pre">conjunto</span> <span class="pre">de</span> <span class="pre">datos</span> <span class="pre">de</span> <span class="pre">prueba</span></code>.</p></li>
</ul>
</section>
<section id="analisis-de-kneighborsclassifier">
<h2>Análisis de <code class="docutils literal notranslate"><span class="pre">KNeighborsClassifier</span></code><a class="headerlink" href="#analisis-de-kneighborsclassifier" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Para los conjuntos de datos bidimensionales, también podemos ilustrar la <code class="docutils literal notranslate"><span class="pre">predicción</span> <span class="pre">para</span> <span class="pre">todos</span> <span class="pre">los</span> <span class="pre">posibles</span> <span class="pre">puntos</span> <span class="pre">de</span> <span class="pre">prueba</span> <span class="pre">en</span> <span class="pre">el</span> <span class="pre">plano</span></code> <span class="math notranslate nohighlight">\(xy\)</span>. Coloreamos el plano según la clase que se asignaría a un punto en esta región. Esto nos permite ver el <code class="docutils literal notranslate"><span class="pre">límite</span> <span class="pre">de</span> <span class="pre">decisión</span> <span class="pre">(decision</span> <span class="pre">boundary)</span></code> (ver <a class="reference external" href="https://github.com/amueller/mglearn/blob/master/mglearn/plot_2d_separator.py">plot_2d_separator</a>), el cual está <code class="docutils literal notranslate"><span class="pre">entre</span> <span class="pre">el</span> <span class="pre">lugar</span> <span class="pre">donde</span> <span class="pre">el</span> <span class="pre">algoritmo</span> <span class="pre">asigna</span> <span class="pre">la</span> <span class="pre">clase</span> <span class="pre">0</span> <span class="pre">y</span> <span class="pre">el</span> <span class="pre">lugar</span> <span class="pre">donde</span> <span class="pre">asigna</span> <span class="pre">la</span> <span class="pre">clase</span> <span class="pre">1</span></code>.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>

<span class="k">for</span> <span class="n">n_neighbors</span><span class="p">,</span> <span class="n">ax</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">9</span><span class="p">],</span> <span class="n">axes</span><span class="p">):</span>
    <span class="n">clf</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="n">n_neighbors</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">mglearn</span><span class="o">.</span><span class="n">plots</span><span class="o">.</span><span class="n">plot_2d_separator</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">fill</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">.4</span><span class="p">)</span>
    <span class="n">mglearn</span><span class="o">.</span><span class="n">discrete_scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">y</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{}</span><span class="s2"> neighbor(s)&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">n_neighbors</span><span class="p">))</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;feature 0&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;feature 1&quot;</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/7b6468bffb2c5d1dd4c5cfc15dbb3d35198dbd4db687b94ff6f11608bd41ca16.png" src="_images/7b6468bffb2c5d1dd4c5cfc15dbb3d35198dbd4db687b94ff6f11608bd41ca16.png" />
</div>
</div>
<ul class="simple">
<li><p>Como se puede ver en la figura de la izquierda, <code class="docutils literal notranslate"><span class="pre">el</span> <span class="pre">uso</span> <span class="pre">de</span> <span class="pre">un</span> <span class="pre">solo</span> <span class="pre">vecino</span> <span class="pre">da</span> <span class="pre">como</span> <span class="pre">resultado</span> <span class="pre">una</span> <span class="pre">decisión</span> <span class="pre">que</span> <span class="pre">sigue</span> <span class="pre">de</span> <span class="pre">cerca</span> <span class="pre">los</span> <span class="pre">datos</span> <span class="pre">de</span> <span class="pre">entrenamiento</span></code>. La consideración de <code class="docutils literal notranslate"><span class="pre">más</span> <span class="pre">vecinos</span> <span class="pre">conduce</span> <span class="pre">a</span> <span class="pre">un</span> <span class="pre">límite</span> <span class="pre">de</span> <span class="pre">decisión</span> <span class="pre">más</span> <span class="pre">suave</span></code>. Un límite más suave corresponde a un <code class="docutils literal notranslate"><span class="pre">modelo</span> <span class="pre">más</span> <span class="pre">sencillo</span></code>. En otras palabras, <code class="docutils literal notranslate"><span class="pre">el</span> <span class="pre">uso</span> <span class="pre">de</span> <span class="pre">pocos</span> <span class="pre">vecinos</span> <span class="pre">corresponde</span> <span class="pre">a</span> <span class="pre">una</span> <span class="pre">alta</span> <span class="pre">complejidad</span> <span class="pre">del</span> <span class="pre">modelo</span></code> (como se muestra en el lado derecho), y <code class="docutils literal notranslate"><span class="pre">el</span> <span class="pre">uso</span> <span class="pre">de</span> <span class="pre">muchos</span> <span class="pre">vecinos</span> <span class="pre">corresponde</span> <span class="pre">a</span> <span class="pre">una</span> <span class="pre">baja</span> <span class="pre">complejidad</span> <span class="pre">del</span> <span class="pre">modelo</span></code>.</p></li>
<li><p>Si se considera el caso extremo en el que el <code class="docutils literal notranslate"><span class="pre">número</span> <span class="pre">de</span> <span class="pre">vecinos</span> <span class="pre">es</span> <span class="pre">el</span> <span class="pre">número</span> <span class="pre">de</span> <span class="pre">todos</span> <span class="pre">los</span> <span class="pre">puntos</span> <span class="pre">de</span> <span class="pre">datos</span> <span class="pre">del</span> <span class="pre">conjunto</span> <span class="pre">de</span> <span class="pre">entrenamiento</span></code>, cada punto de prueba tendría exactamente los mismos vecinos (todos puntos de entrenamiento) y todas las predicciones serían las mismas: <code class="docutils literal notranslate"><span class="pre">la</span> <span class="pre">clase</span> <span class="pre">más</span> <span class="pre">frecuente</span> <span class="pre">en</span> <span class="pre">el</span> <span class="pre">conjunto</span> <span class="pre">de</span> <span class="pre">entrenamiento</span></code>.</p></li>
</ul>
</section>
<section id="aplicacion-breast-cancer-dataset">
<h2>Aplicación: Breast Cancer Dataset<a class="headerlink" href="#aplicacion-breast-cancer-dataset" title="Link to this heading">#</a></h2>
<figure class="align-center" id="breast-cancer-knn-fig">
<a class="reference internal image-reference" href="_images/breast_cancer_knn.png"><img alt="_images/breast_cancer_knn.png" src="_images/breast_cancer_knn.png" style="width: 616.5px; height: 511.2px;" />
</a>
</figure>
<ul class="simple">
<li><p><strong><code class="docutils literal notranslate"><span class="pre">Breast</span> <span class="pre">Cancer</span> <span class="pre">Dataset</span></code></strong>. Investiguemos si podemos confirmar la <code class="docutils literal notranslate"><span class="pre">conexión</span> <span class="pre">entre</span> <span class="pre">la</span> <span class="pre">complejidad</span> <span class="pre">del</span> <span class="pre">modelo</span> <span class="pre">y</span> <span class="pre">la</span> <span class="pre">generalización</span></code> que hemos discutido antes. Lo haremos con el conjunto de datos de cáncer de mama <code class="docutils literal notranslate"><span class="pre">(Breast</span> <span class="pre">Cancer)</span></code> del mundo real.</p></li>
</ul>
</section>
<section id="analisis-exploratorio-de-datos">
<h2>Análisis Exploratorio de Datos<a class="headerlink" href="#analisis-exploratorio-de-datos" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Procedemos a realizar un <code class="docutils literal notranslate"><span class="pre">análisis</span> <span class="pre">exploratorio</span> <span class="pre">de</span> <span class="pre">datos</span></code> para investigar y resumir principales características de nuestros datos. Primero cargamos nuestro dataset usando la función <code class="docutils literal notranslate"><span class="pre">load_breast_cancer()</span></code> de <code class="docutils literal notranslate"><span class="pre">sklearn.datasets</span></code></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_breast_cancer</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cancer</span> <span class="o">=</span> <span class="n">load_breast_cancer</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">list</span><span class="p">(</span><span class="n">cancer</span><span class="o">.</span><span class="n">target_names</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;malignant&#39;, &#39;benign&#39;]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">list</span><span class="p">(</span><span class="n">cancer</span><span class="o">.</span><span class="n">feature_names</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;mean radius&#39;,
 &#39;mean texture&#39;,
 &#39;mean perimeter&#39;,
 &#39;mean area&#39;,
 &#39;mean smoothness&#39;,
 &#39;mean compactness&#39;,
 &#39;mean concavity&#39;,
 &#39;mean concave points&#39;,
 &#39;mean symmetry&#39;,
 &#39;mean fractal dimension&#39;,
 &#39;radius error&#39;,
 &#39;texture error&#39;,
 &#39;perimeter error&#39;,
 &#39;area error&#39;,
 &#39;smoothness error&#39;,
 &#39;compactness error&#39;,
 &#39;concavity error&#39;,
 &#39;concave points error&#39;,
 &#39;symmetry error&#39;,
 &#39;fractal dimension error&#39;,
 &#39;worst radius&#39;,
 &#39;worst texture&#39;,
 &#39;worst perimeter&#39;,
 &#39;worst area&#39;,
 &#39;worst smoothness&#39;,
 &#39;worst compactness&#39;,
 &#39;worst concavity&#39;,
 &#39;worst concave points&#39;,
 &#39;worst symmetry&#39;,
 &#39;worst fractal dimension&#39;]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cancer</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(569, 30)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cancer</span><span class="o">.</span><span class="n">target</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(569,)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">cancer</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">columns</span> <span class="o">=</span> <span class="n">cancer</span><span class="o">.</span><span class="n">feature_names</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;diagnosis&#39;</span><span class="p">,</span> <span class="n">cancer</span><span class="o">.</span><span class="n">target</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>diagnosis</th>
      <th>mean radius</th>
      <th>mean texture</th>
      <th>mean perimeter</th>
      <th>mean area</th>
      <th>mean smoothness</th>
      <th>mean compactness</th>
      <th>mean concavity</th>
      <th>mean concave points</th>
      <th>mean symmetry</th>
      <th>...</th>
      <th>worst radius</th>
      <th>worst texture</th>
      <th>worst perimeter</th>
      <th>worst area</th>
      <th>worst smoothness</th>
      <th>worst compactness</th>
      <th>worst concavity</th>
      <th>worst concave points</th>
      <th>worst symmetry</th>
      <th>worst fractal dimension</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>17.99</td>
      <td>10.38</td>
      <td>122.80</td>
      <td>1001.0</td>
      <td>0.11840</td>
      <td>0.27760</td>
      <td>0.3001</td>
      <td>0.14710</td>
      <td>0.2419</td>
      <td>...</td>
      <td>25.38</td>
      <td>17.33</td>
      <td>184.60</td>
      <td>2019.0</td>
      <td>0.1622</td>
      <td>0.6656</td>
      <td>0.7119</td>
      <td>0.2654</td>
      <td>0.4601</td>
      <td>0.11890</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0</td>
      <td>20.57</td>
      <td>17.77</td>
      <td>132.90</td>
      <td>1326.0</td>
      <td>0.08474</td>
      <td>0.07864</td>
      <td>0.0869</td>
      <td>0.07017</td>
      <td>0.1812</td>
      <td>...</td>
      <td>24.99</td>
      <td>23.41</td>
      <td>158.80</td>
      <td>1956.0</td>
      <td>0.1238</td>
      <td>0.1866</td>
      <td>0.2416</td>
      <td>0.1860</td>
      <td>0.2750</td>
      <td>0.08902</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0</td>
      <td>19.69</td>
      <td>21.25</td>
      <td>130.00</td>
      <td>1203.0</td>
      <td>0.10960</td>
      <td>0.15990</td>
      <td>0.1974</td>
      <td>0.12790</td>
      <td>0.2069</td>
      <td>...</td>
      <td>23.57</td>
      <td>25.53</td>
      <td>152.50</td>
      <td>1709.0</td>
      <td>0.1444</td>
      <td>0.4245</td>
      <td>0.4504</td>
      <td>0.2430</td>
      <td>0.3613</td>
      <td>0.08758</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0</td>
      <td>11.42</td>
      <td>20.38</td>
      <td>77.58</td>
      <td>386.1</td>
      <td>0.14250</td>
      <td>0.28390</td>
      <td>0.2414</td>
      <td>0.10520</td>
      <td>0.2597</td>
      <td>...</td>
      <td>14.91</td>
      <td>26.50</td>
      <td>98.87</td>
      <td>567.7</td>
      <td>0.2098</td>
      <td>0.8663</td>
      <td>0.6869</td>
      <td>0.2575</td>
      <td>0.6638</td>
      <td>0.17300</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0</td>
      <td>20.29</td>
      <td>14.34</td>
      <td>135.10</td>
      <td>1297.0</td>
      <td>0.10030</td>
      <td>0.13280</td>
      <td>0.1980</td>
      <td>0.10430</td>
      <td>0.1809</td>
      <td>...</td>
      <td>22.54</td>
      <td>16.67</td>
      <td>152.20</td>
      <td>1575.0</td>
      <td>0.1374</td>
      <td>0.2050</td>
      <td>0.4000</td>
      <td>0.1625</td>
      <td>0.2364</td>
      <td>0.07678</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 31 columns</p>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_copy</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Aquí <code class="docutils literal notranslate"><span class="pre">0=malignant,</span> <span class="pre">1=benign</span></code>. Verifiquemos que tipos de datos contiene el dataset. La función <code class="docutils literal notranslate"><span class="pre">info()</span></code> proporciona información sobre los <code class="docutils literal notranslate"><span class="pre">tipos</span> <span class="pre">de</span> <span class="pre">datos,</span> <span class="pre">columnas,</span> <span class="pre">recuento</span> <span class="pre">de</span> <span class="pre">valores</span> <span class="pre">nulos,</span> <span class="pre">uso</span> <span class="pre">de</span> <span class="pre">memoria</span></code>, etc.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">info</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 569 entries, 0 to 568
Data columns (total 31 columns):
 #   Column                   Non-Null Count  Dtype  
---  ------                   --------------  -----  
 0   diagnosis                569 non-null    int32  
 1   mean radius              569 non-null    float64
 2   mean texture             569 non-null    float64
 3   mean perimeter           569 non-null    float64
 4   mean area                569 non-null    float64
 5   mean smoothness          569 non-null    float64
 6   mean compactness         569 non-null    float64
 7   mean concavity           569 non-null    float64
 8   mean concave points      569 non-null    float64
 9   mean symmetry            569 non-null    float64
 10  mean fractal dimension   569 non-null    float64
 11  radius error             569 non-null    float64
 12  texture error            569 non-null    float64
 13  perimeter error          569 non-null    float64
 14  area error               569 non-null    float64
 15  smoothness error         569 non-null    float64
 16  compactness error        569 non-null    float64
 17  concavity error          569 non-null    float64
 18  concave points error     569 non-null    float64
 19  symmetry error           569 non-null    float64
 20  fractal dimension error  569 non-null    float64
 21  worst radius             569 non-null    float64
 22  worst texture            569 non-null    float64
 23  worst perimeter          569 non-null    float64
 24  worst area               569 non-null    float64
 25  worst smoothness         569 non-null    float64
 26  worst compactness        569 non-null    float64
 27  worst concavity          569 non-null    float64
 28  worst concave points     569 non-null    float64
 29  worst symmetry           569 non-null    float64
 30  worst fractal dimension  569 non-null    float64
dtypes: float64(30), int32(1)
memory usage: 135.7 KB
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>El método <code class="docutils literal notranslate"><span class="pre">DataFrame.describe()</span></code> genera <code class="docutils literal notranslate"><span class="pre">estadísticos</span> <span class="pre">descriptivos</span></code> que resumen <code class="docutils literal notranslate"><span class="pre">tendencia</span> <span class="pre">central,</span> <span class="pre">dispersión</span></code> y la <code class="docutils literal notranslate"><span class="pre">forma</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">distribución</span> <span class="pre">de</span> <span class="pre">un</span> <span class="pre">conjunto</span> <span class="pre">de</span> <span class="pre">datos</span></code>, excluyendo los valores <code class="docutils literal notranslate"><span class="pre">NaN</span></code>. Una cosa importante es que el método <code class="docutils literal notranslate"><span class="pre">describe()</span> <span class="pre">sólo</span> <span class="pre">trabaja</span> <span class="pre">con</span> <span class="pre">valores</span> <span class="pre">numéricos</span></code>. Por lo tanto, si hay algún valor categórico en una columna, el método describe() lo ignorará y mostrará el resumen de las demás columnas, a menos que se pase el <code class="docutils literal notranslate"><span class="pre">parámetro</span> <span class="pre">include=&quot;all&quot;</span></code>.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>diagnosis</th>
      <th>mean radius</th>
      <th>mean texture</th>
      <th>mean perimeter</th>
      <th>mean area</th>
      <th>mean smoothness</th>
      <th>mean compactness</th>
      <th>mean concavity</th>
      <th>mean concave points</th>
      <th>mean symmetry</th>
      <th>...</th>
      <th>worst radius</th>
      <th>worst texture</th>
      <th>worst perimeter</th>
      <th>worst area</th>
      <th>worst smoothness</th>
      <th>worst compactness</th>
      <th>worst concavity</th>
      <th>worst concave points</th>
      <th>worst symmetry</th>
      <th>worst fractal dimension</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>569.000000</td>
      <td>569.000000</td>
      <td>569.000000</td>
      <td>569.000000</td>
      <td>569.000000</td>
      <td>569.000000</td>
      <td>569.000000</td>
      <td>569.000000</td>
      <td>569.000000</td>
      <td>569.000000</td>
      <td>...</td>
      <td>569.000000</td>
      <td>569.000000</td>
      <td>569.000000</td>
      <td>569.000000</td>
      <td>569.000000</td>
      <td>569.000000</td>
      <td>569.000000</td>
      <td>569.000000</td>
      <td>569.000000</td>
      <td>569.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>0.627417</td>
      <td>14.127292</td>
      <td>19.289649</td>
      <td>91.969033</td>
      <td>654.889104</td>
      <td>0.096360</td>
      <td>0.104341</td>
      <td>0.088799</td>
      <td>0.048919</td>
      <td>0.181162</td>
      <td>...</td>
      <td>16.269190</td>
      <td>25.677223</td>
      <td>107.261213</td>
      <td>880.583128</td>
      <td>0.132369</td>
      <td>0.254265</td>
      <td>0.272188</td>
      <td>0.114606</td>
      <td>0.290076</td>
      <td>0.083946</td>
    </tr>
    <tr>
      <th>std</th>
      <td>0.483918</td>
      <td>3.524049</td>
      <td>4.301036</td>
      <td>24.298981</td>
      <td>351.914129</td>
      <td>0.014064</td>
      <td>0.052813</td>
      <td>0.079720</td>
      <td>0.038803</td>
      <td>0.027414</td>
      <td>...</td>
      <td>4.833242</td>
      <td>6.146258</td>
      <td>33.602542</td>
      <td>569.356993</td>
      <td>0.022832</td>
      <td>0.157336</td>
      <td>0.208624</td>
      <td>0.065732</td>
      <td>0.061867</td>
      <td>0.018061</td>
    </tr>
    <tr>
      <th>min</th>
      <td>0.000000</td>
      <td>6.981000</td>
      <td>9.710000</td>
      <td>43.790000</td>
      <td>143.500000</td>
      <td>0.052630</td>
      <td>0.019380</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.106000</td>
      <td>...</td>
      <td>7.930000</td>
      <td>12.020000</td>
      <td>50.410000</td>
      <td>185.200000</td>
      <td>0.071170</td>
      <td>0.027290</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.156500</td>
      <td>0.055040</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>0.000000</td>
      <td>11.700000</td>
      <td>16.170000</td>
      <td>75.170000</td>
      <td>420.300000</td>
      <td>0.086370</td>
      <td>0.064920</td>
      <td>0.029560</td>
      <td>0.020310</td>
      <td>0.161900</td>
      <td>...</td>
      <td>13.010000</td>
      <td>21.080000</td>
      <td>84.110000</td>
      <td>515.300000</td>
      <td>0.116600</td>
      <td>0.147200</td>
      <td>0.114500</td>
      <td>0.064930</td>
      <td>0.250400</td>
      <td>0.071460</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>1.000000</td>
      <td>13.370000</td>
      <td>18.840000</td>
      <td>86.240000</td>
      <td>551.100000</td>
      <td>0.095870</td>
      <td>0.092630</td>
      <td>0.061540</td>
      <td>0.033500</td>
      <td>0.179200</td>
      <td>...</td>
      <td>14.970000</td>
      <td>25.410000</td>
      <td>97.660000</td>
      <td>686.500000</td>
      <td>0.131300</td>
      <td>0.211900</td>
      <td>0.226700</td>
      <td>0.099930</td>
      <td>0.282200</td>
      <td>0.080040</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>1.000000</td>
      <td>15.780000</td>
      <td>21.800000</td>
      <td>104.100000</td>
      <td>782.700000</td>
      <td>0.105300</td>
      <td>0.130400</td>
      <td>0.130700</td>
      <td>0.074000</td>
      <td>0.195700</td>
      <td>...</td>
      <td>18.790000</td>
      <td>29.720000</td>
      <td>125.400000</td>
      <td>1084.000000</td>
      <td>0.146000</td>
      <td>0.339100</td>
      <td>0.382900</td>
      <td>0.161400</td>
      <td>0.317900</td>
      <td>0.092080</td>
    </tr>
    <tr>
      <th>max</th>
      <td>1.000000</td>
      <td>28.110000</td>
      <td>39.280000</td>
      <td>188.500000</td>
      <td>2501.000000</td>
      <td>0.163400</td>
      <td>0.345400</td>
      <td>0.426800</td>
      <td>0.201200</td>
      <td>0.304000</td>
      <td>...</td>
      <td>36.040000</td>
      <td>49.540000</td>
      <td>251.200000</td>
      <td>4254.000000</td>
      <td>0.222600</td>
      <td>1.058000</td>
      <td>1.252000</td>
      <td>0.291000</td>
      <td>0.663800</td>
      <td>0.207500</td>
    </tr>
  </tbody>
</table>
<p>8 rows × 31 columns</p>
</div></div></div>
</div>
<ul class="simple">
<li><p>Realicemos <code class="docutils literal notranslate"><span class="pre">tabla</span> <span class="pre">de</span> <span class="pre">frecuencias</span> <span class="pre">y</span> <span class="pre">diagrama</span> <span class="pre">de</span> <span class="pre">barras</span></code> para nuestra variable respuesta</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">diagnosis</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>diagnosis
1    357
0    212
Name: count, dtype: int64
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set_style</span><span class="p">(</span><span class="s2">&quot;whitegrid&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Count of cancer type&#39;</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">countplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">df</span><span class="o">.</span><span class="n">diagnosis</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Diagnosis&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Frequency&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/f52e43759d471ce4e616bcf25fc95be993094256dd0cf94b5482cd3437576327.png" src="_images/f52e43759d471ce4e616bcf25fc95be993094256dd0cf94b5482cd3437576327.png" />
</div>
</div>
<ul class="simple">
<li><p>Nótese que nuestro dataset está <code class="docutils literal notranslate"><span class="pre">desbalanceado</span></code>. Existen técnicas como <code class="docutils literal notranslate"><span class="pre">SMOTE</span></code> y <code class="docutils literal notranslate"><span class="pre">Stratified</span> <span class="pre">sampling</span></code>, que pueden utilizarse para <code class="docutils literal notranslate"><span class="pre">mejorar</span> <span class="pre">el</span> <span class="pre">score</span> <span class="pre">de</span> <span class="pre">clasificación</span></code> de datos desbalanceados. <code class="docutils literal notranslate"><span class="pre">Utilícela</span> <span class="pre">en</span> <span class="pre">su</span> <span class="pre">proyecto</span> <span class="pre">final</span> <span class="pre">de</span> <span class="pre">investigación</span></code>.  Verifiquemos además si existen <code class="docutils literal notranslate"><span class="pre">datos</span> <span class="pre">faltantes</span></code> en nuestro <code class="docutils literal notranslate"><span class="pre">Dataframe</span></code></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>diagnosis                  0
mean radius                0
mean texture               0
mean perimeter             0
mean area                  0
mean smoothness            0
mean compactness           0
mean concavity             0
mean concave points        0
mean symmetry              0
mean fractal dimension     0
radius error               0
texture error              0
perimeter error            0
area error                 0
smoothness error           0
compactness error          0
concavity error            0
concave points error       0
symmetry error             0
fractal dimension error    0
worst radius               0
worst texture              0
worst perimeter            0
worst area                 0
worst smoothness           0
worst compactness          0
worst concavity            0
worst concave points       0
worst symmetry             0
worst fractal dimension    0
dtype: int64
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Pasamos a verficar si existe <code class="docutils literal notranslate"><span class="pre">correlación</span> <span class="pre">entre</span> <span class="pre">las</span> <span class="pre">características</span></code></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">corr</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span> <span class="p">,</span> <span class="mi">1</span><span class="p">:]</span><span class="o">.</span><span class="n">corr</span><span class="p">()</span>
<span class="n">corr</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(30, 30)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">corr</span><span class="p">)</span>
<span class="n">mask</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">triu_indices_from</span><span class="p">(</span><span class="n">mask</span><span class="p">)]</span> <span class="o">=</span> <span class="kc">True</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">font_scale</span><span class="o">=</span><span class="mf">1.8</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">20</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">corr</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="n">mask</span><span class="p">,</span> <span class="n">cbar</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s1">&#39;.1f&#39;</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">annot_kws</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;size&#39;</span><span class="p">:</span><span class="mi">15</span><span class="p">},</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;Reds&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/4e5b8d6fbd03733db49323211fa8f3a84bc1fd184e1a82c1e6171f9727188d50.png" src="_images/4e5b8d6fbd03733db49323211fa8f3a84bc1fd184e1a82c1e6171f9727188d50.png" />
</div>
</div>
<ul class="simple">
<li><p>Trazamos <code class="docutils literal notranslate"><span class="pre">histogramas</span> <span class="pre">de</span> <span class="pre">cada</span> <span class="pre">característica</span></code> en nuestro dataset</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">font_scale</span><span class="o">=</span><span class="mf">1.8</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span> <span class="p">,</span> <span class="mi">1</span><span class="p">:]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">30</span><span class="p">,</span><span class="mi">30</span><span class="p">),</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;red&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/b3c25499ab70cde16b9db11d47b12662ab1b017e62288a18a3afd32a10d53f1e.png" src="_images/b3c25499ab70cde16b9db11d47b12662ab1b017e62288a18a3afd32a10d53f1e.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">font_scale</span><span class="o">=</span><span class="mf">1.8</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">20</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s1">&#39;diagnosis&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="p">,</span><span class="n">width</span><span class="o">=</span><span class="mf">0.3</span> <span class="p">,</span> <span class="n">saturation</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span><span class="n">orient</span><span class="o">=</span><span class="s2">&quot;h&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/a3bc7a420508bee86ca9a40deb6859b2b3674db90c68b40e9c30cdd9bf503a25.png" src="_images/a3bc7a420508bee86ca9a40deb6859b2b3674db90c68b40e9c30cdd9bf503a25.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">melted_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">melt</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">id_vars</span> <span class="o">=</span> <span class="s2">&quot;diagnosis&quot;</span><span class="p">,</span><span class="n">value_vars</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;mean radius&#39;</span><span class="p">,</span> <span class="s1">&#39;mean texture&#39;</span><span class="p">,</span> 
                                                              <span class="s1">&#39;mean perimeter&#39;</span><span class="p">])</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">font_scale</span><span class="o">=</span><span class="mf">1.8</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="s2">&quot;value&quot;</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="s2">&quot;variable&quot;</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s2">&quot;diagnosis&quot;</span><span class="p">,</span><span class="n">data</span><span class="o">=</span> <span class="n">melted_data</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/e6a2e47693227d3911cbd979d2ebf11b838463f37d9f0425deaa24eee7af7965.png" src="_images/e6a2e47693227d3911cbd979d2ebf11b838463f37d9f0425deaa24eee7af7965.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">melted_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">melt</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">id_vars</span> <span class="o">=</span> <span class="s2">&quot;diagnosis&quot;</span><span class="p">,</span><span class="n">value_vars</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;radius error&#39;</span><span class="p">,</span> 
                                                              <span class="s1">&#39;texture error&#39;</span><span class="p">,</span> <span class="s1">&#39;perimeter error&#39;</span><span class="p">])</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">font_scale</span><span class="o">=</span><span class="mf">1.8</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="s2">&quot;value&quot;</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="s2">&quot;variable&quot;</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s2">&quot;diagnosis&quot;</span><span class="p">,</span><span class="n">data</span><span class="o">=</span> <span class="n">melted_data</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/d6f5e958e731b5f45a9124713ef0b8d5aa46dc154461dcd26ed32c79a01a59a2.png" src="_images/d6f5e958e731b5f45a9124713ef0b8d5aa46dc154461dcd26ed32c79a01a59a2.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">melted_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">melt</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">id_vars</span> <span class="o">=</span> <span class="s2">&quot;diagnosis&quot;</span><span class="p">,</span><span class="n">value_vars</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;worst radius&#39;</span><span class="p">,</span> 
                                                              <span class="s1">&#39;worst texture&#39;</span><span class="p">,</span> <span class="s1">&#39;worst perimeter&#39;</span><span class="p">])</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">font_scale</span><span class="o">=</span><span class="mf">1.8</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="s2">&quot;value&quot;</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="s2">&quot;variable&quot;</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s2">&quot;diagnosis&quot;</span><span class="p">,</span><span class="n">data</span><span class="o">=</span> <span class="n">melted_data</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/6fccd420b43aaf7d8c093a06d108194216ac451385424ec8f2fee9c4e80321ef.png" src="_images/6fccd420b43aaf7d8c093a06d108194216ac451385424ec8f2fee9c4e80321ef.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;diagnosis&#39;</span><span class="p">,</span> <span class="s1">&#39;mean radius&#39;</span><span class="p">,</span> <span class="s1">&#39;mean texture&#39;</span><span class="p">,</span> <span class="s1">&#39;mean perimeter&#39;</span><span class="p">,</span> 
           <span class="s1">&#39;mean area&#39;</span><span class="p">,</span> <span class="s1">&#39;mean smoothness&#39;</span><span class="p">,</span> <span class="s1">&#39;mean compactness&#39;</span><span class="p">,</span> <span class="s1">&#39;mean concavity&#39;</span><span class="p">]</span>

<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">font_scale</span><span class="o">=</span><span class="mf">4.0</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">pairplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="n">columns</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="s2">&quot;diagnosis&quot;</span><span class="p">,</span> <span class="n">palette</span><span class="o">=</span><span class="s1">&#39;viridis&#39;</span><span class="p">,</span> <span class="n">corner</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mf">7.0</span><span class="p">,</span> <span class="n">aspect</span><span class="o">=</span><span class="mf">1.0</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/0ead738d899a78006068a418ea814c6aac705aa167bcbaf304e3e4b34a698097.png" src="_images/0ead738d899a78006068a418ea814c6aac705aa167bcbaf304e3e4b34a698097.png" />
</div>
</div>
<ul class="simple">
<li><p>Diagrama de <code class="docutils literal notranslate"><span class="pre">densidad</span> <span class="pre">de</span> <span class="pre">distribución</span> <span class="pre">KDE</span></code> y distribución mediante el diagrama de dispersión <code class="docutils literal notranslate"><span class="pre">stripplot()</span></code></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">matplotlib</span><span class="o">.</span><span class="n">rc_file_defaults</span><span class="p">()</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set_style</span><span class="p">(</span><span class="s2">&quot;whitegrid&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sns</span><span class="o">.</span><span class="n">FacetGrid</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s2">&quot;diagnosis&quot;</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mi">6</span><span class="p">)</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">sns</span><span class="o">.</span><span class="n">kdeplot</span><span class="p">,</span> <span class="s2">&quot;mean radius&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">add_legend</span><span class="p">();</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/7e7598d42480cbf51fa88d5bbb7f088a63f35d2a0f2255ddcdddc277122e956a.png" src="_images/7e7598d42480cbf51fa88d5bbb7f088a63f35d2a0f2255ddcdddc277122e956a.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sns</span><span class="o">.</span><span class="n">stripplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">&quot;diagnosis&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;mean radius&quot;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">,</span> <span class="n">jitter</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s2">&quot;gray&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/5742d9327c824d74ff975016703ea6b1a323ba92e4affa1509027ee594591128.png" src="_images/5742d9327c824d74ff975016703ea6b1a323ba92e4affa1509027ee594591128.png" />
</div>
</div>
<section id="multicolinealidad">
<h3>Multicolinealidad<a class="headerlink" href="#multicolinealidad" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>La <code class="docutils literal notranslate"><span class="pre">multicolinealidad</span></code> es un problema ya que, <code class="docutils literal notranslate"><span class="pre">reduce</span> <span class="pre">la</span> <span class="pre">importancia</span> <span class="pre">de</span> <span class="pre">las</span> <span class="pre">variables</span> <span class="pre">independientes</span></code>. A fin de solucionar este problema,  se <code class="docutils literal notranslate"><span class="pre">eliminan</span> <span class="pre">los</span> <span class="pre">predictores</span> <span class="pre">altamente</span> <span class="pre">correlacionados</span></code>. Podemos comprobar la presencia de multicolinealidad entre algunas de las variables. Por ejemplo, la columna <code class="docutils literal notranslate"><span class="pre">mean</span> <span class="pre">radius</span></code> tiene una <code class="docutils literal notranslate"><span class="pre">correlación</span> <span class="pre">de</span> <span class="pre">1.0</span></code> con las columnas <code class="docutils literal notranslate"><span class="pre">mean</span> <span class="pre">perimeter</span></code> y <code class="docutils literal notranslate"><span class="pre">mean</span> <span class="pre">area</span></code>, respectivamente. Esto se debe a que <code class="docutils literal notranslate"><span class="pre">las</span> <span class="pre">tres</span> <span class="pre">columnas</span> <span class="pre">contienen</span> <span class="pre">esencialmente</span> <span class="pre">la</span> <span class="pre">misma</span> <span class="pre">información</span></code>, que es el tamaño físico de la observación.</p></li>
<li><p>Por lo tanto, <code class="docutils literal notranslate"><span class="pre">sólo</span> <span class="pre">debemos</span> <span class="pre">elegir</span> <span class="pre">una</span> <span class="pre">de</span> <span class="pre">las</span> <span class="pre">tres</span> <span class="pre">columnas</span> <span class="pre">cuando</span> <span class="pre">pasemos</span> <span class="pre">al</span> <span class="pre">análisis</span> <span class="pre">posterior</span></code>. Otro lugar donde la <code class="docutils literal notranslate"><span class="pre">multicolinealidad</span></code> es evidente, es entre las columnas <code class="docutils literal notranslate"><span class="pre">&quot;mean&quot;</span></code> y <code class="docutils literal notranslate"><span class="pre">&quot;worst&quot;</span></code>. Por ejemplo, la columna <code class="docutils literal notranslate"><span class="pre">mean</span> <span class="pre">radius</span></code> tiene una <code class="docutils literal notranslate"><span class="pre">correlación</span> <span class="pre">de</span> <span class="pre">1.0</span></code> con la columna <code class="docutils literal notranslate"><span class="pre">worst</span> <span class="pre">radius</span></code>. También hay multicolinealidad entre los atributos <code class="docutils literal notranslate"><span class="pre">compactness,</span> <span class="pre">concavity</span></code> y <code class="docutils literal notranslate"><span class="pre">concave</span> <span class="pre">points</span></code>. Así que podemos elegir sólo uno de estos, por ejemplo <code class="docutils literal notranslate"><span class="pre">compactness</span></code>. De la matriz de correlación sabemos que estas columnas están altamente correlacionadas con las columnas <code class="docutils literal notranslate"><span class="pre">mean</span> <span class="pre">radius</span></code>, <code class="docutils literal notranslate"><span class="pre">perimeter</span></code>, <code class="docutils literal notranslate"><span class="pre">area</span></code>. Por lo tanto, estas columnas serán eliminadas.</p></li>
</ul>
<ul class="simple">
<li><p>Primero, eliminamos todas las columnas <code class="docutils literal notranslate"><span class="pre">worst</span></code>, por su evidente correlación con las columnas <code class="docutils literal notranslate"><span class="pre">mean</span></code></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cols</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;worst radius&#39;</span><span class="p">,</span> 
        <span class="s1">&#39;worst texture&#39;</span><span class="p">,</span> 
        <span class="s1">&#39;worst perimeter&#39;</span><span class="p">,</span> 
        <span class="s1">&#39;worst area&#39;</span><span class="p">,</span> 
        <span class="s1">&#39;worst smoothness&#39;</span><span class="p">,</span> 
        <span class="s1">&#39;worst compactness&#39;</span><span class="p">,</span> 
        <span class="s1">&#39;worst concavity&#39;</span><span class="p">,</span>
        <span class="s1">&#39;worst concave points&#39;</span><span class="p">,</span> 
        <span class="s1">&#39;worst symmetry&#39;</span><span class="p">,</span> 
        <span class="s1">&#39;worst fractal dimension&#39;</span><span class="p">]</span>
<span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">cols</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>A continuación, <code class="docutils literal notranslate"><span class="pre">elimine</span> <span class="pre">todas</span> <span class="pre">las</span> <span class="pre">columnas</span> <span class="pre">relacionadas</span> <span class="pre">con</span></code> los atributos <code class="docutils literal notranslate"><span class="pre">perimeter</span></code> y <code class="docutils literal notranslate"><span class="pre">area</span></code>.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cols</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;mean perimeter&#39;</span><span class="p">,</span>
        <span class="s1">&#39;mean area&#39;</span><span class="p">,</span>
        <span class="s1">&#39;perimeter error&#39;</span><span class="p">,</span> 
        <span class="s1">&#39;area error&#39;</span><span class="p">]</span>
<span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">cols</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Por último, elimine todas las columnas relacionadas con los atributos <code class="docutils literal notranslate"><span class="pre">concavity</span></code> y <code class="docutils literal notranslate"><span class="pre">concave</span> <span class="pre">points</span></code></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cols</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;mean concavity&#39;</span><span class="p">,</span>
        <span class="s1">&#39;concavity error&#39;</span><span class="p">,</span> 
        <span class="s1">&#39;mean concave points&#39;</span><span class="p">,</span> 
        <span class="s1">&#39;concave points error&#39;</span><span class="p">]</span>
<span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">cols</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Verificar las columnas restantes</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">columns</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Index([&#39;diagnosis&#39;, &#39;mean radius&#39;, &#39;mean texture&#39;, &#39;mean smoothness&#39;,
       &#39;mean compactness&#39;, &#39;mean symmetry&#39;, &#39;mean fractal dimension&#39;,
       &#39;radius error&#39;, &#39;texture error&#39;, &#39;smoothness error&#39;,
       &#39;compactness error&#39;, &#39;symmetry error&#39;, &#39;fractal dimension error&#39;],
      dtype=&#39;object&#39;)
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Volvemos a dibujar el <code class="docutils literal notranslate"><span class="pre">mapa</span> <span class="pre">de</span> <span class="pre">calor</span></code> con la <code class="docutils literal notranslate"><span class="pre">nueva</span> <span class="pre">matriz</span> <span class="pre">de</span> <span class="pre">correlaciones</span></code></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">corr</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">corr</span><span class="p">()</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>

<span class="n">cmap</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">diverging_palette</span><span class="p">(</span><span class="mi">220</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">as_cmap</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">corr</span><span class="p">)</span>
<span class="n">mask</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">triu_indices_from</span><span class="p">(</span><span class="n">mask</span><span class="p">)]</span> <span class="o">=</span> <span class="kc">True</span>

<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">font_scale</span><span class="o">=</span><span class="mf">1.8</span><span class="p">)</span>
<span class="n">f</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">20</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">corr</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="n">mask</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmap</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">center</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">square</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mf">.5</span><span class="p">,</span>
            <span class="n">cbar_kws</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;shrink&quot;</span><span class="p">:</span> <span class="mf">.5</span><span class="p">},</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/ce811481c99450c7010808cd4a012b61cb8f08ed161bba38d9dd6f9f6d02c3bd.png" src="_images/ce811481c99450c7010808cd4a012b61cb8f08ed161bba38d9dd6f9f6d02c3bd.png" />
</div>
</div>
</section>
<section id="factor-de-inflacion-de-la-varianza-vif">
<h3>Factor de Inflación de la Varianza (VIF)<a class="headerlink" href="#factor-de-inflacion-de-la-varianza-vif" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>Para abordar la multicolinealidad, se pueden aplicar técnicas como la regularización o la selección de características para, seleccionar un subconjunto de variables independientes que no estén altamente correlacionadas entre sí. En esta sección, nos centraremos en la más común: <code class="docutils literal notranslate"><span class="pre">VIF</span> <span class="pre">(Factores</span> <span class="pre">de</span> <span class="pre">Inflación</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">Varianza)</span></code>.</p></li>
<li><p>El <code class="docutils literal notranslate"><span class="pre">VIF</span></code> determina la <code class="docutils literal notranslate"><span class="pre">fuerza</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">correlación</span> <span class="pre">entre</span> <span class="pre">las</span> <span class="pre">variables</span> <span class="pre">independientes</span></code>. Se pronostica tomando una variable y comparándola con todas las demás. La puntuación <code class="docutils literal notranslate"><span class="pre">VIF</span></code> de una variable independiente representa hasta qué punto la variable se explica por otras variables independientes.</p></li>
<li><p>El valor <span class="math notranslate nohighlight">\(R^2\)</span> se determina para averiguar hasta qué punto una variable independiente es descrita por las demás variables independientes. Un valor alto de <span class="math notranslate nohighlight">\(R^{2}\)</span> significa que la variable está muy correlacionada con las demás variables. Esto se refleja en el <code class="docutils literal notranslate"><span class="pre">VIF</span></code>, que se indica a continuación:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\text{VIF}=\frac{1}{1-R^{2}}
\]</div>
<ul class="simple">
<li><p>Así, cuanto más se acerque el valor de <span class="math notranslate nohighlight">\(R^2\)</span> a 1, mayor será el valor de <code class="docutils literal notranslate"><span class="pre">VIF</span></code> y mayor la multicolinealidad con la variable independiente concreta.</p></li>
</ul>
<div class="tip admonition">
<p class="admonition-title">Observación</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Un</span> <span class="pre">valor</span> <span class="pre">VIF</span> <span class="pre">de</span> <span class="pre">1</span></code>: Sin multicolinealidad (variable perfectamente independiente).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Un</span> <span class="pre">valor</span> <span class="pre">VIF</span> <span class="pre">entre</span> <span class="pre">1</span> <span class="pre">y</span> <span class="pre">5</span></code>: Multicolinealidad baja a moderada (no se considera problemática).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Un</span> <span class="pre">valor</span> <span class="pre">VIF</span> <span class="pre">entre</span> <span class="pre">5</span> <span class="pre">y</span> <span class="pre">10</span></code>: Multicolinealidad moderada a alta (considerada problemática).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Un</span> <span class="pre">valor</span> <span class="pre">VIF</span> <span class="pre">superior</span> <span class="pre">a</span> <span class="pre">10</span></code>: Multicolinealidad alta (preocupación grave, requiere medidas).</p></li>
</ul>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">statsmodels.stats.outliers_influence</span> <span class="kn">import</span> <span class="n">variance_inflation_factor</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">VIF_calculation</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
    <span class="n">VIF</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>
    <span class="n">VIF</span><span class="p">[</span><span class="s2">&quot;variable&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">columns</span>
    <span class="n">VIF</span><span class="p">[</span><span class="s2">&quot;VIF&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">variance_inflation_factor</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])]</span>
    <span class="n">VIF</span> <span class="o">=</span> <span class="n">VIF</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s1">&#39;VIF&#39;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
    <span class="k">return</span><span class="p">(</span><span class="n">VIF</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">delete_multicollinearity</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">target_name</span><span class="p">,</span> <span class="n">VIF_threshold</span><span class="p">):</span>
  <span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">target_name</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
  <span class="n">VIF_mat</span> <span class="o">=</span> <span class="n">VIF_calculation</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
  <span class="n">n_VIF</span> <span class="o">=</span> <span class="n">VIF_mat</span><span class="p">[</span><span class="s2">&quot;VIF&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
  <span class="k">if</span> <span class="p">(</span><span class="n">n_VIF</span> <span class="o">&lt;=</span> <span class="n">VIF_threshold</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;There is no multicollinearity!&quot;</span><span class="p">)</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="k">while</span> <span class="p">(</span><span class="n">n_VIF</span> <span class="o">&gt;</span> <span class="n">VIF_threshold</span><span class="p">):</span>
      <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">VIF_mat</span><span class="p">[</span><span class="s2">&quot;variable&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
      <span class="n">VIF_mat</span> <span class="o">=</span> <span class="n">VIF_calculation</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
      <span class="n">n_VIF</span> <span class="o">=</span> <span class="n">VIF_mat</span><span class="p">[</span><span class="s2">&quot;VIF&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
  <span class="n">display</span><span class="p">(</span><span class="n">VIF_mat</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">X</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_copy</span> <span class="o">=</span> <span class="n">delete_multicollinearity</span><span class="p">(</span><span class="n">df_copy</span><span class="p">,</span> <span class="s2">&quot;diagnosis&quot;</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>variable</th>
      <th>VIF</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>symmetry error</td>
      <td>8.648328</td>
    </tr>
    <tr>
      <th>1</th>
      <td>smoothness error</td>
      <td>8.347757</td>
    </tr>
    <tr>
      <th>2</th>
      <td>fractal dimension error</td>
      <td>7.644681</td>
    </tr>
    <tr>
      <th>3</th>
      <td>texture error</td>
      <td>7.103564</td>
    </tr>
    <tr>
      <th>4</th>
      <td>concavity error</td>
      <td>6.666504</td>
    </tr>
    <tr>
      <th>5</th>
      <td>worst concavity</td>
      <td>4.620458</td>
    </tr>
    <tr>
      <th>6</th>
      <td>area error</td>
      <td>2.190762</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_copy</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>texture error</th>
      <th>area error</th>
      <th>smoothness error</th>
      <th>concavity error</th>
      <th>symmetry error</th>
      <th>fractal dimension error</th>
      <th>worst concavity</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.9053</td>
      <td>153.40</td>
      <td>0.006399</td>
      <td>0.05373</td>
      <td>0.03003</td>
      <td>0.006193</td>
      <td>0.7119</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.7339</td>
      <td>74.08</td>
      <td>0.005225</td>
      <td>0.01860</td>
      <td>0.01389</td>
      <td>0.003532</td>
      <td>0.2416</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.7869</td>
      <td>94.03</td>
      <td>0.006150</td>
      <td>0.03832</td>
      <td>0.02250</td>
      <td>0.004571</td>
      <td>0.4504</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1.1560</td>
      <td>27.23</td>
      <td>0.009110</td>
      <td>0.05661</td>
      <td>0.05963</td>
      <td>0.009208</td>
      <td>0.6869</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.7813</td>
      <td>94.44</td>
      <td>0.011490</td>
      <td>0.05688</td>
      <td>0.01756</td>
      <td>0.005115</td>
      <td>0.4000</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">corr</span> <span class="o">=</span> <span class="n">df_copy</span><span class="o">.</span><span class="n">corr</span><span class="p">()</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>

<span class="n">cmap</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">diverging_palette</span><span class="p">(</span><span class="mi">220</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">as_cmap</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">corr</span><span class="p">)</span>
<span class="n">mask</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">triu_indices_from</span><span class="p">(</span><span class="n">mask</span><span class="p">)]</span> <span class="o">=</span> <span class="kc">True</span>

<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">font_scale</span><span class="o">=</span><span class="mf">1.8</span><span class="p">)</span>
<span class="n">f</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">20</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">corr</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="n">mask</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmap</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">center</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">square</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mf">.5</span><span class="p">,</span>
            <span class="n">cbar_kws</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;shrink&quot;</span><span class="p">:</span> <span class="mf">.5</span><span class="p">},</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/c8ddec1d4b7b00182be84234823e3ef945a0536f848f832b54448e706418de6c.png" src="_images/c8ddec1d4b7b00182be84234823e3ef945a0536f848f832b54448e706418de6c.png" />
</div>
</div>
</section>
</section>
<section id="seleccion-del-modelo-k-nn">
<h2>Selección del modelo K-NN<a class="headerlink" href="#seleccion-del-modelo-k-nn" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">División</span> <span class="pre">en</span> <span class="pre">entrenamiento</span> <span class="pre">(train)</span> <span class="pre">y</span> <span class="pre">prueba</span> <span class="pre">(test)</span></code>. Dividimos la variable objetivo y las variables independientes. A continuación, evaluamos el <code class="docutils literal notranslate"><span class="pre">rendimiento</span> <span class="pre">del</span> <span class="pre">conjunto</span> <span class="pre">de</span> <span class="pre">entrenamiento</span> <span class="pre">y</span> <span class="pre">de</span> <span class="pre">prueba</span> <span class="pre">con</span> <span class="pre">diferentes</span> <span class="pre">números</span> <span class="pre">de</span> <span class="pre">vecinos</span></code></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Utilizaremos en el presente problema las columnas obtenidas luego de aplicar el <code class="docutils literal notranslate"><span class="pre">Factor</span> <span class="pre">de</span> <span class="pre">Inflación</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">Varianza</span> <span class="pre">(VIF)</span></code>. Pude verificar que sucede cuando utiliza el dataset inicial, en el cual se retiraron de manera manual varias características, con base en la matriz de correlación</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">df_copy</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;diagnosis&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">cancer</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">66</span><span class="p">)</span>

<span class="n">training_accuracy</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">test_accuracy</span> <span class="o">=</span> <span class="p">[]</span>

<span class="n">neighbors_settings</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">15</span><span class="p">)</span>
<span class="k">for</span> <span class="n">n_neighbors</span> <span class="ow">in</span> <span class="n">neighbors_settings</span><span class="p">:</span>
    <span class="n">clf</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="n">n_neighbors</span><span class="p">)</span>
    <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">training_accuracy</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">))</span>
    <span class="n">test_accuracy</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">matplotlib</span><span class="o">.</span><span class="n">rc_file_defaults</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">neighbors_settings</span><span class="p">,</span> <span class="n">training_accuracy</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Training accuracy&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">neighbors_settings</span><span class="p">,</span> <span class="n">test_accuracy</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Test accuracy&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Accuracy&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;n_neighbors&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/2845374ceb2e8f10228f1797c7ddd93613bf276ddb03f292775916d4958de80b.png" src="_images/2845374ceb2e8f10228f1797c7ddd93613bf276ddb03f292775916d4958de80b.png" />
</div>
</div>
<ul class="simple">
<li><p>El gráfico muestra <code class="docutils literal notranslate"><span class="pre">accuracy</span> <span class="pre">para</span> <span class="pre">los</span> <span class="pre">conjuntos</span> <span class="pre">de</span> <span class="pre">entrenamiento</span> <span class="pre">y</span> <span class="pre">de</span> <span class="pre">prueba</span> <span class="pre">en</span> <span class="pre">el</span> <span class="pre">eje</span></code> <span class="math notranslate nohighlight">\(y\)</span> contra el ajuste de <code class="docutils literal notranslate"><span class="pre">n_vecinos</span></code> en el eje <span class="math notranslate nohighlight">\(x\)</span>. Aunque los gráficos del mundo real no suelen ser muy suaves, podemos reconocer algunas de las características del sobreajuste <code class="docutils literal notranslate"><span class="pre">(overfitting)</span></code> y del subajuste <code class="docutils literal notranslate"><span class="pre">(underfitting)</span></code>. Si se considera <code class="docutils literal notranslate"><span class="pre">un</span> <span class="pre">solo</span> <span class="pre">vecino</span> <span class="pre">más</span> <span class="pre">cercano,</span> <span class="pre">la</span> <span class="pre">predicción</span> <span class="pre">en</span> <span class="pre">el</span> <span class="pre">conjunto</span> <span class="pre">de</span> <span class="pre">entrenamiento</span> <span class="pre">es</span> <span class="pre">perfecta</span></code>. Pero <code class="docutils literal notranslate"><span class="pre">cuando</span> <span class="pre">se</span> <span class="pre">consideran</span> <span class="pre">más</span> <span class="pre">vecinos,</span> <span class="pre">el</span> <span class="pre">modelo</span> <span class="pre">se</span> <span class="pre">simplifica</span> <span class="pre">y</span> <span class="pre">la</span> <span class="pre">precisión</span> <span class="pre">del</span> <span class="pre">entrenamiento</span> <span class="pre">disminuye</span></code>.</p></li>
<li><p>La <code class="docutils literal notranslate"><span class="pre">precisión</span> <span class="pre">del</span> <span class="pre">conjunto</span> <span class="pre">de</span> <span class="pre">prueba</span> <span class="pre">cuando</span> <span class="pre">se</span> <span class="pre">utiliza</span> <span class="pre">un</span> <span class="pre">solo</span> <span class="pre">vecino</span> <span class="pre">es</span> <span class="pre">menor</span> <span class="pre">que</span> <span class="pre">cuando</span> <span class="pre">se</span> <span class="pre">utilizan</span> <span class="pre">más</span> <span class="pre">vecinos</span></code>, lo que indica que <code class="docutils literal notranslate"><span class="pre">el</span> <span class="pre">uso</span> <span class="pre">de</span> <span class="pre">un</span> <span class="pre">solo</span> <span class="pre">vecino</span> <span class="pre">más</span> <span class="pre">cercano</span> <span class="pre">conduce</span> <span class="pre">a</span> <span class="pre">una</span> <span class="pre">mayor</span> <span class="pre">precisión</span> <span class="pre">en</span> <span class="pre">el</span> <span class="pre">conjunto</span> <span class="pre">de</span> <span class="pre">entrenamiento</span> <span class="pre">(modelo</span> <span class="pre">demasiado</span> <span class="pre">complejo)</span></code>. Pero cuando se consideran más vecinos, el modelo se simplifica y la precisión del entrenamiento disminuye.</p></li>
</ul>
<!-- - Por otro lado, cuando se consideran 10 vecinos, el modelo es demasiado simple y el rendimiento es aún peor. `El mejor rendimiento se encuentra en un punto intermedio, utilizando alrededor de seis vecinos`. Aun así, es bueno tener en cuenta la escala de la figura. El peor rendimiento está en torno al 88% de precisión, lo que podría ser aceptable. --><div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">clf</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">9</span><span class="p">)</span>
<span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span> <span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.8755868544600939 0.8881118881118881
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Queda como ejercicio para el lector aplicar las técnicas de <code class="docutils literal notranslate"><span class="pre">validación</span> <span class="pre">cruzada</span> <span class="pre">y</span> <span class="pre">grid</span> <span class="pre">search</span></code> para obtener el mejor modelo <span class="math notranslate nohighlight">\(k\)</span>-NN para este problema de aplicación.</p></li>
</ul>
</section>
<section id="regresion-por-k-vecinos">
<h2>Regresión por <span class="math notranslate nohighlight">\(k\)</span>-vecinos<a class="headerlink" href="#regresion-por-k-vecinos" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>También existe una <code class="docutils literal notranslate"><span class="pre">variante</span> <span class="pre">de</span> <span class="pre">regresión</span> <span class="pre">del</span> <span class="pre">algoritmo</span></code> <span class="math notranslate nohighlight">\(k\)</span><code class="docutils literal notranslate"><span class="pre">-vecinos</span> <span class="pre">más</span> <span class="pre">cercanos</span></code>. Una vez más, vamos a empezar utilizando el <code class="docutils literal notranslate"><span class="pre">vecino</span> <span class="pre">más</span> <span class="pre">cercano</span> <span class="pre">simple</span></code>, esta vez utilizando el conjunto de datos <code class="docutils literal notranslate"><span class="pre">wave</span></code>. Hemos añadido tres puntos de datos de prueba como estrellas verdes en el eje <span class="math notranslate nohighlight">\(x\)</span>. <code class="docutils literal notranslate"><span class="pre">La</span> <span class="pre">predicción</span> <span class="pre">utilizando</span> <span class="pre">un</span> <span class="pre">solo</span> <span class="pre">vecino</span> <span class="pre">es</span> <span class="pre">sólo</span> <span class="pre">el</span> <span class="pre">valor</span> <span class="pre">objetivo</span> <span class="pre">del</span> <span class="pre">vecino</span> <span class="pre">más</span> <span class="pre">cercano</span></code></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mglearn</span><span class="o">.</span><span class="n">plots</span><span class="o">.</span><span class="n">plot_knn_regression</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/99acb73c5c1429f2790d18f99b2d627cecdc238d12a4e6f7e4890c64b3baf28c.png" src="_images/99acb73c5c1429f2790d18f99b2d627cecdc238d12a4e6f7e4890c64b3baf28c.png" />
</div>
</div>
<ul class="simple">
<li><p>De nuevo, podemos utilizar más que el único vecino más cercano para la regresión. <code class="docutils literal notranslate"><span class="pre">Cuando</span> <span class="pre">se</span> <span class="pre">utilizan</span> <span class="pre">varios</span> <span class="pre">vecinos</span> <span class="pre">más</span> <span class="pre">cercanos,</span> <span class="pre">la</span> <span class="pre">predicción</span> <span class="pre">es</span> <span class="pre">el</span> <span class="pre">promedio,</span> <span class="pre">o</span> <span class="pre">la</span> <span class="pre">media,</span> <span class="pre">de</span> <span class="pre">los</span> <span class="pre">vecinos</span></code></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mglearn</span><span class="o">.</span><span class="n">plots</span><span class="o">.</span><span class="n">plot_knn_regression</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/c73dbcfc00e1e95f4f4010ee54ac4fbacb15107e5f1c1c5b622ecb126a1b7f23.png" src="_images/c73dbcfc00e1e95f4f4010ee54ac4fbacb15107e5f1c1c5b622ecb126a1b7f23.png" />
</div>
</div>
<ul class="simple">
<li><p>El algoritmo de <span class="math notranslate nohighlight">\(k\)</span>-vecinos más cercanos para la <code class="docutils literal notranslate"><span class="pre">regresión</span></code> se implementa en la clase <code class="docutils literal notranslate"><span class="pre">KNeighbors</span> <span class="pre">Regressor</span></code> en <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code>. Se utiliza de forma similar a <code class="docutils literal notranslate"><span class="pre">KNeighborsClassifier</span></code></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsRegressor</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">mglearn</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">make_wave</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">40</span><span class="p">)</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">reg</span> <span class="o">=</span> <span class="n">KNeighborsRegressor</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">reg</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-2" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>KNeighborsRegressor(n_neighbors=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-2" type="checkbox" checked><label for="sk-estimator-id-2" class="sk-toggleable__label sk-toggleable__label-arrow">KNeighborsRegressor</label><div class="sk-toggleable__content"><pre>KNeighborsRegressor(n_neighbors=3)</pre></div></div></div></div></div></div></div>
</div>
<ul class="simple">
<li><p>Ahora podemos hacer predicciones sobre el conjunto de prueba</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test set predictions:</span><span class="se">\n</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">reg</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Test set predictions:
[-0.05396539  0.35686046  1.13671923 -1.89415682 -1.13881398 -1.63113382
  0.35686046  0.91241374 -0.44680446 -1.13881398]
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>También podemos <code class="docutils literal notranslate"><span class="pre">evaluar</span> <span class="pre">el</span> <span class="pre">modelo</span> <span class="pre">utilizando</span> <span class="pre">el</span> <span class="pre">método</span> <span class="pre">score</span></code>, que para los regresores devuelve la puntuación <span class="math notranslate nohighlight">\(R^2\)</span>. La puntuación <span class="math notranslate nohighlight">\(R^2\)</span>, también conocida como <code class="docutils literal notranslate"><span class="pre">coeficiente</span> <span class="pre">de</span> <span class="pre">determinación</span></code>, es una medida de predicción de un modelo de regresión, y arroja una puntuación entre 0 y 1. <code class="docutils literal notranslate"><span class="pre">Un</span> <span class="pre">valor</span> <span class="pre">de</span> <span class="pre">1</span> <span class="pre">corresponde</span> <span class="pre">a</span> <span class="pre">una</span> <span class="pre">predicción</span> <span class="pre">perfecta,</span> <span class="pre">y</span> <span class="pre">un</span> <span class="pre">valor</span> <span class="pre">de</span> <span class="pre">0</span> <span class="pre">corresponde</span> <span class="pre">a</span> <span class="pre">un</span> <span class="pre">modelo</span> <span class="pre">constante</span> <span class="pre">que</span> <span class="pre">sólo</span> <span class="pre">predice</span> <span class="pre">la</span> <span class="pre">media</span> <span class="pre">de</span> <span class="pre">las</span> <span class="pre">respuestas</span> <span class="pre">del</span> <span class="pre">conjunto</span> <span class="pre">de</span> <span class="pre">entrenamiento</span></code>, <code class="docutils literal notranslate"><span class="pre">y_train</span></code>. Aquí, el <code class="docutils literal notranslate"><span class="pre">score</span></code> es de 0.83, lo que indica un ajuste del modelo relativamente bueno.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test set R^2: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">reg</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Test set R^2: 0.83
</pre></div>
</div>
</div>
</div>
</section>
<section id="analisis-de-kneighborsregressor">
<h2>Análisis de <code class="docutils literal notranslate"><span class="pre">KNeighborsRegressor</span></code><a class="headerlink" href="#analisis-de-kneighborsregressor" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Para nuestro conjunto de datos unidimensional, podemos ver cómo son las predicciones para todos los valores posibles de las características. Para ello, creamos un conjunto de datos de prueba compuesto por muchos puntos de la línea</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>

<span class="n">line</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="k">for</span> <span class="n">n_neighbors</span><span class="p">,</span> <span class="n">ax</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">9</span><span class="p">],</span> <span class="n">axes</span><span class="p">):</span>
    <span class="n">reg</span> <span class="o">=</span> <span class="n">KNeighborsRegressor</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="n">n_neighbors</span><span class="p">)</span>
    <span class="n">reg</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">line</span><span class="p">,</span> <span class="n">reg</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">line</span><span class="p">))</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="s1">&#39;^&#39;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">mglearn</span><span class="o">.</span><span class="n">cm2</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="s1">&#39;v&#39;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">mglearn</span><span class="o">.</span><span class="n">cm2</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{}</span><span class="s2"> neighbor(s)</span><span class="se">\n</span><span class="s2"> train score: </span><span class="si">{:.2f}</span><span class="s2"> test score: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">n_neighbors</span><span class="p">,</span> 
                                                                                  <span class="n">reg</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span>
                                                                                  <span class="n">reg</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Feature&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Target&quot;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s2">&quot;Model predictions&quot;</span><span class="p">,</span> <span class="s2">&quot;Training data/target&quot;</span><span class="p">,</span> <span class="s2">&quot;Test data/target&quot;</span><span class="p">],</span> <span class="n">loc</span><span class="o">=</span><span class="s2">&quot;best&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/e9d7bbaeae45bbfd38c30bc0e60150b34b1e0323c7e93b978e8eba6a5a2d0a6a.png" src="_images/e9d7bbaeae45bbfd38c30bc0e60150b34b1e0323c7e93b978e8eba6a5a2d0a6a.png" />
</div>
</div>
<ul class="simple">
<li><p>Como podemos ver en el gráfico, <code class="docutils literal notranslate"><span class="pre">al</span> <span class="pre">utilizar</span> <span class="pre">un</span> <span class="pre">solo</span> <span class="pre">vecino</span></code>, cada punto del conjunto de entrenamiento tiene una influencia obvia en las predicciones, y <code class="docutils literal notranslate"><span class="pre">los</span> <span class="pre">valores</span> <span class="pre">predichos</span> <span class="pre">pasan</span> <span class="pre">por</span> <span class="pre">todos</span> <span class="pre">los</span> <span class="pre">puntos</span> <span class="pre">de</span> <span class="pre">datos</span></code>. Esto conduce a una predicción muy inestable. <code class="docutils literal notranslate"><span class="pre">Tener</span> <span class="pre">en</span> <span class="pre">cuenta</span> <span class="pre">más</span> <span class="pre">vecinos</span> <span class="pre">conduce</span> <span class="pre">a</span> <span class="pre">predicciones</span> <span class="pre">más</span> <span class="pre">suaves</span></code>, pero éstas no se ajustan tan bien a los datos de entrenamiento.</p></li>
</ul>
<section id="aplicacion-world-hydropower-generation">
<h3>Aplicación: World Hydropower Generation<a class="headerlink" href="#aplicacion-world-hydropower-generation" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p><strong><code class="docutils literal notranslate"><span class="pre">World</span> <span class="pre">Hydropower</span> <span class="pre">Generation</span></code></strong>: Esta sección se centra en el uso del modelo <span class="math notranslate nohighlight">\(k\)</span>-NN y sus hiperparamétros, para garantizar una mejor comprensión de este algoritmo. <code class="docutils literal notranslate"><span class="pre">No</span> <span class="pre">se</span> <span class="pre">utilizan</span> <span class="pre">otros</span> <span class="pre">recursos</span> <span class="pre">como</span> <span class="pre">la</span> <span class="pre">ingeniería</span> <span class="pre">de</span> <span class="pre">características,</span> <span class="pre">la</span> <span class="pre">reducción</span> <span class="pre">de</span> <span class="pre">dimensionalidad</span></code>. El conjunto de datos utilizado es una recopilación de la <code class="docutils literal notranslate"><span class="pre">generación</span> <span class="pre">de</span> <span class="pre">energía</span> <span class="pre">de</span> <span class="pre">varios</span> <span class="pre">países</span> <span class="pre">europeos</span></code>, medida en <code class="docutils literal notranslate"><span class="pre">THh</span> <span class="pre">entre</span> <span class="pre">2000</span> <span class="pre">y</span> <span class="pre">2019</span></code>. Su contenido fue extraído de <code class="docutils literal notranslate"><span class="pre">World</span> <span class="pre">in</span> <span class="pre">Data</span></code>.</p></li>
</ul>
<ul class="simple">
<li><p>En primer lugar, se importan las librerías básicas: <code class="docutils literal notranslate"><span class="pre">pandas,</span> <span class="pre">matplotlib</span></code> y <code class="docutils literal notranslate"><span class="pre">numpy</span></code> para <code class="docutils literal notranslate"><span class="pre">Dataframes,</span> <span class="pre">Gráficos</span></code> y <code class="docutils literal notranslate"><span class="pre">operaciones</span> <span class="pre">numéricas</span></code>;<code class="docutils literal notranslate"><span class="pre">MinMaxScaler</span></code> para normalizar nuestros datos entre 0 y 1, <code class="docutils literal notranslate"><span class="pre">train_test_split</span></code> para ayudar a dividir el conjunto de datos (normalmente 70% entrenamiento/ 30% prueba) y <code class="docutils literal notranslate"><span class="pre">neighbors</span></code> para generar nuestros modelos usando kNN</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>  
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">MinMaxScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">neighbors</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_absolute_error</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_squared_error</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_squared_log_error</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">r2_score</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">explained_variance_score</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Para medir la eficacia de nuestros modelos generados, utilizamoslas siguientes métricas:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">mean_absolute_error</span> <span class="pre">(MAE)</span></code>: medida de los errores entre observaciones emparejadas que expresan el mismo fenómeno; <span class="math notranslate nohighlight">\(\text{MAE}=\frac{1}{n}\sum_{j=1}^{n}|y_{j}-\hat{y}_{j}|\)</span></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">mean_squared_error</span> <span class="pre">(root</span> <span class="pre">-</span> <span class="pre">RMSE)</span></code>: la desviación estándar de los residuos (errores de predicción); <span class="math notranslate nohighlight">\(\text{RMSE}=\sqrt{\frac{1}{n}\sum_{j=1}^{n}(y_{j}-\hat{y}_{j})^{2}}\)</span></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">mean_squared_log_error</span> <span class="pre">(root</span> <span class="pre">-</span> <span class="pre">RMSLE)</span></code>: mide la relación entre lo real y lo predicho; <span class="math notranslate nohighlight">\(\text{RMSLE}=\sqrt{\frac{1}{n}\sum_{j=1}^{n}(\log(y_{j}+1)-\log(\hat{y}_{j}+1))^{2}}\)</span></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">r2_score</span> <span class="pre">(R2):</span></code>: coeficiente de determinación, la proporción de la varianza en la variable dependiente que es predecible a partir de la(s) variable(s) independiente(s); <span class="math notranslate nohighlight">\(R^{2}=1-\sum_{j=1}^{n}(y_{j}-\hat{y}_{j})^{2}/\sum_{j=1}^{n}(y_{j}-\overline{y}_{j})^{2}\)</span></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">explained_variance_score</span> <span class="pre">(EVS)</span></code>: mide la discrepancia entre un modelo y los datos reales <span class="math notranslate nohighlight">\(\text{EVS}=1-\text{Var}(y-\hat{y})/\text{Var}(y).\)</span></p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p><strong><code class="docutils literal notranslate"><span class="pre">Preprocesamiento</span> <span class="pre">de</span> <span class="pre">datos</span></code></strong>: Inicialmente, los datos son importados, y se excluyen las columnas categóricas (en este caso, sólo <code class="docutils literal notranslate"><span class="pre">&quot;Country&quot;</span></code>). Para transformar el conjunto de datos y mantenerlo como un <code class="docutils literal notranslate"><span class="pre">Dataframe</span></code>, se utiliza la librería <code class="docutils literal notranslate"><span class="pre">scaler</span></code> dentro de la librería <code class="docutils literal notranslate"><span class="pre">Dataframe,</span> <span class="pre">normalizando</span> <span class="pre">los</span> <span class="pre">datos</span> <span class="pre">entre</span> <span class="pre">0</span> <span class="pre">y</span> <span class="pre">1,</span> <span class="pre">y</span> <span class="pre">manteniendo</span> <span class="pre">las</span> <span class="pre">propiedades</span> <span class="pre">del</span> <span class="pre">dataframe</span></code>. Después de esto, se llama a la función <code class="docutils literal notranslate"><span class="pre">describe</span></code>, para mostrar algunos datos importantes sobre el <code class="docutils literal notranslate"><span class="pre">dataframe</span></code>, como <code class="docutils literal notranslate"><span class="pre">mean,</span> <span class="pre">max,</span> <span class="pre">min,</span> <span class="pre">std</span></code> y otros.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pd</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">display</span><span class="o">.</span><span class="n">float_format</span> <span class="o">=</span> <span class="s1">&#39;</span><span class="si">{:.4f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span>

<span class="n">scaler</span> <span class="o">=</span> <span class="n">MinMaxScaler</span><span class="p">(</span><span class="n">feature_range</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

<span class="n">df_power</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;https://raw.githubusercontent.com/lihkir/Data/main/Hydropower_Consumption.csv&#39;</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s1">&#39;,&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_power</span><span class="o">.</span><span class="n">info</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 153 entries, 0 to 152
Data columns (total 21 columns):
 #   Column   Non-Null Count  Dtype 
---  ------   --------------  ----- 
 0   Country  153 non-null    object
 1   2000     153 non-null    int64 
 2   2001     153 non-null    int64 
 3   2002     153 non-null    int64 
 4   2003     153 non-null    int64 
 5   2004     153 non-null    int64 
 6   2005     153 non-null    int64 
 7   2006     153 non-null    int64 
 8   2007     153 non-null    int64 
 9   2008     153 non-null    int64 
 10  2009     153 non-null    int64 
 11  2010     153 non-null    int64 
 12  2011     153 non-null    int64 
 13  2012     153 non-null    int64 
 14  2013     153 non-null    int64 
 15  2014     153 non-null    int64 
 16  2015     153 non-null    int64 
 17  2016     153 non-null    int64 
 18  2017     153 non-null    int64 
 19  2018     153 non-null    int64 
 20  2019     153 non-null    int64 
dtypes: int64(20), object(1)
memory usage: 25.2+ KB
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_power</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Country</th>
      <th>2000</th>
      <th>2001</th>
      <th>2002</th>
      <th>2003</th>
      <th>2004</th>
      <th>2005</th>
      <th>2006</th>
      <th>2007</th>
      <th>2008</th>
      <th>...</th>
      <th>2010</th>
      <th>2011</th>
      <th>2012</th>
      <th>2013</th>
      <th>2014</th>
      <th>2015</th>
      <th>2016</th>
      <th>2017</th>
      <th>2018</th>
      <th>2019</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Afghanistan</td>
      <td>312</td>
      <td>498</td>
      <td>555</td>
      <td>63</td>
      <td>565</td>
      <td>59</td>
      <td>637</td>
      <td>748</td>
      <td>542</td>
      <td>...</td>
      <td>751</td>
      <td>595</td>
      <td>71</td>
      <td>804</td>
      <td>895</td>
      <td>989</td>
      <td>1025</td>
      <td>105</td>
      <td>105</td>
      <td>107</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Africa</td>
      <td>75246</td>
      <td>80864</td>
      <td>85181</td>
      <td>82873</td>
      <td>87405</td>
      <td>89066</td>
      <td>92241</td>
      <td>95341</td>
      <td>97157</td>
      <td>...</td>
      <td>107427</td>
      <td>110445</td>
      <td>110952</td>
      <td>117673</td>
      <td>123727</td>
      <td>115801</td>
      <td>123816</td>
      <td>130388</td>
      <td>132735</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Albania</td>
      <td>4548</td>
      <td>3519</td>
      <td>3477</td>
      <td>5117</td>
      <td>5411</td>
      <td>5319</td>
      <td>4951</td>
      <td>276</td>
      <td>3759</td>
      <td>...</td>
      <td>7673</td>
      <td>4036</td>
      <td>4725</td>
      <td>6959</td>
      <td>4726</td>
      <td>5866</td>
      <td>7136</td>
      <td>448</td>
      <td>448</td>
      <td>4018</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Algeria</td>
      <td>54</td>
      <td>69</td>
      <td>57</td>
      <td>265</td>
      <td>251</td>
      <td>555</td>
      <td>218</td>
      <td>226</td>
      <td>283</td>
      <td>...</td>
      <td>173</td>
      <td>378</td>
      <td>389</td>
      <td>99</td>
      <td>193</td>
      <td>145</td>
      <td>72</td>
      <td>56</td>
      <td>117</td>
      <td>152</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Angola</td>
      <td>903</td>
      <td>1007</td>
      <td>1132</td>
      <td>1229</td>
      <td>1733</td>
      <td>2197</td>
      <td>2638</td>
      <td>2472</td>
      <td>3103</td>
      <td>...</td>
      <td>3666</td>
      <td>3967</td>
      <td>3734</td>
      <td>4719</td>
      <td>4991</td>
      <td>5037</td>
      <td>5757</td>
      <td>7576</td>
      <td>7576</td>
      <td>8422</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 21 columns</p>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">countries</span> <span class="o">=</span> <span class="n">df_power</span><span class="o">.</span><span class="n">Country</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_power</span> <span class="o">=</span> <span class="n">df_power</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Country&quot;</span><span class="p">])</span>
<span class="n">df_power</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df_power</span><span class="p">),</span> 
                        <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;2000&#39;</span><span class="p">,</span><span class="s1">&#39;2001&#39;</span><span class="p">,</span><span class="s1">&#39;2002&#39;</span><span class="p">,</span><span class="s1">&#39;2003&#39;</span><span class="p">,</span><span class="s1">&#39;2004&#39;</span><span class="p">,</span><span class="s1">&#39;2005&#39;</span><span class="p">,</span>
                                 <span class="s1">&#39;2006&#39;</span><span class="p">,</span><span class="s1">&#39;2007&#39;</span><span class="p">,</span><span class="s1">&#39;2008&#39;</span><span class="p">,</span><span class="s1">&#39;2009&#39;</span><span class="p">,</span><span class="s1">&#39;2010&#39;</span><span class="p">,</span><span class="s1">&#39;2011&#39;</span><span class="p">,</span>
                                 <span class="s1">&#39;2012&#39;</span><span class="p">,</span><span class="s1">&#39;2013&#39;</span><span class="p">,</span><span class="s1">&#39;2014&#39;</span><span class="p">,</span><span class="s1">&#39;2015&#39;</span><span class="p">,</span><span class="s1">&#39;2016&#39;</span><span class="p">,</span><span class="s1">&#39;2017&#39;</span><span class="p">,</span>
                                 <span class="s1">&#39;2018&#39;</span><span class="p">,</span><span class="s1">&#39;2019&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_power</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>2000</th>
      <th>2001</th>
      <th>2002</th>
      <th>2003</th>
      <th>2004</th>
      <th>2005</th>
      <th>2006</th>
      <th>2007</th>
      <th>2008</th>
      <th>2009</th>
      <th>2010</th>
      <th>2011</th>
      <th>2012</th>
      <th>2013</th>
      <th>2014</th>
      <th>2015</th>
      <th>2016</th>
      <th>2017</th>
      <th>2018</th>
      <th>2019</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>153.0000</td>
      <td>153.0000</td>
      <td>153.0000</td>
      <td>153.0000</td>
      <td>153.0000</td>
      <td>153.0000</td>
      <td>153.0000</td>
      <td>153.0000</td>
      <td>153.0000</td>
      <td>153.0000</td>
      <td>153.0000</td>
      <td>153.0000</td>
      <td>153.0000</td>
      <td>153.0000</td>
      <td>153.0000</td>
      <td>153.0000</td>
      <td>153.0000</td>
      <td>153.0000</td>
      <td>153.0000</td>
      <td>153.0000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>0.0327</td>
      <td>0.0353</td>
      <td>0.0355</td>
      <td>0.0328</td>
      <td>0.0419</td>
      <td>0.0390</td>
      <td>0.0415</td>
      <td>0.0434</td>
      <td>0.0371</td>
      <td>0.0445</td>
      <td>0.0328</td>
      <td>0.0433</td>
      <td>0.0352</td>
      <td>0.0290</td>
      <td>0.0282</td>
      <td>0.0265</td>
      <td>0.0306</td>
      <td>0.0296</td>
      <td>0.0388</td>
      <td>0.0259</td>
    </tr>
    <tr>
      <th>std</th>
      <td>0.1229</td>
      <td>0.1262</td>
      <td>0.1278</td>
      <td>0.1249</td>
      <td>0.1372</td>
      <td>0.1364</td>
      <td>0.1366</td>
      <td>0.1440</td>
      <td>0.1293</td>
      <td>0.1493</td>
      <td>0.1208</td>
      <td>0.1459</td>
      <td>0.1294</td>
      <td>0.1121</td>
      <td>0.1062</td>
      <td>0.1031</td>
      <td>0.1117</td>
      <td>0.1110</td>
      <td>0.1317</td>
      <td>0.1043</td>
    </tr>
    <tr>
      <th>min</th>
      <td>0.0000</td>
      <td>0.0000</td>
      <td>0.0000</td>
      <td>0.0000</td>
      <td>0.0000</td>
      <td>0.0000</td>
      <td>0.0000</td>
      <td>0.0000</td>
      <td>0.0000</td>
      <td>0.0000</td>
      <td>0.0000</td>
      <td>0.0000</td>
      <td>0.0000</td>
      <td>0.0000</td>
      <td>0.0000</td>
      <td>0.0000</td>
      <td>0.0000</td>
      <td>0.0000</td>
      <td>0.0000</td>
      <td>0.0000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>0.0002</td>
      <td>0.0003</td>
      <td>0.0003</td>
      <td>0.0003</td>
      <td>0.0003</td>
      <td>0.0004</td>
      <td>0.0003</td>
      <td>0.0004</td>
      <td>0.0004</td>
      <td>0.0003</td>
      <td>0.0004</td>
      <td>0.0002</td>
      <td>0.0004</td>
      <td>0.0002</td>
      <td>0.0003</td>
      <td>0.0002</td>
      <td>0.0002</td>
      <td>0.0002</td>
      <td>0.0003</td>
      <td>0.0002</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>0.0027</td>
      <td>0.0030</td>
      <td>0.0026</td>
      <td>0.0027</td>
      <td>0.0037</td>
      <td>0.0028</td>
      <td>0.0031</td>
      <td>0.0039</td>
      <td>0.0032</td>
      <td>0.0035</td>
      <td>0.0043</td>
      <td>0.0040</td>
      <td>0.0034</td>
      <td>0.0025</td>
      <td>0.0024</td>
      <td>0.0019</td>
      <td>0.0025</td>
      <td>0.0020</td>
      <td>0.0029</td>
      <td>0.0019</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>0.0116</td>
      <td>0.0128</td>
      <td>0.0119</td>
      <td>0.0118</td>
      <td>0.0155</td>
      <td>0.0107</td>
      <td>0.0149</td>
      <td>0.0151</td>
      <td>0.0147</td>
      <td>0.0152</td>
      <td>0.0145</td>
      <td>0.0156</td>
      <td>0.0140</td>
      <td>0.0096</td>
      <td>0.0121</td>
      <td>0.0086</td>
      <td>0.0117</td>
      <td>0.0113</td>
      <td>0.0171</td>
      <td>0.0097</td>
    </tr>
    <tr>
      <th>max</th>
      <td>1.0000</td>
      <td>1.0000</td>
      <td>1.0000</td>
      <td>1.0000</td>
      <td>1.0000</td>
      <td>1.0000</td>
      <td>1.0000</td>
      <td>1.0000</td>
      <td>1.0000</td>
      <td>1.0000</td>
      <td>1.0000</td>
      <td>1.0000</td>
      <td>1.0000</td>
      <td>1.0000</td>
      <td>1.0000</td>
      <td>1.0000</td>
      <td>1.0000</td>
      <td>1.0000</td>
      <td>1.0000</td>
      <td>1.0000</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<ul class="simple">
<li><p>Ahora, el objetivo es crear un <code class="docutils literal notranslate"><span class="pre">modelo</span> <span class="pre">que</span> <span class="pre">prediga</span> <span class="pre">la</span> <span class="pre">generación</span> <span class="pre">de</span> <span class="pre">energía</span> <span class="pre">para</span> <span class="pre">2019,</span> <span class="pre">basándose</span> <span class="pre">en</span> <span class="pre">los</span> <span class="pre">18</span> <span class="pre">años</span> <span class="pre">anteriores</span> <span class="pre">(2000</span> <span class="pre">-</span> <span class="pre">2018)</span></code> con <code class="docutils literal notranslate"><span class="pre">al</span> <span class="pre">menos</span> <span class="pre">un</span> <span class="pre">75%</span> <span class="pre">de</span> <span class="pre">precisión</span></code>. Para ello, el conjunto de datos se separó en <code class="docutils literal notranslate"><span class="pre">X</span></code> e <code class="docutils literal notranslate"><span class="pre">y</span></code>, siendo <code class="docutils literal notranslate"><span class="pre">X</span></code> datos de predicción e <code class="docutils literal notranslate"><span class="pre">y</span></code> lo que se pretende predecir. Para ello, se dividen en <code class="docutils literal notranslate"><span class="pre">entrenamiento</span> <span class="pre">(70%)</span></code> y <code class="docutils literal notranslate"><span class="pre">prueba</span> <span class="pre">(30%)</span></code>.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">df_power</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;2019&quot;</span><span class="p">])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df_power</span><span class="p">[</span><span class="s2">&quot;2019&quot;</span><span class="p">]</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Como ya tenemos seleccionados los datos de entrenamiento y de prueba, es necesario <code class="docutils literal notranslate"><span class="pre">encontrar</span> <span class="pre">el</span> <span class="pre">factor</span></code> <span class="math notranslate nohighlight">\(k\)</span> que genere los <code class="docutils literal notranslate"><span class="pre">mejores</span> <span class="pre">resultados</span> <span class="pre">para</span> <span class="pre">el</span> <span class="pre">algoritmo</span></code>. Una de las formas de encontrar este factor <span class="math notranslate nohighlight">\(k\)</span> es <code class="docutils literal notranslate"><span class="pre">realizar</span> <span class="pre">una</span> <span class="pre">prueba</span> <span class="pre">con</span> <span class="pre">varios</span> <span class="pre">valores</span> <span class="pre">y</span> <span class="pre">medir</span> <span class="pre">los</span> <span class="pre">resultados</span> <span class="pre">porcentuales</span></code>. Será necesario agotar un gran número de posibilidades de <span class="math notranslate nohighlight">\(k\)</span></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rmsle_val</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">best_rmsle</span> <span class="o">=</span> <span class="mf">1.0</span>

<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">20</span><span class="p">):</span>
    <span class="n">k</span> <span class="o">=</span> <span class="n">k</span><span class="o">+</span><span class="mi">1</span>
    <span class="n">knn</span> <span class="o">=</span> <span class="n">neighbors</span><span class="o">.</span><span class="n">KNeighborsRegressor</span><span class="p">(</span><span class="n">n_neighbors</span> <span class="o">=</span> <span class="n">k</span><span class="p">)</span>
    <span class="n">knn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span> 
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">knn</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
    <span class="n">rmsle</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">mean_squared_log_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="n">y_pred</span><span class="p">))</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">rmsle</span> <span class="o">&lt;</span> <span class="n">best_rmsle</span><span class="p">):</span>
        <span class="n">best_rmsle</span> <span class="o">=</span> <span class="n">rmsle</span>
        <span class="n">best_k</span> <span class="o">=</span> <span class="n">k</span>
    <span class="n">rmsle_val</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">rmsle</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;RMSLE value for k= &#39;</span> <span class="p">,</span> <span class="n">k</span> <span class="p">,</span> <span class="s1">&#39;is:&#39;</span><span class="p">,</span> <span class="n">rmsle</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Best RMSLE: </span><span class="si">{</span><span class="n">best_rmsle</span><span class="si">}</span><span class="s2">, Best k: </span><span class="si">{</span><span class="n">best_k</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>RMSLE value for k=  1 is: 0.05771085849033799
RMSLE value for k=  2 is: 0.046287824938614094
RMSLE value for k=  3 is: 0.05245290672301628
RMSLE value for k=  4 is: 0.03904370874530979
RMSLE value for k=  5 is: 0.04413545109970342
RMSLE value for k=  6 is: 0.049397885066996064
RMSLE value for k=  7 is: 0.05368842644105438
RMSLE value for k=  8 is: 0.057205532019402504
RMSLE value for k=  9 is: 0.05970971610365409
RMSLE value for k=  10 is: 0.06264220706736034
RMSLE value for k=  11 is: 0.06519555508343818
RMSLE value for k=  12 is: 0.06683376633168203
RMSLE value for k=  13 is: 0.06835697276199447
RMSLE value for k=  14 is: 0.0700987590270357
RMSLE value for k=  15 is: 0.0714815908074978
RMSLE value for k=  16 is: 0.07276108145829546
RMSLE value for k=  17 is: 0.07381745094856672
RMSLE value for k=  18 is: 0.07488933459172763
RMSLE value for k=  19 is: 0.07579673979403485
RMSLE value for k=  20 is: 0.07667076282857414
Best RMSLE: 0.03904370874530979, Best k: 4
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Nuestra métrica indica que <code class="docutils literal notranslate"><span class="pre">el</span> <span class="pre">menor</span> <span class="pre">error</span> <span class="pre">se</span> <span class="pre">produce</span> <span class="pre">cuando</span> <span class="pre">tenemos</span></code> <span class="math notranslate nohighlight">\(k = 4\)</span> <code class="docutils literal notranslate"><span class="pre">(RMSLE</span> <span class="pre">de</span> <span class="pre">0.0390)</span></code>, lo que indica un error relativo entre los valores predichos y los actuales del 3,90%. Por lo tanto, <code class="docutils literal notranslate"><span class="pre">presentaremos</span> <span class="pre">todos</span> <span class="pre">los</span> <span class="pre">valores</span> <span class="pre">en</span> <span class="pre">un</span> <span class="pre">gráfico,</span> <span class="pre">que</span> <span class="pre">nos</span> <span class="pre">mostrará</span> <span class="pre">visualmente</span> <span class="pre">los</span> <span class="pre">resultados</span> <span class="pre">obtenidos</span></code>. Esta función se conoce como <code class="docutils literal notranslate"><span class="pre">&quot;función</span> <span class="pre">codo&quot;</span></code>, dada la variación porcentual que se produce entre los valores de <span class="math notranslate nohighlight">\(k\)</span>, primero hacia abajo y luego hacia arriba, cuando <span class="math notranslate nohighlight">\(k\)</span> encuentra su mejor valor. Estamos trazando los valores <code class="docutils literal notranslate"><span class="pre">RMSLE</span></code> frente a los valores de <span class="math notranslate nohighlight">\(k\)</span>.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">curve</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">rmsle_val</span><span class="p">)</span>
<span class="n">curve</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">5</span><span class="p">));</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/71ddf71220d286c55bc95860b6a998116213027b0b3b97bce66fe6523cdc8636.png" src="_images/71ddf71220d286c55bc95860b6a998116213027b0b3b97bce66fe6523cdc8636.png" />
</div>
</div>
<ul class="simple">
<li><p>El gráfico muestra una <code class="docutils literal notranslate"><span class="pre">caída</span> <span class="pre">brusca</span> <span class="pre">del</span> <span class="pre">RMSLE</span></code> a medida que <span class="math notranslate nohighlight">\(k\)</span> avanza hasta 4, momento en el que empieza a aumentar indefinidamente, lo que nos lleva a la conclusión de que <code class="docutils literal notranslate"><span class="pre">4</span> <span class="pre">es</span> <span class="pre">el</span> <span class="pre">mejor</span> <span class="pre">resultado</span> <span class="pre">para</span></code> <span class="math notranslate nohighlight">\(k\)</span>. Una vez encontrado el mejor valor para <span class="math notranslate nohighlight">\(k\)</span>, es hora de entrenar el modelo y predecir los resultados. También haremos uso de la función de <code class="docutils literal notranslate"><span class="pre">score</span></code>, que nos permitirá ver la <code class="docutils literal notranslate"><span class="pre">tasa</span> <span class="pre">de</span> <span class="pre">precisión</span> <span class="pre">de</span> <span class="pre">nuestro</span> <span class="pre">modelo</span> <span class="pre">(80,16%)</span></code>.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">knn</span> <span class="o">=</span> <span class="n">neighbors</span><span class="o">.</span><span class="n">KNeighborsRegressor</span><span class="p">(</span><span class="n">n_neighbors</span> <span class="o">=</span> <span class="mi">4</span><span class="p">)</span>

<span class="n">knn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">knn</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">knn</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.8016285342188538
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Una vez se ha construido el modelo y se prueban algunas predicciones, podemos aplicar las <code class="docutils literal notranslate"><span class="pre">métricas</span></code> y <code class="docutils literal notranslate"><span class="pre">analizar</span> <span class="pre">los</span> <span class="pre">resultados</span></code>. Aquí se <code class="docutils literal notranslate"><span class="pre">comparan</span> <span class="pre">el</span> <span class="pre">conjunto</span> <span class="pre">de</span> <span class="pre">prueba</span> <span class="pre">con</span> <span class="pre">las</span> <span class="pre">predicciones</span></code> usando las métricas <code class="docutils literal notranslate"><span class="pre">R2,</span> <span class="pre">EVS,</span> <span class="pre">MAE,</span> <span class="pre">RMSE,</span> <span class="pre">RMSLE</span></code>, para verificar cuáles son los resultados de cada una de ellas.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">r2_valid</span> <span class="o">=</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="n">mae_valid</span> <span class="o">=</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="n">evs_valid</span> <span class="o">=</span> <span class="n">explained_variance_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">multioutput</span><span class="o">=</span><span class="s1">&#39;uniform_average&#39;</span><span class="p">)</span>
<span class="n">rmse_valid</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
<span class="n">rmsle_valid</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">mean_squared_log_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;R2 Valid:&#39;</span><span class="p">,</span><span class="n">r2_valid</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;EVS Valid:&#39;</span><span class="p">,</span> <span class="n">evs_valid</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;MAE Valid:&#39;</span><span class="p">,</span> <span class="n">mae_valid</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;RMSE Valid:&#39;</span><span class="p">,</span><span class="n">rmse_valid</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;RMSLE Valid:&#39;</span><span class="p">,</span> <span class="n">rmsle_valid</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>R2 Valid: 0.8016285342188538
EVS Valid: 0.8131526313306373
MAE Valid: 0.017960057840249434
RMSE Valid: 0.04999229884993785
RMSLE Valid: 0.03904370874530979
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Los resultados muestran un <code class="docutils literal notranslate"><span class="pre">R2</span> <span class="pre">del</span> <span class="pre">80,16%</span></code> y un <code class="docutils literal notranslate"><span class="pre">EVS</span> <span class="pre">del</span> <span class="pre">81,31%</span></code>, lo que indica que nuestro modelo tiene un <code class="docutils literal notranslate"><span class="pre">gran</span> <span class="pre">ajuste</span> <span class="pre">a</span> <span class="pre">su</span> <span class="pre">muestra</span> <span class="pre">(R2)</span></code> y una <code class="docutils literal notranslate"><span class="pre">fuerte</span> <span class="pre">asociación</span> <span class="pre">entre</span> <span class="pre">el</span> <span class="pre">modelo</span> <span class="pre">y</span> <span class="pre">sus</span> <span class="pre">datos</span> <span class="pre">actuales</span> <span class="pre">(EVS)</span></code>. En cuanto al <code class="docutils literal notranslate"><span class="pre">RMSLE</span></code>, sólo tiene en cuenta el <code class="docutils literal notranslate"><span class="pre">error</span> <span class="pre">relativo</span> <span class="pre">entre</span> <span class="pre">el</span> <span class="pre">valor</span> <span class="pre">previsto</span> <span class="pre">y</span> <span class="pre">el</span> <span class="pre">real,</span> <span class="pre">y</span> <span class="pre">la</span> <span class="pre">escala</span> <span class="pre">del</span> <span class="pre">error</span> <span class="pre">no</span> <span class="pre">es</span> <span class="pre">significativa</span></code>. Por otro lado, el valor <code class="docutils literal notranslate"><span class="pre">RMSE</span> <span class="pre">aumenta</span> <span class="pre">en</span> <span class="pre">magnitud</span> <span class="pre">si</span> <span class="pre">aumenta</span> <span class="pre">la</span> <span class="pre">escala</span> <span class="pre">del</span> <span class="pre">error</span></code>.</p></li>
</ul>
<ul class="simple">
<li><p>Una vez realizada la predicción y comprobado el modelo, <code class="docutils literal notranslate"><span class="pre">organizamos</span> <span class="pre">los</span> <span class="pre">resultados</span> <span class="pre">uno</span> <span class="pre">al</span> <span class="pre">lado</span> <span class="pre">del</span> <span class="pre">otro</span> <span class="pre">para</span> <span class="pre">poder</span> <span class="pre">hacer</span> <span class="pre">una</span> <span class="pre">comparación</span></code>.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">country_test</span> <span class="o">=</span> <span class="n">countries</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">countries</span><span class="p">)</span><span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="n">y_test</span><span class="p">):]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data_prediction</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="n">y_pred</span><span class="p">))</span>
<span class="n">data_prediction</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data_prediction</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Test&#39;</span><span class="p">,</span><span class="s1">&#39;Prediction&#39;</span><span class="p">])</span>
<span class="n">data_prediction</span> <span class="o">=</span> <span class="n">data_prediction</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="n">country_test</span><span class="p">)</span>
<span class="n">data_prediction</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Test</th>
      <th>Prediction</th>
    </tr>
    <tr>
      <th>Country</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Papua New Guinea</th>
      <td>0.0406</td>
      <td>0.0268</td>
    </tr>
    <tr>
      <th>Paraguay</th>
      <td>0.0044</td>
      <td>0.0039</td>
    </tr>
    <tr>
      <th>Peru</th>
      <td>0.0134</td>
      <td>0.0096</td>
    </tr>
    <tr>
      <th>Phillipines</th>
      <td>0.0280</td>
      <td>0.0128</td>
    </tr>
    <tr>
      <th>Poland</th>
      <td>0.0164</td>
      <td>0.0125</td>
    </tr>
    <tr>
      <th>Portugal</th>
      <td>0.0321</td>
      <td>0.0155</td>
    </tr>
    <tr>
      <th>Puerto Rico</th>
      <td>0.4982</td>
      <td>0.3417</td>
    </tr>
    <tr>
      <th>Reunion</th>
      <td>0.5331</td>
      <td>0.3417</td>
    </tr>
    <tr>
      <th>Romania</th>
      <td>0.0007</td>
      <td>0.0075</td>
    </tr>
    <tr>
      <th>Russia</th>
      <td>0.0032</td>
      <td>0.0039</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s1">&#39;font.size&#39;</span><span class="p">:</span> <span class="mi">18</span><span class="p">});</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">8</span><span class="p">));</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">data_prediction</span><span class="o">.</span><span class="n">index</span><span class="p">,</span> <span class="n">data_prediction</span><span class="o">.</span><span class="n">Test</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Test&quot;</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">data_prediction</span><span class="o">.</span><span class="n">index</span><span class="p">,</span> <span class="n">data_prediction</span><span class="o">.</span><span class="n">Prediction</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Prediction&quot;</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">rotation</span><span class="o">=</span><span class="mi">90</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s2">&quot;upper right&quot;</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Country&quot;</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Hydropower Generation&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/9daf3746b4d63e4927a0b3da6b8b6e26355e11d6c75e43709cb4edae41d335ae.png" src="_images/9daf3746b4d63e4927a0b3da6b8b6e26355e11d6c75e43709cb4edae41d335ae.png" />
</div>
</div>
<ul class="simple">
<li><p>Nótese que el conjunto de prueba para este ejemplo fue tomado como, el <code class="docutils literal notranslate"><span class="pre">último</span> <span class="pre">30%</span> <span class="pre">de</span> <span class="pre">nuestras</span> <span class="pre">observaciones</span></code>, lo cual corresponde a los <code class="docutils literal notranslate"><span class="pre">últimos</span> <span class="pre">46</span> <span class="pre">países</span></code> (observaciones) existentes en nuestro dataset. En la sección dedicada a la <code class="docutils literal notranslate"><span class="pre">evaluación</span> <span class="pre">de</span> <span class="pre">modelos</span></code>, se abordarán técnicas especificas para que <code class="docutils literal notranslate"><span class="pre">pliegues</span> <span class="pre">de</span> <span class="pre">prueba</span> <span class="pre">sean</span> <span class="pre">repartidos</span> <span class="pre">proporcionalmente</span> <span class="pre">en</span> <span class="pre">todas</span> <span class="pre">las</span> <span class="pre">posiciones</span> <span class="pre">posibles</span> <span class="pre">en</span> <span class="pre">nuestro</span> <span class="pre">data</span> <span class="pre">set</span></code>, usando la librería <code class="docutils literal notranslate"><span class="pre">KFold</span></code>, así como también hiperparametrización usando <code class="docutils literal notranslate"><span class="pre">GridSearch</span></code>.</p></li>
</ul>
<div class="tip admonition">
<p class="admonition-title">Puntos fuertes, puntos débiles y parámetros</p>
<ul class="simple">
<li><p>En principio, hay <code class="docutils literal notranslate"><span class="pre">dos</span> <span class="pre">parámetros</span> <span class="pre">importantes</span></code> en el clasificador <code class="docutils literal notranslate"><span class="pre">KNeighbors</span></code>: el <code class="docutils literal notranslate"><span class="pre">número</span> <span class="pre">de</span> <span class="pre">vecinos</span></code> y <code class="docutils literal notranslate"><span class="pre">cómo</span> <span class="pre">se</span> <span class="pre">mide</span> <span class="pre">la</span> <span class="pre">distancia</span> <span class="pre">entre</span> <span class="pre">los</span> <span class="pre">puntos</span> <span class="pre">de</span> <span class="pre">datos</span></code>. En la práctica, utilizar <code class="docutils literal notranslate"><span class="pre">un</span> <span class="pre">número</span> <span class="pre">pequeño</span> <span class="pre">de</span> <span class="pre">vecinos,</span> <span class="pre">como</span> <span class="pre">tres</span> <span class="pre">o</span> <span class="pre">cinco,</span> <span class="pre">suele</span> <span class="pre">funcionar</span> <span class="pre">bien,</span> <span class="pre">pero</span> <span class="pre">se</span> <span class="pre">debería</span> <span class="pre">ajustar</span> <span class="pre">este</span> <span class="pre">parámetro</span></code>.</p></li>
<li><p>La elección de la <code class="docutils literal notranslate"><span class="pre">medida</span> <span class="pre">de</span> <span class="pre">distancia</span> <span class="pre">correcta</span> <span class="pre">es</span> <span class="pre">también</span> <span class="pre">crucial</span></code>. Por defecto, <code class="docutils literal notranslate"><span class="pre">KNeighbors</span></code> utiliza la <code class="docutils literal notranslate"><span class="pre">distancia</span> <span class="pre">euclidiana</span></code>, que funciona bien en muchos casos. Uno de los puntos fuertes de <span class="math notranslate nohighlight">\(k\)</span>-NN es que <code class="docutils literal notranslate"><span class="pre">el</span> <span class="pre">modelo</span> <span class="pre">es</span> <span class="pre">muy</span> <span class="pre">fácil</span> <span class="pre">de</span> <span class="pre">entender</span></code>, y a menudo da un rendimiento razonable sin necesidad de muchos ajustes. El uso de este algoritmo es un buen <code class="docutils literal notranslate"><span class="pre">método</span> <span class="pre">de</span> <span class="pre">referencia</span> <span class="pre">para</span> <span class="pre">probar,</span> <span class="pre">antes</span> <span class="pre">de</span> <span class="pre">considerar</span> <span class="pre">técnicas</span> <span class="pre">más</span> <span class="pre">avanzadas</span></code>.</p></li>
<li><p>La construcción del modelo de vecinos más cercanos suele ser muy rápida, pero <code class="docutils literal notranslate"><span class="pre">cuando</span> <span class="pre">el</span> <span class="pre">conjunto</span> <span class="pre">de</span> <span class="pre">entrenamiento</span> <span class="pre">es</span> <span class="pre">muy</span> <span class="pre">grande</span> <span class="pre">(ya</span> <span class="pre">sea</span> <span class="pre">en</span> <span class="pre">número</span> <span class="pre">de</span> <span class="pre">características</span> <span class="pre">o</span> <span class="pre">en</span> <span class="pre">número</span> <span class="pre">de</span> <span class="pre">muestras)</span> <span class="pre">la</span> <span class="pre">predicción</span> <span class="pre">puede</span> <span class="pre">ser</span> <span class="pre">lenta</span></code>. Cuando se utiliza el algoritmo <span class="math notranslate nohighlight">\(k\)</span>-NN, es importante <code class="docutils literal notranslate"><span class="pre">pre-procesar</span> <span class="pre">los</span> <span class="pre">datos</span></code>, tema que revisaremos en secciones posteriores. Este enfoque <code class="docutils literal notranslate"><span class="pre">no</span> <span class="pre">suele</span> <span class="pre">funcionar</span> <span class="pre">bien</span> <span class="pre">en</span> <span class="pre">conjuntos</span> <span class="pre">de</span> <span class="pre">datos</span> <span class="pre">con</span> <span class="pre">muchas</span> <span class="pre">características</span> <span class="pre">(cientos</span> <span class="pre">o</span> <span class="pre">más)</span></code>, y <code class="docutils literal notranslate"><span class="pre">lo</span> <span class="pre">hace</span> <span class="pre">especialmente</span> <span class="pre">mal</span> <span class="pre">con</span> <span class="pre">conjuntos</span> <span class="pre">de</span> <span class="pre">datos</span> <span class="pre">en</span> <span class="pre">los</span> <span class="pre">que</span> <span class="pre">la</span> <span class="pre">mayoría</span> <span class="pre">de</span> <span class="pre">las</span> <span class="pre">características</span> <span class="pre">son</span> <span class="pre">0</span> <span class="pre">la</span> <span class="pre">mayor</span> <span class="pre">parte</span> <span class="pre">del</span> <span class="pre">tiempo</span> <span class="pre">(los</span> <span class="pre">llamados</span> <span class="pre">conjuntos</span> <span class="pre">de</span> <span class="pre">datos</span> <span class="pre">dispersos</span></code>).</p></li>
<li><p>Por lo tanto, aunque el algoritmo de <span class="math notranslate nohighlight">\(k\)</span><code class="docutils literal notranslate"><span class="pre">-vecinos</span> <span class="pre">más</span> <span class="pre">cercanos</span></code> es fácil de entender, <code class="docutils literal notranslate"><span class="pre">no</span> <span class="pre">se</span> <span class="pre">utiliza</span> <span class="pre">a</span> <span class="pre">menudo</span> <span class="pre">en</span> <span class="pre">la</span> <span class="pre">práctica,</span> <span class="pre">debido</span> <span class="pre">a</span> <span class="pre">que</span> <span class="pre">la</span> <span class="pre">predicción</span> <span class="pre">es</span> <span class="pre">lenta</span> <span class="pre">y</span> <span class="pre">a</span> <span class="pre">su</span> <span class="pre">incapacidad</span> <span class="pre">para</span> <span class="pre">manejar</span> <span class="pre">muchas</span> <span class="pre">características</span></code>.</p></li>
</ul>
</div>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="supervised_intro.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Aprendizaje supervisado</p>
      </div>
    </a>
    <a class="right-next"
       href="linear_model.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Modelos lineales</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#analisis">Análisis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#implementacion">Implementación</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#analisis-de-kneighborsclassifier">Análisis de <code class="docutils literal notranslate"><span class="pre">KNeighborsClassifier</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#aplicacion-breast-cancer-dataset">Aplicación: Breast Cancer Dataset</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#analisis-exploratorio-de-datos">Análisis Exploratorio de Datos</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#multicolinealidad">Multicolinealidad</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#factor-de-inflacion-de-la-varianza-vif">Factor de Inflación de la Varianza (VIF)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#seleccion-del-modelo-k-nn">Selección del modelo K-NN</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#regresion-por-k-vecinos">Regresión por <span class="math notranslate nohighlight">\(k\)</span>-vecinos</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#analisis-de-kneighborsregressor">Análisis de <code class="docutils literal notranslate"><span class="pre">KNeighborsRegressor</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#aplicacion-world-hydropower-generation">Aplicación: World Hydropower Generation</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Lihki Rubio, Ph.D.
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
<div class="extra_footer">
  <p>Lihki Rubio, Ph.D. All rights reserved.</p>
</div>
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>