
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Redes Neuronales y Deep Learning &#8212; Machine Learning</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.1/css/all.min.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.1/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.1/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.1/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=384b581d" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/proof.css?v=ca93fcec" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css?v=0a3b3ea7" />
    <link rel="stylesheet" type="text/css" href="_static/custom.css?v=530fe47d" />
    <link rel="stylesheet" type="text/css" href="_static/.ipynb_checkpoints/custom-checkpoint.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae" />
  <script src="_static/vendor/fontawesome/6.5.1/js/all.min.js?digest=8d27b9dea8ad943066ae"></script>

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=efea14e4"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=36754332"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'ann_model';</script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="_static/custom.js?v=14184634"></script>
    <script src="_static/.ipynb_checkpoints/custom-checkpoint.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Análisis de Componentes Principales" href="practical_pca.html" />
    <link rel="prev" title="Máquinas de vectores de soporte" href="svm_model.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a id="pst-skip-link" class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <header class="bd-header navbar navbar-expand-lg bd-navbar">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/fotolihki.jpg" class="logo__image only-light" alt="Machine Learning - Home"/>
    <script>document.write(`<img src="_static/fotolihki.jpg" class="logo__image only-dark" alt="Machine Learning - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn navbar-btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Profesor: Dr. Lihki Rubio
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="supervised_intro.html">Aprendizaje supervisado</a></li>
<li class="toctree-l1"><a class="reference internal" href="knn_model.html"><span class="math notranslate nohighlight">\(k\)</span>-Vecinos más cercanos</a></li>
<li class="toctree-l1"><a class="reference internal" href="linear_model.html">Modelos lineales</a></li>
<li class="toctree-l1"><a class="reference internal" href="bayes_model.html">Clasificadores Naive Bayes</a></li>
<li class="toctree-l1"><a class="reference internal" href="decisiontree_model.html">Árboles de decisión</a></li>

<li class="toctree-l1"><a class="reference internal" href="svm_model.html">Máquinas de vectores de soporte</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Redes Neuronales y Deep Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="practical_pca.html">Análisis de Componentes Principales</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_evaluation.html">Evaluación de modelos</a></li>
<li class="toctree-l1"><a class="reference internal" href="chains_pipelines.html">Cadenas de Algoritmos y Pipelines</a></li>
<li class="toctree-l1"><a class="reference internal" href="appendix.html">Apéndice</a></li>
<li class="toctree-l1"><a class="reference internal" href="biblio.html">Bibliografía</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/ann_model.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Redes Neuronales y Deep Learning</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gradiente-descendiente">Gradiente descendiente</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#redes-neuronales">Redes neuronales</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#el-perceptron">El perceptrón</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#redes-neuronales-multicapa-feed-forward">Redes Neuronales Multicapa Feed-Forward</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#redes-totalmente-conectadas">Redes Totalmente Conectadas</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#el-algoritmo-de-backpropagation">El Algoritmo De Backpropagation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#el-esquema-de-backpropagation-para-gradiente-descendiente">El Esquema De Backpropagation Para Gradiente Descendiente</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#calculo-de-gradientes">Cálculo de gradientes</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#calculo-de-delta-nj-r">Cálculo de <span class="math notranslate nohighlight">\(\delta_{nj}^{r}\)</span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tuning-de-redes-neuronales">Tuning de Redes Neuronales</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#analisis-de-malware-por-api-calls">Análisis de Malware por API calls</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#redes-neuronales-convolucionales">Redes Neuronales Convolucionales</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#la-necesidad-de-convoluciones">La necesidad de convoluciones</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#la-etapa-de-convolucion">La etapa de convolución</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#el-paso-de-la-no-linealidad">El paso de la no linealidad</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#la-etapa-de-agrupacion">La etapa de agrupación</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#convolucion-sobre-volumenes">Convolución sobre volúmenes</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#red-en-red-y-convolucion-1-1">Red en red y convolución 1 × 1</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#arquitectura-cnn-completa">Arquitectura CNN completa</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#arquitecturas-de-redes-neuronales-convolucionales">Arquitecturas de Redes Neuronales Convolucionales</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#reconocimiento-facial-de-emociones">Reconocimiento facial de emociones</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#redes-neuronales-recurrentes">Redes Neuronales Recurrentes</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#backpropagation-en-tiempo">Backpropagation en tiempo</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#desvanecimiento-y-explosion-de-gradientes">Desvanecimiento y explosión de gradientes</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#red-de-memoria-a-largo-plazo-lstm">Red de memoria a largo plazo (LSTM)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#atencion-y-memoria">Atención y Memoria</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#entrenamiento-adversario">Entrenamiento adversario</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#modelos-generativos-profundos">Modelos Generativos Profundos</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#maquina-de-boltzmann-restringida">Máquina de Boltzmann Restringida</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#autoencoders">Autoencoders</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#aplicacion-procesamiento-del-lenguaje-natural">Aplicación: Procesamiento del Lenguaje Natural</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="redes-neuronales-y-deep-learning">
<h1>Redes Neuronales y Deep Learning<a class="headerlink" href="#redes-neuronales-y-deep-learning" title="Link to this heading">#</a></h1>
<section id="gradiente-descendiente">
<h2>Gradiente descendiente<a class="headerlink" href="#gradiente-descendiente" title="Link to this heading">#</a></h2>
<ul>
<li><p>El <code class="docutils literal notranslate"><span class="pre">método</span> <span class="pre">de</span> <span class="pre">gradiente</span> <span class="pre">descendiente</span></code> es uno de los mas ampliamente usados para la <code class="docutils literal notranslate"><span class="pre">minimización</span> <span class="pre">iterativa</span> <span class="pre">de</span> <span class="pre">una</span> <span class="pre">función</span> <span class="pre">de</span> <span class="pre">costo</span> <span class="pre">diferenciable</span></code>, <span class="math notranslate nohighlight">\(J(\boldsymbol{\theta}),~\boldsymbol{\theta}\in\mathbb{R}^{l}\)</span>. Como cualquier otra técnica iterativa, el método <code class="docutils literal notranslate"><span class="pre">parte</span> <span class="pre">de</span> <span class="pre">una</span> <span class="pre">estimación</span> <span class="pre">inicial</span></code>, <span class="math notranslate nohighlight">\(\boldsymbol{\theta}^{(0)}\)</span>, <code class="docutils literal notranslate"><span class="pre">y</span> <span class="pre">genera</span> <span class="pre">una</span> <span class="pre">sucesión</span></code> <span class="math notranslate nohighlight">\(\boldsymbol{\theta}^{(i)},~i=1,2,\dots,\)</span> tal que:</p>
<div class="math notranslate nohighlight">
\[
    \boldsymbol{\theta}^{(i)}=\boldsymbol{\theta}^{(i-1)}+\mu_{i}\Delta\boldsymbol{\theta}^{(i)},~ i &gt;0,~\mu_{i}&gt;0.
    \]</div>
</li>
<li><p>La diferencia entre cada método radica en la forma que <span class="math notranslate nohighlight">\(\mu_{i}\)</span> y <span class="math notranslate nohighlight">\(\Delta\boldsymbol{\theta}^{(i)}\)</span> son seleccionados. <span class="math notranslate nohighlight">\(\Delta\boldsymbol{\theta}^{(i)}\)</span> es conocido como la <code class="docutils literal notranslate"><span class="pre">dirección</span> <span class="pre">de</span> <span class="pre">actualización</span> <span class="pre">o</span> <span class="pre">de</span> <span class="pre">búsqueda</span></code>. La sucesión <span class="math notranslate nohighlight">\(\mu_{i}\)</span> es conocida como el <code class="docutils literal notranslate"><span class="pre">tamaño</span> <span class="pre">o</span> <span class="pre">longitud</span> <span class="pre">de</span> <span class="pre">paso</span></code> en la <span class="math notranslate nohighlight">\(i\)</span>-ésima iteración, estos valores pueden ser constantes o cambiar. En el método de gradiente descendiente, <code class="docutils literal notranslate"><span class="pre">la</span> <span class="pre">selección</span> <span class="pre">de</span></code> <span class="math notranslate nohighlight">\(\Delta\boldsymbol{\theta}^{(i)}\)</span> <code class="docutils literal notranslate"><span class="pre">es</span> <span class="pre">realizada</span> <span class="pre">para</span> <span class="pre">garantizar</span> <span class="pre">que</span></code> <span class="math notranslate nohighlight">\(J(\boldsymbol{\theta}^{(i)})&lt;J(\boldsymbol{\theta}^{(i-1)})\)</span>, excepto en el minimizador <span class="math notranslate nohighlight">\(\boldsymbol{\theta}_{\star}\)</span>.</p></li>
</ul>
<figure class="align-center" id="curva-nivel">
<a class="reference internal image-reference" href="_images/curva_nivel.png"><img alt="_images/curva_nivel.png" src="_images/curva_nivel.png" style="width: 504.8px; height: 386.40000000000003px;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 25 </span><span class="caption-text">Función de coste en el espacio de parámetros bidimensional.</span><a class="headerlink" href="#curva-nivel" title="Link to this image">#</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p>Suponga que en la iteración <span class="math notranslate nohighlight">\(i-1\)</span> el valor <span class="math notranslate nohighlight">\(\boldsymbol{\theta}^{(i-1)}\)</span> <code class="docutils literal notranslate"><span class="pre">ha</span> <span class="pre">sido</span> <span class="pre">obtenido</span></code></p></li>
</ul>
<div class="math notranslate nohighlight">
\[
J(\boldsymbol{\theta}^{(i)})=J(\boldsymbol{\theta}^{(i-1)}+\mu_{i}\Delta\boldsymbol{\theta}^{(i)})\approx J(\boldsymbol{\theta}^{(i-1)})+\mu_{i}\cdot\nabla^{T}J(\boldsymbol{\theta}^{(i-1)})\Delta\boldsymbol{\theta}^{(i-1)}.
\]</div>
<ul class="simple">
<li><p>Nótese que <code class="docutils literal notranslate"><span class="pre">seleccionando</span> <span class="pre">la</span> <span class="pre">dirección</span> <span class="pre">tal</span> <span class="pre">que</span></code> <span class="math notranslate nohighlight">\(\nabla^{T}J(\boldsymbol{\theta}^{(i-1)})\Delta\boldsymbol{\theta}^{(i)}&lt;0\)</span>, <code class="docutils literal notranslate"><span class="pre">garantizará</span> <span class="pre">que</span></code> <span class="math notranslate nohighlight">\(J(\boldsymbol{\theta}^{(i-1)}+\mu_{i}\Delta\boldsymbol{\theta}^{(i)})&lt;J(\boldsymbol{\theta}^{(i-1)})\)</span>. Tal selección de <span class="math notranslate nohighlight">\(\Delta\boldsymbol{\theta}^{(i)}\)</span> y <span class="math notranslate nohighlight">\(\nabla J(\boldsymbol{\theta}^{(i-1)})\)</span> debe formar un <code class="docutils literal notranslate"><span class="pre">ángulo</span> <span class="pre">obtuso</span></code>. Las curvas de nivel asociadas a <span class="math notranslate nohighlight">\(J(\boldsymbol{\theta})\)</span> pueden tomar cualquier forma, la cual va a <code class="docutils literal notranslate"><span class="pre">depender</span> <span class="pre">de</span> <span class="pre">como</span> <span class="pre">está</span> <span class="pre">definido</span></code> <span class="math notranslate nohighlight">\(J(\boldsymbol{\theta})\)</span>.</p></li>
<li><p><span class="math notranslate nohighlight">\(J(\boldsymbol{\theta})\)</span> se supone diferenciable, por lo tanto, las <code class="docutils literal notranslate"><span class="pre">curvas</span> <span class="pre">de</span> <span class="pre">nivel</span> <span class="pre">o</span> <span class="pre">contornos</span> <span class="pre">deben</span> <span class="pre">ser</span> <span class="pre">suaves</span> <span class="pre">y</span> <span class="pre">aceptar</span> <span class="pre">un</span> <span class="pre">plano</span> <span class="pre">tangente</span> <span class="pre">en</span> <span class="pre">cualquier</span> <span class="pre">punto</span></code>. Además, de los cursos de cálculo sabemos que el <code class="docutils literal notranslate"><span class="pre">vector</span> <span class="pre">gradiente</span></code> <span class="math notranslate nohighlight">\(\nabla J(\boldsymbol{\theta})\)</span> <code class="docutils literal notranslate"><span class="pre">es</span> <span class="pre">perpendicular</span> <span class="pre">al</span> <span class="pre">plano</span> <span class="pre">tangente</span></code> (recta tangente) <code class="docutils literal notranslate"><span class="pre">a</span> <span class="pre">la</span> <span class="pre">correspondiente</span> <span class="pre">curva</span> <span class="pre">de</span> <span class="pre">nivel</span> <span class="pre">en</span> <span class="pre">el</span> <span class="pre">punto</span></code> <span class="math notranslate nohighlight">\(\boldsymbol{\theta}\)</span>. Nótese que <code class="docutils literal notranslate"><span class="pre">seleccionando</span> <span class="pre">la</span> <span class="pre">dirección</span> <span class="pre">de</span> <span class="pre">búsqueda</span></code> <span class="math notranslate nohighlight">\(\Delta\boldsymbol{\theta}^{(i)}\)</span> <code class="docutils literal notranslate"><span class="pre">que</span> <span class="pre">forma</span> <span class="pre">un</span> <span class="pre">angulo</span> <span class="pre">obtuso</span> <span class="pre">con</span> <span class="pre">el</span> <span class="pre">gradiente,</span> <span class="pre">se</span> <span class="pre">coloca</span> <span class="pre">a</span></code> <span class="math notranslate nohighlight">\(\boldsymbol{\theta}^{(i-1)}+\mu_{i}\Delta\boldsymbol{\theta}^{(i)}\)</span> <code class="docutils literal notranslate"><span class="pre">en</span> <span class="pre">un</span> <span class="pre">punto</span> <span class="pre">sobre</span> <span class="pre">el</span> <span class="pre">contorno</span> <span class="pre">el</span> <span class="pre">cual</span> <span class="pre">corresponde</span> <span class="pre">a</span> <span class="pre">un</span> <span class="pre">valor</span> <span class="pre">menor</span> <span class="pre">que</span></code> <span class="math notranslate nohighlight">\(J(\boldsymbol{\theta})\)</span>.</p></li>
</ul>
<ul class="simple">
<li><p>Dos problemas surgen ahora:</p>
<ol class="arabic simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Escoger</span> <span class="pre">la</span> <span class="pre">mejor</span> <span class="pre">dirección</span> <span class="pre">de</span> <span class="pre">búsqueda</span></code></p></li>
<li><p>Calcular <code class="docutils literal notranslate"><span class="pre">que</span> <span class="pre">tan</span> <span class="pre">lejos</span> <span class="pre">es</span> <span class="pre">aceptable</span> <span class="pre">un</span> <span class="pre">movimiento</span> <span class="pre">a</span> <span class="pre">traves</span> <span class="pre">de</span> <span class="pre">esta</span> <span class="pre">dirección</span></code>.</p></li>
</ol>
</li>
</ul>
<figure class="align-center" id="maximun-dec-cost-function">
<a class="reference internal image-reference" href="_images/maximun_dec_cost_function.png"><img alt="_images/maximun_dec_cost_function.png" src="_images/maximun_dec_cost_function.png" style="width: 495.20000000000005px; height: 365.6px;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 26 </span><span class="caption-text">El vector gradiente en un punto <span class="math notranslate nohighlight">\(\boldsymbol{\theta}\)</span> es perpendicular al plano tangente (línea punteada) en la curva de nivel que cruza <span class="math notranslate nohighlight">\(\boldsymbol{\theta}\)</span>. La dirección de descenso forma un ángulo obtuso, <span class="math notranslate nohighlight">\(\phi\)</span>, con el vector gradiente.</span><a class="headerlink" href="#maximun-dec-cost-function" title="Link to this image">#</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p>Nótese que <code class="docutils literal notranslate"><span class="pre">si</span></code> <span class="math notranslate nohighlight">\(\mu_{i}\|\Delta\boldsymbol{\theta}^{(i)}\|\)</span> <code class="docutils literal notranslate"><span class="pre">es</span> <span class="pre">demasiado</span> <span class="pre">grande,</span> <span class="pre">entonces</span> <span class="pre">el</span> <span class="pre">nuevo</span> <span class="pre">punto</span> <span class="pre">puede</span> <span class="pre">ser</span> <span class="pre">colocado</span> <span class="pre">en</span> <span class="pre">un</span> <span class="pre">contorno</span> <span class="pre">correspondiente</span> <span class="pre">a</span> <span class="pre">un</span> <span class="pre">valor</span> <span class="pre">mayor</span> <span class="pre">al</span> <span class="pre">del</span> <span class="pre">actual</span></code> contorno.</p></li>
</ul>
<figure class="align-center" id="curva-nivel-cost-function">
<a class="reference internal image-reference" href="_images/curva_nivel_cost_function.png"><img alt="_images/curva_nivel_cost_function.png" src="_images/curva_nivel_cost_function.png" style="width: 484.2px; height: 359.1px;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 27 </span><span class="caption-text">Las correspondientes curvas de nivel para la función de coste, en el plano bidimensional. Nótese que a medida que nos alejamos del valor óptimo, <span class="math notranslate nohighlight">\(\boldsymbol{\theta}_{\star}\)</span>, los valores de <span class="math notranslate nohighlight">\(c\)</span> aumentan.</span><a class="headerlink" href="#curva-nivel-cost-function" title="Link to this image">#</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p>Para abordar (1), <code class="docutils literal notranslate"><span class="pre">supongamos</span> <span class="pre">que</span></code> <span class="math notranslate nohighlight">\(\mu_{i}=1\)</span> y <code class="docutils literal notranslate"><span class="pre">buscamos</span> <span class="pre">todos</span> <span class="pre">los</span> <span class="pre">vectores</span></code> <span class="math notranslate nohighlight">\(\boldsymbol{z}\)</span> <code class="docutils literal notranslate"><span class="pre">con</span> <span class="pre">norma</span> <span class="pre">Euclidiana</span> <span class="pre">unitaria,</span> <span class="pre">con</span> <span class="pre">inicio</span> <span class="pre">(cola)</span> <span class="pre">en</span></code> <span class="math notranslate nohighlight">\(\boldsymbol{\theta}^{(i-1)}\)</span>. Entonces, para todas las posibles direcciones, la que entrega el valor más negativo del producto interno, <span class="math notranslate nohighlight">\(\nabla^{T}J(\boldsymbol{\theta}^{(i-1)})z\)</span>, es aquella de gradiente negativo</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
z=-\frac{\nabla J(\boldsymbol{\theta}^{(i-1)})}{\|\nabla J(\boldsymbol{\theta}^{(i-1)}\|}
\]</div>
<ul class="simple">
<li><p>Centrando <span class="math notranslate nohighlight">\(\boldsymbol{\theta}^{(i-1)}\)</span> en la bola con norma Euclideana uno. <code class="docutils literal notranslate"><span class="pre">De</span> <span class="pre">todos</span> <span class="pre">los</span> <span class="pre">vectores</span> <span class="pre">con</span> <span class="pre">norma</span> <span class="pre">unitaria</span> <span class="pre">y</span> <span class="pre">origen</span> <span class="pre">en</span></code> <span class="math notranslate nohighlight">\(\boldsymbol{\theta}^{(i-1)}\)</span>, <code class="docutils literal notranslate"><span class="pre">seleccionamos</span> <span class="pre">aquel</span> <span class="pre">que</span> <span class="pre">apunta</span> <span class="pre">en</span> <span class="pre">la</span> <span class="pre">dirección</span> <span class="pre">negativa</span> <span class="pre">del</span> <span class="pre">gradiente</span></code>. Por lo tanto, para todos los vectores con norma Euclidiana 1, la <code class="docutils literal notranslate"><span class="pre">dirección</span> <span class="pre">de</span> <span class="pre">descenso</span> <span class="pre">mas</span> <span class="pre">pronunciada</span> <span class="pre">coincide</span> <span class="pre">con</span> <span class="pre">la</span> <span class="pre">dirección</span> <span class="pre">del</span> <span class="pre">gradiente</span> <span class="pre">descendiente,</span> <span class="pre">negativo</span></code>, y la correspondiente actualización recursiva se convierte en</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\boldsymbol{\theta}^{(i)}=\boldsymbol{\theta}^{(i-1)}-\mu_{i}\nabla J(\boldsymbol{\theta}^{(i-1)}),\quad\text{Gradiente descendiente}.
\]</div>
<figure class="align-center" id="fig-desc-gradient">
<a class="reference internal image-reference" href="_images/desc_gradient.png"><img alt="_images/desc_gradient.png" src="_images/desc_gradient.png" style="width: 480.6px; height: 352.8px;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 28 </span><span class="caption-text">Representación del gradiente negativo el cual conduce a la máxima disminución de la función de coste.</span><a class="headerlink" href="#fig-desc-gradient" title="Link to this image">#</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p>La selección de <span class="math notranslate nohighlight">\(\mu_{i}\)</span> debe ser realizada de tal forma que <code class="docutils literal notranslate"><span class="pre">garantice</span> <span class="pre">convergencia</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">secuencia</span> <span class="pre">de</span> <span class="pre">minimización</span></code>. Nótese que <code class="docutils literal notranslate"><span class="pre">el</span> <span class="pre">algoritmo</span> <span class="pre">puede</span> <span class="pre">oscilar</span> <span class="pre">en</span> <span class="pre">torno</span> <span class="pre">al</span> <span class="pre">mínimo</span> <span class="pre">sin</span> <span class="pre">converger,</span> <span class="pre">si</span> <span class="pre">no</span> <span class="pre">seleccionamos</span> <span class="pre">la</span> <span class="pre">dirección</span> <span class="pre">correcta</span></code>. La selección de <span class="math notranslate nohighlight">\(\mu_{i}\)</span> <code class="docutils literal notranslate"><span class="pre">dependerá</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">convergencia</span> <span class="pre">a</span> <span class="pre">cero</span> <span class="pre">del</span> <span class="pre">error</span> <span class="pre">entre</span></code> <span class="math notranslate nohighlight">\(\boldsymbol{\theta}^{(i)}\)</span> <code class="docutils literal notranslate"><span class="pre">y</span> <span class="pre">el</span> <span class="pre">mínimo</span> <span class="pre">real</span> <span class="pre">en</span> <span class="pre">forma</span> <span class="pre">de</span> <span class="pre">serie</span> <span class="pre">geométrica</span></code>. Por ejemplo, para el caso de la función de coste del error cuadrático medio, la longitud de paso está dada por: <span class="math notranslate nohighlight">\(0&lt;\mu&lt;2/\lambda_{\max}\)</span>, donde <span class="math notranslate nohighlight">\(\lambda_{\max}\)</span> el máximo eigenvalor de la matriz de covarianza <span class="math notranslate nohighlight">\(\Sigma_{x}=\mathbb{E}[\boldsymbol{x}\boldsymbol{x}^{T}]\)</span>, donde <span class="math notranslate nohighlight">\(J(\boldsymbol{\theta})=E[(y-\boldsymbol{\theta}^{T}\boldsymbol{x})^{2}]\)</span> (ver <span id="id1">[<a class="reference internal" href="biblio.html#id17" title="S. Theodoridis. Machine Learning: A Bayesian and Optimization Perspective. Elsevier Science, 2020. ISBN 9780128188040. URL: https://books.google.com.co/books?id=l-nEDwAAQBAJ.">Theodoridis, 2020</a>]</span>).</p></li>
</ul>
</section>
<section id="redes-neuronales">
<h2>Redes neuronales<a class="headerlink" href="#redes-neuronales" title="Link to this heading">#</a></h2>
<div class="admonition-introduccion admonition">
<p class="admonition-title">Introducción</p>
<ul class="simple">
<li><p>Las redes neuronales son <code class="docutils literal notranslate"><span class="pre">sistemas</span> <span class="pre">de</span> <span class="pre">aprendizaje</span> <span class="pre">compuestos</span> <span class="pre">por</span> <span class="pre">neuronas</span> <span class="pre">conectadas</span> <span class="pre">en</span> <span class="pre">capas</span> <span class="pre">que</span> <span class="pre">ajustan</span> <span class="pre">sus</span> <span class="pre">conexiones</span> <span class="pre">para</span> <span class="pre">aprender</span></code>. Tras un período de <code class="docutils literal notranslate"><span class="pre">25</span> <span class="pre">años</span> <span class="pre">desde</span> <span class="pre">su</span> <span class="pre">inicio,</span> <span class="pre">las</span> <span class="pre">redes</span> <span class="pre">neuronales</span> <span class="pre">se</span> <span class="pre">convirtieron</span> <span class="pre">en</span> <span class="pre">la</span> <span class="pre">norma</span> <span class="pre">en</span> <span class="pre">el</span> <span class="pre">aprendizaje</span> <span class="pre">automático</span></code>. En un principio, dominaron durante una década, pero <code class="docutils literal notranslate"><span class="pre">luego</span> <span class="pre">fueron</span> <span class="pre">superadas</span> <span class="pre">por</span> <span class="pre">máquinas</span> <span class="pre">de</span> <span class="pre">vectores</span> <span class="pre">de</span> <span class="pre">soporte</span></code>. Sin embargo, <code class="docutils literal notranslate"><span class="pre">desde</span> <span class="pre">2010,</span> <span class="pre">las</span> <span class="pre">redes</span> <span class="pre">neuronales</span> <span class="pre">profundas</span> <span class="pre">se</span> <span class="pre">han</span> <span class="pre">vuelto</span> <span class="pre">populares</span> <span class="pre">gracias</span> <span class="pre">a</span> <span class="pre">mejoras</span> <span class="pre">en</span> <span class="pre">la</span> <span class="pre">tecnología</span> <span class="pre">y</span> <span class="pre">la</span> <span class="pre">disponibilidad</span> <span class="pre">de</span> <span class="pre">grandes</span> <span class="pre">conjuntos</span> <span class="pre">de</span> <span class="pre">datos</span></code>, impulsando el campo del aprendizaje automático.</p></li>
</ul>
</div>
</section>
<section id="el-perceptron">
<h2>El perceptrón<a class="headerlink" href="#el-perceptron" title="Link to this heading">#</a></h2>
<ul>
<li><p>Nuestro punto de partida será considerar el problema simple de una <code class="docutils literal notranslate"><span class="pre">tarea</span> <span class="pre">de</span> <span class="pre">clasificación</span> <span class="pre">conformada</span> <span class="pre">por</span> <span class="pre">dos</span> <span class="pre">clases</span> <span class="pre">linealmente</span> <span class="pre">separables</span></code>. En otras palabras, dado un conjunto de muestras de entrenamiento, <span class="math notranslate nohighlight">\((y_{n}, \boldsymbol{x}_{n})\)</span>, <span class="math notranslate nohighlight">\(n=1,2,\dots,N\)</span>, con <span class="math notranslate nohighlight">\(y_{n}\in\{-1,+1\},~\boldsymbol{x}_{n}\in\mathbb{R}^{l}\)</span>, suponemos que existe un hiperplano</p>
<div class="math notranslate nohighlight">
\[
    \boldsymbol{\theta}_{\star}^{T}\boldsymbol{x}=0,
    \]</div>
<p>tal que,</p>
<div class="math notranslate nohighlight">
\[\begin{split}
    \begin{cases}
    \boldsymbol{\theta}_{\star}^{T}\boldsymbol{x}&amp;&gt;0,\quad\text{si}\quad\boldsymbol{x}\in\omega_{1}\\
    \boldsymbol{\theta}_{\star}^{T}\boldsymbol{x}&amp;&lt;0,\quad\text{si}\quad\boldsymbol{x}\in\omega_{2}
    \end{cases}
    \end{split}\]</div>
<p>En otras palabras, <code class="docutils literal notranslate"><span class="pre">dicho</span> <span class="pre">hiperplano</span> <span class="pre">clasifica</span> <span class="pre">correctamente</span> <span class="pre">todos</span> <span class="pre">los</span> <span class="pre">puntos</span> <span class="pre">del</span> <span class="pre">conjunto</span> <span class="pre">de</span> <span class="pre">entrenamiento</span></code>. Para simplificar, el <code class="docutils literal notranslate"><span class="pre">término</span> <span class="pre">de</span> <span class="pre">sesgo</span> <span class="pre">del</span> <span class="pre">hiperplano</span> <span class="pre">ha</span> <span class="pre">sido</span> <span class="pre">absorbido</span> <span class="pre">en</span></code> <span class="math notranslate nohighlight">\(\boldsymbol{\theta}_{\star}\)</span> después de extender la dimensionalidad del espacio de entrada en uno. El objetivo ahora es <code class="docutils literal notranslate"><span class="pre">desarrollar</span> <span class="pre">un</span> <span class="pre">algoritmo</span> <span class="pre">que</span> <span class="pre">calcule</span> <span class="pre">iterativamente</span> <span class="pre">un</span> <span class="pre">hiperplano</span> <span class="pre">que</span> <span class="pre">clasifique</span> <span class="pre">correctamente</span> <span class="pre">todos</span> <span class="pre">los</span> <span class="pre">patrones</span> <span class="pre">de</span> <span class="pre">ambas</span> <span class="pre">clases</span></code>. Para ello, se adopta una función de costo.</p>
</li>
</ul>
<ul class="simple">
<li><p>Sea <span class="math notranslate nohighlight">\(\boldsymbol{\theta}\)</span> la <code class="docutils literal notranslate"><span class="pre">estimación</span> <span class="pre">del</span> <span class="pre">vector</span> <span class="pre">de</span> <span class="pre">parámetros</span> <span class="pre">desconocidos,</span> <span class="pre">disponible</span> <span class="pre">en</span> <span class="pre">la</span> <span class="pre">actual</span> <span class="pre">iteración</span></code>. Entonces hay dos posibilidades. La primera es que <code class="docutils literal notranslate"><span class="pre">todos</span> <span class="pre">los</span> <span class="pre">puntos</span> <span class="pre">estén</span> <span class="pre">clasificados</span> <span class="pre">correctamente</span></code>; esto significa que se ha obtenido una solución. La otra alternativa es que <span class="math notranslate nohighlight">\(\boldsymbol{\theta}\)</span> <code class="docutils literal notranslate"><span class="pre">clasifique</span> <span class="pre">correctamente</span> <span class="pre">algunos</span> <span class="pre">de</span> <span class="pre">los</span> <span class="pre">puntos</span></code> y el resto estén mal clasificados.</p></li>
</ul>
<div class="tip admonition">
<p class="admonition-title">Costo perceptrón</p>
<p>Sea <span class="math notranslate nohighlight">\(\mathcal{Y}\)</span> el conjunto de todas las muestras mal clasificadas. La <strong><code class="docutils literal notranslate"><span class="pre">función</span> <span class="pre">de</span> <span class="pre">costo,</span> <span class="pre">perceptrón</span></code></strong> se define como</p>
<div class="math notranslate nohighlight">
\[
J(\boldsymbol{\theta})=-\sum_{n:\boldsymbol{x}_{n}\in\mathcal{Y}}y_{n}\boldsymbol{\theta}^{T}\boldsymbol{x}_{n}:\quad\textit{Costo perceptrón},
\]</div>
<p>donde</p>
<div class="math notranslate nohighlight">
\[\begin{split}
y_{n}=
\begin{cases}
+1,&amp;\quad\text{si}~\boldsymbol{x}\in\omega_{1}\\
-1,&amp;\quad\text{si}~\boldsymbol{x}\in\omega_{2}.
\end{cases}
\end{split}\]</div>
</div>
<ul class="simple">
<li><p>Nótese que la función <code class="docutils literal notranslate"><span class="pre">la</span> <span class="pre">función</span> <span class="pre">de</span> <span class="pre">costo</span> <span class="pre">es</span> <span class="pre">no</span> <span class="pre">negativa</span></code>. En efecto, dado que la suma es sobre los puntos mal clasificados, si <span class="math notranslate nohighlight">\(\boldsymbol{x}_{n}\in\omega_{1}~(\omega_{2}),~\)</span> entonces <span class="math notranslate nohighlight">\(\boldsymbol{\theta}^{T}\boldsymbol{x}_{n}\leq (\geq)~0\)</span>, entregando así un producto <span class="math notranslate nohighlight">\(-y_{n}\boldsymbol{\theta}^{T}\boldsymbol{x}_{n}\geq0\)</span>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">La</span> <span class="pre">función</span> <span class="pre">de</span> <span class="pre">costo</span> <span class="pre">es</span> <span class="pre">cero,</span> <span class="pre">si</span> <span class="pre">no</span> <span class="pre">existen</span> <span class="pre">puntos</span> <span class="pre">mal</span> <span class="pre">clasificados</span></code>, esto es, <span class="math notranslate nohighlight">\(\mathcal{Y}=\emptyset\)</span>. La función de costo perceptrón <code class="docutils literal notranslate"><span class="pre">no</span> <span class="pre">es</span> <span class="pre">diferenciable</span> <span class="pre">en</span> <span class="pre">todos</span> <span class="pre">los</span> <span class="pre">puntos,</span> <span class="pre">es</span> <span class="pre">lineal</span> <span class="pre">por</span> <span class="pre">tramos</span></code>. Si reescribimos <span class="math notranslate nohighlight">\(J(\boldsymbol{\theta})\)</span> en una forma ligeramente diferente:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
J(\boldsymbol{\theta})=\left(-\sum_{n:\boldsymbol{x}_{n}\in\mathcal{Y}}y_{n}\boldsymbol{x}_{n}^{T}\right)\boldsymbol{\theta}.
\]</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Nótese</span> <span class="pre">que</span> <span class="pre">esta</span> <span class="pre">es</span> <span class="pre">una</span> <span class="pre">función</span> <span class="pre">lineal</span> <span class="pre">con</span> <span class="pre">respeto</span> <span class="pre">a</span></code> <span class="math notranslate nohighlight">\(\boldsymbol{\theta}\)</span>, siempre que el conjunto de puntos mal clasificados permanezca igual. Además, <code class="docutils literal notranslate"><span class="pre">nótese</span> <span class="pre">que</span> <span class="pre">ligeros</span> <span class="pre">cambios</span> <span class="pre">del</span> <span class="pre">valor</span></code> <span class="math notranslate nohighlight">\(\boldsymbol{\theta}\)</span> <code class="docutils literal notranslate"><span class="pre">corresponden</span> <span class="pre">a</span> <span class="pre">cambios</span> <span class="pre">de</span> <span class="pre">posición</span> <span class="pre">del</span> <span class="pre">respectivo</span> <span class="pre">hiperplano</span></code>. Como consecuencia, existirá un punto donde el número de muestras mal clasificadas en <span class="math notranslate nohighlight">\(\mathcal{Y}\)</span>, repentinamente cambia; este es el tiempo donde <code class="docutils literal notranslate"><span class="pre">una</span> <span class="pre">muestra</span> <span class="pre">en</span> <span class="pre">el</span> <span class="pre">conjunto</span> <span class="pre">de</span> <span class="pre">entrenamiento</span> <span class="pre">cambia</span> <span class="pre">su</span> <span class="pre">posición</span> <span class="pre">relativa</span> <span class="pre">con</span> <span class="pre">respecto</span> <span class="pre">a</span> <span class="pre">el</span> <span class="pre">hiperplano</span> <span class="pre">en</span> <span class="pre">movimiento</span></code>, y en consecuencia, el conjunto <span class="math notranslate nohighlight">\(\mathcal{Y}\)</span> es modificado. Después de este cambio, el conjunto, <span class="math notranslate nohighlight">\(J(\boldsymbol{\theta})\)</span>, corresponderá a una nueva  función lineal.</p></li>
</ul>
<div class="tip admonition">
<p class="admonition-title">El algoritmo perceptrón</p>
<p>A partir del <code class="docutils literal notranslate"><span class="pre">método</span> <span class="pre">de</span> <span class="pre">subgradientes</span></code> se puede verificar fácilmente que, iniciando desde un punto arbitrario, <span class="math notranslate nohighlight">\(\boldsymbol{\theta}^{(0)}\)</span>, el siguiente método iterativo,</p>
<div class="math notranslate nohighlight">
\[
\boldsymbol{\theta}^{(i)}=\boldsymbol{\theta}^{(i-1)}+\mu_{i}\sum_{n:\boldsymbol{x}_{n}\in\mathcal{Y}}y_{n}\boldsymbol{x}_{n}:\quad\text{Regla perceptrón}, 
\]</div>
<p>converge después de un <em>número finito de pasos</em>. La sucesión de parámetros <span class="math notranslate nohighlight">\(\mu_{i}\)</span> es seleccionada adecuadamente para garantizar convergencia.</p>
</div>
<ul class="simple">
<li><p>Nótese que usando el <code class="docutils literal notranslate"><span class="pre">método</span> <span class="pre">de</span> <span class="pre">subgradiente</span> <span class="pre">(ver</span> <span class="pre">apéndice)</span></code> se tiene que</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\boldsymbol{\theta}^{(i)}&amp;=\boldsymbol{\theta}^{(i-1)}-\mu_{i}J'(\boldsymbol{\theta}^{(i-1)})\\
&amp;=\boldsymbol{\theta}^{(i-1)}-\mu_{i}\left(-\sum_{n:\boldsymbol{x}_{n}\in\mathcal{Y}}y_{n}\boldsymbol{x}_{n}^{T}\right)\\
&amp;=\boldsymbol{\theta}^{(i-1)}+\mu_{i}\sum_{n:\boldsymbol{x}_{n}\in\mathcal{Y}}y_{n}\boldsymbol{x}_{n}.
\end{align*}
\end{split}\]</div>
<ul class="simple">
<li><p>Otra versión del algoritmo considera una <code class="docutils literal notranslate"><span class="pre">muestra</span> <span class="pre">por</span> <span class="pre">iteración</span> <span class="pre">en</span> <span class="pre">un</span> <span class="pre">esquema</span> <span class="pre">cíclico,</span> <span class="pre">hasta</span> <span class="pre">que</span> <span class="pre">el</span> <span class="pre">algoritmo</span> <span class="pre">converge</span></code>. Denotemos por <span class="math notranslate nohighlight">\(y_{(i)}\)</span>, <span class="math notranslate nohighlight">\(\boldsymbol{x}_{i},~i\in\{1,2,\dots,N\}\)</span> los <code class="docutils literal notranslate"><span class="pre">pares</span> <span class="pre">de</span> <span class="pre">entrenamiento</span> <span class="pre">presentados</span> <span class="pre">al</span> <span class="pre">algoritmo</span> <span class="pre">en</span> <span class="pre">la</span> <span class="pre">iteración</span></code> <span class="math notranslate nohighlight">\(i\)</span><code class="docutils literal notranslate"><span class="pre">-ésima</span></code>. Entonces, la iteración de actualización se convierte en:</p></li>
</ul>
<div class="math notranslate nohighlight" id="equation-eq-perceptron-algo2">
<span class="eqno">(51)<a class="headerlink" href="#equation-eq-perceptron-algo2" title="Link to this equation">#</a></span>\[\begin{split}
\boldsymbol{\theta}^{(i)}=
\begin{cases}
\boldsymbol{\theta}^{(i-1)}+\mu_{i}y_{(i)}\boldsymbol{x}_{(i)},&amp;\quad\text{si}\,\boldsymbol{x}_{(i)}\,\text{es mal clasificado por}\,\boldsymbol{\theta}^{(i-1)},\\
\boldsymbol{\theta}^{(i-1)},&amp;\quad\text{otro caso}.
\end{cases}
\end{split}\]</div>
<ul class="simple">
<li><p>Esto es, partiendo de una estimación inicial de forma random, <code class="docutils literal notranslate"><span class="pre">inicializando</span></code> <span class="math notranslate nohighlight">\(\boldsymbol{\theta}^{(0)}\)</span> <code class="docutils literal notranslate"><span class="pre">con</span> <span class="pre">algunos</span> <span class="pre">valores</span> <span class="pre">pequeños,</span> <span class="pre">testeamos</span> <span class="pre">cada</span> <span class="pre">una</span> <span class="pre">de</span> <span class="pre">las</span> <span class="pre">muestras</span></code>, <span class="math notranslate nohighlight">\(\boldsymbol{x}_{n},~n=1,2,\dots,N\)</span>. <code class="docutils literal notranslate"><span class="pre">Cada</span> <span class="pre">vez</span> <span class="pre">que</span> <span class="pre">una</span> <span class="pre">muestra</span> <span class="pre">es</span> <span class="pre">mal</span> <span class="pre">clasificada,</span> <span class="pre">se</span> <span class="pre">toma</span> <span class="pre">acción</span> <span class="pre">por</span> <span class="pre">medio</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">regla</span> <span class="pre">perceptrón</span> <span class="pre">para</span> <span class="pre">una</span> <span class="pre">corrección</span></code>. <code class="docutils literal notranslate"><span class="pre">En</span> <span class="pre">otro</span> <span class="pre">caso,</span> <span class="pre">ninguna</span> <span class="pre">acción</span> <span class="pre">es</span> <span class="pre">requerida</span></code>. Una vez que todas las muestras han sido consideradas, decimos que una <strong><code class="docutils literal notranslate"><span class="pre">época</span> <span class="pre">(epoch)</span></code></strong> ha sido completada. Si no se obtiene convergencia, todas las muestras son reconsideradas en una segunda época, y así sucesivamente. La versión de este algoritmo es conocida como esquema <strong><code class="docutils literal notranslate"><span class="pre">pattern-by-pattern</span></code></strong>. Algunas veces también es referido como el <code class="docutils literal notranslate"><span class="pre">algoritmo</span> <span class="pre">online</span></code>. Nótese que el número total de datos muestrales es fijo, y que el algoritmo las considera en forma cíclica, época por época (<code class="docutils literal notranslate"><span class="pre">epoch-by-epoch</span></code>).</p></li>
<li><p>Después de un número finito de épocas, se garantiza que el algoritmo es convergente. <code class="docutils literal notranslate"><span class="pre">Nótese</span> <span class="pre">que</span> <span class="pre">para</span> <span class="pre">obtener</span> <span class="pre">dicha</span> <span class="pre">convergencia,</span> <span class="pre">la</span> <span class="pre">sucesión</span></code> <span class="math notranslate nohighlight">\(\mu_{i}\)</span> <code class="docutils literal notranslate"><span class="pre">debe</span> <span class="pre">ser</span> <span class="pre">seleccionada</span> <span class="pre">apropiadamente</span></code>. Sin embargo para el caso del <code class="docutils literal notranslate"><span class="pre">algoritmo</span> <span class="pre">perceptrón,</span> <span class="pre">la</span> <span class="pre">convergencia</span> <span class="pre">es</span> <span class="pre">garantizada</span></code> (<span class="math notranslate nohighlight">\(J\)</span> convexa), aún cuando <span class="math notranslate nohighlight">\(\mu_{i}\)</span> es una constante positiva, <span class="math notranslate nohighlight">\(\mu_{i}=\mu&gt;0\)</span>, <code class="docutils literal notranslate"><span class="pre">usualmente</span> <span class="pre">tomado</span> <span class="pre">igual</span> <span class="pre">a</span> <span class="pre">uno</span></code>. La formulación en <a class="reference internal" href="#equation-eq-perceptron-algo2">(51)</a> es conocida también como la filosofía de aprendizaje <strong><code class="docutils literal notranslate"><span class="pre">reward-punishment</span></code></strong>. Si la actual estimación es exitosa en la predicción de la clase del respectivo patron, ninguna acción es tomada (<code class="docutils literal notranslate"><span class="pre">reward</span></code>), en otro caso, el algoritmo es obligado a realizar una actualización (<code class="docutils literal notranslate"><span class="pre">punishment</span></code>).</p></li>
</ul>
<figure class="align-center" id="perceptron-rule">
<img alt="_images/perceptron_rule.png" src="_images/perceptron_rule.png" />
<figcaption>
<p><span class="caption-number">Fig. 29 </span><span class="caption-text">El punto <span class="math notranslate nohighlight">\(x\)</span> está mal clasificado por la línea roja. La regla perceptrón gira el hiperplano hacia el punto <span class="math notranslate nohighlight">\(x\)</span>, para intentar incluirlo en el lado correcto del nuevo hiperplano y clasificarlo correctamente. El nuevo hiperplano está definido por <span class="math notranslate nohighlight">\(θ^{(i)}\)</span> y se muestra con la línea negra.</span><a class="headerlink" href="#perceptron-rule" title="Link to this image">#</a></p>
</figcaption>
</figure>
<ul>
<li><p>La <a class="reference internal" href="#perceptron-rule"><span class="std std-numref">Fig. 29</span></a> ofrece una interpretación geométrica de la <code class="docutils literal notranslate"><span class="pre">regla</span> <span class="pre">del</span> <span class="pre">perceptrón</span></code>. Supongamos que la muestra <span class="math notranslate nohighlight">\(\boldsymbol{x}\)</span> está mal clasificada por el hiperplano, <span class="math notranslate nohighlight">\(\boldsymbol{\theta}^{(i-1)}\)</span>. Como sabemos, por geometría analítica, <span class="math notranslate nohighlight">\(\boldsymbol{\theta}^{(i-1)}\)</span> <code class="docutils literal notranslate"><span class="pre">corresponde</span> <span class="pre">a</span> <span class="pre">un</span> <span class="pre">vector</span> <span class="pre">que</span> <span class="pre">es</span> <span class="pre">perpendicular</span> <span class="pre">al</span> <span class="pre">hiperplano</span> <span class="pre">que</span> <span class="pre">está</span> <span class="pre">definido</span> <span class="pre">por</span> <span class="pre">este</span> <span class="pre">vector</span></code>. Como <span class="math notranslate nohighlight">\(\boldsymbol{x}\)</span> se encuentra en el lado <span class="math notranslate nohighlight">\((-)\)</span> del hiperplano y está mal clasificado, pertenece a la clase <span class="math notranslate nohighlight">\(\omega_{1}\)</span>; asumiendo <span class="math notranslate nohighlight">\(\mu = 1\)</span>, la corrección aplicada por el algoritmo es</p>
<div class="math notranslate nohighlight">
\[\begin{split}
    \\[1mm]
    \boldsymbol{\theta}^{(i)}=\boldsymbol{\theta}^{(i-1)}+\boldsymbol{x},
    \end{split}\]</div>
<p>y su efecto es <code class="docutils literal notranslate"><span class="pre">girar</span> <span class="pre">el</span> <span class="pre">hiperplano</span> <span class="pre">en</span> <span class="pre">dirección</span> <span class="pre">a</span></code> <span class="math notranslate nohighlight">\(\boldsymbol{x}\)</span> para colocarlo en el lado <span class="math notranslate nohighlight">\((+)\)</span> del nuevo hiperplano, que está definido por la estimación actualizada <span class="math notranslate nohighlight">\(\boldsymbol{\theta^{(i)}}\)</span>. El <code class="docutils literal notranslate"><span class="pre">algoritmo</span> <span class="pre">perceptrón</span></code> en su modo de funcionamiento patrón por patrón (<code class="docutils literal notranslate"><span class="pre">pattern-by-pattern</span></code>) se resume en el siguiente algoritmo.</p>
</li>
</ul>
<div class="proof algorithm admonition" id="my_algorithm_pattern_by_pattern">
<p class="admonition-title"><span class="caption-number">Algorithm 2 </span> (Algoritmo perceptrón <em>pattern-by-pattern</em>)</p>
<section class="algorithm-content" id="proof-content">
<p><strong>Inicialización</strong></p>
<ol class="arabic simple">
<li><p>Inicializar <span class="math notranslate nohighlight">\(\boldsymbol{\theta}^{(0)}\)</span>; usualmente, de forma <code class="docutils literal notranslate"><span class="pre">random,</span> <span class="pre">un</span> <span class="pre">número</span> <span class="pre">pequeño</span></code></p></li>
<li><p>Seleccionar <span class="math notranslate nohighlight">\(\mu\)</span>; usualmente <code class="docutils literal notranslate"><span class="pre">establecido</span> <span class="pre">como</span> <span class="pre">uno</span></code></p></li>
<li><p><span class="math notranslate nohighlight">\(i=1\)</span></p></li>
</ol>
<p><strong>Repeat</strong> Cada iteración corresponde a un <code class="docutils literal notranslate"><span class="pre">epoch</span></code></p>
<ol class="arabic">
<li><p><code class="docutils literal notranslate"><span class="pre">counter</span> <span class="pre">=</span> <span class="pre">0</span></code>; Contador del número de actualizaciones por <code class="docutils literal notranslate"><span class="pre">epoch</span></code></p></li>
<li><p><strong>For</strong> <span class="math notranslate nohighlight">\(n=1,2,\dots,N\)</span> <strong>Do</strong> Para cada <code class="docutils literal notranslate"><span class="pre">epoch</span></code>, todas las muestras son presentadas una vez</p>
<p><strong>If</strong>(<span class="math notranslate nohighlight">\(y_{n}\boldsymbol{x}_{n}^{T}\leq0\)</span>) <strong>Then</strong></p>
<ol class="arabic simple">
<li><p><span class="math notranslate nohighlight">\(\boldsymbol{\theta}^{(i)}=\boldsymbol{\theta}^{(i-1)}+\mu y_{n}\boldsymbol{x}_{n}\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(i=i+1\)</span></p></li>
<li><p>counter = counter + 1</p></li>
</ol>
<p><strong>End For</strong></p>
</li>
<li><p><strong>Until</strong> counter = 0</p></li>
</ol>
</section>
</div><ul class="simple">
<li><p>Una vez que el <code class="docutils literal notranslate"><span class="pre">algoritmo</span> <span class="pre">perceptrón</span> <span class="pre">se</span> <span class="pre">ha</span> <span class="pre">ejecutado</span> <span class="pre">y</span> <span class="pre">converge</span></code>, tenemos los <code class="docutils literal notranslate"><span class="pre">pesos</span></code>, <span class="math notranslate nohighlight">\(\theta_{i},~i = 1,2,\dots,l\)</span>, <code class="docutils literal notranslate"><span class="pre">de</span> <span class="pre">las</span> <span class="pre">sinapsis</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">neurona/perceptrón</span></code> asociada, así como el término de sesgo <span class="math notranslate nohighlight">\(\theta_{0}\)</span>. Ahora se pueden <code class="docutils literal notranslate"><span class="pre">utilizar</span> <span class="pre">para</span> <span class="pre">clasificar</span> <span class="pre">patrones</span> <span class="pre">desconocidos</span></code>. Las características <span class="math notranslate nohighlight">\(x_{i}, i = 1, 2,\dots,l\)</span>, se aplican a los nodos de entrada. A su vez, <code class="docutils literal notranslate"><span class="pre">cada</span> <span class="pre">característica</span> <span class="pre">se</span> <span class="pre">multiplica</span> <span class="pre">por</span> <span class="pre">la</span> <span class="pre">sinapsis</span> <span class="pre">respectiva</span> <span class="pre">(peso),</span> <span class="pre">y</span> <span class="pre">luego</span> <span class="pre">se</span> <span class="pre">añade</span> <span class="pre">el</span> <span class="pre">término</span> <span class="pre">de</span> <span class="pre">sesgo</span> <span class="pre">en</span> <span class="pre">su</span> <span class="pre">combinación</span> <span class="pre">lineal</span></code>. El resultado de esta operación <code class="docutils literal notranslate"><span class="pre">pasa</span> <span class="pre">por</span> <span class="pre">una</span> <span class="pre">función</span> <span class="pre">no</span> <span class="pre">lineal</span></code>, <span class="math notranslate nohighlight">\(f\)</span>, conocida como <code class="docutils literal notranslate"><span class="pre">función</span> <span class="pre">de</span> <span class="pre">activación</span></code> (ver <a class="reference external" href="https://en.wikipedia.org/wiki/Activation_function">Activation function</a>). Dependiendo de la forma de la no linealidad, se producen diferentes tipos de neuronas. La mas clásica conocida como <code class="docutils literal notranslate"><span class="pre">neurona</span> <span class="pre">McCulloch-Pitts</span></code>, la función de <code class="docutils literal notranslate"><span class="pre">activación</span> <span class="pre">es</span> <span class="pre">la</span> <span class="pre">de</span> <span class="pre">Heaviside</span></code>, es decir,</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}
f(z)=
\begin{cases}
1,&amp;\quad\text{si}~z&gt;0,\\
0,&amp;\quad\text{si}~z\leq0.
\end{cases}
\end{split}\]</div>
<figure class="align-center" id="mcculloch-pitts">
<a class="reference internal image-reference" href="_images/mcculloch_pitts.png"><img alt="_images/mcculloch_pitts.png" src="_images/mcculloch_pitts.png" style="width: 532.0px; height: 167.20000000000002px;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 30 </span><span class="caption-text">Arquitectura básica de neuronas/perceptrones.</span><a class="headerlink" href="#mcculloch-pitts" title="Link to this image">#</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p>En la arquitectura básica de neuronas/perceptrones, las <code class="docutils literal notranslate"><span class="pre">características</span> <span class="pre">de</span> <span class="pre">entrada</span> <span class="pre">se</span> <span class="pre">aplican</span> <span class="pre">a</span> <span class="pre">los</span> <span class="pre">nodos</span> <span class="pre">de</span> <span class="pre">entrada</span> <span class="pre">y</span> <span class="pre">se</span> <span class="pre">ponderan</span> <span class="pre">por</span> <span class="pre">los</span> <span class="pre">respectivos</span> <span class="pre">pesos</span> <span class="pre">que</span> <span class="pre">definen</span> <span class="pre">las</span> <span class="pre">sinapsis</span></code>. A continuación <code class="docutils literal notranslate"><span class="pre">se</span> <span class="pre">añade</span> <span class="pre">el</span> <span class="pre">término</span> <span class="pre">de</span> <span class="pre">sesgo</span> <span class="pre">en</span> <span class="pre">su</span> <span class="pre">combinación</span> <span class="pre">lineal</span> <span class="pre">y</span> <span class="pre">el</span> <span class="pre">resultado</span> <span class="pre">es</span> <span class="pre">empujado</span> <span class="pre">a</span> <span class="pre">través</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">no</span> <span class="pre">linealidad</span></code>. En la neurona <code class="docutils literal notranslate"><span class="pre">McCulloch-Pitts</span></code>, la salida es 1 para los patrones de la clase <span class="math notranslate nohighlight">\(\omega_{1}\)</span> o 0 para la clase <span class="math notranslate nohighlight">\(\omega_{2}\)</span>. La suma y la operación no lineal se unen para simplificar el gráfico.</p></li>
</ul>
<figure class="align-center" id="hidden-layer-activationf-function-fig">
<a class="reference internal image-reference" href="_images/hidden_layer_activationf_function.png"><img alt="_images/hidden_layer_activationf_function.png" src="_images/hidden_layer_activationf_function.png" style="width: 508.9px; height: 256.2px;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 31 </span><span class="caption-text">Selección de función de activación para <code class="docutils literal notranslate"><span class="pre">hidden</span> <span class="pre">layers</span></code>. (Fuente <span id="id2">[<a class="reference internal" href="biblio.html#id56" title="J. Brownlee and Machine Learning Mastery. Deep Learning with Python: Develop Deep Learning Models on Theano and TensorFlow Using Keras. Machine Learning Mastery, 2017. URL: https://books.google.com.co/books?id=eJw2nQAACAAJ.">Brownlee and Mastery, 2017</a>]</span>).</span><a class="headerlink" href="#hidden-layer-activationf-function-fig" title="Link to this image">#</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p>Para las capas ocultas, la función de <code class="docutils literal notranslate"><span class="pre">activación</span> <span class="pre">tangente</span> <span class="pre">hiperbólica</span> <span class="pre">suele</span> <span class="pre">funcionar</span> <span class="pre">mejor</span> <span class="pre">que</span> <span class="pre">la</span> <span class="pre">sigmoidea</span> <span class="pre">logística</span></code>. Tanto la función <code class="docutils literal notranslate"><span class="pre">sigmoid</span></code> como <code class="docutils literal notranslate"><span class="pre">tanh</span></code> pueden hacer que el modelo sea más <code class="docutils literal notranslate"><span class="pre">susceptible</span> <span class="pre">a</span> <span class="pre">los</span> <span class="pre">problemas</span> <span class="pre">durante</span> <span class="pre">el</span> <span class="pre">entrenamiento,</span> <span class="pre">a</span> <span class="pre">través</span> <span class="pre">del</span> <span class="pre">llamado</span> <span class="pre">problema</span> <span class="pre">de</span> <span class="pre">los</span> <span class="pre">gradientes</span> <span class="pre">desvanecientes</span></code>. Los modelos modernos de redes neuronales con arquitecturas comunes, como <code class="docutils literal notranslate"><span class="pre">MLP</span> <span class="pre">y</span> <span class="pre">CNN,</span> <span class="pre">harán</span> <span class="pre">uso</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">función</span> <span class="pre">de</span> <span class="pre">activación</span> <span class="pre">ReLU</span></code>, o extensiones.</p></li>
<li><p>Las <code class="docutils literal notranslate"><span class="pre">redes</span> <span class="pre">recurrentes</span> <span class="pre">recurrentes</span></code> suelen utilizar funciones de activación <code class="docutils literal notranslate"><span class="pre">tanh</span></code> o <code class="docutils literal notranslate"><span class="pre">sigmoid</span></code>, o incluso ambas. Por ejemplo, la <code class="docutils literal notranslate"><span class="pre">LSTM</span> <span class="pre">suele</span> <span class="pre">utilizar</span> <span class="pre">la</span> <span class="pre">activación</span> <span class="pre">sigmoid</span> <span class="pre">para</span> <span class="pre">las</span> <span class="pre">conexiones</span> <span class="pre">recurrentes</span> <span class="pre">y</span> <span class="pre">la</span> <span class="pre">activación</span> <span class="pre">tanh</span> <span class="pre">para</span> <span class="pre">la</span> <span class="pre">salida</span></code>.</p></li>
</ul>
<figure class="align-center" id="output-layer-activation-function">
<a class="reference internal image-reference" href="_images/output_layer_activation_function.png"><img alt="_images/output_layer_activation_function.png" src="_images/output_layer_activation_function.png" style="width: 485.79999999999995px; height: 301.7px;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 32 </span><span class="caption-text">Selección de función de activación para <code class="docutils literal notranslate"><span class="pre">hidden</span> <span class="pre">layers</span></code>. (Fuente <span id="id3">[<a class="reference internal" href="biblio.html#id56" title="J. Brownlee and Machine Learning Mastery. Deep Learning with Python: Develop Deep Learning Models on Theano and TensorFlow Using Keras. Machine Learning Mastery, 2017. URL: https://books.google.com.co/books?id=eJw2nQAACAAJ.">Brownlee and Mastery, 2017</a>]</span>).</span><a class="headerlink" href="#output-layer-activation-function" title="Link to this image">#</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p>Si su problema es de <code class="docutils literal notranslate"><span class="pre">regresión,</span> <span class="pre">debe</span> <span class="pre">utilizar</span> <span class="pre">una</span> <span class="pre">función</span> <span class="pre">de</span> <span class="pre">activación</span> <span class="pre">lineal</span></code>. Si su problema es de <code class="docutils literal notranslate"><span class="pre">clasificación</span></code>, el modelo predice la probabilidad de pertenencia a una clase, que se puede convertir en una <code class="docutils literal notranslate"><span class="pre">etiqueta</span> <span class="pre">de</span> <span class="pre">clase</span> <span class="pre">mediante</span> <span class="pre">redondeo</span> <span class="pre">(para</span> <span class="pre">sigmoid)</span></code> o <code class="docutils literal notranslate"><span class="pre">argmax</span> <span class="pre">(para</span> <span class="pre">softmax)</span></code>.</p></li>
</ul>
</section>
<section id="redes-neuronales-multicapa-feed-forward">
<h2>Redes Neuronales Multicapa Feed-Forward<a class="headerlink" href="#redes-neuronales-multicapa-feed-forward" title="Link to this heading">#</a></h2>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">Una</span> <span class="pre">sola</span> <span class="pre">neurona</span> <span class="pre">está</span> <span class="pre">asociada</span> <span class="pre">a</span> <span class="pre">un</span> <span class="pre">hiperplano</span></code></p>
<div class="math notranslate nohighlight">
\[\begin{split}
    \\[1mm]
    H: \theta_{1}x_{1}+\theta_{2}x_{2}+\cdots+\theta_{l}x_{l}+\theta_{0}=0,
    \end{split}\]</div>
<p>en el espacio de entrada, y la <code class="docutils literal notranslate"><span class="pre">clasificación</span> <span class="pre">se</span> <span class="pre">basa</span> <span class="pre">en</span> <span class="pre">una</span> <span class="pre">función</span> <span class="pre">no</span> <span class="pre">lineal</span></code> que produce un resultado de uno o cero según en qué lado del hiperplano <span class="math notranslate nohighlight">\(H\)</span> se encuentre un punto. A continuación, se mostrará cómo <code class="docutils literal notranslate"><span class="pre">combinar</span> <span class="pre">varias</span> <span class="pre">neuronas</span> <span class="pre">en</span> <span class="pre">capas</span> <span class="pre">para</span> <span class="pre">crear</span> <span class="pre">clasificadores</span> <span class="pre">no</span> <span class="pre">lineales</span></code>. Seguiremos un enfoque constructivo simple que será útil al abordar aspectos de las redes neuronales, especialmente en el contexto de arquitecturas profundas de aprendizaje profundo (<code class="docutils literal notranslate"><span class="pre">deep</span> <span class="pre">learning</span></code>).</p>
</li>
</ul>
<ul class="simple">
<li><p>Como punto de partida, consideramos el caso en el que las <code class="docutils literal notranslate"><span class="pre">clases</span> <span class="pre">del</span> <span class="pre">espacio</span> <span class="pre">de</span> <span class="pre">características</span> <span class="pre">están</span> <span class="pre">formadas</span> <span class="pre">por</span> <span class="pre">uniones</span> <span class="pre">de</span> <span class="pre">regiones</span> <span class="pre">poliédricas</span></code></p></li>
</ul>
<figure class="align-center" id="regiones-poliedricas">
<a class="reference internal image-reference" href="_images/regiones_poliedricas.png"><img alt="_images/regiones_poliedricas.png" src="_images/regiones_poliedricas.png" style="width: 452.9px; height: 290.5px;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 33 </span><span class="caption-text">Clases formadas por uniones de regiones poliédricas. Las regiones se etiquetan según el lado en el que se encuentran, con respecto a las tres líneas, <span class="math notranslate nohighlight">\(H_{1}, H_{2}\)</span> y <span class="math notranslate nohighlight">\(H_{3}\)</span>.</span><a class="headerlink" href="#regiones-poliedricas" title="Link to this image">#</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p>Las regiones poliédricas se forman como <code class="docutils literal notranslate"><span class="pre">intersecciones</span> <span class="pre">de</span> <span class="pre">semiespacios,</span> <span class="pre">cada</span> <span class="pre">uno</span> <span class="pre">de</span> <span class="pre">ellos</span> <span class="pre">asociado</span> <span class="pre">a</span> <span class="pre">un</span> <span class="pre">hiperplano</span></code>. En la <a class="reference internal" href="#regiones-poliedricas"><span class="std std-numref">Fig. 33</span></a>, hay tres hiperplanos (líneas rectas en <span class="math notranslate nohighlight">\(\mathbb{R}^2\)</span>), indicados como <span class="math notranslate nohighlight">\(H_{1}, H_{2}, H_{3}\)</span>, que dan lugar a siete regiones poliédricas. Para cada hiperplano se indican los lados <span class="math notranslate nohighlight">\((+)\)</span> y <span class="math notranslate nohighlight">\((-)\)</span> (semiespacios). Cada una de las regiones se <code class="docutils literal notranslate"><span class="pre">etiqueta</span> <span class="pre">con</span> <span class="pre">un</span> <span class="pre">triplete</span> <span class="pre">de</span> <span class="pre">números</span> <span class="pre">binarios</span></code>, según el lado que se encuentra con respecto a <span class="math notranslate nohighlight">\(H_{1}, H_{2}, H_{3}\)</span>. Por ejemplo, la región etiquetada como <span class="math notranslate nohighlight">\((101)\)</span> se encuentra en el lado <span class="math notranslate nohighlight">\((+)\)</span> de <span class="math notranslate nohighlight">\(H_{1}\)</span>, el lado <span class="math notranslate nohighlight">\((-)\)</span> de <span class="math notranslate nohighlight">\(H_{2}\)</span> y el lado <span class="math notranslate nohighlight">\((+)\)</span> de <span class="math notranslate nohighlight">\(H_{3}\)</span>.</p></li>
</ul>
<figure class="align-center" id="poliedros-neurons">
<a class="reference internal image-reference" href="_images/poliedros_neurons.png"><img alt="_images/poliedros_neurons.png" src="_images/poliedros_neurons.png" style="width: 613.9px; height: 301.0px;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 34 </span><span class="caption-text">(A) Las neuronas de la primera capa oculta son activadas por los valores de las características aplicadas en los nodos de entrada y forman las regiones poliédricas. (B) Las neuronas de la segunda capa tienen como entradas las salidas de la primera capa, y así
forman las clases.</span><a class="headerlink" href="#poliedros-neurons" title="Link to this image">#</a></p>
</figcaption>
</figure>
<p>La <a class="reference internal" href="#poliedros-neurons"><span class="std std-numref">Fig. 34</span></a> muestra tres neuronas, correspondientes a los tres hiperplanos, <span class="math notranslate nohighlight">\(H_{1}, H_{2}\)</span> y <span class="math notranslate nohighlight">\(H_{3}\)</span>, de la <a class="reference internal" href="#regiones-poliedricas"><span class="std std-numref">Fig. 33</span></a>, respectivamente. Las salidas asociadas, denotadas como <span class="math notranslate nohighlight">\(y_{1}, y_{2}\)</span>, y <span class="math notranslate nohighlight">\(y_{3}\)</span>, forman la <code class="docutils literal notranslate"><span class="pre">etiqueta</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">región</span> <span class="pre">a</span> <span class="pre">la</span> <span class="pre">que</span> <span class="pre">el</span> <span class="pre">patrón</span> <span class="pre">de</span> <span class="pre">entrada</span> <span class="pre">correspondiente</span> <span class="pre">pertenece</span></code>. De hecho, si los pesos de las sinapsis se han fijado adecuadamente, entonces, si un patrón se origina en la región, digamos, <span class="math notranslate nohighlight">\((010)\)</span>, la primera neurona de la izquierda asigna un cero <span class="math notranslate nohighlight">\((y_{1} = 0)\)</span>, la del medio un uno <span class="math notranslate nohighlight">\((y_{2} = 1)\)</span>, y la de la derecha un cero <span class="math notranslate nohighlight">\((y_{3} = 0)\)</span>. En otras palabras, <code class="docutils literal notranslate"><span class="pre">combinando</span> <span class="pre">las</span> <span class="pre">tres</span> <span class="pre">neuronas,</span> <span class="pre">hemos</span> <span class="pre">logrado</span> <span class="pre">un</span> <span class="pre">mapeo</span> <span class="pre">del</span> <span class="pre">espacio</span> <span class="pre">de</span> <span class="pre">características</span> <span class="pre">de</span> <span class="pre">entrada</span> <span class="pre">en</span> <span class="pre">el</span> <span class="pre">espacio</span> <span class="pre">tridimensional</span></code>. Más concretamente, el <code class="docutils literal notranslate"><span class="pre">mapeo</span> <span class="pre">se</span> <span class="pre">realiza</span> <span class="pre">en</span> <span class="pre">los</span> <span class="pre">vértices</span> <span class="pre">del</span> <span class="pre">cubo</span> <span class="pre">unitario</span></code> en <span class="math notranslate nohighlight">\(\mathbb{R}^{3}\)</span>, como se muestra en la <a class="reference internal" href="#mapping-input-feature"><span class="std std-numref">Fig. 35</span></a></p>
<figure class="align-center" id="mapping-input-feature">
<a class="reference internal image-reference" href="_images/mapping_input_feature.png"><img alt="_images/mapping_input_feature.png" src="_images/mapping_input_feature.png" style="width: 449.4px; height: 411.59999999999997px;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 35 </span><span class="caption-text">Las neuronas de la primera capa oculta realizan un mapeo del espacio de características de entrada a los vértices de un hipercubo unitario. El vértice 110, denotado como un círculo sin sombrear, no corresponde a ninguna región.</span><a class="headerlink" href="#mapping-input-feature" title="Link to this image">#</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p>Ahora utilizaremos esta nueva <code class="docutils literal notranslate"><span class="pre">representación,</span> <span class="pre">proporcionada</span> <span class="pre">por</span> <span class="pre">las</span> <span class="pre">salidas</span> <span class="pre">de</span> <span class="pre">las</span> <span class="pre">neuronas</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">primera</span> <span class="pre">capa</span> <span class="pre">oculta</span></code>, como entrada que alimenta las neuronas de una segunda capa oculta, la cual se construye de la siguiente forma. Elegimos todas las <code class="docutils literal notranslate"><span class="pre">regiones</span> <span class="pre">que</span> <span class="pre">pertenecen</span> <span class="pre">a</span> <span class="pre">una</span> <span class="pre">clase</span></code>. Para nuestro ejemplo de la <a class="reference internal" href="#regiones-poliedricas"><span class="std std-numref">Fig. 33</span></a>, seleccionamos las dos regiones que corresponden a la clase <span class="math notranslate nohighlight">\(\omega_{1}\)</span>, es decir, <span class="math notranslate nohighlight">\((000)\)</span> y <span class="math notranslate nohighlight">\((111)\)</span>. Recordemos que todos los <code class="docutils literal notranslate"><span class="pre">puntos</span> <span class="pre">de</span> <span class="pre">estas</span> <span class="pre">regiones</span> <span class="pre">se</span> <span class="pre">mapean</span> <span class="pre">a</span> <span class="pre">los</span> <span class="pre">respectivos</span> <span class="pre">vértices</span> <span class="pre">del</span> <span class="pre">cubo</span> <span class="pre">unitario</span></code> en la <span class="math notranslate nohighlight">\(\mathbb{R}^{3}\)</span>. Sin embargo, en este nuevo espacio transformado, <code class="docutils literal notranslate"><span class="pre">cada</span> <span class="pre">uno</span> <span class="pre">de</span> <span class="pre">los</span> <span class="pre">vértices</span> <span class="pre">es</span> <span class="pre">linealmente</span> <span class="pre">separable</span> <span class="pre">del</span> <span class="pre">resto</span></code>.</p></li>
</ul>
<ul class="simple">
<li><p>Observe que <code class="docutils literal notranslate"><span class="pre">la</span> <span class="pre">salida</span></code> <span class="math notranslate nohighlight">\(z_{1}\)</span> <code class="docutils literal notranslate"><span class="pre">de</span> <span class="pre">la</span> <span class="pre">neurona</span> <span class="pre">izquierda</span> <span class="pre">arroja</span> <span class="pre">un</span> <span class="pre">1</span> <span class="pre">sólo</span> <span class="pre">si</span> <span class="pre">el</span> <span class="pre">patrón</span> <span class="pre">de</span> <span class="pre">entrada</span> <span class="pre">se</span> <span class="pre">origina</span> <span class="pre">en</span> <span class="pre">la</span> <span class="pre">región</span></code> <span class="math notranslate nohighlight">\(000\)</span> y <code class="docutils literal notranslate"><span class="pre">0</span> <span class="pre">para</span> <span class="pre">todos</span> <span class="pre">los</span> <span class="pre">demás</span> <span class="pre">patrones</span></code>. Para la neurona de la derecha, la salida <span class="math notranslate nohighlight">\(z_{2}\)</span> será 1 para todos los patrones procedentes de la región <span class="math notranslate nohighlight">\((111)\)</span> y cero para el resto (ver <a class="reference internal" href="#mapping-input-feature"><span class="std std-numref">Fig. 35</span></a>). Nótese que <code class="docutils literal notranslate"><span class="pre">esta</span> <span class="pre">segunda</span> <span class="pre">capa</span> <span class="pre">de</span> <span class="pre">neuronas</span> <span class="pre">ha</span> <span class="pre">realizado</span> <span class="pre">un</span> <span class="pre">segundo</span> <span class="pre">mapeo</span></code>, esta vez a los vértices del rectángulo unitario en <span class="math notranslate nohighlight">\(\mathbb{R}^{2}\)</span>.</p></li>
</ul>
<figure class="align-center" id="map-layer-intor2">
<a class="reference internal image-reference" href="_images/map_layer_intor2.png"><img alt="_images/map_layer_intor2.png" src="_images/map_layer_intor2.png" style="width: 507.20000000000005px; height: 364.0px;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 36 </span><span class="caption-text">Los patrones de la clase <span class="math notranslate nohighlight">\(\omega_{1}\)</span> <code class="docutils literal notranslate"><span class="pre">se</span> <span class="pre">asignan</span> <span class="pre">a</span> <span class="pre">(01)</span> <span class="pre">o</span> <span class="pre">a</span> <span class="pre">(10)</span></code> y los patrones de la clase <span class="math notranslate nohighlight">\(\omega_{2}\)</span> <code class="docutils literal notranslate"><span class="pre">se</span> <span class="pre">asignan</span> <span class="pre">a</span> <span class="pre">(00)</span></code>. Clases ahora linealmente separables a través de una línea recta realizada por una neurona.</span><a class="headerlink" href="#map-layer-intor2" title="Link to this image">#</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p>Este mapeo proporciona una <code class="docutils literal notranslate"><span class="pre">nueva</span> <span class="pre">representación</span> <span class="pre">de</span> <span class="pre">los</span> <span class="pre">patrones</span> <span class="pre">de</span> <span class="pre">entrada</span></code>, y esta representación <code class="docutils literal notranslate"><span class="pre">codifica</span> <span class="pre">la</span> <span class="pre">información</span> <span class="pre">relacionada</span> <span class="pre">con</span> <span class="pre">las</span> <span class="pre">clases</span> <span class="pre">de</span> <span class="pre">las</span> <span class="pre">regiones</span></code>. La <a class="reference internal" href="#map-layer-intor2"><span class="std std-numref">Fig. 36</span></a> muestra el mapeo a los vértices del rectángulo unitario en el espacio <span class="math notranslate nohighlight">\((z_{1}, z_{2})\)</span>. Nótese que todos los puntos procedentes de la clase <span class="math notranslate nohighlight">\(\omega_{2}\)</span> están mapeados a <span class="math notranslate nohighlight">\((00)\)</span> y los puntos de la clase <span class="math notranslate nohighlight">\(\omega_{1}\)</span> están asignados a <span class="math notranslate nohighlight">\((10)\)</span> o a <span class="math notranslate nohighlight">\((01)\)</span>. Esto es, <code class="docutils literal notranslate"><span class="pre">mediante</span> <span class="pre">mapeos</span> <span class="pre">sucesivos,</span> <span class="pre">hemos</span> <span class="pre">transformado</span> <span class="pre">nuestra</span> <span class="pre">tarea,</span> <span class="pre">originalmente,</span> <span class="pre">linealmente</span> <span class="pre">no</span> <span class="pre">separable</span> <span class="pre">a</span> <span class="pre">una</span> <span class="pre">que</span> <span class="pre">es</span> <span class="pre">linealmente</span> <span class="pre">separable</span></code>. En efecto, el punto <span class="math notranslate nohighlight">\((00)\)</span> puede separarse linealmente de <span class="math notranslate nohighlight">\((01)\)</span> y <span class="math notranslate nohighlight">\((10)\)</span>, y esto puede realizarse mediante una neurona adicional que opera en el espacio <span class="math notranslate nohighlight">\((z_{1}, z_{2})\)</span>; la cual se conoce como la neurona de salida, porque proporciona la decisión final de clasificación.</p></li>
</ul>
<figure class="align-center" id="final-neural-network-fig">
<a class="reference internal image-reference" href="_images/final_neural_network.png"><img alt="_images/final_neural_network.png" src="_images/final_neural_network.png" style="width: 317.79999999999995px; height: 376.59999999999997px;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 37 </span><span class="caption-text">Red neuronal feed-forward de tres capas. Comprende la capa de entrada (no de procesamiento), dos capas ocultas y una capa de salida de neuronas</span><a class="headerlink" href="#final-neural-network-fig" title="Link to this image">#</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p>La red final resultante se muestra en la <a class="reference internal" href="#final-neural-network-fig"><span class="std std-numref">Fig. 37</span></a>. Llamamos a esta red <code class="docutils literal notranslate"><span class="pre">feed-forward</span></code>, porque la <code class="docutils literal notranslate"><span class="pre">información</span> <span class="pre">fluye</span> <span class="pre">hacia</span> <span class="pre">adelante</span> <span class="pre">desde</span> <span class="pre">la</span> <span class="pre">capa</span> <span class="pre">de</span> <span class="pre">entrada</span> <span class="pre">a</span> <span class="pre">la</span> <span class="pre">de</span> <span class="pre">salida</span></code>. Se compone de la <code class="docutils literal notranslate"><span class="pre">capa</span> <span class="pre">de</span> <span class="pre">entrada,</span> <span class="pre">que</span> <span class="pre">es</span> <span class="pre">una</span> <span class="pre">capa</span> <span class="pre">no</span> <span class="pre">procesadora</span></code>, <code class="docutils literal notranslate"><span class="pre">dos</span> <span class="pre">capas</span> <span class="pre">ocultas</span></code>, y <code class="docutils literal notranslate"><span class="pre">una</span> <span class="pre">capa</span> <span class="pre">de</span> <span class="pre">salida</span></code>. Llamamos a esta red neuronal, <strong><code class="docutils literal notranslate"><span class="pre">red</span> <span class="pre">de</span> <span class="pre">tres</span> <span class="pre">capas</span></code></strong>, sin contar la capa de entrada de nodos no procesadores. Esta red neuronal de tres capas puede resolver cualquier tarea de clasificación, en la que las clases están formadas por uniones de regiones poliédricas.</p></li>
</ul>
<ul class="simple">
<li><p>Considerando esta estructura de la <code class="docutils literal notranslate"><span class="pre">red</span> <span class="pre">multicapa</span></code>. Nuestro interés ahora se centrará en <code class="docutils literal notranslate"><span class="pre">buscar</span> <span class="pre">formas</span> <span class="pre">de</span> <span class="pre">estimar</span> <span class="pre">los</span> <span class="pre">pesos</span> <span class="pre">desconocidos</span> <span class="pre">de</span> <span class="pre">las</span> <span class="pre">sinapsis</span> <span class="pre">y</span> <span class="pre">los</span> <span class="pre">sesgos</span> <span class="pre">de</span> <span class="pre">las</span> <span class="pre">neuronas</span></code>. Sin embargo, desde un punto de vista conceptual, debemos <code class="docutils literal notranslate"><span class="pre">recordar</span> <span class="pre">que</span> <span class="pre">cada</span> <span class="pre">capa</span> <span class="pre">realiza</span> <span class="pre">un</span> <span class="pre">mapeo</span> <span class="pre">en</span> <span class="pre">un</span> <span class="pre">nuevo</span> <span class="pre">espacio,</span> <span class="pre">y</span> <span class="pre">cada</span> <span class="pre">mapeo</span> <span class="pre">proporciona</span> <span class="pre">una</span> <span class="pre">representación</span> <span class="pre">diferente</span></code> de los datos de entrada, hasta la última capa, donde la tarea se ha transformado en una que es fácil de resolver.</p></li>
</ul>
</section>
<section id="redes-totalmente-conectadas">
<h2>Redes Totalmente Conectadas<a class="headerlink" href="#redes-totalmente-conectadas" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Para resumir de manera más formal el tipo de <code class="docutils literal notranslate"><span class="pre">operaciones</span> <span class="pre">que</span> <span class="pre">tienen</span> <span class="pre">lugar</span> <span class="pre">en</span> <span class="pre">una</span> <span class="pre">red</span> <span class="pre">totalmente</span> <span class="pre">conectada</span></code>, centrémonos en, por ejemplo, la <code class="docutils literal notranslate"><span class="pre">capa</span></code> <span class="math notranslate nohighlight">\(r\)</span> <code class="docutils literal notranslate"><span class="pre">de</span> <span class="pre">una</span> <span class="pre">red</span> <span class="pre">neuronal</span> <span class="pre">multicapa</span> <span class="pre">y</span> <span class="pre">supongamos</span> <span class="pre">que</span> <span class="pre">está</span> <span class="pre">formada</span> <span class="pre">por</span></code> <span class="math notranslate nohighlight">\(k_{r}\)</span> <code class="docutils literal notranslate"><span class="pre">neuronas</span></code>. El vector de <code class="docutils literal notranslate"><span class="pre">entrada</span> <span class="pre">a</span> <span class="pre">esta</span> <span class="pre">capa</span> <span class="pre">está</span> <span class="pre">formado</span> <span class="pre">por</span> <span class="pre">las</span> <span class="pre">salidas</span> <span class="pre">de</span> <span class="pre">los</span> <span class="pre">nodos</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">capa</span> <span class="pre">anterior,</span> <span class="pre">que</span> <span class="pre">se</span> <span class="pre">denomina</span></code> <span class="math notranslate nohighlight">\(\boldsymbol{y}^{r-1}\)</span>. Sea <span class="math notranslate nohighlight">\(\boldsymbol{\theta}_{j}^{r}\)</span> el vector de los <code class="docutils literal notranslate"><span class="pre">pesos</span> <span class="pre">sinápticos,</span> <span class="pre">incluido</span> <span class="pre">el</span> <span class="pre">término</span> <span class="pre">de</span> <span class="pre">sesgo,</span> <span class="pre">asociado</span> <span class="pre">a</span> <span class="pre">la</span> <span class="pre">neurona</span></code> <span class="math notranslate nohighlight">\(j\)</span> <code class="docutils literal notranslate"><span class="pre">de</span> <span class="pre">la</span> <span class="pre">capa</span></code> <span class="math notranslate nohighlight">\(r\)</span>, donde <span class="math notranslate nohighlight">\(j = 1,2,\dots, k_{r}\)</span>. La <code class="docutils literal notranslate"><span class="pre">dimensión</span> <span class="pre">respectiva</span></code> de este vector es <span class="math notranslate nohighlight">\(k_{r-1} + 1\)</span>, donde <span class="math notranslate nohighlight">\(k_{r-1}\)</span> es el <code class="docutils literal notranslate"><span class="pre">número</span> <span class="pre">de</span> <span class="pre">neuronas</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">capa</span> <span class="pre">anterior</span></code>, <span class="math notranslate nohighlight">\(r-1\)</span>, <code class="docutils literal notranslate"><span class="pre">y</span> <span class="pre">el</span> <span class="pre">aumento</span> <span class="pre">en</span> <span class="pre">1</span> <span class="pre">representa</span> <span class="pre">el</span> <span class="pre">término</span> <span class="pre">de</span> <span class="pre">sesgo</span></code>. Entonces las operaciones realizadas, antes de la no linealidad, son los productos internos</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
z_{j}^{r}=\boldsymbol{\theta}_{j}^{rT}\boldsymbol{y}^{r-1},\quad j=1,2,\dots,k_{r}.
\]</div>
<ul class="simple">
<li><p>Colocando todos los valores de salida en un vector <span class="math notranslate nohighlight">\(\boldsymbol{z}^{r}=[z_{1}^{r}, z_{2}^{r},\dots,z_{k_{r}}^{r}]^{T}\)</span>, y <code class="docutils literal notranslate"><span class="pre">agrupando</span> <span class="pre">todos</span> <span class="pre">los</span> <span class="pre">vectores</span> <span class="pre">sinápticos</span> <span class="pre">como</span> <span class="pre">filas</span></code>, una debajo de la otra, en una matriz, podemos escribir colectivamente</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\boldsymbol{z}^{r}=\Theta\boldsymbol{y}^{r-1},\quad\text{donde}\quad\Theta:=[\boldsymbol{\theta}_{1}^{r}, \boldsymbol{\theta}_{2}^{r},\dots, \boldsymbol{\theta}_{k_{r}}^{r}].
\]</div>
<ul class="simple">
<li><p>El vector de las salidas de la <span class="math notranslate nohighlight">\(r\)</span> th capa oculta, después de <code class="docutils literal notranslate"><span class="pre">empujar</span> <span class="pre">cada</span></code> <span class="math notranslate nohighlight">\(z_{i}^{r}\)</span> <code class="docutils literal notranslate"><span class="pre">a</span> <span class="pre">través</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">no</span> <span class="pre">linealidad</span></code> <span class="math notranslate nohighlight">\(f\)</span>, está finalmente dado por</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}
\boldsymbol{y}^{r}=
\begin{bmatrix}
1\\
f(\boldsymbol{z}^{r})
\end{bmatrix}
\end{split}\]</div>
<ul class="simple">
<li><p>La notación anterior significa que <span class="math notranslate nohighlight">\(f\)</span> <code class="docutils literal notranslate"><span class="pre">actúa</span> <span class="pre">sobre</span> <span class="pre">cada</span> <span class="pre">uno</span> <span class="pre">de</span> <span class="pre">los</span> <span class="pre">respectivos</span> <span class="pre">componentes</span> <span class="pre">del</span> <span class="pre">vector</span></code>, individualmente, y la <code class="docutils literal notranslate"><span class="pre">extensión</span> <span class="pre">del</span> <span class="pre">vector</span> <span class="pre">en</span> <span class="pre">uno</span> <span class="pre">es</span> <span class="pre">para</span> <span class="pre">dar</span> <span class="pre">cuenta</span> <span class="pre">de</span> <span class="pre">los</span> <span class="pre">términos</span> <span class="pre">de</span> <span class="pre">sesgo</span></code> en la práctica estándar. Para redes grandes, con muchas capas y muchos nodos por capa, este tipo de conectividad resulta ser muy costoso en términos del número de parámetros (pesos), que es del orden de <span class="math notranslate nohighlight">\(k_{r}k_{r-1}\)</span>. Por ejemplo, si <span class="math notranslate nohighlight">\(k_{r-1} = 1000\)</span> y <span class="math notranslate nohighlight">\(k_{r} = 1000\)</span>, <code class="docutils literal notranslate"><span class="pre">esto</span> <span class="pre">equivale</span> <span class="pre">a</span> <span class="pre">un</span> <span class="pre">orden</span> <span class="pre">de</span> <span class="pre">1</span> <span class="pre">millón</span> <span class="pre">de</span> <span class="pre">parámetros</span></code>. Tenga en cuenta que este número es la contribución de los parámetros de una sola de las capas. Sin embargo, <code class="docutils literal notranslate"><span class="pre">un</span> <span class="pre">gran</span> <span class="pre">número</span> <span class="pre">de</span> <span class="pre">parámetros</span> <span class="pre">hace</span> <span class="pre">que</span> <span class="pre">una</span> <span class="pre">red</span> <span class="pre">sea</span> <span class="pre">vulnerable</span> <span class="pre">al</span> <span class="pre">sobreajuste</span></code>, cuando se trata de entrenamiento</p></li>
<li><p>Se pueden emplear las llamadas <code class="docutils literal notranslate"><span class="pre">técnicas</span> <span class="pre">de</span> <span class="pre">reparto</span> <span class="pre">de</span> <span class="pre">pesos</span></code>, en las que un conjunto de parámetros es compartido entre un número de conexiones, a través de restricciones adecuadamente incorporadas. Las <code class="docutils literal notranslate"><span class="pre">redes</span> <span class="pre">neuronales</span> <span class="pre">recurrentes</span> <span class="pre">y</span> <span class="pre">convolucionales</span></code> que se discutirán en en el curso <strong><code class="docutils literal notranslate"><span class="pre">time</span> <span class="pre">series</span> <span class="pre">forecasting</span></code></strong>, pertenecen a esta familia de redes de peso compartido. Como veremos, en una red convolucional, las <code class="docutils literal notranslate"><span class="pre">convoluciones</span> <span class="pre">sustituyen</span> <span class="pre">a</span> <span class="pre">las</span> <span class="pre">operaciones</span> <span class="pre">de</span> <span class="pre">producto</span> <span class="pre">interno</span></code>, lo que permite un reparto de pesos importante que conduce a una reducción sustancial del número de parámetros.</p></li>
</ul>
</section>
<section id="el-algoritmo-de-backpropagation">
<h2>El Algoritmo De Backpropagation<a class="headerlink" href="#el-algoritmo-de-backpropagation" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Una red neuronal considera una <code class="docutils literal notranslate"><span class="pre">función</span> <span class="pre">paramétrica</span> <span class="pre">no</span> <span class="pre">lineal</span></code>, <span class="math notranslate nohighlight">\(\hat{y} = f_{\boldsymbol{\theta}}(\boldsymbol{x})\)</span>, donde <span class="math notranslate nohighlight">\(\boldsymbol{\theta}\)</span> representa todos los pesos/sesgo presentes en la red. Por lo tanto, el entrenamiento de una red neuronal no parece ser diferente del entrenamiento de cualquier otro modelo de predicción paramétrica. Todo lo que se necesita es <code class="docutils literal notranslate"><span class="pre">(a)</span></code> un <code class="docutils literal notranslate"><span class="pre">conjunto</span> <span class="pre">de</span> <span class="pre">muestras</span> <span class="pre">de</span> <span class="pre">entrenamiento</span></code>, <code class="docutils literal notranslate"><span class="pre">(b)</span></code> una <code class="docutils literal notranslate"><span class="pre">función</span> <span class="pre">de</span> <span class="pre">pérdida</span></code> <span class="math notranslate nohighlight">\(\mathcal{L}(y, \hat{y})\)</span>, y <code class="docutils literal notranslate"><span class="pre">(c)</span></code> un <code class="docutils literal notranslate"><span class="pre">esquema</span> <span class="pre">iterativo</span></code>, por ejemplo, el <code class="docutils literal notranslate"><span class="pre">gradiente</span> <span class="pre">descendiente</span></code>, para realizar la optimización de la función de coste asociada (<code class="docutils literal notranslate"><span class="pre">pérdida</span> <span class="pre">empírica</span></code>).</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
J(\boldsymbol{\theta})=\sum_{n=1}^{N}\mathcal{L}(y_{n}, f_{\boldsymbol{\theta}}(\boldsymbol{x}_{n})).
\]</div>
<ul class="simple">
<li><p>La dificultad del entrenamiento de las redes neuronales radica en su <code class="docutils literal notranslate"><span class="pre">estructura</span> <span class="pre">multicapa</span> <span class="pre">que</span> <span class="pre">complica</span> <span class="pre">el</span> <span class="pre">cálculo</span> <span class="pre">de</span> <span class="pre">los</span> <span class="pre">gradientes,</span> <span class="pre">que</span> <span class="pre">intervienen</span> <span class="pre">en</span> <span class="pre">la</span> <span class="pre">optimización</span></code>. Además, la neurona <code class="docutils literal notranslate"><span class="pre">McCulloch-Pitts</span></code> se basa en la función de activación discontinua de <code class="docutils literal notranslate"><span class="pre">Heaviside,</span> <span class="pre">que</span> <span class="pre">no</span> <span class="pre">es</span> <span class="pre">diferenciable</span></code>.</p></li>
</ul>
<ul class="simple">
<li><p>La <code class="docutils literal notranslate"><span class="pre">neurona</span> <span class="pre">sigmoidea</span> <span class="pre">logística</span></code>: Una posibilidad es adoptar la función <code class="docutils literal notranslate"><span class="pre">sigmoidea</span> <span class="pre">logística</span></code>, es decir,</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
f(z)=\sigma(z):=\frac{1}{1+\exp(-az)}.
\]</div>
<ul class="simple">
<li><p>Nótese que <code class="docutils literal notranslate"><span class="pre">cuanto</span> <span class="pre">mayor</span> <span class="pre">sea</span> <span class="pre">el</span> <span class="pre">valor</span> <span class="pre">del</span> <span class="pre">parámetro</span></code> <span class="math notranslate nohighlight">\(a\)</span>, <code class="docutils literal notranslate"><span class="pre">la</span> <span class="pre">gráfica</span> <span class="pre">correspondiente</span> <span class="pre">se</span> <span class="pre">acerca</span> <span class="pre">más</span> <span class="pre">a</span> <span class="pre">la</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">función</span> <span class="pre">de</span> <span class="pre">Heaviside</span></code> (ver <a class="reference internal" href="#sigmoid-act-function"><span class="std std-numref">Fig. 38</span></a>).</p></li>
</ul>
<figure class="align-center" id="sigmoid-act-function">
<a class="reference internal image-reference" href="_images/sigmoid_act_function.png"><img alt="_images/sigmoid_act_function.png" src="_images/sigmoid_act_function.png" style="width: 507.20000000000005px; height: 471.20000000000005px;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 38 </span><span class="caption-text">La función sigmoidea logística para diferentes valores del parámetro <span class="math notranslate nohighlight">\(a\)</span>.</span><a class="headerlink" href="#sigmoid-act-function" title="Link to this image">#</a></p>
</figcaption>
</figure>
<ul>
<li><p>Otra posibilidad sería <code class="docutils literal notranslate"><span class="pre">utilizar</span> <span class="pre">la</span> <span class="pre">función</span></code>,</p>
<div class="math notranslate nohighlight">
\[
    f(z)=a\tanh\left(\frac{cz}{2}\right),
    \]</div>
<p>donde <span class="math notranslate nohighlight">\(c\)</span> y <span class="math notranslate nohighlight">\(a\)</span> son parámetros de control. El gráfico de esta función se muestra en la <a class="reference internal" href="#tanh-act-function"><span class="std std-numref">Fig. 39</span></a>. Nótese que a diferencia de la sigmoidea logística, ésta es una <code class="docutils literal notranslate"><span class="pre">función</span> <span class="pre">es</span> <span class="pre">no</span> <span class="pre">simétrica</span></code>, es decir, <span class="math notranslate nohighlight">\(f(-z)=-f(z)\)</span>. Ambas son también conocidas como <code class="docutils literal notranslate"><span class="pre">funciones</span> <span class="pre">de</span> <span class="pre">reducción,</span> <span class="pre">porque</span> <span class="pre">limitan</span> <span class="pre">la</span> <span class="pre">salida</span> <span class="pre">a</span> <span class="pre">un</span> <span class="pre">rango</span> <span class="pre">finito</span> <span class="pre">de</span> <span class="pre">valores</span></code>.</p>
</li>
</ul>
<figure class="align-center" id="tanh-act-function">
<a class="reference internal image-reference" href="_images/tanh_act_function.png"><img alt="_images/tanh_act_function.png" src="_images/tanh_act_function.png" style="width: 693.6px; height: 435.20000000000005px;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 39 </span><span class="caption-text">Función de reducción de la tangente hiperbólica para <span class="math notranslate nohighlight">\(a = 1.7\)</span> y <span class="math notranslate nohighlight">\(c = 4/3\)</span>.</span><a class="headerlink" href="#tanh-act-function" title="Link to this image">#</a></p>
</figcaption>
</figure>
<ul>
<li><p>Recordemos que la regla de <code class="docutils literal notranslate"><span class="pre">actualización</span> <span class="pre">del</span> <span class="pre">algoritmo</span> <span class="pre">gradiente</span> <span class="pre">descendiente</span></code>, en su versión unidimensional se convierte en</p>
<div class="math notranslate nohighlight">
\[\begin{split}
    \\[1mm]
    \theta(new)=\theta(old)-\mu\left.\frac{d J}{d\theta}\right|_{\theta(old)},
    \end{split}\]</div>
<p>y las iteraciones parten de un punto inicial arbitrario, <span class="math notranslate nohighlight">\(\theta^{(0)}\)</span>. Si en la iteración actual el algoritmo está digamos, en el punto <span class="math notranslate nohighlight">\(\theta(old) = \theta_{1}\)</span>, entonces se moverá hacia el mínimo local, <span class="math notranslate nohighlight">\(\theta_{l}\)</span>. Esto se debe a que la derivada del coste en <span class="math notranslate nohighlight">\(\theta_{1}\)</span> es igual a la tangente de <span class="math notranslate nohighlight">\(\phi_{1}\)</span>, que es negativa (el ángulo es obtuso) y la actualización, <span class="math notranslate nohighlight">\(\theta(new)\)</span>, se moverá a la derecha, hacia el mínimo local, <span class="math notranslate nohighlight">\(\theta_{l}\)</span>.</p>
</li>
</ul>
<figure class="align-center" id="convex-function-saddle-point">
<a class="reference internal image-reference" href="_images/convex_function_saddle_point.png"><img alt="_images/convex_function_saddle_point.png" src="_images/convex_function_saddle_point.png" style="width: 635.2px; height: 354.40000000000003px;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 40 </span><span class="caption-text">Función no convexa global, con mínimos locales y puntos de silla.</span><a class="headerlink" href="#convex-function-saddle-point" title="Link to this image">#</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p>La <code class="docutils literal notranslate"><span class="pre">elección</span> <span class="pre">del</span> <span class="pre">tamaño</span> <span class="pre">del</span> <span class="pre">paso</span></code>, <span class="math notranslate nohighlight">\(\mu\)</span>, <code class="docutils literal notranslate"><span class="pre">es</span> <span class="pre">crítica</span> <span class="pre">para</span> <span class="pre">la</span> <span class="pre">convergencia</span> <span class="pre">del</span> <span class="pre">algoritmo</span></code>. En problemas reales en espacios multidimensionales, el número de mínimos locales puede ser grande, por lo que el algoritmo puede converger a uno local. Sin embargo, esto no es necesariamente una mala noticia. Si este <code class="docutils literal notranslate"><span class="pre">mínimo</span> <span class="pre">local</span> <span class="pre">es</span> <span class="pre">lo</span> <span class="pre">suficientemente</span> <span class="pre">profundo</span></code>, es decir, si el valor de la función de coste en este punto, por ejemplo, <span class="math notranslate nohighlight">\(J(\theta_{l})\)</span>, <code class="docutils literal notranslate"><span class="pre">no</span> <span class="pre">es</span> <span class="pre">mucho</span> <span class="pre">mayor</span> <span class="pre">que</span> <span class="pre">el</span> <span class="pre">alcanzado</span> <span class="pre">en</span> <span class="pre">el</span> <span class="pre">mínimo</span> <span class="pre">global</span></code>, es decir, <span class="math notranslate nohighlight">\(J(\theta_{g})\)</span>, la <code class="docutils literal notranslate"><span class="pre">convergencia</span> <span class="pre">a</span> <span class="pre">dicho</span> <span class="pre">mínimo</span> <span class="pre">local</span> <span class="pre">puede</span> <span class="pre">corresponder</span> <span class="pre">a</span> <span class="pre">una</span> <span class="pre">buena</span> <span class="pre">solución</span></code>.</p></li>
</ul>
</section>
<section id="el-esquema-de-backpropagation-para-gradiente-descendiente">
<h2>El Esquema De Backpropagation Para Gradiente Descendiente<a class="headerlink" href="#el-esquema-de-backpropagation-para-gradiente-descendiente" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Habiendo adoptado una función de activación diferenciable, estamos listos para proceder a desarrollar el <code class="docutils literal notranslate"><span class="pre">esquema</span> <span class="pre">iterativo</span> <span class="pre">de</span> <span class="pre">gradiente</span> <span class="pre">descendiente</span> <span class="pre">para</span> <span class="pre">la</span> <span class="pre">minimización</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">función</span> <span class="pre">de</span> <span class="pre">coste</span></code>. Formularemos la tarea en un marco general.</p></li>
<li><p>Sea <span class="math notranslate nohighlight">\((\boldsymbol{y}_{n}, \boldsymbol{x}_{n}), n = 1, 2,\dots, N\)</span>, es el conjunto de muestras de entrenamiento. <code class="docutils literal notranslate"><span class="pre">Nótese</span> <span class="pre">que</span> <span class="pre">hemos</span> <span class="pre">asumido</span> <span class="pre">múltiples</span> <span class="pre">variables</span> <span class="pre">output</span></code>, como vectores. Suponemos que la red consta de <span class="math notranslate nohighlight">\(L\)</span> capas, <span class="math notranslate nohighlight">\(L-1\)</span> capas ocultas y una capa de salida. Cada capa consta de <span class="math notranslate nohighlight">\(k_{r}, r = 1, 2,\dots, L\)</span>, neuronas. Así, los vectores de salida (objetivo/deseado) son</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\boldsymbol{y}_{n}=[y_{n1}, y_{n2},\dots, y_{nk_{L}}]^{T}\in\mathbb{R}^{K_{L}},\quad n=1,2,\dots,N.
\]</div>
<ul class="simple">
<li><p>Para ciertas derivaciones matemáticas, también denotamos el número de nodos de entrada como <span class="math notranslate nohighlight">\(k_{0}\)</span>; es decir <span class="math notranslate nohighlight">\(k_{0} = l\)</span>, donde <span class="math notranslate nohighlight">\(l\)</span> es la <code class="docutils literal notranslate"><span class="pre">dimensionalidad</span> <span class="pre">del</span> <span class="pre">espacio</span> <span class="pre">de</span> <span class="pre">características</span> <span class="pre">de</span> <span class="pre">entrada</span></code>.</p></li>
<li><p>Sea <span class="math notranslate nohighlight">\(\boldsymbol{\theta}_{j}^{r}\)</span> denota el <code class="docutils literal notranslate"><span class="pre">vector</span> <span class="pre">de</span> <span class="pre">los</span> <span class="pre">pesos</span> <span class="pre">sinápticos</span> <span class="pre">asociados</span> <span class="pre">a</span> <span class="pre">la</span></code> <span class="math notranslate nohighlight">\(j\)</span><code class="docutils literal notranslate"><span class="pre">-th</span> <span class="pre">neurona</span> <span class="pre">de</span> <span class="pre">la</span></code> <span class="math notranslate nohighlight">\(r\)</span><code class="docutils literal notranslate"><span class="pre">-th</span> <span class="pre">capa</span></code>, con <span class="math notranslate nohighlight">\(j = 1, 2,\dots, k_{r}\)</span> y <span class="math notranslate nohighlight">\(r = 1, 2,\dots,L\)</span>, donde el término de sesgo se incluye en <span class="math notranslate nohighlight">\(\boldsymbol{\theta}_{j}^{r}\)</span> , es decir,</p></li>
</ul>
<div class="math notranslate nohighlight" id="equation-parameters-vector-def">
<span class="eqno">(52)<a class="headerlink" href="#equation-parameters-vector-def" title="Link to this equation">#</a></span>\[
\boldsymbol{\theta}_{j}^{r}:=[\theta_{j0}^{r}, \theta_{j1}^{r},\dots, \theta_{jk_{r-1}}^{r}]^{T}.
\]</div>
<ul class="simple">
<li><p>Los pesos sinápticos enlazan la neurona respectiva con todas las neuronas de la capa <span class="math notranslate nohighlight">\(k_{r-1}\)</span> (véase la <a class="reference internal" href="#synaptic-weights-link"><span class="std std-numref">Fig. 41</span></a>). El paso iterativo básico para el esquema de gradiente descendiente se escribe como</p></li>
</ul>
<div class="math notranslate nohighlight" id="equation-update-equations-gd">
<span class="eqno">(53)<a class="headerlink" href="#equation-update-equations-gd" title="Link to this equation">#</a></span>\[\begin{split}
\begin{align*}
\boldsymbol{\theta}_{j}^{r}(\text{new})&amp;=\boldsymbol{\theta}_{j}^{r}(old)+\Delta\boldsymbol{\theta}_{j}^{r},\\
\Delta\boldsymbol{\theta}_{j}^{r}&amp;:=-\mu\left.\frac{\partial J}{\partial\boldsymbol{\theta}_{j}^{r}}\right|_{\boldsymbol{\theta}_{j}^{r}(old)}.
\end{align*}
\end{split}\]</div>
<ul class="simple">
<li><p>El parámetro <span class="math notranslate nohighlight">\(\mu\)</span> es el tamaño de paso definido por el usuario (también puede depender de la iteración) y <span class="math notranslate nohighlight">\(J\)</span> denota la función de coste.</p></li>
</ul>
<figure class="align-center" id="synaptic-weights-link">
<a class="reference internal image-reference" href="_images/synaptic_weights_link.png"><img alt="_images/synaptic_weights_link.png" src="_images/synaptic_weights_link.png" style="width: 529.6px; height: 355.20000000000005px;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 41 </span><span class="caption-text">Enlaces y las variables asociadas de la <span class="math notranslate nohighlight">\(j\)</span> th neurona en la <span class="math notranslate nohighlight">\(r\)</span> th capa. <span class="math notranslate nohighlight">\(y_{k}^{r-1}\)</span> es la salida de la <span class="math notranslate nohighlight">\(k\)</span> th neurona de la <span class="math notranslate nohighlight">\((r - 1)\)</span> th capa y <span class="math notranslate nohighlight">\(\theta_{jk}^{r}\)</span> es el peso respectivo que conecta estas dos neuronas.</span><a class="headerlink" href="#synaptic-weights-link" title="Link to this image">#</a></p>
</figcaption>
</figure>
<ul>
<li><p>Las ecuaciones de actualización <a class="reference internal" href="#equation-update-equations-gd">(53)</a> comprenden el par del esquema de gradiente descendiente  para la optimización. Como se ha dicho anteriormente, la dificultad de las redes neuronales <code class="docutils literal notranslate"><span class="pre">feed-forward</span></code> surge de su estructura multicapa. Para calcular los gradientes en la Ecuación <a class="reference internal" href="#equation-update-equations-gd">(53)</a>, para todas las neuronas en todas las capas, se deben seguir dos pasos en su cálculo</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">Forward</span> <span class="pre">computations</span></code>: Para un vector de entrada dado <span class="math notranslate nohighlight">\(\boldsymbol{x}_{n}, n = 1, 2,\dots, N\)</span>, se utilizan las estimaciones actuales de los parámetros (pesos sinápticos) (<span class="math notranslate nohighlight">\(\boldsymbol{\theta}_{j}^{r}(old)\)</span>) y calcula todas las salidas de todas las neuronas en todas las capas, denotadas como <span class="math notranslate nohighlight">\(y_{nj}^{r}\)</span>; en la <a class="reference internal" href="#synaptic-weights-link"><span class="std std-numref">Fig. 41</span></a>, se ha suprimido el índice <span class="math notranslate nohighlight">\(n\)</span> para no afectar la notación.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Backward</span> <span class="pre">computations</span></code>: Utilizando las salidas neuronales calculadas anteriormente junto con los valores objetivo conocidos, <span class="math notranslate nohighlight">\(y_{nk}\)</span>, de la capa de salida, se calculan los gradientes de la función de coste. Esto implica <span class="math notranslate nohighlight">\(L\)</span> pasos, es decir, tantos como el número de capas. La secuencia de los pasos algorítmicos se indica a continuación:</p>
<ul>
<li><p>Calcular el gradiente de la función de coste con respecto a los parámetros de las neuronas de la última capa, es decir, <span class="math notranslate nohighlight">\(\displaystyle{\frac{\partial J}{\partial\boldsymbol{\theta}_{j}^{L}}, j = 1, 2,\dots, k_{L}}\)</span>.</p></li>
<li><p><strong>For</strong> <span class="math notranslate nohighlight">\(r = L-1\)</span> to <span class="math notranslate nohighlight">\(1\)</span>, <strong>Do</strong></p>
<p>Calcular los gradientes con respecto a los parámetros asociados a las neuronas de la <span class="math notranslate nohighlight">\(r\)</span> th capa, es decir, <span class="math notranslate nohighlight">\(\displaystyle{\frac{\partial J}{\partial\boldsymbol{\theta}_{k}^{r}}, k= 1, 2,\dots, k_{r}}\)</span> basado en todos los gradientes <span class="math notranslate nohighlight">\(\displaystyle{\frac{\partial J}{\partial\boldsymbol{\theta}_{j}^{r+1}}, j= 1, 2,\dots, k_{r+1}}\)</span>, con respecto a los parámetros de la capa <span class="math notranslate nohighlight">\(r + 1\)</span> que se han calculado en el paso anterior.</p>
</li>
<li><p><strong>End For</strong></p></li>
</ul>
</li>
</ul>
</li>
</ul>
<ul>
<li><p>El esquema de cálculo hacia atrás <code class="docutils literal notranslate"><span class="pre">backpropagation</span></code> es una aplicación directa de la <code class="docutils literal notranslate"><span class="pre">regla</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">cadena</span> <span class="pre">para</span> <span class="pre">las</span> <span class="pre">derivadas</span></code>, y comienza con el paso inicial de <code class="docutils literal notranslate"><span class="pre">calcular</span> <span class="pre">las</span> <span class="pre">derivadas</span> <span class="pre">asociadas</span> <span class="pre">a</span> <span class="pre">la</span> <span class="pre">última</span> <span class="pre">capa</span> <span class="pre">(de</span> <span class="pre">salida)</span></code>, que resulta ser sencillo. A continuación, el algoritmo “fluye” hacia atrás en la jerarquía de capas. Esto se debe a la naturaleza de la red multicapa, donde las <code class="docutils literal notranslate"><span class="pre">salidas,</span> <span class="pre">capa</span> <span class="pre">tras</span> <span class="pre">capa,</span> <span class="pre">se</span> <span class="pre">forman</span> <span class="pre">como</span> <span class="pre">funciones</span> <span class="pre">de</span> <span class="pre">funciones</span></code>. En efecto, centrémonos en la salida <span class="math notranslate nohighlight">\(y_{k}^{r}\)</span> de la neurona <span class="math notranslate nohighlight">\(k\)</span> en la capa <span class="math notranslate nohighlight">\(r\)</span>. Entonces tenemos</p>
<div class="math notranslate nohighlight">
\[\begin{split}
    \\[1mm]
    y_{k}^{r}=f(\boldsymbol{\theta}_{k}^{r^T}\boldsymbol{y}^{r-1}),\quad k=1,2,\dots, k_{r},
    \end{split}\]</div>
<p>donde <span class="math notranslate nohighlight">\(\boldsymbol{y}^{r-1}\)</span> es el vector (ampliado) que comprende todas las salidas de la capa anterior, <span class="math notranslate nohighlight">\(r-1\)</span>, y <span class="math notranslate nohighlight">\(f\)</span> denota la no-linealidad.</p>
</li>
</ul>
<ul>
<li><p>De acuerdo con lo anterior, la salida de la <span class="math notranslate nohighlight">\(j\)</span> th neurona en la siguiente capa viene dada por</p>
<div class="math notranslate nohighlight">
\[\begin{split}
    \\[1mm]
    y_{j}^{r+1}=f(\boldsymbol{\theta}_{j}^{r+1^T}\boldsymbol{y}^{r})=f\left(\boldsymbol{\theta}_{j}^{r+1^{T}}
    \begin{bmatrix}
    1\\
    f(\Theta^{r}\boldsymbol{y}^{r-1})
    \end{bmatrix}
    \right),
    \end{split}\]</div>
<p>donde <span class="math notranslate nohighlight">\(\Theta^{r}:=[\boldsymbol{\theta}_{1}^{r}, \boldsymbol{\theta}_{2}^{r},\dots,\boldsymbol{\theta}_{k_{r}}]^{T}\)</span> denota la matriz cuyas columnas corresponden al vector de pesos en el layer <span class="math notranslate nohighlight">\(r\)</span>.</p>
</li>
</ul>
<ul class="simple">
<li><p>Nótese que obtuvimos <code class="docutils literal notranslate"><span class="pre">evaluación</span> <span class="pre">de</span> <span class="pre">&quot;una</span> <span class="pre">función</span> <span class="pre">interna</span> <span class="pre">bajo</span> <span class="pre">una</span> <span class="pre">función</span> <span class="pre">externa&quot;</span></code>. Claramente, esto continúa a medida que avanzamos en la jerarquía. Esta <code class="docutils literal notranslate"><span class="pre">estructura</span> <span class="pre">de</span> <span class="pre">evaluación</span> <span class="pre">de</span> <span class="pre">funciones</span> <span class="pre">internas</span> <span class="pre">por</span> <span class="pre">funciones</span> <span class="pre">externas</span></code>, es el subproducto de la <code class="docutils literal notranslate"><span class="pre">naturaleza</span> <span class="pre">multicapa</span> <span class="pre">de</span> <span class="pre">las</span> <span class="pre">redes</span> <span class="pre">neuronales,</span> <span class="pre">la</span> <span class="pre">cual</span> <span class="pre">es</span> <span class="pre">una</span> <span class="pre">operación</span> <span class="pre">altamente</span> <span class="pre">no</span> <span class="pre">lineal</span></code>, que da lugar a la dificultad de calcular los gradientes, a diferencia de otros modelos, como por ejemplo <code class="docutils literal notranslate"><span class="pre">SVM</span></code>. Sin embargo, se puede observar fácilmente que <strong><code class="docutils literal notranslate"><span class="pre">el</span> <span class="pre">cálculo</span> <span class="pre">de</span> <span class="pre">los</span> <span class="pre">gradientes</span> <span class="pre">con</span> <span class="pre">respecto</span> <span class="pre">a</span> <span class="pre">los</span> <span class="pre">parámetros</span> <span class="pre">que</span> <span class="pre">definen</span> <span class="pre">la</span> <span class="pre">capa</span> <span class="pre">de</span> <span class="pre">salida</span> <span class="pre">no</span> <span class="pre">plantea</span> <span class="pre">ninguna</span> <span class="pre">dificultad</span></code></strong>. En efecto, la salida de la <span class="math notranslate nohighlight">\(j\)</span> th neurona de la última capa (que es en realidad la respectiva estimación de salida actual) se escribe como:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\hat{y}_{j}:=y_{j}^{L}=f(\boldsymbol{\theta}_{j}^{L^{T}}\boldsymbol{y}^{L-1}).
\]</div>
<ul class="simple">
<li><p>Dado que <span class="math notranslate nohighlight">\(\boldsymbol{y}^{L-1}\)</span> es conocido, después de los cálculos durante el paso adelante, tomando la derivada con respecto a <span class="math notranslate nohighlight">\(\boldsymbol{\theta}_{j}^{L}\)</span> es sencillo; <code class="docutils literal notranslate"><span class="pre">no</span> <span class="pre">hay</span> <span class="pre">ninguna</span> <span class="pre">operación</span> <span class="pre">de</span> <span class="pre">función</span> <span class="pre">sobre</span> <span class="pre">función</span></code>. Por esto es que <code class="docutils literal notranslate"><span class="pre">empezamos</span> <span class="pre">por</span> <span class="pre">la</span> <span class="pre">capa</span> <span class="pre">superior</span> <span class="pre">y</span> <span class="pre">luego</span> <span class="pre">nos</span> <span class="pre">movemos</span> <span class="pre">hacia</span> <span class="pre">atrás</span></code>. Debido a su <code class="docutils literal notranslate"><span class="pre">importancia</span> <span class="pre">histórica</span></code>, se dará la derivación completa del algoritmo <code class="docutils literal notranslate"><span class="pre">backpropagation</span></code>.</p></li>
</ul>
<ul>
<li><p>Para la derivación detallada del algoritmo backpropagation, <code class="docutils literal notranslate"><span class="pre">se</span> <span class="pre">adopta</span> <span class="pre">como</span> <span class="pre">ejemplo</span> <span class="pre">la</span> <span class="pre">función</span> <span class="pre">de</span> <span class="pre">pérdida</span> <span class="pre">del</span> <span class="pre">error</span> <span class="pre">cuadrático</span></code>, es decir</p>
<div class="math notranslate nohighlight" id="equation-gradient-desc-scheme">
<span class="eqno">(54)<a class="headerlink" href="#equation-gradient-desc-scheme" title="Link to this equation">#</a></span>\[
    J(\boldsymbol{\theta})=\sum_{n=1}^{N}J_{n}(\boldsymbol{\theta})\quad\text{y}\quad J_{n}(\boldsymbol{\theta})=\frac{1}{2}\sum_{k=1}^{k_{L}}(\hat{y}_{nk}-y_{nk})^{2},
    \]</div>
<p>donde <span class="math notranslate nohighlight">\(\hat{y}_{nk},~k=1,2,\dots,k_{L}\)</span>, son las estimaciones proporcionadas en los correspondientes nodos de salida de la red. Las consideraremos como los elementos de un vector correspondiente, <span class="math notranslate nohighlight">\(\hat{\boldsymbol{y}}_{n}\)</span>.</p>
</li>
</ul>
</section>
<section id="calculo-de-gradientes">
<h2>Cálculo de gradientes<a class="headerlink" href="#calculo-de-gradientes" title="Link to this heading">#</a></h2>
<ul>
<li><p>Sea <span class="math notranslate nohighlight">\(z_{nj}^{r}\)</span> la <code class="docutils literal notranslate"><span class="pre">salida</span> <span class="pre">del</span> <span class="pre">combinador</span> <span class="pre">lineal</span></code> de la <span class="math notranslate nohighlight">\(j\)</span>-th neurona en la capa <span class="math notranslate nohighlight">\(r\)</span> en el <code class="docutils literal notranslate"><span class="pre">instante</span> <span class="pre">de</span> <span class="pre">tiempo</span></code> <span class="math notranslate nohighlight">\(n\)</span>, cuando se aplica el patrón <span class="math notranslate nohighlight">\(\boldsymbol{x}_{n}\)</span> en los nodos de entrada (véase la <a class="reference internal" href="#synaptic-weights-link"><span class="std std-numref">Fig. 41</span></a>). Entonces, para <span class="math notranslate nohighlight">\(n, j\)</span> fijos, podemos escribir</p>
<div class="math notranslate nohighlight" id="equation-eq-znj">
<span class="eqno">(55)<a class="headerlink" href="#equation-eq-znj" title="Link to this equation">#</a></span>\[
    z_{nj}^{r}=\sum_{m=1}^{k_{r-1}}\theta_{jm}^{r}y_{nm}^{r-1}+\theta_{j0}^{r}=\sum_{m=0}^{k_{r-1}}\theta_{jm}^{r}y_{nm}^{r-1}=\boldsymbol{\theta}_{j}^{r^{T}}\boldsymbol{y}_{n}^{r-1},
    \]</div>
<p>donde por definición</p>
<div class="math notranslate nohighlight">
\[
    \boldsymbol{y}_{n}^{r-1}:=[1, y_{n1}^{r-1},\dots, y_{nk_{r-1}}^{r-1}]^{T},
    \]</div>
<p>y <span class="math notranslate nohighlight">\(y_{n0}^{r}\equiv 1,~\forall~r, n\)</span> y <span class="math notranslate nohighlight">\(\theta_{j}^{r}\)</span> ha sido definido en la Ecuación <a class="reference internal" href="#equation-parameters-vector-def">(52)</a>.</p>
</li>
</ul>
<ul class="simple">
<li><p>Para las neuronas de la capa de salida <span class="math notranslate nohighlight">\(r=L,~y_{nm}^{L}=\hat{y}_{nm},~m=1,2,\dots, k_{L}\)</span>, y para <span class="math notranslate nohighlight">\(r=1\)</span>, tenemos <span class="math notranslate nohighlight">\(y_{nm}^{1}=x_{nm},~m=1,2,\dots, k_{1}\)</span>; esto es, <span class="math notranslate nohighlight">\(y_{nm}^{1}\)</span> se fijan iguales a los <code class="docutils literal notranslate"><span class="pre">valores</span> <span class="pre">de</span> <span class="pre">las</span> <span class="pre">características</span> <span class="pre">de</span> <span class="pre">entrada</span></code>.</p></li>
</ul>
<ul class="simple">
<li><p>Por lo tanto, podemos escribir ahora</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\frac{\partial J_{n}}{\partial\boldsymbol{\theta}_{j}^{r}}=\frac{\partial J_{n}}{\partial z_{nj}^{r}}\frac{\partial z_{nj}^{r}}{\partial\boldsymbol{\theta}_{j}^{r}}=\frac{\partial J_{n}}{\partial z_{nj}^{r}}\boldsymbol{y}_{n}^{r-1}.
\]</div>
<ul class="simple">
<li><p>Definamos</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\delta_{nj}^{r}:=\frac{\partial J_{n}}{\partial z_{nj}^{r}}.
\]</div>
<ul class="simple">
<li><p>Entonces la Ecuación <a class="reference internal" href="#equation-update-equations-gd">(53)</a> puede escribirse como</p></li>
</ul>
<div class="math notranslate nohighlight" id="equation-eq-delta-theta-jr">
<span class="eqno">(56)<a class="headerlink" href="#equation-eq-delta-theta-jr" title="Link to this equation">#</a></span>\[
\Delta\boldsymbol{\theta}_{j}^{r}=\left.-\mu\frac{\partial J}{\partial\boldsymbol{\theta}_{j}^{r}}\right|_{\boldsymbol{\theta}_{j}^{r}(\text{old})}=-\mu\frac{\partial}{\partial\boldsymbol{\theta}_{j}^{r}}\left.\sum_{n=1}^{N}J_{n}\right|_{\boldsymbol{\theta}_{j}^{r}(\text{old})}=-\mu\sum_{n=1}^{N}\delta_{nj}^{r}\boldsymbol{y}_{n}^{r-1},\quad r=1,2,\dots,L.
\]</div>
</section>
<section id="calculo-de-delta-nj-r">
<h2>Cálculo de <span class="math notranslate nohighlight">\(\delta_{nj}^{r}\)</span><a class="headerlink" href="#calculo-de-delta-nj-r" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Este es el <code class="docutils literal notranslate"><span class="pre">cálculo</span> <span class="pre">principal</span> <span class="pre">del</span> <span class="pre">algoritmo</span> <span class="pre">backpropagation</span></code>. Para el cálculo de los gradientes, <span class="math notranslate nohighlight">\(\delta_{nj}^{r}\)</span>, se <code class="docutils literal notranslate"><span class="pre">comienza</span> <span class="pre">en</span> <span class="pre">la</span> <span class="pre">última</span> <span class="pre">capa</span></code>, <span class="math notranslate nohighlight">\(r = L\)</span>, y se <code class="docutils literal notranslate"><span class="pre">procede</span> <span class="pre">hacia</span> <span class="pre">atrás</span></code>, hacia <span class="math notranslate nohighlight">\(r = 1\)</span>; esta “filosofía” justifica el nombre dado al algoritmo.</p></li>
</ul>
<ol class="arabic">
<li><p><span class="math notranslate nohighlight">\(r=L\)</span>: Tenemos que</p>
<div class="math notranslate nohighlight">
\[
    \delta_{nj}^{L}:=\frac{\partial J_{n}}{\partial z_{nj}^{L}}.
    \]</div>
<p>Para la función de pérdida del <code class="docutils literal notranslate"><span class="pre">error</span> <span class="pre">al</span> <span class="pre">cuadrado</span></code>,</p>
<div class="math notranslate nohighlight">
\[
    J_{n}=\frac{1}{2}\sum_{k=1}^{k_{L}}\left(\hat{y}_{nk}-y_{nk}\right)^{2}=\frac{1}{2}\sum_{k=1}^{k_{L}}\left(f(z_{nk}^{L})-y_{nk}\right)^{2}.
    \]</div>
<p>Por lo tanto,</p>
<div class="math notranslate nohighlight" id="equation-eq-delta-njl">
<span class="eqno">(57)<a class="headerlink" href="#equation-eq-delta-njl" title="Link to this equation">#</a></span>\[\begin{split}
    \begin{align*}
    \delta_{nj}^{L}=\frac{\partial}{\partial z_{nj}^{L}}\left(\frac{1}{2}\sum_{k=1}^{k_{L}}\left(f(z_{nk}^{L})-y_{nk}\right)^{2}\right)&amp;=(f(z_{nj}^{L})-y_{nj})f'(z_{nj}^{L})\\
    &amp;=(\hat{y}_{nj}-y_{nj})f'(z_{nj}^{L})=e_{nj}f'(z_{nj}^{L}),
    \end{align*}
    \end{split}\]</div>
<p>donde <span class="math notranslate nohighlight">\(j=1,2,\dots, k_{L}\)</span>, <span class="math notranslate nohighlight">\(f'\)</span> denota la derivada de <span class="math notranslate nohighlight">\(f\)</span> y <span class="math notranslate nohighlight">\(e_{nj}\)</span> es el error asociado con el <span class="math notranslate nohighlight">\(j\)</span> th output en el tiempo <span class="math notranslate nohighlight">\(n\)</span>. <code class="docutils literal notranslate"><span class="pre">Nótese</span> <span class="pre">que</span> <span class="pre">para</span> <span class="pre">el</span> <span class="pre">último</span> <span class="pre">layer,</span> <span class="pre">el</span> <span class="pre">cálculo</span> <span class="pre">del</span> <span class="pre">gradiente</span></code>, <span class="math notranslate nohighlight">\(\delta_{nj}^{L}\)</span> <code class="docutils literal notranslate"><span class="pre">es</span> <span class="pre">sencillo</span></code>.</p>
</li>
</ol>
<ol class="arabic" start="2">
<li><p><span class="math notranslate nohighlight">\(r&lt;L\)</span>: Debido a la <code class="docutils literal notranslate"><span class="pre">dependencia</span> <span class="pre">sucesiva</span> <span class="pre">entre</span> <span class="pre">las</span> <span class="pre">capas</span></code>, el valor de <span class="math notranslate nohighlight">\(z_{nj}^{r-1}\)</span> <code class="docutils literal notranslate"><span class="pre">influye</span> <span class="pre">en</span> <span class="pre">todos</span> <span class="pre">los</span> <span class="pre">valores</span></code> <span class="math notranslate nohighlight">\(z_{nk}^{r},~k = 1, 2,\dots, k_{r}\)</span>, <code class="docutils literal notranslate"><span class="pre">de</span> <span class="pre">la</span> <span class="pre">capa</span> <span class="pre">siguiente</span></code>. Empleando la <code class="docutils literal notranslate"><span class="pre">regla</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">cadena</span></code> para la diferenciación, obtenemos, para <span class="math notranslate nohighlight">\(r=L, L-1,\dots, 2\)</span>:</p>
<div class="math notranslate nohighlight" id="equation-partial-der-znk1">
<span class="eqno">(58)<a class="headerlink" href="#equation-partial-der-znk1" title="Link to this equation">#</a></span>\[
    \delta_{nj}^{r-1}=\frac{\partial J_{n}}{\partial z_{nj}^{r-1}}=\sum_{k=1}^{k_{r}}\frac{\partial J_{n}}{\partial z_{nk}^{r}}\frac{\partial z_{nk}^{r}}{\partial z_{nj}^{r-1}},
    \]</div>
<p>o</p>
<div class="math notranslate nohighlight" id="equation-partial-der-znk2">
<span class="eqno">(59)<a class="headerlink" href="#equation-partial-der-znk2" title="Link to this equation">#</a></span>\[
    \delta_{nj}^{r-1}=\sum_{k=1}^{k_{r}}\delta_{nk}^{r}\frac{\partial z_{nk}^{r}}{\partial z_{nj}^{r-1}}.
    \]</div>
<p>Además, <code class="docutils literal notranslate"><span class="pre">usando</span> <span class="pre">Ecuación</span></code> <a class="reference internal" href="#equation-eq-znj">(55)</a> se tiene,</p>
<div class="math notranslate nohighlight">
\[
    \frac{\partial z_{nk}^{r}}{\partial z_{nj}^{r-1}}=\frac{\partial}{\partial z_{nj}^{r-1}}\left(\sum_{m=0}^{k_{r-1}}\theta_{km}^{r}y_{nm}^{r-1}\right),
    \]</div>
<p>donde <span class="math notranslate nohighlight">\(\textcolor{blue}{y_{nm}^{r-1}=f(z_{nm}^{r-1})}=f(\boldsymbol{\theta}_{m}^{r-1^{T}}\boldsymbol{y}_{n}^{r-2})\)</span>. Entonces,</p>
<div class="math notranslate nohighlight">
\[
    \frac{\partial z_{nk}^{r}}{\partial z_{nj}^{r-1}}=\theta_{kj}^{r}f'(z_{nj}^{r-1}),
    \]</div>
<p>y combinando las Ecuaciones <a class="reference internal" href="#equation-partial-der-znk1">(58)</a> y <a class="reference internal" href="#equation-partial-der-znk2">(59)</a>, obtenemos la regla recursiva</p>
<div class="math notranslate nohighlight">
\[
    \delta_{nj}^{r-1}=\left(\sum_{k=1}^{k_{r}}\delta_{nk}^{r}\theta_{kj}^{r}\right)f'(z_{nj}^{r-1}).
    \]</div>
</li>
</ol>
<ul>
<li><p>Manteniendo la misma notación en la Ecuación <a class="reference internal" href="#equation-eq-delta-njl">(57)</a>, definimos</p>
<div class="math notranslate nohighlight">
\[\begin{split}
    \\[1mm]
    e_{nj}^{r-1}:=\sum_{k=1}^{k_{r}}\delta_{nk}^{r}\theta_{kj}^{r},
    \end{split}\]</div>
<p>y finalmente obtenemos,</p>
<div class="math notranslate nohighlight" id="equation-eq-delta-njr-1">
<span class="eqno">(60)<a class="headerlink" href="#equation-eq-delta-njr-1" title="Link to this equation">#</a></span>\[
    \delta_{nj}^{r-1}=e_{nj}^{r-1}f'(z_{nj}^{r-1}).
    \]</div>
</li>
</ul>
<ul class="simple">
<li><p>El único cálculo que queda es la derivada de <span class="math notranslate nohighlight">\(f\)</span>. Para el caso de la <code class="docutils literal notranslate"><span class="pre">función</span> <span class="pre">sigmoidea</span> <span class="pre">logística</span></code> se demuestra fácilmente que es igual a</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
f'(z)=af(z)(1-f(z)).
\]</div>
<ul class="simple">
<li><p>La derivación se ha completado y el esquema <code class="docutils literal notranslate"><span class="pre">backpropagation</span> <span class="pre">neural</span> <span class="pre">network</span></code> se resume en el siguiente algoritmo</p></li>
</ul>
<div class="proof algorithm admonition" id="my_algorithm_backpropagation">
<p class="admonition-title"><span class="caption-number">Algorithm 3 </span> (Algoritmo Backpropagation Gradiente Descendiente)</p>
<section class="algorithm-content" id="proof-content">
<p><strong>Inicialización</strong></p>
<ol class="arabic simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Inicializar</span> <span class="pre">todos</span> <span class="pre">los</span> <span class="pre">pesos</span> <span class="pre">y</span> <span class="pre">sesgos</span> <span class="pre">sinápticos</span> <span class="pre">al</span> <span class="pre">azar</span> <span class="pre">con</span> <span class="pre">valores</span> <span class="pre">pequeños</span></code>, pero no muy pequeños.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Seleccione</span> <span class="pre">el</span> <span class="pre">tamaño</span> <span class="pre">del</span> <span class="pre">paso</span></code> <span class="math notranslate nohighlight">\(\mu\)</span>.</p></li>
<li><p>Fije <span class="math notranslate nohighlight">\(y_{nj}^{1}=x_{nj},\quad j=1,2,\dots,k_{1}:=l,\quad n=1,2,\dots,N\)</span></p></li>
</ol>
<p><strong>Repeat</strong> Cada repetición completa un <code class="docutils literal notranslate"><span class="pre">epoch</span></code></p>
<ol class="arabic">
<li><p><strong>For</strong> <span class="math notranslate nohighlight">\(n=1,2,\dots,N\)</span> <strong>Do</strong></p>
<ol class="arabic">
<li><p><strong>For</strong> <span class="math notranslate nohighlight">\(r=1,2,\dots,L\)</span> <strong>Do</strong> Cálculo <code class="docutils literal notranslate"><span class="pre">Forward</span></code></p>
<ol class="arabic">
<li><p><strong>For</strong> <span class="math notranslate nohighlight">\(j=1,2,\dots,k_{r}\)</span> <strong>Do</strong></p>
<p>Calcule <span class="math notranslate nohighlight">\(z_{nj}^{r}\)</span> a partir de la Ecuación <a class="reference internal" href="#equation-eq-znj">(55)</a>
Calcule <span class="math notranslate nohighlight">\(y_{nj}^{r}=f(z_{nj}^{r})\)</span></p>
</li>
<li><p><strong>End For</strong></p></li>
</ol>
</li>
<li><p><strong>End For</strong></p></li>
<li><p><strong>For</strong> <span class="math notranslate nohighlight">\(j = 1, 2,\dots, k_{L}\)</span>, <strong>Do</strong>; Cálculo <code class="docutils literal notranslate"><span class="pre">Backward</span></code> (<code class="docutils literal notranslate"><span class="pre">output</span> <span class="pre">layer</span></code>)</p>
<p>Calcule <span class="math notranslate nohighlight">\(\delta_{nj}^{L}\)</span> a partir de la Ecuación <a class="reference internal" href="#equation-eq-delta-njr-1">(60)</a></p>
</li>
<li><p><strong>End For</strong></p></li>
<li><p><strong>For</strong> <span class="math notranslate nohighlight">\(r=L, L-1,\dots, 2\)</span>, <strong>Do</strong>; Cálculo <code class="docutils literal notranslate"><span class="pre">Backward</span></code> (<code class="docutils literal notranslate"><span class="pre">hidden</span> <span class="pre">layers</span></code>)</p>
<ol class="arabic">
<li><p><strong>For</strong> <span class="math notranslate nohighlight">\(j=1,2,\dots, k_{r}\)</span>, <strong>Do</strong></p>
<p>Calcule <span class="math notranslate nohighlight">\(\delta_{nj}^{r-1}\)</span> a partir de la Ecuación <a class="reference internal" href="#equation-eq-delta-njr-1">(60)</a></p>
</li>
<li><p><strong>End For</strong></p></li>
</ol>
</li>
<li><p><strong>End For</strong></p></li>
</ol>
</li>
<li><p><strong>End For</strong></p></li>
<li><p><strong>For</strong> <span class="math notranslate nohighlight">\(r=1,2,\dots,L\)</span>, <strong>Do</strong>: Actualice los pesos</p>
<ol class="arabic">
<li><p><strong>For</strong> <span class="math notranslate nohighlight">\(j=1,2,\dots,k_{r}\)</span>, <strong>Do</strong></p>
<p>Calcule <span class="math notranslate nohighlight">\(\Delta\boldsymbol{\theta}_{j}^{r}\)</span> a partir de la Ecuación <a class="reference internal" href="#equation-eq-delta-theta-jr">(56)</a></p>
<p><span class="math notranslate nohighlight">\(\boldsymbol{\theta}_{j}^{r}=\boldsymbol{\theta}_{j}^{r}+\Delta\boldsymbol{\theta}_{j}^{r}\)</span></p>
</li>
<li><p><strong>End For</strong></p></li>
</ol>
</li>
<li><p><strong>End For</strong></p></li>
<li><p><strong>Until</strong> Un criterio de parada se cumpla.</p></li>
</ol>
</section>
</div><ul class="simple">
<li><p>El algoritmo de <code class="docutils literal notranslate"><span class="pre">backpropagation</span></code> puede reivindicar una serie de padres. La popularización del algoritmo se asocia con el artículo clásico <span id="id4">[<a class="reference internal" href="biblio.html#id21" title="David E Rumelhart, Geoffrey E Hinton, and Ronald J Williams. Learning representations by back-propagating errors. nature, 323(6088):533–536, 1986.">Rumelhart <em>et al.</em>, 1986</a>]</span>, donde se proporciona la derivación del algoritmo. La idea de <code class="docutils literal notranslate"><span class="pre">backpropagation</span></code> también aparece en <span id="id5">[<a class="reference internal" href="biblio.html#id22" title="Arthur E Bryson Jr, Walter F Denham, and Stewart E Dreyfus. Optimal programming problems with inequality constraints. AIAA journal, 1(11):2544–2550, 1963.">Bryson Jr <em>et al.</em>, 1963</a>]</span> en el contexto del control óptimo.</p></li>
<li><p>Existen diferentes variaciones del algoritmo <code class="docutils literal notranslate"><span class="pre">backpropagation</span></code>, tales como: <code class="docutils literal notranslate"><span class="pre">Gradiende</span> <span class="pre">descendiente</span> <span class="pre">con</span> <span class="pre">término</span> <span class="pre">de</span> <span class="pre">momento,</span> <span class="pre">Algoritmo</span> <span class="pre">de</span> <span class="pre">momentos</span> <span class="pre">de</span> <span class="pre">Nesterov's,</span> <span class="pre">Algoritmo</span> <span class="pre">AdaGrad,</span> <span class="pre">RMSProp</span> <span class="pre">con</span> <span class="pre">momento</span> <span class="pre">de</span> <span class="pre">Nesterov,</span> <span class="pre">Algortimo</span> <span class="pre">de</span> <span class="pre">estimación</span> <span class="pre">de</span> <span class="pre">momentos</span> <span class="pre">adaptativo</span></code> los cuales pueden ser utlizados para resolver la tarea de optimización (ver <span id="id6">[<a class="reference internal" href="biblio.html#id17" title="S. Theodoridis. Machine Learning: A Bayesian and Optimization Perspective. Elsevier Science, 2020. ISBN 9780128188040. URL: https://books.google.com.co/books?id=l-nEDwAAQBAJ.">Theodoridis, 2020</a>]</span>).</p></li>
</ul>
</section>
<section id="tuning-de-redes-neuronales">
<h2>Tuning de Redes Neuronales<a class="headerlink" href="#tuning-de-redes-neuronales" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Profundizaremos en la <code class="docutils literal notranslate"><span class="pre">mecánica</span> <span class="pre">del</span> <span class="pre">Perceptrón</span> <span class="pre">Multicapa</span> <span class="pre">(MLP)</span></code> empleando el <code class="docutils literal notranslate"><span class="pre">MLPClassifier()</span> <span class="pre">en</span> <span class="pre">el</span> <span class="pre">conjunto</span> <span class="pre">de</span> <span class="pre">datos</span> <span class="pre">two_moons</span></code> que se utilizó anteriormente en esta sección</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.neural_network</span> <span class="kn">import</span> <span class="n">MLPClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_moons</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">import</span> <span class="nn">mglearn</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_moons</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mlp</span> <span class="o">=</span> <span class="n">MLPClassifier</span><span class="p">(</span><span class="n">solver</span><span class="o">=</span><span class="s1">&#39;lbfgs&#39;</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mglearn</span><span class="o">.</span><span class="n">plots</span><span class="o">.</span><span class="n">plot_2d_separator</span><span class="p">(</span><span class="n">mlp</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">fill</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">.3</span><span class="p">)</span>
<span class="n">mglearn</span><span class="o">.</span><span class="n">discrete_scatter</span><span class="p">(</span><span class="n">X_train</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_train</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Feature 0&quot;</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Feature 1&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/39d03721fe580f58904598dd7d26acca0783a07e35c4370c6bd5cf841be46a19.png" src="_images/39d03721fe580f58904598dd7d26acca0783a07e35c4370c6bd5cf841be46a19.png" />
</div>
</div>
<ul class="simple">
<li><p>Evidentemente, la <code class="docutils literal notranslate"><span class="pre">red</span> <span class="pre">neuronal</span></code> ha adquirido un <code class="docutils literal notranslate"><span class="pre">límite</span> <span class="pre">de</span> <span class="pre">decisión</span> <span class="pre">decisivamente</span> <span class="pre">no</span> <span class="pre">lineal</span></code> pero relativamente gradual. Se empleó el <code class="docutils literal notranslate"><span class="pre">algoritmo</span> <span class="pre">'lbfgs'</span></code> (ver <a class="reference external" href="https://en.wikipedia.org/wiki/Broyden%E2%80%93Fletcher%E2%80%93Goldfarb%E2%80%93Shanno_algorithm">Broyden–Fletcher–Goldfarb–Shanno algorithm</a>, <code class="docutils literal notranslate"><span class="pre">optimizador</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">familia</span> <span class="pre">de</span> <span class="pre">los</span> <span class="pre">métodos</span> <span class="pre">cuasi-Newton.)</span></code>. En particular, el <code class="docutils literal notranslate"><span class="pre">MLP</span> <span class="pre">emplea</span> <span class="pre">100</span> <span class="pre">nodos</span> <span class="pre">ocultos</span> <span class="pre">por</span> <span class="pre">defecto</span></code>, un número considerable para este conjunto de datos compacto. Sin embargo, <code class="docutils literal notranslate"><span class="pre">incluso</span> <span class="pre">con</span> <span class="pre">un</span> <span class="pre">número</span> <span class="pre">reducido</span> <span class="pre">de</span> <span class="pre">nodos,</span> <span class="pre">se</span> <span class="pre">puede</span> <span class="pre">lograr</span> <span class="pre">un</span> <span class="pre">resultado</span> <span class="pre">satisfactorio</span></code></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mlp</span> <span class="o">=</span> <span class="n">MLPClassifier</span><span class="p">(</span><span class="n">solver</span><span class="o">=</span><span class="s1">&#39;lbfgs&#39;</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">400</span><span class="p">,</span> <span class="n">hidden_layer_sizes</span><span class="o">=</span><span class="p">[</span><span class="mi">10</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mlp</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-1" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>MLPClassifier(hidden_layer_sizes=[10], max_iter=400, random_state=0,
              solver=&#x27;lbfgs&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-1" type="checkbox" checked><label for="sk-estimator-id-1" class="sk-toggleable__label sk-toggleable__label-arrow">MLPClassifier</label><div class="sk-toggleable__content"><pre>MLPClassifier(hidden_layer_sizes=[10], max_iter=400, random_state=0,
              solver=&#x27;lbfgs&#x27;)</pre></div></div></div></div></div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mglearn</span><span class="o">.</span><span class="n">plots</span><span class="o">.</span><span class="n">plot_2d_separator</span><span class="p">(</span><span class="n">mlp</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">fill</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">.3</span><span class="p">)</span>
<span class="n">mglearn</span><span class="o">.</span><span class="n">discrete_scatter</span><span class="p">(</span><span class="n">X_train</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_train</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Feature 0&quot;</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Feature 1&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/5cb49ce05468c2ee5b0d89a7c0b461edc1c9533d2126d654f2a17228ecfd1bb4.png" src="_images/5cb49ce05468c2ee5b0d89a7c0b461edc1c9533d2126d654f2a17228ecfd1bb4.png" />
</div>
</div>
<ul class="simple">
<li><p>Al <code class="docutils literal notranslate"><span class="pre">reducir</span> <span class="pre">las</span> <span class="pre">unidades</span> <span class="pre">ocultas</span> <span class="pre">a</span> <span class="pre">10</span> <span class="pre">hace</span> <span class="pre">que</span> <span class="pre">el</span> <span class="pre">límite</span> <span class="pre">de</span> <span class="pre">decisión</span> <span class="pre">tenga</span> <span class="pre">un</span> <span class="pre">aspecto</span> <span class="pre">algo</span> <span class="pre">irregular</span></code>. La <code class="docutils literal notranslate"><span class="pre">no</span> <span class="pre">linealidad</span> <span class="pre">por</span> <span class="pre">defecto</span> <span class="pre">empleada</span> <span class="pre">es</span> <span class="pre">la</span> <span class="pre">&quot;relu&quot;</span></code></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">line</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">line</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">line</span><span class="p">),</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;tanh&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">line</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">line</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s2">&quot;best&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;x&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;relu(x), tanh(x)&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/f03d6676369d98afa601815c4ba99eb8bad03183f7411d260bbc62ffcca1e944.png" src="_images/f03d6676369d98afa601815c4ba99eb8bad03183f7411d260bbc62ffcca1e944.png" />
</div>
</div>
<ul class="simple">
<li><p>En el caso de <code class="docutils literal notranslate"><span class="pre">una</span> <span class="pre">sola</span> <span class="pre">capa</span> <span class="pre">oculta</span></code>, esto implica que la <code class="docutils literal notranslate"><span class="pre">función</span> <span class="pre">de</span> <span class="pre">decisión</span> <span class="pre">comprende</span> <span class="pre">10</span> <span class="pre">segmentos</span> <span class="pre">de</span> <span class="pre">línea</span> <span class="pre">recta</span></code>. Para conseguir un <code class="docutils literal notranslate"><span class="pre">límite</span> <span class="pre">de</span> <span class="pre">decisión</span> <span class="pre">más</span> <span class="pre">gradual</span></code>, las alternativas incluyen <code class="docutils literal notranslate"><span class="pre">aumentar</span> <span class="pre">las</span> <span class="pre">unidades</span> <span class="pre">ocultas,</span> <span class="pre">introducir</span> <span class="pre">una</span> <span class="pre">segunda</span> <span class="pre">capa</span> <span class="pre">oculta</span> <span class="pre">o</span> <span class="pre">emplear</span> <span class="pre">la</span> <span class="pre">no</span> <span class="pre">linealidad</span> <span class="pre">&quot;tanh&quot;</span></code>.</p></li>
</ul>
<ul class="simple">
<li><p>Utilizando <code class="docutils literal notranslate"><span class="pre">dos</span> <span class="pre">capas</span> <span class="pre">ocultas,</span> <span class="pre">con</span> <span class="pre">10</span> <span class="pre">unidades</span> <span class="pre">cada</span> <span class="pre">una</span></code></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mlp</span> <span class="o">=</span> <span class="n">MLPClassifier</span><span class="p">(</span><span class="n">solver</span><span class="o">=</span><span class="s1">&#39;lbfgs&#39;</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">hidden_layer_sizes</span><span class="o">=</span><span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mlp</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>C:\Users\USER\miniconda3\envs\ml_tf\lib\site-packages\sklearn\neural_network\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result(&quot;lbfgs&quot;, opt_res, self.max_iter)
</pre></div>
</div>
<div class="output text_html"><style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-2" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>MLPClassifier(hidden_layer_sizes=[10, 10], random_state=0, solver=&#x27;lbfgs&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-2" type="checkbox" checked><label for="sk-estimator-id-2" class="sk-toggleable__label sk-toggleable__label-arrow">MLPClassifier</label><div class="sk-toggleable__content"><pre>MLPClassifier(hidden_layer_sizes=[10, 10], random_state=0, solver=&#x27;lbfgs&#x27;)</pre></div></div></div></div></div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mglearn</span><span class="o">.</span><span class="n">plots</span><span class="o">.</span><span class="n">plot_2d_separator</span><span class="p">(</span><span class="n">mlp</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">fill</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">.3</span><span class="p">)</span>
<span class="n">mglearn</span><span class="o">.</span><span class="n">discrete_scatter</span><span class="p">(</span><span class="n">X_train</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_train</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Feature 0&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Feature 1&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/9881eab1c8c5f303fc85691a7e92dc0ad8502071ca6a8aa1677013211ddf8764.png" src="_images/9881eab1c8c5f303fc85691a7e92dc0ad8502071ca6a8aa1677013211ddf8764.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mlp</span> <span class="o">=</span> <span class="n">MLPClassifier</span><span class="p">(</span><span class="n">solver</span><span class="o">=</span><span class="s1">&#39;lbfgs&#39;</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;tanh&#39;</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">400</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">hidden_layer_sizes</span><span class="o">=</span><span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mlp</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-3" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>MLPClassifier(activation=&#x27;tanh&#x27;, hidden_layer_sizes=[10, 10], max_iter=400,
              random_state=0, solver=&#x27;lbfgs&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-3" type="checkbox" checked><label for="sk-estimator-id-3" class="sk-toggleable__label sk-toggleable__label-arrow">MLPClassifier</label><div class="sk-toggleable__content"><pre>MLPClassifier(activation=&#x27;tanh&#x27;, hidden_layer_sizes=[10, 10], max_iter=400,
              random_state=0, solver=&#x27;lbfgs&#x27;)</pre></div></div></div></div></div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mglearn</span><span class="o">.</span><span class="n">plots</span><span class="o">.</span><span class="n">plot_2d_separator</span><span class="p">(</span><span class="n">mlp</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">fill</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">.3</span><span class="p">)</span>
<span class="n">mglearn</span><span class="o">.</span><span class="n">discrete_scatter</span><span class="p">(</span><span class="n">X_train</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_train</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Feature 0&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Feature 1&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/20a661fa9634bd3588646535a4146efaf4b4d7bc8749bdaf2439e2d58681f514.png" src="_images/20a661fa9634bd3588646535a4146efaf4b4d7bc8749bdaf2439e2d58681f514.png" />
</div>
</div>
<ul class="simple">
<li><p>Además, podemos <code class="docutils literal notranslate"><span class="pre">influir</span> <span class="pre">en</span> <span class="pre">la</span> <span class="pre">complejidad</span> <span class="pre">de</span> <span class="pre">una</span> <span class="pre">red</span> <span class="pre">neuronal</span> <span class="pre">incorporando</span> <span class="pre">una</span> <span class="pre">penalización</span> <span class="pre">l2</span></code>, similar al enfoque de la <code class="docutils literal notranslate"><span class="pre">regresión</span> <span class="pre">de</span> <span class="pre">ridge</span> <span class="pre">y</span> <span class="pre">los</span> <span class="pre">clasificadores</span> <span class="pre">lineales</span></code>. El parámetro responsable de esto en el <code class="docutils literal notranslate"><span class="pre">MLPClassifier</span> <span class="pre">es</span> <span class="pre">'alpha'</span></code>, análogo a los modelos de regresión lineal. Por <code class="docutils literal notranslate"><span class="pre">defecto,</span> <span class="pre">asume</span> <span class="pre">un</span> <span class="pre">valor</span> <span class="pre">mínimo</span> <span class="pre">(regularización</span> <span class="pre">limitada)</span></code>. El siguiente experimento incluye <code class="docutils literal notranslate"><span class="pre">dos</span> <span class="pre">capas</span> <span class="pre">ocultas</span></code>, cada una de ellas compuesta por 10 o 100 unidades y <code class="docutils literal notranslate"><span class="pre">diferentes</span> <span class="pre">valores</span> <span class="pre">de</span> <span class="pre">alpha</span></code></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>

<span class="k">for</span> <span class="n">axx</span><span class="p">,</span> <span class="n">n_hidden_nodes</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">axes</span><span class="p">,</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">]):</span>
    <span class="k">for</span> <span class="n">ax</span><span class="p">,</span> <span class="n">alpha</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">axx</span><span class="p">,</span> <span class="p">[</span><span class="mf">0.0001</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]):</span>
        <span class="n">mlp</span> <span class="o">=</span> <span class="n">MLPClassifier</span><span class="p">(</span><span class="n">solver</span><span class="o">=</span><span class="s1">&#39;lbfgs&#39;</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">hidden_layer_sizes</span><span class="o">=</span><span class="p">[</span><span class="n">n_hidden_nodes</span><span class="p">,</span> <span class="n">n_hidden_nodes</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">)</span>
        <span class="n">mlp</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
        <span class="n">mglearn</span><span class="o">.</span><span class="n">plots</span><span class="o">.</span><span class="n">plot_2d_separator</span><span class="p">(</span><span class="n">mlp</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">fill</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">.3</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
        <span class="n">mglearn</span><span class="o">.</span><span class="n">discrete_scatter</span><span class="p">(</span><span class="n">X_train</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_train</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;n_hidden=[</span><span class="si">{}</span><span class="s2">, </span><span class="si">{}</span><span class="s2">]</span><span class="se">\n</span><span class="s2">alpha=</span><span class="si">{:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">n_hidden_nodes</span><span class="p">,</span> <span class="n">n_hidden_nodes</span><span class="p">,</span> <span class="n">alpha</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/9f15f4762b0aa8dcd19e1f5ba18419fbdb685b81a1157f4b5e4926a9bc68a01d.png" src="_images/9f15f4762b0aa8dcd19e1f5ba18419fbdb685b81a1157f4b5e4926a9bc68a01d.png" />
</div>
</div>
<div class="proof observation admonition" id="observation_ann1">
<p class="admonition-title"><span class="caption-number">Observation 9 </span></p>
<section class="observation-content" id="proof-content">
<ul class="simple">
<li><p>Como habrá podido comprobar, <code class="docutils literal notranslate"><span class="pre">existen</span> <span class="pre">multitud</span> <span class="pre">de</span> <span class="pre">métodos</span> <span class="pre">para</span> <span class="pre">gestionar</span> <span class="pre">la</span> <span class="pre">complejidad</span> <span class="pre">de</span> <span class="pre">una</span> <span class="pre">red</span> <span class="pre">neuronal</span></code>, como el <code class="docutils literal notranslate"><span class="pre">número</span> <span class="pre">de</span> <span class="pre">capas</span> <span class="pre">ocultas,</span> <span class="pre">las</span> <span class="pre">unidades</span> <span class="pre">en</span> <span class="pre">cada</span> <span class="pre">capa</span> <span class="pre">oculta</span> <span class="pre">y</span> <span class="pre">la</span> <span class="pre">regularización</span> <span class="pre">(alpha)</span></code>, entre otros. Un rasgo fundamental de las redes neuronales reside en su <code class="docutils literal notranslate"><span class="pre">configuración</span> <span class="pre">aleatoria</span> <span class="pre">inicial</span> <span class="pre">de</span> <span class="pre">pesos</span> <span class="pre">antes</span> <span class="pre">de</span> <span class="pre">comenzar</span> <span class="pre">el</span> <span class="pre">aprendizaje</span></code>. Esta aleatoriedad influye en el modelo aprendido resultante. Así, <code class="docutils literal notranslate"><span class="pre">el</span> <span class="pre">empleo</span> <span class="pre">de</span> <span class="pre">parámetros</span> <span class="pre">idénticos</span> <span class="pre">puede</span> <span class="pre">dar</span> <span class="pre">lugar</span> <span class="pre">a</span> <span class="pre">modelos</span> <span class="pre">distintos</span> <span class="pre">debido</span> <span class="pre">a</span> <span class="pre">semillas</span> <span class="pre">aleatorias</span> <span class="pre">diferentes</span></code>. Mientras que este efecto es más pronunciado para redes pequeñas, es <code class="docutils literal notranslate"><span class="pre">menos</span> <span class="pre">significativo</span> <span class="pre">para</span> <span class="pre">redes</span> <span class="pre">de</span> <span class="pre">tamaño</span> <span class="pre">adecuado</span> <span class="pre">donde</span> <span class="pre">la</span> <span class="pre">complejidad</span> <span class="pre">se</span> <span class="pre">elige</span> <span class="pre">apropiadamente</span></code>.</p></li>
</ul>
</section>
</div><div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">ax</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">axes</span><span class="o">.</span><span class="n">ravel</span><span class="p">()):</span>
    <span class="n">mlp</span> <span class="o">=</span> <span class="n">MLPClassifier</span><span class="p">(</span><span class="n">solver</span><span class="o">=</span><span class="s1">&#39;lbfgs&#39;</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">i</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">2000</span><span class="p">,</span> <span class="n">hidden_layer_sizes</span><span class="o">=</span><span class="p">[</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">])</span>
    <span class="n">mlp</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">mglearn</span><span class="o">.</span><span class="n">plots</span><span class="o">.</span><span class="n">plot_2d_separator</span><span class="p">(</span><span class="n">mlp</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">fill</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">.3</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
    <span class="n">mglearn</span><span class="o">.</span><span class="n">discrete_scatter</span><span class="p">(</span><span class="n">X_train</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_train</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/058826e7a0ff900256d4f1420b7969c541a43ed3a51a607aa7eba9ecde5c0fd9.png" src="_images/058826e7a0ff900256d4f1420b7969c541a43ed3a51a607aa7eba9ecde5c0fd9.png" />
</div>
</div>
<ul class="simple">
<li><p>Para una <code class="docutils literal notranslate"><span class="pre">comprensión</span> <span class="pre">más</span> <span class="pre">completa</span> <span class="pre">de</span> <span class="pre">las</span> <span class="pre">redes</span> <span class="pre">neuronales</span> <span class="pre">en</span> <span class="pre">escenarios</span> <span class="pre">prácticos</span></code>, implementaremos el <code class="docutils literal notranslate"><span class="pre">MLPClassifier</span> <span class="pre">en</span> <span class="pre">el</span> <span class="pre">conjunto</span> <span class="pre">de</span> <span class="pre">datos</span> <span class="pre">Breast</span> <span class="pre">Cancer</span></code>. Nuestro paso <code class="docutils literal notranslate"><span class="pre">inicial</span> <span class="pre">consiste</span> <span class="pre">en</span> <span class="pre">utilizar</span> <span class="pre">los</span> <span class="pre">parámetros</span> <span class="pre">por</span> <span class="pre">defecto</span></code>. Queda como tarea para el estudiante, utilizar <code class="docutils literal notranslate"><span class="pre">GridSearchCV</span> <span class="pre">y</span> <span class="pre">Pipeline</span></code>.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_breast_cancer</span>
<span class="n">cancer</span> <span class="o">=</span> <span class="n">load_breast_cancer</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Cancer data per-feature maxima:</span><span class="se">\n</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">cancer</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cancer data per-feature maxima:
[2.811e+01 3.928e+01 1.885e+02 2.501e+03 1.634e-01 3.454e-01 4.268e-01
 2.012e-01 3.040e-01 9.744e-02 2.873e+00 4.885e+00 2.198e+01 5.422e+02
 3.113e-02 1.354e-01 3.960e-01 5.279e-02 7.895e-02 2.984e-02 3.604e+01
 4.954e+01 2.512e+02 4.254e+03 2.226e-01 1.058e+00 1.252e+00 2.910e-01
 6.638e-01 2.075e-01]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">cancer</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">cancer</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mlp</span> <span class="o">=</span> <span class="n">MLPClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mlp</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-4" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>MLPClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-4" type="checkbox" checked><label for="sk-estimator-id-4" class="sk-toggleable__label sk-toggleable__label-arrow">MLPClassifier</label><div class="sk-toggleable__content"><pre>MLPClassifier(random_state=42)</pre></div></div></div></div></div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy on training set: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">mlp</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy on test set: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">mlp</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Accuracy on training set: 0.94
Accuracy on test set: 0.92
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>El <code class="docutils literal notranslate"><span class="pre">MLP</span> <span class="pre">muestra</span> <span class="pre">una</span> <span class="pre">precisión</span> <span class="pre">notable,</span> <span class="pre">aunque</span> <span class="pre">no</span> <span class="pre">a</span> <span class="pre">la</span> <span class="pre">par</span> <span class="pre">de</span> <span class="pre">otros</span> <span class="pre">modelos</span></code>. Al igual que en el caso anterior del <code class="docutils literal notranslate"><span class="pre">SVC</span></code>, esta <code class="docutils literal notranslate"><span class="pre">discrepancia</span> <span class="pre">se</span> <span class="pre">debe</span> <span class="pre">probablemente</span> <span class="pre">al</span> <span class="pre">escalado</span> <span class="pre">de</span> <span class="pre">los</span> <span class="pre">datos</span></code>. Las <code class="docutils literal notranslate"><span class="pre">redes</span> <span class="pre">neuronales</span> <span class="pre">exigen</span> <span class="pre">una</span> <span class="pre">varianza</span> <span class="pre">uniforme</span> <span class="pre">entre</span> <span class="pre">las</span> <span class="pre">características</span> <span class="pre">de</span> <span class="pre">entrada</span></code>, idealmente con una <code class="docutils literal notranslate"><span class="pre">media</span> <span class="pre">de</span> <span class="pre">0</span> <span class="pre">y</span> <span class="pre">una</span> <span class="pre">varianza</span> <span class="pre">de</span> <span class="pre">1</span></code>. Para satisfacer estos criterios, <code class="docutils literal notranslate"><span class="pre">los</span> <span class="pre">datos</span> <span class="pre">deben</span> <span class="pre">reescalarse</span></code>. Mientras que aquí estamos implementando este proceso manualmente, en el capítulo <code class="docutils literal notranslate"><span class="pre">Evaluación</span> <span class="pre">de</span> <span class="pre">modelos</span> <span class="pre">y</span> <span class="pre">Pipelines</span></code> se usa <code class="docutils literal notranslate"><span class="pre">StandardScaler</span></code> para el <code class="docutils literal notranslate"><span class="pre">manejo</span> <span class="pre">automatizado</span> <span class="pre">de</span> <span class="pre">este</span> <span class="pre">procedimiento</span></code></p></li>
</ul>
<ul class="simple">
<li><p>Calculamos el <code class="docutils literal notranslate"><span class="pre">valor</span> <span class="pre">medio</span> <span class="pre">por</span> <span class="pre">característica</span></code> en el conjunto de entrenamiento</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mean_on_train</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Calculamos la <code class="docutils literal notranslate"><span class="pre">desviación</span> <span class="pre">estándar</span> <span class="pre">de</span> <span class="pre">cada</span> <span class="pre">característica</span></code> en el conjunto de entrenamiento</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">std_on_train</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Procedemos con el proceso de <code class="docutils literal notranslate"><span class="pre">estandarización</span> <span class="pre">a</span> <span class="pre">media</span> <span class="pre">0</span> <span class="pre">y</span> <span class="pre">desviación</span> <span class="pre">1</span></code></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train_scaled</span> <span class="o">=</span> <span class="p">(</span><span class="n">X_train</span> <span class="o">-</span> <span class="n">mean_on_train</span><span class="p">)</span> <span class="o">/</span> <span class="n">std_on_train</span>
<span class="n">X_test_scaled</span>  <span class="o">=</span> <span class="p">(</span><span class="n">X_test</span> <span class="o">-</span> <span class="n">mean_on_train</span><span class="p">)</span> <span class="o">/</span> <span class="n">std_on_train</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mlp</span> <span class="o">=</span> <span class="n">MLPClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">400</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mlp</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-5" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>MLPClassifier(max_iter=400, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-5" type="checkbox" checked><label for="sk-estimator-id-5" class="sk-toggleable__label sk-toggleable__label-arrow">MLPClassifier</label><div class="sk-toggleable__content"><pre>MLPClassifier(max_iter=400, random_state=0)</pre></div></div></div></div></div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy on training set: </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">mlp</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy on test set: </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">mlp</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test_scaled</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Accuracy on training set: 1.000
Accuracy on test set: 0.972
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Dado que se aprecia una <code class="docutils literal notranslate"><span class="pre">disparidad</span> <span class="pre">entre</span> <span class="pre">el</span> <span class="pre">rendimiento</span> <span class="pre">de</span> <span class="pre">entrenamiento</span> <span class="pre">y</span> <span class="pre">el</span> <span class="pre">de</span> <span class="pre">prueba</span></code>, se puede intentar <code class="docutils literal notranslate"><span class="pre">mejorar</span> <span class="pre">el</span> <span class="pre">rendimiento</span> <span class="pre">de</span> <span class="pre">generalización</span> <span class="pre">reduciendo</span> <span class="pre">la</span> <span class="pre">complejidad</span> <span class="pre">del</span> <span class="pre">modelo</span></code>. En este escenario, optamos por <code class="docutils literal notranslate"><span class="pre">intensificar</span> <span class="pre">el</span> <span class="pre">parámetro</span> <span class="pre">&quot;alpha&quot;</span> <span class="pre">(de</span> <span class="pre">0.0001</span> <span class="pre">a</span> <span class="pre">1)</span></code> para <code class="docutils literal notranslate"><span class="pre">imponer</span> <span class="pre">una</span> <span class="pre">regularización</span> <span class="pre">más</span> <span class="pre">potente</span> <span class="pre">de</span> <span class="pre">los</span> <span class="pre">pesos</span></code></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mlp</span> <span class="o">=</span> <span class="n">MLPClassifier</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mlp</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><style>#sk-container-id-6 {color: black;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-6" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>MLPClassifier(alpha=1, max_iter=1000, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-6" type="checkbox" checked><label for="sk-estimator-id-6" class="sk-toggleable__label sk-toggleable__label-arrow">MLPClassifier</label><div class="sk-toggleable__content"><pre>MLPClassifier(alpha=1, max_iter=1000, random_state=0)</pre></div></div></div></div></div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy on training set: </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">mlp</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy on test set: </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">mlp</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test_scaled</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Accuracy on training set: 0.988
Accuracy on test set: 0.972
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Descubrir</span> <span class="pre">lo</span> <span class="pre">que</span> <span class="pre">ha</span> <span class="pre">aprendido</span> <span class="pre">una</span> <span class="pre">red</span> <span class="pre">neuronal</span> <span class="pre">suele</span> <span class="pre">ser</span> <span class="pre">todo</span> <span class="pre">un</span> <span class="pre">reto</span></code>. Una técnica para comprender mejor los conocimientos adquiridos consiste en <code class="docutils literal notranslate"><span class="pre">analizar</span> <span class="pre">los</span> <span class="pre">pesos</span> <span class="pre">del</span> <span class="pre">modelo</span></code>. Puede ver un ejemplo en la galería de <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code>. Sin embargo, para el conjunto de <code class="docutils literal notranslate"><span class="pre">datos</span> <span class="pre">de</span> <span class="pre">Cáncer</span> <span class="pre">de</span> <span class="pre">Mama,</span> <span class="pre">la</span> <span class="pre">comprensión</span> <span class="pre">puede</span> <span class="pre">ser</span> <span class="pre">algo</span> <span class="pre">desafiante</span></code>. La siguiente rutina muestra los <code class="docutils literal notranslate"><span class="pre">pesos</span> <span class="pre">aprendidos,</span> <span class="pre">conectando</span> <span class="pre">la</span> <span class="pre">entrada</span> <span class="pre">a</span> <span class="pre">la</span> <span class="pre">primera</span> <span class="pre">capa</span> <span class="pre">oculta</span></code>. Las <code class="docutils literal notranslate"><span class="pre">filas</span> <span class="pre">corresponden</span> <span class="pre">a</span> <span class="pre">las</span> <span class="pre">30</span> <span class="pre">características</span> <span class="pre">de</span> <span class="pre">entrada</span></code>, mientras que las <code class="docutils literal notranslate"><span class="pre">columnas</span> <span class="pre">corresponden</span> <span class="pre">a</span> <span class="pre">las</span> <span class="pre">100</span> <span class="pre">unidades</span> <span class="pre">ocultas</span></code>.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">15</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">font_scale</span><span class="o">=</span><span class="mf">1.8</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">mlp</span><span class="o">.</span><span class="n">coefs_</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">interpolation</span><span class="o">=</span><span class="s1">&#39;none&#39;</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;viridis&#39;</span><span class="p">,</span> <span class="n">aspect</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">30</span><span class="p">),</span> <span class="n">cancer</span><span class="o">.</span><span class="n">feature_names</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Columns in weight matrix&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Input feature&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">();</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/f38d49e4f16b6f82b34fbe19be913078773a80f9d6ecfffbf5c22d4d9eb6a15c.png" src="_images/f38d49e4f16b6f82b34fbe19be913078773a80f9d6ecfffbf5c22d4d9eb6a15c.png" />
</div>
</div>
<ul class="simple">
<li><p>Una posible inferencia que podemos hacer es que las <code class="docutils literal notranslate"><span class="pre">características</span> <span class="pre">que</span> <span class="pre">tienen</span> <span class="pre">pesos</span> <span class="pre">muy</span> <span class="pre">pequeños</span> <span class="pre">para</span> <span class="pre">todas</span> <span class="pre">las</span> <span class="pre">unidades</span> <span class="pre">ocultas</span> <span class="pre">son</span> <span class="pre">&quot;menos</span> <span class="pre">importantes&quot;</span> <span class="pre">para</span> <span class="pre">el</span> <span class="pre">modelo</span></code>. Podemos ver que <code class="docutils literal notranslate"><span class="pre">&quot;mean</span> <span class="pre">smoothness&quot;</span></code> y <code class="docutils literal notranslate"><span class="pre">&quot;mean</span> <span class="pre">compactness&quot;</span></code>, además de las características encontradas entre <code class="docutils literal notranslate"><span class="pre">&quot;smoothness</span> <span class="pre">error&quot;</span></code> y <code class="docutils literal notranslate"><span class="pre">&quot;fractal</span> <span class="pre">dimension</span> <span class="pre">error&quot;</span></code>, tienen <code class="docutils literal notranslate"><span class="pre">pesos</span> <span class="pre">relativamente</span> <span class="pre">bajos</span> <span class="pre">comparados</span> <span class="pre">con</span> <span class="pre">otras</span> <span class="pre">características</span></code>. Esto podría significar que se trata de <code class="docutils literal notranslate"><span class="pre">rasgos</span> <span class="pre">menos</span> <span class="pre">importantes</span> <span class="pre">o,</span> <span class="pre">posiblemente,</span> <span class="pre">que</span> <span class="pre">no</span> <span class="pre">las</span> <span class="pre">representamos</span> <span class="pre">de</span> <span class="pre">forma</span> <span class="pre">que</span> <span class="pre">la</span> <span class="pre">red</span> <span class="pre">neuronal</span> <span class="pre">pudiera</span> <span class="pre">utilizarlas.</span></code></p></li>
<li><p>También podemos <code class="docutils literal notranslate"><span class="pre">visualizar</span> <span class="pre">los</span> <span class="pre">pesos</span> <span class="pre">que</span> <span class="pre">conectan</span> <span class="pre">la</span> <span class="pre">capa</span> <span class="pre">oculta</span> <span class="pre">con</span> <span class="pre">la</span> <span class="pre">capa</span> <span class="pre">de</span> <span class="pre">salida,</span> <span class="pre">pero</span> <span class="pre">son</span> <span class="pre">aún</span> <span class="pre">más</span> <span class="pre">difíciles</span> <span class="pre">de</span> <span class="pre">interpretar</span></code>. Aunque <code class="docutils literal notranslate"><span class="pre">MLPClassifier</span> <span class="pre">y</span> <span class="pre">MLPRegressor</span> <span class="pre">proporcionan</span> <span class="pre">interfaces</span> <span class="pre">fáciles</span> <span class="pre">de</span> <span class="pre">usar</span></code> para las arquitecturas de redes neuronales más comunes, <code class="docutils literal notranslate"><span class="pre">sólo</span> <span class="pre">capturan</span> <span class="pre">un</span> <span class="pre">pequeño</span> <span class="pre">subconjunto</span> <span class="pre">de</span> <span class="pre">lo</span> <span class="pre">que</span> <span class="pre">es</span> <span class="pre">posible</span> <span class="pre">con</span> <span class="pre">las</span> <span class="pre">redes</span> <span class="pre">neuronales</span></code>. Si está interesado en trabajar con <code class="docutils literal notranslate"><span class="pre">modelos</span> <span class="pre">más</span> <span class="pre">flexibles</span> <span class="pre">o</span> <span class="pre">modelos</span> <span class="pre">más</span> <span class="pre">grandes</span></code>, se recomienda mirar más allá de <code class="docutils literal notranslate"><span class="pre">scikit-learn</span> <span class="pre">en</span> <span class="pre">las</span> <span class="pre">fantásticas</span> <span class="pre">bibliotecas</span> <span class="pre">de</span> <span class="pre">aprendizaje</span> <span class="pre">profundo</span></code>. Para los usuarios de <code class="docutils literal notranslate"><span class="pre">Python</span></code>, las más conocidas son <code class="docutils literal notranslate"><span class="pre">keras,</span> <span class="pre">lasagna</span> <span class="pre">y</span> <span class="pre">tensor-flow</span></code>. Estas bibliotecas proporcionan una interfaz mucho más <code class="docutils literal notranslate"><span class="pre">flexible</span> <span class="pre">para</span> <span class="pre">construir</span> <span class="pre">redes</span> <span class="pre">neuronales</span></code> y seguir el rápido progreso en la investigación del aprendizaje profundo, también permiten el uso de <code class="docutils literal notranslate"><span class="pre">unidades</span> <span class="pre">de</span> <span class="pre">procesamiento</span> <span class="pre">gráfico</span> <span class="pre">(GPU)</span> <span class="pre">de</span> <span class="pre">alto</span> <span class="pre">rendimiento</span> <span class="pre">que</span> <span class="pre">scikit-learn</span> <span class="pre">no</span> <span class="pre">soporta</span></code>.</p></li>
</ul>
</section>
<section id="analisis-de-malware-por-api-calls">
<h2>Análisis de Malware por API calls<a class="headerlink" href="#analisis-de-malware-por-api-calls" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>El siguiente conjunto de datos forma parte de una investigación sobre la <code class="docutils literal notranslate"><span class="pre">detección</span> <span class="pre">y</span> <span class="pre">clasificación</span> <span class="pre">de</span> <span class="pre">Malware</span> <span class="pre">mediante</span> <span class="pre">Deep</span> <span class="pre">Learning</span></code> (ver <a class="reference external" href="https://www.techrxiv.org/articles/preprint/Behavioral_Malware_Detection_Using_Deep_Graph_Convolutional_Neural_Networks/10043099">Oliveira, Angelo; Sassi, Renato José (2019)</a>). Contiene <code class="docutils literal notranslate"><span class="pre">42.797</span> <span class="pre">secuencias</span> <span class="pre">de</span> <span class="pre">llamadas</span> <span class="pre">a</span> <span class="pre">la</span> <span class="pre">API</span> <span class="pre">de</span> <span class="pre">malware</span> <span class="pre">y</span> <span class="pre">1.079</span> <span class="pre">secuencias</span> <span class="pre">de</span> <span class="pre">llamadas</span> <span class="pre">a</span> <span class="pre">la</span> <span class="pre">API</span> <span class="pre">de</span> <span class="pre">goodware</span></code>. Cada secuencia de llamadas a la API se compone de las <code class="docutils literal notranslate"><span class="pre">100</span> <span class="pre">primeras</span> <span class="pre">llamadas</span> <span class="pre">a</span> <span class="pre">la</span> <span class="pre">API</span> <span class="pre">consecutivas</span> <span class="pre">no</span> <span class="pre">repetidas</span> <span class="pre">asociadas</span> <span class="pre">al</span> <span class="pre">proceso</span> <span class="pre">principal</span></code>, extraídas de los elementos <code class="docutils literal notranslate"><span class="pre">&quot;calls&quot;</span></code> de los informes de <a class="reference external" href="https://cuckoosandbox.org/">Cuckoo Sandbox</a>.</p></li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">Características</span></code></strong></p>
<ol class="arabic simple">
<li><ul>
<li><p><code class="docutils literal notranslate"><span class="pre">Nombre</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">columna</span></code>: hash</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Descripción</span></code>: El hash MD5 del ejemplo</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Tipo</span></code>: Cadena de 32 bytes</p></li>
</ul>
</li>
<li><ul>
<li><p><code class="docutils literal notranslate"><span class="pre">Nombre</span> <span class="pre">de</span> <span class="pre">columna</span></code>: t_0, t_1,…, t99</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Descripción</span></code>: Llamada a la API</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Tipo</span></code>: Entero (0-306)</p></li>
</ul>
</li>
<li><ul>
<li><p><code class="docutils literal notranslate"><span class="pre">Nombre</span> <span class="pre">de</span> <span class="pre">columna</span></code>: malware</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Descripción</span></code>: Clase</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Tipo</span></code>: Entero: 0 (Goodware) o 1 (Malware)</p></li>
</ul>
</li>
</ol>
</li>
</ul>
<figure class="align-center" id="trojan-horse-malware">
<a class="reference internal image-reference" href="_images/trojan_horse_malware.png"><img alt="_images/trojan_horse_malware.png" src="_images/trojan_horse_malware.png" style="width: 495.0px; height: 483.59999999999997px;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 42 </span><span class="caption-text">Gráfico de comportamiento del malware troyano con hash MD5 ac65ce897a1f0dc273e8dc54fe3768ec.</span><a class="headerlink" href="#trojan-horse-malware" title="Link to this image">#</a></p>
</figcaption>
</figure>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pylab</span> <span class="k">as</span> <span class="nn">pl</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span> 
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">from</span> <span class="nn">sklearn.utils</span> <span class="kn">import</span> <span class="n">shuffle</span>
<span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span><span class="p">,</span><span class="n">classification_report</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span><span class="p">,</span> <span class="n">GridSearchCV</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">make_pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.neural_network</span> <span class="kn">import</span> <span class="n">MLPClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">import</span> <span class="nn">pickle</span>
<span class="kn">import</span> <span class="nn">glob</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">f1_score</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">classification_report</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">roc_curve</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">precision_recall_curve</span>
<span class="kn">from</span> <span class="nn">time</span> <span class="kn">import</span> <span class="n">process_time</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;https://raw.githubusercontent.com/lihkir/Data/main/api_call_sequence_per_malware.csv&quot;</span><span class="p">)</span>
<span class="n">data</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(43876, 102)
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>La siguiente es una construida en el presente curso, la cual puede ser útil para quienes solo desean presentar unas cuantas columnas al inicio y al final de cada <code class="docutils literal notranslate"><span class="pre">pandas</span></code>. Solo requiere del nombre del <code class="docutils literal notranslate"><span class="pre">pandas</span></code> y el número de columnas que deseamos visualziar al inicio y al final. Es bastante util, para utilizar en los <code class="docutils literal notranslate"><span class="pre">Jupyter</span> <span class="pre">Books</span></code>, donde el espacio horizontal es reducido.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">idx_lr</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">n_new_cols</span><span class="p">):</span>
    <span class="n">n_data_cols</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
    <span class="n">idx_l</span>  <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">n_new_cols</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)))</span>
    <span class="n">idx_r</span>  <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">n_data_cols</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n_data_cols</span> <span class="o">-</span> <span class="n">n_new_cols</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)))</span>
    <span class="k">return</span> <span class="n">idx_l</span> <span class="o">+</span> <span class="n">idx_r</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Para imprimir por ejemplo las tres primeras columnas al inicio y al final del pandas <code class="docutils literal notranslate"><span class="pre">data</span></code> utilizamos la orden <code class="docutils literal notranslate"><span class="pre">data.iloc[:,</span> <span class="pre">idx_lr(data,</span> <span class="pre">4)]</span></code>. Nótese que no contamos con datos faltantes que requieran de un procedimiento de imputación (ver <a class="reference external" href="https://lihkir.github.io/ShinyDash/an%C3%A1lisis-con-datos-faltantes.html">Análisis con datos faltantes</a>). Además, nótese que todas las columnas con la excepción de <code class="docutils literal notranslate"><span class="pre">hash</span></code> corresponde a datos numericos discretos.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="n">idx_lr</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="mi">4</span><span class="p">)]</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>hash</th>
      <th>t_0</th>
      <th>t_1</th>
      <th>t_2</th>
      <th>t_97</th>
      <th>t_98</th>
      <th>t_99</th>
      <th>malware</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>071e8c3f8922e186e57548cd4c703a5d</td>
      <td>112</td>
      <td>274</td>
      <td>158</td>
      <td>208</td>
      <td>56</td>
      <td>71</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>33f8e6d08a6aae939f25a8e0d63dd523</td>
      <td>82</td>
      <td>208</td>
      <td>187</td>
      <td>171</td>
      <td>215</td>
      <td>35</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>b68abd064e975e1c6d5f25e748663076</td>
      <td>16</td>
      <td>110</td>
      <td>240</td>
      <td>65</td>
      <td>113</td>
      <td>112</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>72049be7bd30ea61297ea624ae198067</td>
      <td>82</td>
      <td>208</td>
      <td>187</td>
      <td>302</td>
      <td>228</td>
      <td>302</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>c9b3700a77facf29172f32df6bc77f48</td>
      <td>82</td>
      <td>240</td>
      <td>117</td>
      <td>260</td>
      <td>141</td>
      <td>260</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;# NaN values:&quot;</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">isna</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span># NaN values: 0
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data</span><span class="o">.</span><span class="n">dtypes</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>hash       object
t_0         int64
t_1         int64
t_2         int64
t_3         int64
            ...  
t_96        int64
t_97        int64
t_98        int64
t_99        int64
malware     int64
Length: 102, dtype: object
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Pasamos ahora a eliminar aquellas variables (columnas) irrelevantes en el análisis predictivo, a saber la columna <code class="docutils literal notranslate"><span class="pre">hash</span></code> del pandas <code class="docutils literal notranslate"><span class="pre">data</span></code> y creamos uno nuevo al cual nombraremos <code class="docutils literal notranslate"><span class="pre">data_new</span></code>.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data_new</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;hash&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">data_new</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(43876, 101)
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Verifiquemos si nuestros datos están desbalanceados respecto a las clases de interés <code class="docutils literal notranslate"> <span class="pre">0</span> <span class="pre">(Goodware)</span> <span class="pre">o</span> <span class="pre">1</span> <span class="pre">(Malware)</span></code></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib</span>
<span class="n">matplotlib</span><span class="o">.</span><span class="n">rc_file_defaults</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cnt_pro</span> <span class="o">=</span> <span class="n">data_new</span><span class="p">[</span><span class="s1">&#39;malware&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
<span class="n">sns</span><span class="o">.</span><span class="n">barplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">cnt_pro</span><span class="o">.</span><span class="n">index</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">cnt_pro</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Number of data&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Malware Type&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/25ba92077349077d09f2138896a4f62abea48edbbf536aec1119e4917722cf70.png" src="_images/25ba92077349077d09f2138896a4f62abea48edbbf536aec1119e4917722cf70.png" />
</div>
</div>
<ul class="simple">
<li><p>Claramente existe un desbalance entre los tipos de Malware. Por otro lado, verifiquemos para algunos Hash, como se distribuyen la frecuencia de cada uno de sus API calls. Las columnas representan las frecuencias de cada API call representado por los valores <code class="docutils literal notranslate"><span class="pre">t_0,</span> <span class="pre">t_1,...,</span> <span class="pre">t99</span></code>.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">12</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s2">&quot;Malware API Calls by Hash&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mf">0.92</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">ax</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">axs</span><span class="o">.</span><span class="n">ravel</span><span class="p">()):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
    <span class="n">n_hash</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">data_new</span><span class="p">))</span>
    <span class="n">data_new</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">n_hash</span><span class="p">,:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s1">&#39;bar&#39;</span><span class="p">,</span> <span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;Hash: &#39;</span><span class="o">+</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;hash&#39;</span><span class="p">][</span><span class="n">n_hash</span><span class="p">],</span> <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;API Call&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/6c49d4facf279156bed83d01d1cedf1397e2b3df4c1ae6d31e3c41d1d3e01f44.png" src="_images/6c49d4facf279156bed83d01d1cedf1397e2b3df4c1ae6d31e3c41d1d3e01f44.png" />
</div>
</div>
<ul class="simple">
<li><p>Procedemos a hacer uso de <code class="docutils literal notranslate"><span class="pre">make_pipeline</span></code> y <code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code> para obtener parámetros del mejor modelo. En este caso utilizaremos el clasificador <code class="docutils literal notranslate"><span class="pre">MLPClassifier</span></code>, el cual se estudió en clase de forma analítica.</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\boldsymbol{\theta}^{(i)}=\boldsymbol{\theta}^{(i-1)}-\mu_{i}\nabla J(\boldsymbol{\theta}^{(i-1)}),\quad\text{Gradiente descendiente}.
\]</div>
<ul class="simple">
<li><p>El algoritmo clasificador <code class="docutils literal notranslate"><span class="pre">MLPClassifier</span></code> denota el valor de la <code class="docutils literal notranslate"><span class="pre">longitud</span> <span class="pre">de</span> <span class="pre">paso</span></code> <span class="math notranslate nohighlight">\(\mu_{i}\)</span> como <code class="docutils literal notranslate"><span class="pre">learning_rate</span></code>, el cual asume los valores <code class="docutils literal notranslate"><span class="pre">constant,</span> <span class="pre">invscaling,</span> <span class="pre">adaptive</span></code>. En este ejemplo se ha probado con los tres parámetros, obteniendo siempre el mejor score cuando <code class="docutils literal notranslate"><span class="pre">learning_rate</span> <span class="pre">=</span> <span class="pre">constant</span></code>. Por otro lado, <code class="docutils literal notranslate"><span class="pre">hidden_layer_sizes</span></code> representa el número de neuronas en el <span class="math notranslate nohighlight">\(i\)</span>th layer. En este problema de clasificación optamos por selecciona desde uno a tres capas escondidas (<code class="docutils literal notranslate"><span class="pre">hidden</span> <span class="pre">layers</span></code>), pero siempre el mejor score entregado por <code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code>, fue obtenido considerando una sola capa. Por lo tanto en este problema hacemos solo un grid search sobre el número de neuronas sobre una sola capa. Dado que nuestro problema es de clasificación binaria, también consideramos en el <code class="docutils literal notranslate"><span class="pre">param_grid</span></code>, solo <code class="docutils literal notranslate"><span class="pre">activation</span> <span class="pre">=</span> <span class="pre">logistic</span></code>. Las opciones del clasificador son <code class="docutils literal notranslate"><span class="pre">identity,</span> <span class="pre">logistic,</span> <span class="pre">tanh,</span> <span class="pre">relu</span></code>, pero <code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code> entregó el mejor score usando <code class="docutils literal notranslate"><span class="pre">logistic</span></code> como era de esperarse. El parámetro <code class="docutils literal notranslate"><span class="pre">alpha</span></code> es la fuerza del término de regularización <span class="math notranslate nohighlight">\(L^2\)</span>, similar al utilizado en la regresión <code class="docutils literal notranslate"><span class="pre">ridge</span></code> cuando deseamos reducir la complejidad de un modelo. Puede revisar la documentación del clasificador para ver todos los parámteros asociados, y aquellos que son por defecto (ver <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html">MLPClassifier</a>).</p></li>
</ul>
<figure class="align-center" id="final-neural-network">
<a class="reference internal image-reference" href="_images/final_neural_network.png"><img alt="_images/final_neural_network.png" src="_images/final_neural_network.png" style="width: 317.79999999999995px; height: 376.59999999999997px;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 43 </span><span class="caption-text">Red neuronal feed-forward de tres capas.</span><a class="headerlink" href="#final-neural-network" title="Link to this image">#</a></p>
</figcaption>
</figure>
<p><strong><code class="docutils literal notranslate"><span class="pre">La</span> <span class="pre">capa</span> <span class="pre">de</span> <span class="pre">entrada</span></code></strong></p>
<ul class="simple">
<li><p>En general las ANNs tienen exactamente una capa de entrada. Con respecto al número de neuronas que componen esta capa, este parámetro se determina de forma completa y única, una vez que se conoce la forma de los datos de entrenamiento. <code class="docutils literal notranslate"><span class="pre">En</span> <span class="pre">concreto,</span> <span class="pre">el</span> <span class="pre">número</span> <span class="pre">de</span> <span class="pre">neuronas</span> <span class="pre">que</span> <span class="pre">componen</span> <span class="pre">esa</span> <span class="pre">capa</span> <span class="pre">es</span> <span class="pre">igual</span> <span class="pre">al</span> <span class="pre">número</span> <span class="pre">de</span> <span class="pre">características</span> <span class="pre">(columnas)</span> <span class="pre">de</span> <span class="pre">sus</span> <span class="pre">datos</span></code>. Algunas configuraciones de ANNs añaden un nodo adicional para un término de sesgo.</p></li>
</ul>
<p><strong><code class="docutils literal notranslate"><span class="pre">La</span> <span class="pre">capa</span> <span class="pre">de</span> <span class="pre">salida</span></code></strong></p>
<ul class="simple">
<li><p>Al igual que la capa de entrada, <code class="docutils literal notranslate"><span class="pre">cada</span> <span class="pre">ANN</span> <span class="pre">tiene</span> <span class="pre">exactamente</span> <span class="pre">una</span> <span class="pre">capa</span> <span class="pre">de</span> <span class="pre">salida.</span> <span class="pre">Determinar</span> <span class="pre">su</span> <span class="pre">tamaño</span> <span class="pre">(número</span> <span class="pre">de</span> <span class="pre">neuronas)</span> <span class="pre">es</span> <span class="pre">sencillo;</span> <span class="pre">está</span> <span class="pre">completamente</span> <span class="pre">determinado</span> <span class="pre">por</span> <span class="pre">la</span> <span class="pre">configuración</span> <span class="pre">del</span> <span class="pre">modelo</span> <span class="pre">elegido.</span></code> Si la ANN es un <code class="docutils literal notranslate"><span class="pre">regresor</span></code>, la capa de salida tiene un solo nodo (<code class="docutils literal notranslate"><span class="pre">Time</span> <span class="pre">Series</span> <span class="pre">Forecasting</span></code>). Si la ANN es un <code class="docutils literal notranslate"><span class="pre">clasificador</span></code>, entonces también tiene un solo nodo, a menos que se utilice <code class="docutils literal notranslate"><span class="pre">softmax</span></code>, en cuyo caso la capa de salida tiene un nodo por cada etiqueta de clase en su modelo.</p></li>
</ul>
<p><strong><code class="docutils literal notranslate"><span class="pre">Las</span> <span class="pre">capas</span> <span class="pre">ocultas</span></code></strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">¿Cuántas</span> <span class="pre">capas</span> <span class="pre">ocultas?</span></code>. Si los datos son <code class="docutils literal notranslate"><span class="pre">linealmente</span> <span class="pre">separables</span> <span class="pre">(lo</span> <span class="pre">que</span> <span class="pre">a</span> <span class="pre">menudo</span> <span class="pre">se</span> <span class="pre">sabe</span> <span class="pre">cuando</span> <span class="pre">se</span> <span class="pre">empieza</span> <span class="pre">a</span> <span class="pre">codificar</span> <span class="pre">una</span> <span class="pre">ANN,</span> <span class="pre">SVM</span> <span class="pre">puede</span> <span class="pre">servir</span> <span class="pre">de</span> <span class="pre">test)</span></code>, entonces no se necesita ninguna capa oculta. Por supuesto, tampoco se necesita una ANN para resolver los datos, pero está seguirá haciendo su trabajo.</p></li>
<li><p>Sobre la configuración de las capas ocultas en las ANNs, existe un consenso dentro de este tema, y es la diferencia de rendimiento al añadir capas ocultas adicionales: <code class="docutils literal notranslate"><span class="pre">las</span> <span class="pre">situaciones</span> <span class="pre">en</span> <span class="pre">las</span> <span class="pre">que</span> <span class="pre">el</span> <span class="pre">rendimiento</span> <span class="pre">mejora</span> <span class="pre">con</span> <span class="pre">una</span> <span class="pre">segunda</span> <span class="pre">(o</span> <span class="pre">tercera,</span> <span class="pre">etc.)</span> <span class="pre">capa</span> <span class="pre">oculta</span> <span class="pre">son</span> <span class="pre">muy</span> <span class="pre">pocas</span></code>. Una capa oculta es suficiente para la gran mayoría de los problemas.</p></li>
<li><p>Entonces, <code class="docutils literal notranslate"><span class="pre">¿qué</span> <span class="pre">pasa</span> <span class="pre">con</span> <span class="pre">el</span> <span class="pre">tamaño</span> <span class="pre">de</span> <span class="pre">la(s)</span> <span class="pre">capa(s)</span> <span class="pre">oculta(s),</span> <span class="pre">cuántas</span> <span class="pre">neuronas?</span></code>. Existen algunas reglas empíricas; de ellas, la más utilizada es <strong><code class="docutils literal notranslate"><span class="pre">'The</span> <span class="pre">optimal</span> <span class="pre">size</span> <span class="pre">of</span> <span class="pre">the</span> <span class="pre">hidden</span> <span class="pre">layer</span> <span class="pre">is</span> <span class="pre">usually</span> <span class="pre">between</span> <span class="pre">the</span> <span class="pre">size</span> <span class="pre">of</span> <span class="pre">the</span> <span class="pre">input</span> <span class="pre">and</span> <span class="pre">size</span> <span class="pre">of</span> <span class="pre">the</span> <span class="pre">output</span> <span class="pre">layers'</span></code></strong>. <code class="docutils literal notranslate"><span class="pre">Jeff</span> <span class="pre">Heaton,</span> <span class="pre">the</span> <span class="pre">author</span> <span class="pre">of</span> <span class="pre">Introduction</span> <span class="pre">to</span> <span class="pre">Neural</span> <span class="pre">Networks</span> <span class="pre">in</span> <span class="pre">Java</span></code>.</p></li>
</ul>
<ul>
<li><p>Hay una regla empírica adicional que ayuda en los problemas de aprendizaje supervisado. Normalmente <code class="docutils literal notranslate"><span class="pre">se</span> <span class="pre">puede</span> <span class="pre">evitar</span> <span class="pre">el</span> <span class="pre">sobreajuste</span> <span class="pre">si</span> <span class="pre">se</span> <span class="pre">mantiene</span> <span class="pre">el</span> <span class="pre">número</span> <span class="pre">de</span> <span class="pre">neuronas</span> <span class="pre">por</span> <span class="pre">debajo</span> <span class="pre">de</span></code>:</p>
<div class="math notranslate nohighlight">
\[
    N_{h}=\frac{N_{s}}{(\alpha\cdot(N_{i}+N_{o}))}
    \]</div>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(N_{i}=\)</span> número de neuronas de entrada</p></li>
<li><p><span class="math notranslate nohighlight">\(N_{o}=\)</span> número de neuronas de salida</p></li>
<li><p><span class="math notranslate nohighlight">\(N_{s}=\)</span> número de muestras en el conjunto de datos de entrenamiento</p></li>
<li><p><span class="math notranslate nohighlight">\(\alpha=\)</span> un factor de escala arbitrario, normalmente 2-10</p></li>
</ul>
</li>
<li><p>Un valor de <span class="math notranslate nohighlight">\(\alpha=2\)</span> suele funcionar <code class="docutils literal notranslate"><span class="pre">sin</span> <span class="pre">sobreajustar</span></code>. Se puede pensar en <span class="math notranslate nohighlight">\(\alpha\)</span> como el <code class="docutils literal notranslate"><span class="pre">factor</span> <span class="pre">de</span> <span class="pre">ramificación</span> <span class="pre">efectivo</span> <span class="pre">o</span> <span class="pre">el</span> <span class="pre">número</span> <span class="pre">de</span> <span class="pre">pesos</span> <span class="pre">distintos</span> <span class="pre">de</span> <span class="pre">cero</span> <span class="pre">para</span> <span class="pre">cada</span> <span class="pre">neurona</span></code>. Las capas de salida harán que el factor de ramificación “efectivo” sea muy inferior al factor de ramificación medio real de la red. Para <code class="docutils literal notranslate"><span class="pre">profundizar</span> <span class="pre">mas</span> <span class="pre">en</span> <span class="pre">el</span> <span class="pre">diseño</span> <span class="pre">de</span> <span class="pre">redes</span> <span class="pre">neuronales,</span> <span class="pre">ver</span> <span class="pre">el</span> <span class="pre">siguiente</span> <span class="pre">texto</span> <span class="pre">de</span></code> <a class="reference external" href="https://hagan.okstate.edu/nnd.html">Martin Hagan</a>.</p></li>
</ul>
<ul class="simple">
<li><p>En resumen, para la mayoría de los problemas, probablemente se podría obtener un rendimiento decente (incluso sin un segundo paso de optimización) estableciendo la configuración de la capa oculta utilizando sólo dos reglas:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">el</span> <span class="pre">número</span> <span class="pre">de</span> <span class="pre">capas</span> <span class="pre">ocultas</span> <span class="pre">es</span> <span class="pre">igual</span> <span class="pre">a</span> <span class="pre">uno</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">el</span> <span class="pre">número</span> <span class="pre">de</span> <span class="pre">neuronas</span> <span class="pre">de</span> <span class="pre">esa</span> <span class="pre">capa</span> <span class="pre">es</span> <span class="pre">la</span> <span class="pre">media</span> <span class="pre">de</span> <span class="pre">las</span> <span class="pre">neuronas</span> <span class="pre">de</span> <span class="pre">las</span> <span class="pre">capas</span> <span class="pre">de</span> <span class="pre">entrada</span> <span class="pre">y</span> <span class="pre">salida.</span></code> ¡Nótese que en el ejemplo de esta sección el número de columnas para <span class="math notranslate nohighlight">\(X\)</span> es 100!.</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>Pasamos ahora a implementar un modelo de clasificación para el conjunto de datos relacionados con: <code class="docutils literal notranslate"><span class="pre">Análisis</span> <span class="pre">de</span> <span class="pre">Malware</span> <span class="pre">por</span> <span class="pre">API</span> <span class="pre">calls</span></code>. Utilizaremos la clase <code class="docutils literal notranslate"><span class="pre">MLPClassifier</span></code> y como preprocesamiento, estandarizaremos nuestros datos usando la clase <code class="docutils literal notranslate"><span class="pre">StandardScaler</span></code>. Para encontrar los mejores parámetros y evita problemas de <code class="docutils literal notranslate"><span class="pre">data</span> <span class="pre">leakage</span></code>, utilizaremos <code class="docutils literal notranslate"><span class="pre">Pipeline</span></code> y <code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code> tal como se explicó en secciones anteriores.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pipe</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">StandardScaler</span><span class="p">(),</span> <span class="n">MLPClassifier</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;mlpclassifier__alpha&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.001</span><span class="p">],</span>
              <span class="s1">&#39;mlpclassifier__hidden_layer_sizes&#39;</span><span class="p">:</span> <span class="p">[(</span><span class="mi">10</span><span class="p">,),</span> <span class="p">(</span><span class="mi">100</span><span class="p">,),</span> <span class="p">(</span><span class="mi">1000</span><span class="p">,)],</span>
              <span class="s1">&#39;mlpclassifier__activation&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;logistic&#39;</span><span class="p">],</span>
              <span class="s1">&#39;mlpclassifier__learning_rate&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;constant&#39;</span><span class="p">]}</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Construimos nuestra matriz de caracteristicas, o variable explicativa <code class="docutils literal notranslate"><span class="pre">X</span></code> y el vector de clases o la variable respuesta <code class="docutils literal notranslate"><span class="pre">y</span></code></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">data_new</span><span class="p">[</span><span class="s1">&#39;malware&#39;</span><span class="p">]</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">data_new</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s1">&#39;malware&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Realizamos la división de nuestros datos a priori, con el objetivo de evitar <code class="docutils literal notranslate"><span class="pre">data</span> <span class="pre">leakage</span></code>. Consideramos el mismo <code class="docutils literal notranslate"><span class="pre">random_state</span></code> utilizado en el clasificador, con el objetivo de que los resutlados sean reproducibles.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>El siguiente ciclo <code class="docutils literal notranslate"><span class="pre">if</span></code> ha sido implementado en este curso para evitar reentrenar nuestro modelo clasificador. Nótese que si el algoritmo no detecta que existe un archivo de extensión <code class="docutils literal notranslate"><span class="pre">.pkl</span></code>, reentrena el modelo, de lo contrario, utiliza el modelo entrenado a priori, el cual ha sido guardado en el archivo <code class="docutils literal notranslate"><span class="pre">.pkl</span></code>. Los archivo <code class="docutils literal notranslate"><span class="pre">Pickle</span></code> de extensión <code class="docutils literal notranslate"><span class="pre">.pkl</span></code> en simples palabras se encargan de <code class="docutils literal notranslate"><span class="pre">serializar</span> <span class="pre">un</span> <span class="pre">objeto</span></code>, esto es transformar el mismo en una cadena de bytes única que puede ser guardada en un archivo (<code class="docutils literal notranslate"><span class="pre">de</span> <span class="pre">extensión</span> <span class="pre">.pkl</span></code>), archivo que podemos desempaquetar después y trabajar con su contenido. Para poder utlizarlo necesitamos importarlo con la orden <code class="docutils literal notranslate"><span class="pre">import</span> <span class="pre">pickle</span></code>, e instalar la librería (<code class="docutils literal notranslate"><span class="pre">Pickel</span> <span class="pre">viene</span> <span class="pre">por</span> <span class="pre">defecto</span> <span class="pre">desde</span> <span class="pre">Python</span> <span class="pre">3.9</span></code>) si así se requiere utilizando:</p></li>
</ul>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>pip<span class="w"> </span>install<span class="w"> </span>pickle
</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">grid</span> <span class="o">=</span> <span class="kc">None</span>

<span class="k">if</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="s2">&quot;grid_mlp.pkl&quot;</span><span class="p">))</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">):</span>
    <span class="n">grid</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="nb">open</span><span class="p">(</span><span class="s1">&#39;grid_mlp.pkl&#39;</span><span class="p">,</span><span class="s1">&#39;rb&#39;</span><span class="p">))</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">time_start</span> <span class="o">=</span> <span class="n">process_time</span><span class="p">()</span>
    <span class="n">grid</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">pipe</span><span class="p">,</span> <span class="n">param_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;roc_auc&#39;</span><span class="p">)</span>
    <span class="n">grid</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">time_stop</span> <span class="o">=</span> <span class="n">process_time</span><span class="p">()</span>
    <span class="n">str_cpu_time</span> <span class="o">=</span> <span class="s2">&quot;GridSearchCV CPU time: &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">((</span><span class="n">time_stop</span><span class="o">-</span><span class="n">time_start</span><span class="p">)</span><span class="o">*</span><span class="mf">0.6</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot; minutes&quot;</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">str_cpu_time</span><span class="p">)</span> 
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;cpu_time.txt&#39;</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">str_cpu_time</span><span class="p">)</span>
    <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">grid</span><span class="p">,</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;grid_mlp.pkl&#39;</span><span class="p">,</span> <span class="s1">&#39;wb&#39;</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best CV score = </span><span class="si">%0.3f</span><span class="s2">:&quot;</span> <span class="o">%</span> <span class="n">grid</span><span class="o">.</span><span class="n">best_score_</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best parameters:</span><span class="se">\n</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">grid</span><span class="o">.</span><span class="n">best_params_</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Best CV score = 0.958:
Best parameters:
{&#39;mlpclassifier__activation&#39;: &#39;logistic&#39;, &#39;mlpclassifier__alpha&#39;: 0.01, &#39;mlpclassifier__hidden_layer_sizes&#39;: (100,), &#39;mlpclassifier__learning_rate&#39;: &#39;constant&#39;}
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Utilizamos el <code class="docutils literal notranslate"><span class="pre">f1_score</span></code>, el cual, de acuerdo a lo estudiado en secciones previas, calcula la media armonica entre <code class="docutils literal notranslate"><span class="pre">precision</span></code> y <code class="docutils literal notranslate"><span class="pre">recall</span></code></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;F1 Score of the classifier is: </span><span class="si">{</span><span class="n">f1_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="w"> </span><span class="n">grid</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">))</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>F1 Score of the classifier is: 0.9937633808061063
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Además podemos usar <code class="docutils literal notranslate"><span class="pre">classification_report</span></code> y la matriz de confusión, para identificar aquellas clases que fueron incorrectamente clasificadas por nuestro modelo</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">grid</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>              precision    recall  f1-score   support

           0       0.94      0.56      0.70       283
           1       0.99      1.00      0.99     10686

    accuracy                           0.99     10969
   macro avg       0.96      0.78      0.85     10969
weighted avg       0.99      0.99      0.99     10969
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mlp_cm</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">grid</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">))</span>
<span class="n">f</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">mlp_cm</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">linecolor</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s1">&#39;g&#39;</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;BuPu&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;MLP Confusion Matrix&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Y predict&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Y test&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/f8d952658c33c495fac6fb31713a4b8dd3e6f161af6e4dce36f45b4ffcbfcbdf.png" src="_images/f8d952658c33c495fac6fb31713a4b8dd3e6f161af6e4dce36f45b4ffcbfcbdf.png" />
</div>
</div>
<ul class="simple">
<li><p>Nótese que la <code class="docutils literal notranslate"><span class="pre">clase</span> <span class="pre">0</span></code>, presenta el mayor número de clasificaciones erroneas <code class="docutils literal notranslate"><span class="pre">(FP)</span></code>, obtenidas por nuestra ANN. Justamente esto se debe al desbalance notorio en nuestros datos, el cual se inclina hacia la clases 1, de mayor frecuencia. Si se tiene clara una <code class="docutils literal notranslate"><span class="pre">métrica</span> <span class="pre">de</span> <span class="pre">negocio</span></code> o un <code class="docutils literal notranslate"><span class="pre">punto</span> <span class="pre">de</span> <span class="pre">operación</span></code>, podríamos ajustar el número de prediccion incorrectas a favor de este <code class="docutils literal notranslate"><span class="pre">punto</span> <span class="pre">de</span> <span class="pre">operación</span></code>, tal como en el problema de detección de cancer, donde el interés era reducir (<code class="docutils literal notranslate"><span class="pre">FN</span></code>). Para analizar el comportamiento del clasificador a diferentes umbrales, utilizamos la curva <code class="docutils literal notranslate"><span class="pre">ROC</span></code> y <code class="docutils literal notranslate"><span class="pre">precision-recall</span></code></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fpr_mlp</span><span class="p">,</span> <span class="n">tpr_mlp</span><span class="p">,</span> <span class="n">thresholds_mlp</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">grid</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fpr_mlp</span><span class="p">,</span> <span class="n">tpr_mlp</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;ROC Curve MLP&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;FPR&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;TPR (recall)&quot;</span><span class="p">)</span>
<span class="n">close_default_mlp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">thresholds_mlp</span> <span class="o">-</span> <span class="mf">0.5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fpr_mlp</span><span class="p">[</span><span class="n">close_default_mlp</span><span class="p">],</span> <span class="n">tpr_mlp</span><span class="p">[</span><span class="n">close_default_mlp</span><span class="p">],</span> <span class="s1">&#39;^&#39;</span><span class="p">,</span> 
         <span class="n">markersize</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;threshold 0.5 MLP&quot;</span><span class="p">,</span> <span class="n">fillstyle</span><span class="o">=</span><span class="s2">&quot;none&quot;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">mew</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">4</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/76ffa78f41c8601cbabf5b4f394dbbb989b78e121859f08db61ad1232597389b.png" src="_images/76ffa78f41c8601cbabf5b4f394dbbb989b78e121859f08db61ad1232597389b.png" />
</div>
</div>
<ul class="simple">
<li><p>Nótese que la tasa <code class="docutils literal notranslate"><span class="pre">TPR</span></code> se mantiene aproximadamente contante para valores de <code class="docutils literal notranslate"><span class="pre">FPR&gt;0.2</span></code>, esto es, para esta tasas de <code class="docutils literal notranslate"><span class="pre">FPR</span></code> no se está sacrificando la tasa <code class="docutils literal notranslate"><span class="pre">recall</span></code>. Si deseamos mantener un <code class="docutils literal notranslate"><span class="pre">recall</span></code> alto, aproximadamente, mayor que 0.8, podemos considerar por ejemplo una tasa <code class="docutils literal notranslate"><span class="pre">FPR</span></code> en torno a 0.1, con la que no estaríamos sacrificando <code class="docutils literal notranslate"><span class="pre">recall</span></code> y además, obtendriamos un tasa de falsos positivos <code class="docutils literal notranslate"><span class="pre">FPR</span></code> relativamente baja.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">precision_mlp</span><span class="p">,</span> <span class="n">recall_mlp</span><span class="p">,</span> <span class="n">thresholds_mlp</span> <span class="o">=</span> <span class="n">precision_recall_curve</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">grid</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">precision_mlp</span><span class="p">,</span> <span class="n">recall_mlp</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;MLP&quot;</span><span class="p">)</span>
<span class="n">close_default_mlp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">thresholds_mlp</span> <span class="o">-</span> <span class="mf">0.5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">precision_mlp</span><span class="p">[</span><span class="n">close_default_mlp</span><span class="p">],</span> <span class="n">recall_mlp</span><span class="p">[</span><span class="n">close_default_mlp</span><span class="p">],</span> <span class="s1">&#39;^&#39;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span>
         <span class="n">markersize</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;threshold 0.5 MLP&quot;</span><span class="p">,</span> <span class="n">fillstyle</span><span class="o">=</span><span class="s2">&quot;none&quot;</span><span class="p">,</span> <span class="n">mew</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Precision&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Recall&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s2">&quot;best&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/6080ced56633ce4cba0e4cb80200d8594f4084c49d4076f3a34b0745814ff178.png" src="_images/6080ced56633ce4cba0e4cb80200d8594f4084c49d4076f3a34b0745814ff178.png" />
</div>
</div>
<ul class="simple">
<li><p>Nótese que con el umbral por defecto, la curva <code class="docutils literal notranslate"><span class="pre">precision-recall</span></code> muestra una clasificación con <code class="docutils literal notranslate"><span class="pre">scores</span> <span class="pre">bastante</span> <span class="pre">buenos</span> <span class="pre">para</span> <span class="pre">cada</span> <span class="pre">una</span> <span class="pre">de</span> <span class="pre">estas</span> <span class="pre">métricas</span></code>, incluso, si movemos el umbral un poco, para favorecer la clase 0 que es la menos frecuente, vamos a obtener de igual manera un rango de valores altos para <code class="docutils literal notranslate"><span class="pre">precision</span></code> y <code class="docutils literal notranslate"><span class="pre">recall</span></code>. Sólo valores de <code class="docutils literal notranslate"><span class="pre">precision</span></code> muy elevados, esto es, valores cuya distancia 1 tiende a cero, estaríamos sacrificando <code class="docutils literal notranslate"><span class="pre">recall</span></code>.</p></li>
</ul>
</section>
<section id="redes-neuronales-convolucionales">
<h2>Redes Neuronales Convolucionales<a class="headerlink" href="#redes-neuronales-convolucionales" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Hasta ahora hemos supuesto que las <code class="docutils literal notranslate"><span class="pre">redes</span> <span class="pre">neuronales</span> <span class="pre">reciben</span> <span class="pre">vectores</span> <span class="pre">de</span> <span class="pre">características</span> <span class="pre">en</span> <span class="pre">su</span> <span class="pre">capa</span> <span class="pre">de</span> <span class="pre">entrada</span></code>. Esto coincide con cualquier otro <code class="docutils literal notranslate"><span class="pre">clasificador/predictor</span></code> que se haya analizado en capítulos anteriores. Los vectores de características se generan a partir de los datos brutos en un esfuerzo por <code class="docutils literal notranslate"><span class="pre">compactar</span> <span class="pre">la</span> <span class="pre">información</span> <span class="pre">relevante</span> <span class="pre">para</span> <span class="pre">la</span> <span class="pre">tarea</span> <span class="pre">de</span> <span class="pre">aprendizaje</span> <span class="pre">automático</span></code> en cuestión. Un avance alternativo se produjo a finales de la década de 1980, cuando la <code class="docutils literal notranslate"><span class="pre">fase</span> <span class="pre">de</span> <span class="pre">generación</span> <span class="pre">de</span> <span class="pre">características</span></code> se integró como <code class="docutils literal notranslate"><span class="pre">parte</span> <span class="pre">del</span> <span class="pre">entrenamiento</span> <span class="pre">de</span> <span class="pre">una</span> <span class="pre">red</span> <span class="pre">neuronal</span></code>. La idea era <code class="docutils literal notranslate"><span class="pre">aprender</span> <span class="pre">las</span> <span class="pre">características</span> <span class="pre">a</span> <span class="pre">partir</span> <span class="pre">de</span> <span class="pre">los</span> <span class="pre">datos</span> <span class="pre">junto</span> <span class="pre">con</span> <span class="pre">los</span> <span class="pre">parámetros</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">red</span> <span class="pre">neuronal</span> <span class="pre">y</span> <span class="pre">no</span> <span class="pre">de</span> <span class="pre">forma</span> <span class="pre">independiente</span></code>. Estas redes se denominaron <code class="docutils literal notranslate"><span class="pre">redes</span> <span class="pre">neuronales</span> <span class="pre">convolucionale</span> <span class="pre">(CNN)</span></code> y su éxito se demostró por primera vez en la <code class="docutils literal notranslate"><span class="pre">tarea</span> <span class="pre">OCR</span> <span class="pre">de</span> <span class="pre">reconocimiento</span> <span class="pre">de</span> <span class="pre">dígitos</span> <span class="pre">de</span> <span class="pre">números</span></code> <span id="id7">[<a class="reference internal" href="biblio.html#id27" title="Yann LeCun, Bernhard Boser, John S Denker, Donnie Henderson, Richard E Howard, Wayne Hubbard, and Lawrence D Jackel. Backpropagation applied to handwritten zip code recognition. Neural computation, 1(4):541–551, 1989.">LeCun <em>et al.</em>, 1989</a>]</span>. El nombre <code class="docutils literal notranslate"><span class="pre">&quot;convolucional&quot;</span></code> proviene del hecho de que <code class="docutils literal notranslate"><span class="pre">la</span> <span class="pre">primera</span> <span class="pre">capa</span> <span class="pre">de</span> <span class="pre">una</span> <span class="pre">red</span> <span class="pre">neuronal</span> <span class="pre">realiza</span> <span class="pre">convoluciones</span> <span class="pre">en</span> <span class="pre">lugar</span> <span class="pre">de</span> <span class="pre">productos</span> <span class="pre">internos</span></code>, que son las operaciones básicas
en las <code class="docutils literal notranslate"><span class="pre">redes</span> <span class="pre">totalmente</span> <span class="pre">conectadas</span></code> presentadas en secciones previas.</p></li>
</ul>
<section id="la-necesidad-de-convoluciones">
<h3>La necesidad de convoluciones<a class="headerlink" href="#la-necesidad-de-convoluciones" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>Asegurémonos primero de que entendemos la razón por la que <code class="docutils literal notranslate"><span class="pre">no</span> <span class="pre">podemos,</span> <span class="pre">en</span> <span class="pre">la</span> <span class="pre">práctica,</span> <span class="pre">alimentar</span> <span class="pre">la</span> <span class="pre">entrada</span> <span class="pre">de</span> <span class="pre">una</span> <span class="pre">red</span> <span class="pre">neuronal</span> <span class="pre">directamente</span> <span class="pre">con</span> <span class="pre">datos</span> <span class="pre">brutos</span></code>, por ejemplo, una <code class="docutils literal notranslate"><span class="pre">matriz</span> <span class="pre">de</span> <span class="pre">imágenes</span></code> o las muestras de una <code class="docutils literal notranslate"><span class="pre">versión</span> <span class="pre">digitalizada</span> <span class="pre">de</span> <span class="pre">un</span> <span class="pre">segmento</span> <span class="pre">de</span> <span class="pre">voz</span></code>, y por qué es necesario un <code class="docutils literal notranslate"><span class="pre">preprocesamiento</span> <span class="pre">para</span> <span class="pre">generar</span> <span class="pre">características</span></code>. Lo mismo ocurre para cualquier predictor/aprendiz y no sólo para las redes neuronales. En muchas aplicaciones, <code class="docutils literal notranslate"><span class="pre">trabajar</span> <span class="pre">directamente</span> <span class="pre">con</span> <span class="pre">los</span> <span class="pre">datos</span> <span class="pre">en</span> <span class="pre">bruto</span> <span class="pre">hace</span> <span class="pre">que</span> <span class="pre">la</span> <span class="pre">tarea</span> <span class="pre">sea</span> <span class="pre">sencillamente</span> <span class="pre">inmanejable</span></code>.</p></li>
</ul>
<ul class="simple">
<li><p>Tomemos, como ejemplo, el caso de una <code class="docutils literal notranslate"><span class="pre">imagen,</span> <span class="pre">matriz</span> <span class="pre">de</span> <span class="pre">256</span> <span class="pre">×</span> <span class="pre">256</span></code>. Al <code class="docutils literal notranslate"><span class="pre">vectorizarla</span> <span class="pre">se</span> <span class="pre">obtiene</span> <span class="pre">un</span> <span class="pre">vector</span> <span class="pre">de</span> <span class="pre">entrada</span></code> <span class="math notranslate nohighlight">\(\boldsymbol{x}\in\mathbb{R}^{l}\)</span>, donde <span class="math notranslate nohighlight">\(l\approx 65000\)</span>. Supongamos que el <code class="docutils literal notranslate"><span class="pre">número</span> <span class="pre">de</span> <span class="pre">nodos</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">primera</span> <span class="pre">capa</span></code> es <span class="math notranslate nohighlight">\(k_{1} = 1000\)</span>. Entonces, el número de los parámetros implicados, <span class="math notranslate nohighlight">\(\theta_{jk}, j = 1, 2,\dots, 65000, k = 1, 2,\dots,1000\)</span>, que <code class="docutils literal notranslate"><span class="pre">conectan</span> <span class="pre">todos</span> <span class="pre">los</span> <span class="pre">nodos</span> <span class="pre">de</span> <span class="pre">entrada</span> <span class="pre">a</span> <span class="pre">todos</span> <span class="pre">los</span> <span class="pre">nodos</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">primera</span> <span class="pre">capa</span> <span class="pre">en</span> <span class="pre">una</span> <span class="pre">red</span> <span class="pre">totalmente</span> <span class="pre">conectada</span></code>, sería del orden de
65 millones. <code class="docutils literal notranslate"><span class="pre">Este</span> <span class="pre">número</span> <span class="pre">se</span> <span class="pre">dispara</span> <span class="pre">aún</span> <span class="pre">más</span> <span class="pre">si</span> <span class="pre">la</span> <span class="pre">imagen</span> <span class="pre">de</span> <span class="pre">entrada</span> <span class="pre">es</span> <span class="pre">de</span> <span class="pre">alta</span> <span class="pre">resolución</span></code> y tiene <code class="docutils literal notranslate"><span class="pre">píxeles</span> <span class="pre">del</span> <span class="pre">orden</span> <span class="pre">de</span> <span class="pre">1000</span> <span class="pre">×</span> <span class="pre">1000</span></code>. Además, este número <code class="docutils literal notranslate"><span class="pre">aumenta</span> <span class="pre">si</span> <span class="pre">tratamos,</span> <span class="pre">por</span> <span class="pre">ejemplo,</span> <span class="pre">con</span> <span class="pre">imágenes</span> <span class="pre">en</span> <span class="pre">color</span> <span class="pre">en</span> <span class="pre">las</span> <span class="pre">que</span> <span class="pre">la</span> <span class="pre">dimensionalidad</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">entrada</span> <span class="pre">se</span> <span class="pre">multiplica</span> <span class="pre">por</span> <span class="pre">tres</span></code> para un esquema de representación del <code class="docutils literal notranslate"><span class="pre">color</span> <span class="pre">RGB</span> <span class="pre">(red-green-blue)</span></code>.</p></li>
</ul>
<ul class="simple">
<li><p>Además, <code class="docutils literal notranslate"><span class="pre">a</span> <span class="pre">medida</span> <span class="pre">que</span> <span class="pre">se</span> <span class="pre">añaden</span> <span class="pre">capas</span> <span class="pre">ocultas,</span> <span class="pre">el</span> <span class="pre">número</span> <span class="pre">de</span> <span class="pre">parámetros</span> <span class="pre">sigue</span> <span class="pre">aumentando</span></code>. Asimismo los <code class="docutils literal notranslate"><span class="pre">problemas</span> <span class="pre">de</span> <span class="pre">carga</span> <span class="pre">computacional</span> <span class="pre">asociados</span></code>, sabemos que <code class="docutils literal notranslate"><span class="pre">entrenar</span> <span class="pre">redes</span> <span class="pre">con</span> <span class="pre">un</span> <span class="pre">gran</span> <span class="pre">número</span> <span class="pre">de</span> <span class="pre">parámetros</span> <span class="pre">pone</span> <span class="pre">seriamente</span> <span class="pre">a</span> <span class="pre">prueba</span> <span class="pre">su</span> <span class="pre">rendimiento</span> <span class="pre">de</span> <span class="pre">generalización</span></code>. Estas redes <code class="docutils literal notranslate"><span class="pre">requerirían</span> <span class="pre">una</span> <span class="pre">enorme</span> <span class="pre">cantidad</span> <span class="pre">de</span> <span class="pre">datos</span> <span class="pre">de</span> <span class="pre">entrenamiento</span> <span class="pre">para</span> <span class="pre">hacer</span> <span class="pre">frente</span> <span class="pre">a</span> <span class="pre">la</span> <span class="pre">tendencia</span> <span class="pre">al</span> <span class="pre">sobreajuste</span></code>. Además de la explosión del número de parámetros, la <code class="docutils literal notranslate"><span class="pre">vectorización</span> <span class="pre">de</span> <span class="pre">una</span> <span class="pre">matriz</span> <span class="pre">de</span> <span class="pre">imágenes</span> <span class="pre">conlleva</span> <span class="pre">una</span> <span class="pre">pérdida</span> <span class="pre">de</span> <span class="pre">información</span></code>, ya que desechamos información importante sobre <code class="docutils literal notranslate"><span class="pre">cómo</span> <span class="pre">se</span> <span class="pre">interrelacionan</span> <span class="pre">los</span> <span class="pre">píxeles</span> <span class="pre">en</span> <span class="pre">una</span> <span class="pre">zona</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">imagen</span></code>. De hecho, el objetivo de los distintos métodos de generación de características, que se han desarrollado a lo largo de los años es exactamente eso. Es decir, <code class="docutils literal notranslate"><span class="pre">extraer</span> <span class="pre">información</span> <span class="pre">que</span> <span class="pre">cuantifica</span> <span class="pre">las</span> <span class="pre">correlaciones</span> <span class="pre">u</span> <span class="pre">otras</span> <span class="pre">dependencias</span> <span class="pre">estadísticas</span> <span class="pre">que</span> <span class="pre">relacionan</span> <span class="pre">los</span> <span class="pre">valores</span> <span class="pre">de</span> <span class="pre">los</span> <span class="pre">píxeles</span> <span class="pre">dentro</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">imagen</span></code>. En este modo, se puede <code class="docutils literal notranslate"><span class="pre">&quot;codificar&quot;</span></code> eficazmente la información relacionada con el aprendizaje que reside en los datos brutos.</p></li>
</ul>
<ul class="simple">
<li><p>Al emplear <code class="docutils literal notranslate"><span class="pre">convoluciones</span></code>, se pueden <code class="docutils literal notranslate"><span class="pre">abordar</span> <span class="pre">simultáneamente</span> <span class="pre">ambos</span> <span class="pre">problemas</span></code>, es decir, el de la <code class="docutils literal notranslate"><span class="pre">explosión</span> <span class="pre">de</span> <span class="pre">parámetros</span></code> y el de la <code class="docutils literal notranslate"><span class="pre">extracción</span> <span class="pre">de</span> <span class="pre">información</span> <span class="pre">estadística</span> <span class="pre">útil</span></code>. Los pasos básicos de cualquier red convolucional son:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">la</span> <span class="pre">etapa</span> <span class="pre">de</span> <span class="pre">convolución,</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">el</span> <span class="pre">paso</span> <span class="pre">de</span> <span class="pre">no</span> <span class="pre">linealidad,</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">el</span> <span class="pre">paso</span> <span class="pre">de</span> <span class="pre">agrupación.</span></code></p></li>
</ul>
</li>
</ul>
</section>
<section id="la-etapa-de-convolucion">
<h3>La etapa de convolución<a class="headerlink" href="#la-etapa-de-convolucion" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>Una forma de <code class="docutils literal notranslate"><span class="pre">reducir</span> <span class="pre">el</span> <span class="pre">número</span> <span class="pre">de</span> <span class="pre">parámetros</span></code> es mediante el <code class="docutils literal notranslate"><span class="pre">reparto</span> <span class="pre">de</span> <span class="pre">pesos</span></code>, como se ha comentado brevemente al final de la Sección (Redes Totalmente Conectadas). Ahora tomaremos prestada esta idea del <code class="docutils literal notranslate"><span class="pre">reparto</span> <span class="pre">de</span> <span class="pre">pesos</span> <span class="pre">y</span> <span class="pre">la</span> <span class="pre">utilizaremos</span> <span class="pre">de</span> <span class="pre">una</span> <span class="pre">forma</span> <span class="pre">más</span> <span class="pre">sofisticada</span></code>. Para ello, nos centraremos en el caso en que <code class="docutils literal notranslate"><span class="pre">la</span> <span class="pre">entrada</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">red</span> <span class="pre">esté</span> <span class="pre">formada</span> <span class="pre">por</span> <span class="pre">imágenes</span></code>. La <code class="docutils literal notranslate"><span class="pre">imagen</span> <span class="pre">matricial</span> <span class="pre">de</span> <span class="pre">entrada</span> <span class="pre">se</span> <span class="pre">denomina</span></code> <span class="math notranslate nohighlight">\(I\)</span>.</p></li>
</ul>
<figure class="align-center" id="image-input-conv-numref">
<a class="reference internal image-reference" href="_images/image_input_conv.png"><img alt="_images/image_input_conv.png" src="_images/image_input_conv.png" style="width: 587.2px; height: 367.20000000000005px;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 44 </span><span class="caption-text">(A) Imagen matricial de entrada de <span class="math notranslate nohighlight">\(3\times 3\)</span>. (B) Nodos de la capa oculta.</span><a class="headerlink" href="#image-input-conv-numref" title="Link to this image">#</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p>Para el caso de la <a class="reference internal" href="#image-input-conv-numref"><span class="std std-numref">Fig. 44</span></a>, se trata de una <code class="docutils literal notranslate"><span class="pre">matriz</span> <span class="pre">de</span> <span class="pre">3</span> <span class="pre">×</span> <span class="pre">3</span></code>; nótese que <code class="docutils literal notranslate"><span class="pre">la</span> <span class="pre">entrada</span> <span class="pre">es</span> <span class="pre">no</span> <span class="pre">vectorizada</span></code>. Para <code class="docutils literal notranslate"><span class="pre">enfatizar</span> <span class="pre">que</span> <span class="pre">nos</span> <span class="pre">apartaremos</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">lógica</span> <span class="pre">de</span> <span class="pre">las</span> <span class="pre">operaciones</span> <span class="pre">de</span> <span class="pre">multiplicar-añadir</span> <span class="pre">(producto</span> <span class="pre">interno)</span> <span class="pre">de</span> <span class="pre">las</span> <span class="pre">redes</span> <span class="pre">feed-forward</span> <span class="pre">completamente</span> <span class="pre">conectadas</span></code>, utilizaremos un símbolo diferente <span class="math notranslate nohighlight">\(h\)</span> en lugar de <span class="math notranslate nohighlight">\(\theta\)</span>, para denotar los <code class="docutils literal notranslate"><span class="pre">parámetros</span> <span class="pre">asociados</span></code>.</p></li>
<li><p>Introducimos ahora el concepto de <code class="docutils literal notranslate"><span class="pre">reparto</span> <span class="pre">de</span> <span class="pre">pesos</span></code>. Recordemos que en una red totalmente conectada, cada nodo está asociado con un vector de parámetros, <span class="math notranslate nohighlight">\(\boldsymbol{\theta}_{i}\)</span>, para el nodo <span class="math notranslate nohighlight">\(i\)</span>th <code class="docutils literal notranslate"><span class="pre">cuya</span> <span class="pre">dimensionalidad</span> <span class="pre">es</span> <span class="pre">igual</span> <span class="pre">al</span> <span class="pre">número</span> <span class="pre">de</span> <span class="pre">nodos</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">capa</span> <span class="pre">anterior</span></code>. En cambio, <code class="docutils literal notranslate"><span class="pre">ahora</span> <span class="pre">cada</span> <span class="pre">nodo</span> <span class="pre">estará</span> <span class="pre">asociado</span> <span class="pre">a</span> <span class="pre">un</span> <span class="pre">único</span> <span class="pre">parámetro</span></code>. Para ello, dispondremos los <code class="docutils literal notranslate"><span class="pre">nodos</span> <span class="pre">en</span> <span class="pre">forma</span> <span class="pre">de</span> <span class="pre">matriz</span> <span class="pre">bidimensional</span></code>, como se muestra en <a class="reference internal" href="#image-input-conv-numref"><span class="std std-numref">Fig. 44</span></a> (B). Para el caso de la figura, hemos supuesto <code class="docutils literal notranslate"><span class="pre">cuatro</span> <span class="pre">nodos</span> <span class="pre">dispuestos</span> <span class="pre">en</span> <span class="pre">una</span> <span class="pre">matriz</span> <span class="pre">de</span> <span class="pre">2</span> <span class="pre">×</span> <span class="pre">2</span></code>, <span class="math notranslate nohighlight">\(H\)</span>.</p></li>
</ul>
<ul class="simple">
<li><p>El <code class="docutils literal notranslate"><span class="pre">primer</span> <span class="pre">nodo</span> <span class="pre">se</span> <span class="pre">caracteriza</span> <span class="pre">por</span></code> <span class="math notranslate nohighlight">\(h(1, 1)\)</span>, <code class="docutils literal notranslate"><span class="pre">el</span> <span class="pre">segundo</span> <span class="pre">por</span></code> <span class="math notranslate nohighlight">\(h(1, 2)\)</span>, y así sucesivamente. En otras palabras, <code class="docutils literal notranslate"><span class="pre">cualquier</span> <span class="pre">conexión</span> <span class="pre">que</span> <span class="pre">termine</span> <span class="pre">en</span> <span class="pre">el</span> <span class="pre">primer</span> <span class="pre">nodo</span> <span class="pre">se</span> <span class="pre">multiplicará</span> <span class="pre">por</span> <span class="pre">el</span> <span class="pre">mismo</span> <span class="pre">peso</span></code> <span class="math notranslate nohighlight">\(h(1, 1)\)</span>, y <code class="docutils literal notranslate"><span class="pre">un</span> <span class="pre">argumento</span> <span class="pre">similar</span> <span class="pre">es</span> <span class="pre">válido</span> <span class="pre">para</span> <span class="pre">el</span> <span class="pre">resto</span> <span class="pre">de</span> <span class="pre">los</span> <span class="pre">nodos</span></code>. Este razonamiento reduce drásticamente el número de parámetros. Sin embargo, para que esto tenga sentido, tenemos que <code class="docutils literal notranslate"><span class="pre">alejarnos</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">lógica</span> <span class="pre">de</span> <span class="pre">las</span> <span class="pre">operaciones</span> <span class="pre">de</span> <span class="pre">producto</span> <span class="pre">interior</span> <span class="pre">de</span> <span class="pre">las</span> <span class="pre">redes</span> <span class="pre">totalmente</span> <span class="pre">conectadas</span></code>.</p></li>
<li><p>Para entender por qué, <code class="docutils literal notranslate"><span class="pre">supongamos</span> <span class="pre">que</span> <span class="pre">utilizamos</span> <span class="pre">un</span> <span class="pre">único</span> <span class="pre">parámetro</span> <span class="pre">por</span> <span class="pre">nodo</span> <span class="pre">en</span> <span class="pre">una</span> <span class="pre">red</span> <span class="pre">totalmente</span> <span class="pre">conectada</span></code>. Entonces, <code class="docutils literal notranslate"><span class="pre">la</span> <span class="pre">salida</span> <span class="pre">del</span> <span class="pre">combinador</span> <span class="pre">lineal</span> <span class="pre">asociado</span> <span class="pre">al</span> <span class="pre">primer</span> <span class="pre">nodo</span> <span class="pre">sería</span></code> <span class="math notranslate nohighlight">\(O(1, 1) = h(1, 1)a\)</span>, donde <span class="math notranslate nohighlight">\(a\)</span> es la <code class="docutils literal notranslate"><span class="pre">suma</span> <span class="pre">de</span> <span class="pre">todas</span> <span class="pre">las</span> <span class="pre">entradas</span> <span class="pre">al</span> <span class="pre">nodo</span> <span class="pre">recibidas</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">capa</span> <span class="pre">anterior</span></code>. La salida respectiva del segundo nodo sería <span class="math notranslate nohighlight">\(O(1, 2) = h(1, 2)a\)</span>, y así sucesivamente. Por lo tanto, <code class="docutils literal notranslate"><span class="pre">todos</span> <span class="pre">los</span> <span class="pre">nodos</span> <span class="pre">proporcionarían</span> <span class="pre">básicamente</span> <span class="pre">la</span> <span class="pre">misma</span> <span class="pre">información</span> <span class="pre">con</span> <span class="pre">respecto</span> <span class="pre">a</span> <span class="pre">los</span> <span class="pre">valores</span> <span class="pre">de</span> <span class="pre">entrada</span></code>; la <code class="docutils literal notranslate"><span class="pre">única</span> <span class="pre">diferencia</span></code> serían los <code class="docutils literal notranslate"><span class="pre">distintos</span> <span class="pre">pesos</span> <span class="pre">que</span> <span class="pre">actúan</span> <span class="pre">sobre</span> <span class="pre">la</span> <span class="pre">misma</span> <span class="pre">información</span> <span class="pre">de</span> <span class="pre">entrada</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">capa</span> <span class="pre">anterior</span></code>.</p></li>
</ul>
<ul class="simple">
<li><p>Pasemos ahora a introducir un concepto diferente, en el que <code class="docutils literal notranslate"><span class="pre">mantenemos</span> <span class="pre">un</span> <span class="pre">único</span> <span class="pre">parámetro</span> <span class="pre">por</span> <span class="pre">nodo</span></code>, aunque <code class="docutils literal notranslate"><span class="pre">cada</span> <span class="pre">una</span> <span class="pre">de</span> <span class="pre">las</span> <span class="pre">salidas</span> <span class="pre">de</span> <span class="pre">una</span> <span class="pre">capa</span> <span class="pre">oculta</span> <span class="pre">transmite</span> <span class="pre">información</span> <span class="pre">diferente</span> <span class="pre">con</span> <span class="pre">respecto</span> <span class="pre">a</span> <span class="pre">las</span> <span class="pre">distintas</span> <span class="pre">entradas</span> <span class="pre">que</span> <span class="pre">se</span> <span class="pre">reciben</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">capa</span> <span class="pre">anterior</span></code>. Para ello, <code class="docutils literal notranslate"><span class="pre">introduciremos</span> <span class="pre">las</span> <span class="pre">convoluciones</span></code>. En este contexto, los <strong><code class="docutils literal notranslate"><span class="pre">nodos</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">capa</span> <span class="pre">oculta</span> <span class="pre">se</span> <span class="pre">interpretan</span> <span class="pre">como</span> <span class="pre">elementos</span> <span class="pre">de</span> <span class="pre">una</span> <span class="pre">matriz</span></code></strong> <span class="math notranslate nohighlight">\(H\)</span>, y <code class="docutils literal notranslate"><span class="pre">convolucionamos</span></code> <span class="math notranslate nohighlight">\(H\)</span> <code class="docutils literal notranslate"><span class="pre">con</span> <span class="pre">la</span> <span class="pre">matriz</span> <span class="pre">de</span> <span class="pre">entrada</span> <span class="pre">entrada</span></code> <span class="math notranslate nohighlight">\(I\)</span>. El primer valor de salida de la capa oculta será</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
O(1, 1)=h(1, 1)I(1, 1)+h(1, 2)I(1, 2)+h(2, 1)I(2, 1)+h(2, 2)I(2, 2)
\]</div>
<ul class="simple">
<li><p>El resultado anterior se obtiene si <code class="docutils literal notranslate"><span class="pre">colocamos</span> <span class="pre">la</span> <span class="pre">matriz</span></code> <span class="math notranslate nohighlight">\(H\)</span><code class="docutils literal notranslate"> <span class="pre">de</span></code> <span class="math notranslate nohighlight">\(2\times2\)</span><code class="docutils literal notranslate"> <span class="pre">sobre</span></code> <span class="math notranslate nohighlight">\(I\)</span><code class="docutils literal notranslate"><span class="pre">,</span> <span class="pre">empezando</span> <span class="pre">por</span> <span class="pre">la</span> <span class="pre">esquina</span> <span class="pre">superior</span> <span class="pre">izquierda</span></code> (el cuadrado rojo de <a class="reference internal" href="#image-input-conv-numref"><span class="std std-numref">Fig. 44</span></a>(A) indica la posición de la matriz <span class="math notranslate nohighlight">\(H\)</span>). A continuación, <code class="docutils literal notranslate"><span class="pre">multiplicamos</span> <span class="pre">los</span> <span class="pre">elementos</span> <span class="pre">en</span> <span class="pre">las</span> <span class="pre">partes</span> <span class="pre">superpuestas</span> <span class="pre">de</span> <span class="pre">las</span> <span class="pre">dos</span> <span class="pre">matrices</span> <span class="pre">y</span> <span class="pre">los</span> <span class="pre">sumamos</span></code>. Desde un <code class="docutils literal notranslate"><span class="pre">punto</span> <span class="pre">de</span> <span class="pre">vista</span> <span class="pre">físico</span></code>, el valor <span class="math notranslate nohighlight">\(O(1, 1)\)</span> resultante es una <code class="docutils literal notranslate"><span class="pre">media</span> <span class="pre">ponderada</span> <span class="pre">sobre</span> <span class="pre">un</span> <span class="pre">área</span> <span class="pre">local</span> <span class="pre">dentro</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">matriz</span></code> <span class="math notranslate nohighlight">\(I\)</span>. En la operación anterior, el área correspondiente de la imagen está formada por los <code class="docutils literal notranslate"><span class="pre">píxeles</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">parte</span> <span class="pre">superior</span> <span class="pre">izquierda</span> <span class="pre">2</span> <span class="pre">×</span> <span class="pre">2</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">matriz</span></code> <span class="math notranslate nohighlight">\(I\)</span>. Para obtener el <code class="docutils literal notranslate"><span class="pre">segundo</span> <span class="pre">valor</span> <span class="pre">de</span> <span class="pre">salida,</span></code> <span class="math notranslate nohighlight">\(O(1, 2)\)</span><code class="docutils literal notranslate"><span class="pre">,</span> <span class="pre">deslizamos</span></code> <span class="math notranslate nohighlight">\(H\)</span> <code class="docutils literal notranslate"><span class="pre">un</span> <span class="pre">píxel</span> <span class="pre">hacia</span> <span class="pre">la</span> <span class="pre">derecha</span></code>, como indica el recuadro rojo de puntos. indicado por el recuadro rojo punteado, y repetimos las operaciones, es decir</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
O(1, 2) = h(1, 1)I(1, 2) + h(1, 2)I (1, 3) + h(2, 1)I(2, 2) + h(2, 2)I(2, 3).
\]</div>
<ul class="simple">
<li><p>Siguiendo el mismo razonamiento, <code class="docutils literal notranslate"><span class="pre">deslizamos</span></code> <span class="math notranslate nohighlight">\(H\)</span> <code class="docutils literal notranslate"><span class="pre">para</span> <span class="pre">&quot;escanear&quot;</span> <span class="pre">toda</span> <span class="pre">la</span> <span class="pre">imagen</span> <span class="pre">matricial;</span> <span class="pre">así,</span> <span class="pre">se</span> <span class="pre">obtienen</span> <span class="pre">otros</span> <span class="pre">dos</span> <span class="pre">valores</span> <span class="pre">de</span> <span class="pre">salida</span></code> <span class="math notranslate nohighlight">\(O(2, 1)\)</span> y <span class="math notranslate nohighlight">\(O(2, 2)\)</span>. Las cuatro posiciones posibles de <span class="math notranslate nohighlight">\(H\)</span> encima de <span class="math notranslate nohighlight">\(I\)</span> se indican en la <a class="reference internal" href="#image-input-conv-numref"><span class="std std-numref">Fig. 44</span></a>(A) por los cuadros cuadrados de color rojo completo, rojo punteado, gris oscuro y gris punteado. <code class="docutils literal notranslate"><span class="pre">Para</span> <span class="pre">cada</span> <span class="pre">posición</span> <span class="pre">se</span> <span class="pre">obtiene</span> <span class="pre">un</span> <span class="pre">valor</span> <span class="pre">de</span> <span class="pre">salida</span></code>. Por lo tanto, bajo el escenario descrito anteriormente, <code class="docutils literal notranslate"><span class="pre">las</span> <span class="pre">salidas</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">primera</span> <span class="pre">capa</span> <span class="pre">oculta</span> <span class="pre">forman</span> <span class="pre">una</span> <span class="pre">matriz</span> <span class="pre">de</span></code> <span class="math notranslate nohighlight">\(2\times 2\)</span>, <span class="math notranslate nohighlight">\(O\)</span>. <code class="docutils literal notranslate"><span class="pre">Cada</span> <span class="pre">uno</span> <span class="pre">de</span> <span class="pre">los</span> <span class="pre">elementos</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">matriz</span> <span class="pre">de</span> <span class="pre">salida</span> <span class="pre">codifica</span> <span class="pre">información</span> <span class="pre">de</span> <span class="pre">un</span> <span class="pre">área</span> <span class="pre">diferente</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">imagen</span> <span class="pre">de</span> <span class="pre">entrada</span></code>.</p></li>
</ul>
<ul class="simple">
<li><p>En el entorno más general, la <code class="docutils literal notranslate"><span class="pre">operación</span> <span class="pre">de</span> <span class="pre">convolución</span> <span class="pre">entre</span> <span class="pre">dos</span> <span class="pre">matrices,</span></code> <span class="math notranslate nohighlight">\(H\in R^{m\times m}\)</span> e <span class="math notranslate nohighlight">\(I\in\mathbb{R}^{l\times l}\)</span>, <code class="docutils literal notranslate"><span class="pre">es</span> <span class="pre">otra</span> <span class="pre">matriz,</span> <span class="pre">definida</span> <span class="pre">como</span></code></p></li>
</ul>
<div class="math notranslate nohighlight" id="equation-conv-oph-eq">
<span class="eqno">(61)<a class="headerlink" href="#equation-conv-oph-eq" title="Link to this equation">#</a></span>\[
O(i, j)=\sum_{t=1}^{m}\sum_{r=1}^{m}h(t, r)I(i+t-1, j+r-1),~\text{donde en este caso}~m&lt;l.
\]</div>
<ul class="simple">
<li><p>En otras palabras, <span class="math notranslate nohighlight">\(O(i, j)\)</span> <code class="docutils literal notranslate"><span class="pre">contiene</span> <span class="pre">información</span> <span class="pre">en</span> <span class="pre">un</span> <span class="pre">área</span> <span class="pre">de</span> <span class="pre">ventana</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">matriz</span> <span class="pre">de</span> <span class="pre">entrada</span></code>. De acuerdo con la definición de la Eq. <a class="reference internal" href="#equation-conv-oph-eq">(61)</a> <code class="docutils literal notranslate"><span class="pre">el</span> <span class="pre">elemento</span></code> <span class="math notranslate nohighlight">\(I(i, j)\)</span> <code class="docutils literal notranslate"><span class="pre">es</span> <span class="pre">el</span> <span class="pre">elemento</span> <span class="pre">superior</span> <span class="pre">izquierdo</span> <span class="pre">de</span> <span class="pre">esta</span> <span class="pre">área</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">ventana</span></code>. El tamaño de la ventana depende del valor de <span class="math notranslate nohighlight">\(m\)</span>. El <code class="docutils literal notranslate"><span class="pre">tamaño</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">matriz</span> <span class="pre">de</span> <span class="pre">salida</span> <span class="pre">depende</span> <span class="pre">de</span> <span class="pre">las</span> <span class="pre">suposiciones</span> <span class="pre">que</span> <span class="pre">se</span> <span class="pre">adopten</span> <span class="pre">sobre</span> <span class="pre">cómo</span> <span class="pre">tratar</span> <span class="pre">los</span> <span class="pre">elementos/píxeles</span> <span class="pre">en</span> <span class="pre">los</span> <span class="pre">bordes</span> <span class="pre">de</span></code> <span class="math notranslate nohighlight">\(I\)</span>. En sentido estricto, en la <code class="docutils literal notranslate"><span class="pre">jerga</span> <span class="pre">del</span> <span class="pre">procesamiento</span> <span class="pre">de</span> <span class="pre">señales</span></code>, la Eq. <a class="reference internal" href="#equation-conv-oph-eq">(61)</a> se conoce como <code class="docutils literal notranslate"><span class="pre">operación</span> <span class="pre">de</span> <span class="pre">correlación</span> <span class="pre">cruzada</span></code>. Para la <code class="docutils literal notranslate"><span class="pre">operación</span> <span class="pre">de</span> <span class="pre">convolución</span></code>, primero hay que invertir los índices. Sin embargo, este es el <code class="docutils literal notranslate"><span class="pre">nombre</span> <span class="pre">que</span> <span class="pre">ha</span> <span class="pre">&quot;sobrevivido&quot;</span> <span class="pre">en</span> <span class="pre">la</span> <span class="pre">comunidad</span> <span class="pre">del</span> <span class="pre">aprendizaje</span> <span class="pre">automático</span></code> y bien nos adherimos a él. Al fin y al cabo, ambas son <code class="docutils literal notranslate"><span class="pre">operaciones</span> <span class="pre">ponderadas</span> <span class="pre">sobre</span> <span class="pre">los</span> <span class="pre">píxeles</span> <span class="pre">dentro</span> <span class="pre">de</span> <span class="pre">un</span> <span class="pre">área</span> <span class="pre">de</span> <span class="pre">ventana</span> <span class="pre">de</span> <span class="pre">una</span> <span class="pre">imagen</span></code>.</p></li>
</ul>
<div class="proof observation admonition" id="observation_ann2">
<p class="admonition-title"><span class="caption-number">Observation 10 </span></p>
<section class="observation-content" id="proof-content">
<p>La discusión anterior nos “obliga” a pensar en una <code class="docutils literal notranslate"><span class="pre">capa</span> <span class="pre">oculta</span></code> como una <code class="docutils literal notranslate"><span class="pre">colección</span> <span class="pre">de</span> <span class="pre">nodos</span> <span class="pre">uno</span> <span class="pre">al</span> <span class="pre">lado</span> <span class="pre">del</span> <span class="pre">otro</span></code>. En cambio, <code class="docutils literal notranslate"><span class="pre">en</span> <span class="pre">una</span> <span class="pre">CNN,</span> <span class="pre">cada</span> <span class="pre">capa</span> <span class="pre">oculta</span> <span class="pre">corresponde</span> <span class="pre">a</span> <span class="pre">una</span> <span class="pre">(o</span> <span class="pre">a</span> <span class="pre">más</span> <span class="pre">de</span> <span class="pre">una,</span> <span class="pre">como</span> <span class="pre">pronto</span> <span class="pre">veremos)</span> <span class="pre">matriz</span></code> <span class="math notranslate nohighlight">\(H\)</span>. Además, <span class="math notranslate nohighlight">\(H\)</span> <code class="docutils literal notranslate"><span class="pre">se</span> <span class="pre">utiliza</span> <span class="pre">para</span> <span class="pre">realizar</span> <span class="pre">convoluciones</span></code>. Desde el punto de vista del <code class="docutils literal notranslate"><span class="pre">tratamiento</span> <span class="pre">de</span> <span class="pre">señales,</span> <span class="pre">esta</span> <span class="pre">matriz</span> <span class="pre">es</span> <span class="pre">un</span></code> <strong><code class="docutils literal notranslate"><span class="pre">filtro</span> <span class="pre">que</span> <span class="pre">actúa</span> <span class="pre">sobre</span> <span class="pre">la</span> <span class="pre">entrada</span> <span class="pre">para</span> <span class="pre">proporcionar</span> <span class="pre">la</span> <span class="pre">salida.</span></code></strong> En la jerga del aprendizaje de maquinas, también se denomina <code class="docutils literal notranslate"><span class="pre">matriz</span> <span class="pre">kernel</span> <span class="pre">en</span> <span class="pre">lugar</span> <span class="pre">de</span> <span class="pre">filtro</span></code>. La <code class="docutils literal notranslate"><span class="pre">matriz</span> <span class="pre">de</span> <span class="pre">salida</span> <span class="pre">suele</span> <span class="pre">denominarse</span> <span class="pre">la</span> <span class="pre">matriz</span> <span class="pre">del</span> <span class="pre">mapa</span> <span class="pre">de</span> <span class="pre">características</span></code>.</p>
</section>
</div><ul class="simple">
<li><p>En resumen, <code class="docutils literal notranslate"><span class="pre">al</span> <span class="pre">realizar</span> <span class="pre">convoluciones,</span> <span class="pre">en</span> <span class="pre">lugar</span> <span class="pre">de</span> <span class="pre">operaciones</span> <span class="pre">de</span> <span class="pre">producto</span> <span class="pre">interno</span></code>, hemos conseguido</p>
<ol class="arabic simple">
<li><p>Los <code class="docutils literal notranslate"><span class="pre">parámetros</span> <span class="pre">que</span> <span class="pre">componen</span> <span class="pre">la</span> <span class="pre">capa</span> <span class="pre">oculta</span> <span class="pre">son</span> <span class="pre">compartidos</span> <span class="pre">por</span> <span class="pre">todos</span> <span class="pre">los</span> <span class="pre">píxeles</span> <span class="pre">de</span> <span class="pre">entrada</span></code> y no tenemos un conjunto dedicado de parámetros por elemento de entrada (píxel)</p></li>
<li><p>Las <code class="docutils literal notranslate"><span class="pre">salidas</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">capa</span> <span class="pre">oculta</span> <span class="pre">codifican</span> <span class="pre">la</span> <span class="pre">información</span> <span class="pre">de</span> <span class="pre">correlación</span> <span class="pre">de</span> <span class="pre">vecindad</span> <span class="pre">local</span> <span class="pre">de</span> <span class="pre">las</span> <span class="pre">distintas</span> <span class="pre">zonas</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">imagen</span> <span class="pre">de</span> <span class="pre">entrada</span></code>.</p></li>
<li><p>Además, como la <code class="docutils literal notranslate"><span class="pre">salida</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">capa</span> <span class="pre">oculta</span> <span class="pre">también</span> <span class="pre">es</span> <span class="pre">una</span> <span class="pre">matriz</span> <span class="pre">de</span> <span class="pre">imágenes</span></code>, se puede considerar como la <code class="docutils literal notranslate"><span class="pre">entrada</span> <span class="pre">a</span> <span class="pre">una</span> <span class="pre">segunda</span> <span class="pre">capa</span> <span class="pre">oculta</span> <span class="pre">y</span> <span class="pre">construir</span> <span class="pre">así</span> <span class="pre">una</span> <span class="pre">red</span> <span class="pre">con</span> <span class="pre">muchas</span> <span class="pre">capas,</span> <span class="pre">cada</span> <span class="pre">una</span> <span class="pre">de</span> <span class="pre">las</span> <span class="pre">cuales</span> <span class="pre">realiza</span> <span class="pre">convoluciones</span></code>.</p></li>
</ol>
</li>
</ul>
<ul class="simple">
<li><p>De hecho, <code class="docutils literal notranslate"><span class="pre">estas</span> <span class="pre">operaciones</span> <span class="pre">de</span> <span class="pre">filtrado</span> <span class="pre">se</span> <span class="pre">han</span> <span class="pre">utilizado</span> <span class="pre">tradicionalmente</span> <span class="pre">para</span> <span class="pre">generar</span> <span class="pre">características</span> <span class="pre">a</span> <span class="pre">partir</span> <span class="pre">de</span> <span class="pre">imágenes</span></code>. La diferencia era que los elementos de la matriz de filtrado se preseleccionaban. Tomemos ejemplo, la siguiente matriz:</p></li>
</ul>
<div class="math notranslate nohighlight" id="equation-h-filter-conv-eq">
<span class="eqno">(62)<a class="headerlink" href="#equation-h-filter-conv-eq" title="Link to this equation">#</a></span>\[\begin{split}
H=
\begin{bmatrix}
-1 &amp; -1 &amp; -1\\
-1 &amp; 8 &amp; -1\\
-1 &amp; -1 &amp; -1
\end{bmatrix}
\end{split}\]</div>
<ul class="simple">
<li><p>El filtro anterior se conoce como <code class="docutils literal notranslate"><span class="pre">detector</span> <span class="pre">de</span> <span class="pre">bordes</span></code>. <code class="docutils literal notranslate"><span class="pre">Convolucionando</span> <span class="pre">una</span> <span class="pre">matriz</span> <span class="pre">de</span> <span class="pre">imagen,</span></code> <span class="math notranslate nohighlight">\(I\)</span> <code class="docutils literal notranslate"><span class="pre">,</span> <span class="pre">con</span> <span class="pre">la</span> <span class="pre">matriz</span> <span class="pre">anterior,</span></code> <span class="math notranslate nohighlight">\(H\)</span><code class="docutils literal notranslate"><span class="pre">,detecta</span> <span class="pre">los</span> <span class="pre">bordes</span> <span class="pre">de</span> <span class="pre">una</span> <span class="pre">imagen</span></code>. La <a class="reference internal" href="#edge-detect-convh-numref"><span class="std std-numref">Fig. 45</span></a>A muestra la <code class="docutils literal notranslate"><span class="pre">imagen</span> <span class="pre">de</span> <span class="pre">un</span> <span class="pre">barco</span></code> y la <a class="reference internal" href="#edge-detect-convh-numref"><span class="std std-numref">Fig. 45</span></a>B muestra la <code class="docutils literal notranslate"><span class="pre">salida</span> <span class="pre">después</span> <span class="pre">del</span> <span class="pre">filtrado</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">imagen</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">izquierda</span> <span class="pre">con</span> <span class="pre">la</span> <span class="pre">matriz</span> <span class="pre">de</span> <span class="pre">filtrado</span></code> <span class="math notranslate nohighlight">\(H\)</span> anterior.</p></li>
</ul>
<figure class="align-center" id="edge-detect-convh-numref">
<a class="reference internal image-reference" href="_images/edge_detect_convH.png"><img alt="_images/edge_detect_convH.png" src="_images/edge_detect_convH.png" style="width: 667.2px; height: 360.0px;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 45 </span><span class="caption-text">(A) Imagen original y (B) Bordes de la imagen extraídos tras filtrar la matriz de la imagen original con el filtro <span class="math notranslate nohighlight">\(H\)</span> de la ecuación Eq. <a class="reference internal" href="#equation-h-filter-conv-eq">(62)</a>. Fuente <span id="id8">[<a class="reference internal" href="biblio.html#id17" title="S. Theodoridis. Machine Learning: A Bayesian and Optimization Perspective. Elsevier Science, 2020. ISBN 9780128188040. URL: https://books.google.com.co/books?id=l-nEDwAAQBAJ.">Theodoridis, 2020</a>]</span>.</span><a class="headerlink" href="#edge-detect-convh-numref" title="Link to this image">#</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p>La detección de bordes es de <code class="docutils literal notranslate"><span class="pre">gran</span> <span class="pre">importancia</span> <span class="pre">en</span> <span class="pre">la</span> <span class="pre">comprensión</span> <span class="pre">de</span> <span class="pre">imágenes</span></code>. Además, <code class="docutils literal notranslate"><span class="pre">cambiando</span> <span class="pre">adecuadamente</span> <span class="pre">los</span> <span class="pre">valores</span> <span class="pre">en</span></code> <span class="math notranslate nohighlight">\(H\)</span><code class="docutils literal notranslate"><span class="pre">,</span> <span class="pre">se</span> <span class="pre">pueden</span> <span class="pre">detectar</span> <span class="pre">bordes</span> <span class="pre">en</span> <span class="pre">diferentes</span> <span class="pre">orientaciones</span></code>, por ejemplo, <code class="docutils literal notranslate"><span class="pre">diagonal,</span> <span class="pre">vertical,</span> <span class="pre">horizontal</span></code>; en otras palabras, cambiando los valores de <span class="math notranslate nohighlight">\(H\)</span> se pueden <code class="docutils literal notranslate"><span class="pre">generar</span> <span class="pre">diferentes</span> <span class="pre">tipos</span> <span class="pre">de</span> <span class="pre">características</span></code>.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">skimage.color</span> <span class="kn">import</span> <span class="n">rgb2gray</span>
<span class="kn">from</span> <span class="nn">skimage.io</span> <span class="kn">import</span> <span class="n">imread</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">signal</span>
<span class="kn">import</span> <span class="nn">matplotlib.pylab</span> <span class="k">as</span> <span class="nn">pylab</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">im</span> <span class="o">=</span> <span class="n">rgb2gray</span><span class="p">(</span><span class="n">imread</span><span class="p">(</span><span class="s1">&#39;imgs/cameraman.jpg&#39;</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">im</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">im</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(256, 256) 0.9921568627450982
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">blur_box_kernel</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span> <span class="o">/</span> <span class="mi">9</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">edge_laplace_kernel</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">],[</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span><span class="mi">1</span><span class="p">],[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">]])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">edge_laplace_kernel</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[ 0,  1,  0],
       [ 1, -4,  1],
       [ 0,  1,  0]])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">im_blurred</span> <span class="o">=</span> <span class="n">signal</span><span class="o">.</span><span class="n">convolve2d</span><span class="p">(</span><span class="n">im</span><span class="p">,</span> <span class="n">blur_box_kernel</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">im_edges</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">signal</span><span class="o">.</span><span class="n">convolve2d</span><span class="p">(</span><span class="n">im</span><span class="p">,</span> <span class="n">edge_laplace_kernel</span><span class="p">),</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">pylab</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">ncols</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">sharex</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">sharey</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">im</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">pylab</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">gray</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Original Image&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">im_blurred</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">pylab</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">gray</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Box Blur&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">im_edges</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">pylab</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">gray</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Laplace Edge Detection&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="k">for</span> <span class="n">ax</span> <span class="ow">in</span> <span class="n">axes</span><span class="p">:</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/1e8d29990e0a466bdb8feb949d6f8ebb98bb826ab2416b37ae1843eed5ec51f4.png" src="_images/1e8d29990e0a466bdb8feb949d6f8ebb98bb826ab2416b37ae1843eed5ec51f4.png" />
</div>
</div>
<ul class="simple">
<li><p>Nos hemos acercado a <code class="docutils literal notranslate"><span class="pre">la</span> <span class="pre">idea</span> <span class="pre">que</span> <span class="pre">subyace</span> <span class="pre">a</span> <span class="pre">las</span> <span class="pre">CNN</span></code></p>
<ol class="arabic simple">
<li><p><code class="docutils literal notranslate"><span class="pre">En</span> <span class="pre">lugar</span> <span class="pre">de</span> <span class="pre">utilizar</span> <span class="pre">una</span> <span class="pre">matriz</span> <span class="pre">de</span> <span class="pre">filtro/núcleo</span> <span class="pre">fija</span></code>, como en el ejemplo del detector de bordes, <code class="docutils literal notranslate"><span class="pre">deje</span> <span class="pre">el</span> <span class="pre">cálculo</span> <span class="pre">de</span> <span class="pre">los</span> <span class="pre">valores</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">matriz</span> <span class="pre">de</span> <span class="pre">filtro,</span></code> <span class="math notranslate nohighlight">\(H\)</span> <code class="docutils literal notranslate"><span class="pre">,</span> <span class="pre">para</span> <span class="pre">la</span> <span class="pre">fase</span> <span class="pre">de</span> <span class="pre">entrenamiento</span></code>. En otras palabras, hacemos que <span class="math notranslate nohighlight">\(H\)</span> se adapte a los datos y no preseleccionada.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">En</span> <span class="pre">lugar</span> <span class="pre">de</span> <span class="pre">utilizar</span> <span class="pre">una</span> <span class="pre">única</span> <span class="pre">matriz</span> <span class="pre">de</span> <span class="pre">filtros,</span> <span class="pre">empleamos</span> <span class="pre">más</span> <span class="pre">de</span> <span class="pre">una</span></code>. Cada una de ellas generará un tipo diferente de características. Por ejemplo, una puede <code class="docutils literal notranslate"><span class="pre">generar</span> <span class="pre">bordes</span> <span class="pre">diagonales,</span> <span class="pre">la</span> <span class="pre">otra</span> <span class="pre">horizontales,</span> <span class="pre">etc</span></code>. Por lo tanto, <code class="docutils literal notranslate"><span class="pre">cada</span> <span class="pre">capa</span> <span class="pre">oculta</span> <span class="pre">comprenderá</span> <span class="pre">más</span> <span class="pre">de</span> <span class="pre">una</span> <span class="pre">matriz</span> <span class="pre">de</span> <span class="pre">filtrado</span></code>. Los valores de los elementos de cada una de <code class="docutils literal notranslate"><span class="pre">las</span> <span class="pre">matrices</span> <span class="pre">de</span> <span class="pre">filtrado</span> <span class="pre">se</span> <span class="pre">calcularán</span> <span class="pre">durante</span> <span class="pre">la</span> <span class="pre">fase</span> <span class="pre">de</span> <span class="pre">entrenamiento,</span> <span class="pre">optimizando</span> <span class="pre">algún</span> <span class="pre">criterio</span></code>. En otras palabras, <code class="docutils literal notranslate"><span class="pre">cada</span> <span class="pre">capa</span> <span class="pre">oculta</span> <span class="pre">de</span> <span class="pre">una</span> <span class="pre">CNN</span> <span class="pre">genera</span> <span class="pre">un</span> <span class="pre">conjunto</span> <span class="pre">de</span> <span class="pre">características</span> <span class="pre">de</span> <span class="pre">forma</span> <span class="pre">óptima.</span></code></p></li>
</ol>
</li>
</ul>
<figure class="align-center" id="feature-maps-inp-img-numref">
<a class="reference internal image-reference" href="_images/feature_maps_inp_img.png"><img alt="_images/feature_maps_inp_img.png" src="_images/feature_maps_inp_img.png" style="width: 666.4000000000001px; height: 362.40000000000003px;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 46 </span><span class="caption-text">Ilustración de <code class="docutils literal notranslate"><span class="pre">tres</span> <span class="pre">filtros/núcleos</span></code>. <code class="docutils literal notranslate"><span class="pre">Profundidad</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">capa</span> <span class="pre">oculta</span></code> (número de filtro) es <code class="docutils literal notranslate"><span class="pre">tres</span></code>. Fuente <span id="id9">[<a class="reference internal" href="biblio.html#id17" title="S. Theodoridis. Machine Learning: A Bayesian and Optimization Perspective. Elsevier Science, 2020. ISBN 9780128188040. URL: https://books.google.com.co/books?id=l-nEDwAAQBAJ.">Theodoridis, 2020</a>]</span>.</span><a class="headerlink" href="#feature-maps-inp-img-numref" title="Link to this image">#</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p>La <a class="reference internal" href="#feature-maps-inp-img-numref"><span class="std std-numref">Fig. 46</span></a> ilustra la entrada y la primera capa oculta de una CNN. La entrada comprende una matriz imagen. La <code class="docutils literal notranslate"><span class="pre">capa</span> <span class="pre">oculta</span> <span class="pre">consta</span> <span class="pre">de</span> <span class="pre">tres</span> <span class="pre">matrices</span> <span class="pre">de</span> <span class="pre">filtrado,</span> <span class="pre">a</span> <span class="pre">saber,</span></code> <span class="math notranslate nohighlight">\(H_{1}, H_{2}, H_{3}\)</span>. Nótese que cada matriz es el resultado de <code class="docutils literal notranslate"><span class="pre">convolucionar</span> <span class="pre">una</span> <span class="pre">matriz</span> <span class="pre">de</span> <span class="pre">filtros</span> <span class="pre">diferente</span> <span class="pre">sobre</span> <span class="pre">la</span> <span class="pre">imagen</span> <span class="pre">de</span> <span class="pre">entrada</span></code>. Cuantos <code class="docutils literal notranslate"><span class="pre">más</span> <span class="pre">filtros</span> <span class="pre">se</span> <span class="pre">empleen,</span> <span class="pre">más</span> <span class="pre">mapas</span> <span class="pre">de</span> <span class="pre">características</span> <span class="pre">se</span> <span class="pre">extraerán</span> <span class="pre">y,</span> <span class="pre">en</span> <span class="pre">principio,</span> <span class="pre">mejor</span> <span class="pre">será</span> <span class="pre">el</span> <span class="pre">rendimiento</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">red</span></code>. Sin embargo, cuantos más filtros utilicemos, más parámetros habrá que aprender, lo que plantea <code class="docutils literal notranslate"><span class="pre">problemas</span> <span class="pre">computacionales</span> <span class="pre">y</span> <span class="pre">de</span> <span class="pre">sobreajuste</span></code>. Nótese que <code class="docutils literal notranslate"><span class="pre">cada</span> <span class="pre">píxel</span> <span class="pre">de</span> <span class="pre">una</span> <span class="pre">matriz</span> <span class="pre">de</span> <span class="pre">mapa</span> <span class="pre">de</span> <span class="pre">características</span> <span class="pre">de</span> <span class="pre">salida</span> <span class="pre">codifica</span> <span class="pre">información</span> <span class="pre">dentro</span> <span class="pre">del</span> <span class="pre">área</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">ventana</span></code> que está definida por la <code class="docutils literal notranslate"><span class="pre">posición</span> <span class="pre">correspondiente</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">respectiva</span> <span class="pre">matriz</span> <span class="pre">de</span> <span class="pre">filtro</span></code>.</p></li>
</ul>
<div class="proof observation admonition" id="observation_ann3">
<p class="admonition-title"><span class="caption-number">Observation 11 </span></p>
<section class="observation-content" id="proof-content">
<ul class="simple">
<li><p>Una <code class="docutils literal notranslate"><span class="pre">característica</span> <span class="pre">importante</span> <span class="pre">de</span> <span class="pre">una</span> <span class="pre">CNN</span> <span class="pre">es</span> <span class="pre">que</span> <span class="pre">la</span> <span class="pre">invariancia</span> <span class="pre">de</span> <span class="pre">traslación</span> <span class="pre">está</span> <span class="pre">integrada</span> <span class="pre">de</span> <span class="pre">forma</span> <span class="pre">natural</span> <span class="pre">en</span> <span class="pre">la</span> <span class="pre">red</span> <span class="pre">y</span> <span class="pre">es</span> <span class="pre">un</span> <span class="pre">subproducto</span> <span class="pre">de</span> <span class="pre">las</span> <span class="pre">circunvoluciones</span> <span class="pre">implicadas</span></code>. De hecho, estas últimas <code class="docutils literal notranslate"><span class="pre">se</span> <span class="pre">realizan</span> <span class="pre">deslizando</span> <span class="pre">la</span> <span class="pre">misma</span> <span class="pre">matriz</span> <span class="pre">de</span> <span class="pre">filtros</span> <span class="pre">sobre</span> <span class="pre">toda</span> <span class="pre">la</span> <span class="pre">imagen</span></code>. Así, <code class="docutils literal notranslate"><span class="pre">si</span> <span class="pre">un</span> <span class="pre">objeto</span> <span class="pre">presente</span> <span class="pre">en</span> <span class="pre">una</span> <span class="pre">imagen</span> <span class="pre">se</span> <span class="pre">coloca</span> <span class="pre">en</span> <span class="pre">otra</span> <span class="pre">posición</span></code>, la única diferencia sería que <code class="docutils literal notranslate"><span class="pre">la</span> <span class="pre">contribución</span> <span class="pre">de</span> <span class="pre">este</span> <span class="pre">objeto</span> <span class="pre">a</span> <span class="pre">la</span> <span class="pre">salida</span> <span class="pre">también</span> <span class="pre">se</span> <span class="pre">desplazará</span> <span class="pre">la</span> <span class="pre">misma</span> <span class="pre">cantidad</span> <span class="pre">en</span> <span class="pre">el</span> <span class="pre">número</span> <span class="pre">de</span> <span class="pre">píxeles</span></code>.</p></li>
<li><p>Es interesante señalar que <code class="docutils literal notranslate"><span class="pre">existen</span> <span class="pre">pruebas</span> <span class="pre">sólidas</span> <span class="pre">en</span> <span class="pre">el</span> <span class="pre">campo</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">neurociencia</span> <span class="pre">visual</span> <span class="pre">de</span> <span class="pre">que</span> <span class="pre">en</span> <span class="pre">el</span> <span class="pre">ser</span> <span class="pre">humano</span> <span class="pre">se</span> <span class="pre">realizan</span> <span class="pre">cálculos</span> <span class="pre">similares</span></code>. (ver <span id="id10">[<a class="reference internal" href="biblio.html#id28" title="David H Hubel and Torsten N Wiesel. Receptive fields, binocular interaction and functional architecture in the cat's visual cortex. The Journal of physiology, 160(1):106, 1962.">Hubel and Wiesel, 1962</a>, <a class="reference internal" href="biblio.html#id29" title="Thomas Serre, Gabriel Kreiman, Minjoon Kouh, Charles Cadieu, Ulf Knoblich, and Tomaso Poggio. A quantitative theory of immediate visual recognition. Progress in brain research, 165:33–56, 2007.">Serre <em>et al.</em>, 2007</a>]</span>). La noción de convoluciones fue usada inicialmente por <span id="id11">[<a class="reference internal" href="biblio.html#id30" title="Kunihiko Fukushima, Sei Miyake, and Takayuki Ito. Neocognitron: a neural network model for a mechanism of visual pattern recognition. IEEE transactions on systems, man, and cybernetics, pages 826–834, 1983.">Fukushima <em>et al.</em>, 1983</a>]</span> en el contexto del aprendizaje no supervisado.</p></li>
</ul>
</section>
</div><ul class="simple">
<li><p>A continuación, presentamos algunos <code class="docutils literal notranslate"><span class="pre">términos</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">jerga</span> <span class="pre">utilizada</span> <span class="pre">en</span> <span class="pre">relación</span> <span class="pre">con</span> <span class="pre">las</span> <span class="pre">CNN:</span></code></p></li>
</ul>
<ol class="arabic simple">
<li><p><strong><code class="docutils literal notranslate"><span class="pre">Profundidad</span></code></strong>: La <code class="docutils literal notranslate"><span class="pre">profundidad</span> <span class="pre">de</span> <span class="pre">una</span> <span class="pre">capa</span></code> es el <code class="docutils literal notranslate"><span class="pre">número</span> <span class="pre">de</span> <span class="pre">matrices</span> <span class="pre">de</span> <span class="pre">filtro</span> <span class="pre">que</span> <span class="pre">se</span> <span class="pre">emplean</span> <span class="pre">en</span> <span class="pre">esta</span> <span class="pre">capa</span></code>. No debe confundirse profundidad de la red, que corresponde al número total de capas ocultas utilizadas. <code class="docutils literal notranslate"><span class="pre">A</span> <span class="pre">veces,</span> <span class="pre">nos</span> <span class="pre">referimos</span> <span class="pre">al</span> <span class="pre">número</span> <span class="pre">de</span> <span class="pre">filtros</span> <span class="pre">como</span> <span class="pre">el</span> <span class="pre">número</span> <span class="pre">de</span> <span class="pre">canales</span></code>.</p></li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">Campo</span> <span class="pre">receptivo</span></code></strong>: <code class="docutils literal notranslate"><span class="pre">Cada</span> <span class="pre">píxel</span></code> de una matriz de características de salida resulta como una <code class="docutils literal notranslate"><span class="pre">media</span> <span class="pre">ponderada</span> <span class="pre">de</span> <span class="pre">los</span> <span class="pre">píxeles</span> <span class="pre">dentro</span> <span class="pre">de</span> <span class="pre">un</span> <span class="pre">área</span> <span class="pre">específica</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">matriz</span> <span class="pre">de</span> <span class="pre">imágenes</span> <span class="pre">de</span> <span class="pre">entrada</span></code> (o de la salida de la capa anterior). El área específica que corresponde a un píxel se conoce como su <code class="docutils literal notranslate"><span class="pre">campo</span> <span class="pre">receptivo</span></code> (ver <a class="reference internal" href="#feature-maps-inp-img-numref"><span class="std std-numref">Fig. 46</span></a>).</p></li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">Deslizamiento</span></code></strong>: En la práctica, <code class="docutils literal notranslate"><span class="pre">en</span> <span class="pre">lugar</span> <span class="pre">de</span> <span class="pre">deslizar</span> <span class="pre">la</span> <span class="pre">matriz</span> <span class="pre">de</span> <span class="pre">filtros</span> <span class="pre">de</span> <span class="pre">píxel</span> <span class="pre">en</span> <span class="pre">píxel,</span> <span class="pre">se</span> <span class="pre">puede</span> <span class="pre">deslizar,</span> <span class="pre">por</span> <span class="pre">ejemplo,</span></code> <span class="math notranslate nohighlight">\(s\)</span> <code class="docutils literal notranslate"><span class="pre">píxeles</span></code>. Este valor se conoce como <code class="docutils literal notranslate"><span class="pre">stride</span></code>. Para valores de <span class="math notranslate nohighlight">\(s &gt; 1\)</span>, se obtienen matrices de mapas de características de menor tamaño. Esto se ilustra en <a class="reference internal" href="#stride-conv-prop-numref"><span class="std std-numref">Fig. 47</span></a>A y B.</p></li>
</ol>
<figure class="align-center" id="stride-conv-prop-numref">
<a class="reference internal image-reference" href="_images/stride_conv_prop.png"><img alt="_images/stride_conv_prop.png" src="_images/stride_conv_prop.png" style="width: 671.2px; height: 415.20000000000005px;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 47 </span><span class="caption-text">Matriz de entrada y filtro de tamaños 5 × 5 y 3 × 3 respectivamente. En (A), el paso es igual a <span class="math notranslate nohighlight">\(s = 1\)</span> y en (B) es igual a <span class="math notranslate nohighlight">\(s = 2\)</span>. En (A) la salida es una matriz de tamaño 3 × 3 y en (B) de tamaño 2 × 2. Fuente <span id="id12">[<a class="reference internal" href="biblio.html#id17" title="S. Theodoridis. Machine Learning: A Bayesian and Optimization Perspective. Elsevier Science, 2020. ISBN 9780128188040. URL: https://books.google.com.co/books?id=l-nEDwAAQBAJ.">Theodoridis, 2020</a>]</span>.</span><a class="headerlink" href="#stride-conv-prop-numref" title="Link to this image">#</a></p>
</figcaption>
</figure>
<ol class="arabic simple" start="4">
<li><p><strong><code class="docutils literal notranslate"><span class="pre">Relleno</span> <span class="pre">de</span> <span class="pre">ceros</span></code></strong>: A veces, <code class="docutils literal notranslate"><span class="pre">se</span> <span class="pre">utilizan</span> <span class="pre">ceros</span> <span class="pre">para</span> <span class="pre">rellenar</span> <span class="pre">la</span> <span class="pre">matriz</span> <span class="pre">de</span> <span class="pre">entrada</span> <span class="pre">alrededor</span> <span class="pre">de</span> <span class="pre">los</span> <span class="pre">píxeles</span> <span class="pre">del</span> <span class="pre">borde</span></code>. De esta forma, <code class="docutils literal notranslate"><span class="pre">la</span> <span class="pre">dimensión</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">matriz</span> <span class="pre">aumenta</span></code>. Si la matriz original tiene dimensiones <span class="math notranslate nohighlight">\(l\times l\)</span>, <code class="docutils literal notranslate"><span class="pre">después</span> <span class="pre">de</span> <span class="pre">expandirla</span> <span class="pre">con</span></code> <span class="math notranslate nohighlight">\(p\)</span> <code class="docutils literal notranslate"><span class="pre">columnas</span> <span class="pre">y</span> <span class="pre">filas,</span> <span class="pre">las</span> <span class="pre">nuevas</span> <span class="pre">dimensiones</span> <span class="pre">pasan</span> <span class="pre">a</span> <span class="pre">ser</span></code> (<span class="math notranslate nohighlight">\(l + 2p\)</span>). Esto se muestra en la <a class="reference internal" href="#zero-fill-conv-numref"><span class="std std-numref">Fig. 48</span></a>.</p></li>
</ol>
<figure class="align-center" id="zero-fill-conv-numref">
<a class="reference internal image-reference" href="_images/zero_fill_conv.png"><img alt="_images/zero_fill_conv.png" src="_images/zero_fill_conv.png" style="width: 182.4px; height: 180.8px;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 48 </span><span class="caption-text">Ejemplo en el que la matriz original es de 5 × 5 y tras rellenarla con <span class="math notranslate nohighlight">\(p = 2\)</span> filas y columnas, su tamaño pasa a ser de
9 × 9. Fuente <span id="id13">[<a class="reference internal" href="biblio.html#id17" title="S. Theodoridis. Machine Learning: A Bayesian and Optimization Perspective. Elsevier Science, 2020. ISBN 9780128188040. URL: https://books.google.com.co/books?id=l-nEDwAAQBAJ.">Theodoridis, 2020</a>]</span>.</span><a class="headerlink" href="#zero-fill-conv-numref" title="Link to this image">#</a></p>
</figcaption>
</figure>
<ol class="arabic simple" start="5">
<li><p><strong><code class="docutils literal notranslate"><span class="pre">Término</span> <span class="pre">de</span> <span class="pre">sesgo</span></code></strong>: Después de cada operación de convolución que genera un píxel del mapa de características, <code class="docutils literal notranslate"><span class="pre">se</span> <span class="pre">añade</span> <span class="pre">un</span> <span class="pre">término</span> <span class="pre">de</span> <span class="pre">sesgo,</span></code> <span class="math notranslate nohighlight">\(b\)</span>. El valor de este término también <code class="docutils literal notranslate"><span class="pre">se</span> <span class="pre">calcula</span> <span class="pre">durante</span> <span class="pre">el</span> <span class="pre">entrenamiento</span></code>. Nótese que se utiliza un término de sesgo común para todos los píxeles del mismo mapa de características. Esto está en consonancia con la <code class="docutils literal notranslate"><span class="pre">lógica</span> <span class="pre">del</span> <span class="pre">reparto</span> <span class="pre">de</span> <span class="pre">pesos</span></code>. <code class="docutils literal notranslate"><span class="pre">Del</span> <span class="pre">mismo</span> <span class="pre">modo</span> <span class="pre">que</span> <span class="pre">todos</span> <span class="pre">los</span> <span class="pre">parámetros</span> <span class="pre">de</span> <span class="pre">una</span> <span class="pre">matriz</span> <span class="pre">de</span> <span class="pre">filtro</span> <span class="pre">son</span> <span class="pre">compartidos</span> <span class="pre">por</span> <span class="pre">todos</span> <span class="pre">los</span> <span class="pre">píxeles</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">matriz</span> <span class="pre">de</span> <span class="pre">imágenes</span> <span class="pre">de</span> <span class="pre">entrada,</span> <span class="pre">se</span> <span class="pre">utiliza</span> <span class="pre">el</span> <span class="pre">mismo</span> <span class="pre">término</span> <span class="pre">de</span> <span class="pre">sesgo</span> <span class="pre">para</span> <span class="pre">todos</span> <span class="pre">los</span> <span class="pre">píxeles</span></code>.</p></li>
</ol>
<ul>
<li><p>Se puede <code class="docutils literal notranslate"><span class="pre">ajustar</span> <span class="pre">el</span> <span class="pre">tamaño</span> <span class="pre">de</span> <span class="pre">una</span> <span class="pre">matriz</span> <span class="pre">de</span> <span class="pre">mapa</span> <span class="pre">de</span> <span class="pre">características</span></code> de salida <code class="docutils literal notranslate"><span class="pre">ajustando</span> <span class="pre">el</span> <span class="pre">valor</span> <span class="pre">del</span> <span class="pre">stride,</span></code> <span class="math notranslate nohighlight">\(s\)</span>, y el
<code class="docutils literal notranslate"><span class="pre">número</span> <span class="pre">de</span> <span class="pre">columnas</span> <span class="pre">y</span> <span class="pre">filas</span> <span class="pre">cero</span> <span class="pre">adicionales</span></code> en el relleno. En general, se puede comprobar fácilmente que si <span class="math notranslate nohighlight">\(I\in\mathbb{R}^{l\times l}, H\in\mathbb{R}^{m\times m}\)</span>, y <span class="math notranslate nohighlight">\(p\)</span> <code class="docutils literal notranslate"><span class="pre">es</span> <span class="pre">el</span> <span class="pre">número</span> <span class="pre">de</span> <span class="pre">filas</span> <span class="pre">y</span> <span class="pre">columnas</span> <span class="pre">adicionales</span></code> para el relleno, entonces el mapa de características tiene dimensiones <span class="math notranslate nohighlight">\(k\times k\)</span>, donde</p>
<div class="math notranslate nohighlight" id="equation-resulting-matrix-size">
<span class="eqno">(63)<a class="headerlink" href="#equation-resulting-matrix-size" title="Link to this equation">#</a></span>\[
    k=\lfloor\frac{l+2p-m}{s}+1\rfloor,
    \]</div>
<p>y <span class="math notranslate nohighlight">\(\lfloor\cdot\rfloor\)</span> es el <code class="docutils literal notranslate"><span class="pre">operador</span> <span class="pre">suelo</span></code>, i.e <span class="math notranslate nohighlight">\(\lfloor2.7\rfloor=2\)</span>.</p>
</li>
</ul>
<ul class="simple">
<li><p>Por ejemplo, si <span class="math notranslate nohighlight">\(l = 5, m = 3, p = 0\)</span> y <span class="math notranslate nohighlight">\(s = 1\)</span>, entonces <span class="math notranslate nohighlight">\(k = 3\)</span>. Por otro lado, si <span class="math notranslate nohighlight">\(l = 5, m = 3, p = 0\)</span> y <span class="math notranslate nohighlight">\(s = 2\)</span>, entonces <span class="math notranslate nohighlight">\(k = 2\)</span> (ver <a class="reference internal" href="#stride-conv-prop-numref"><span class="std std-numref">Fig. 47</span></a>A y B). Nótese que si los valores de <span class="math notranslate nohighlight">\(l, m, p\)</span> y <span class="math notranslate nohighlight">\(s\)</span> son tales que la matriz de filtrado, al deslizarse sobre <span class="math notranslate nohighlight">\(I\)</span>, cae fuera de <span class="math notranslate nohighlight">\(I\)</span>, estas operaciones no se realizan. <code class="docutils literal notranslate"><span class="pre">Sólo</span> <span class="pre">realizamos</span> <span class="pre">operaciones</span> <span class="pre">mientras</span> <span class="pre">la</span> <span class="pre">matriz</span> <span class="pre">filtro</span> <span class="pre">esté</span> <span class="pre">contenida</span> <span class="pre">dentro</span> <span class="pre">de</span></code> <span class="math notranslate nohighlight">\(I\)</span>.</p></li>
</ul>
</section>
<section id="el-paso-de-la-no-linealidad">
<h3>El paso de la no linealidad<a class="headerlink" href="#el-paso-de-la-no-linealidad" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>Una vez que <code class="docutils literal notranslate"><span class="pre">se</span> <span class="pre">han</span> <span class="pre">realizado</span> <span class="pre">las</span> <span class="pre">convoluciones</span> <span class="pre">y</span> <span class="pre">se</span> <span class="pre">ha</span> <span class="pre">añadido</span> <span class="pre">el</span> <span class="pre">término</span> <span class="pre">de</span> <span class="pre">sesgo</span></code> a todos los valores del mapa de características, el siguiente paso es <code class="docutils literal notranslate"><span class="pre">aplicar</span> <span class="pre">una</span> <span class="pre">no</span> <span class="pre">linealidad</span> <span class="pre">(función</span> <span class="pre">de</span> <span class="pre">activación)</span> <span class="pre">a</span> <span class="pre">cada</span> <span class="pre">uno</span> <span class="pre">de</span> <span class="pre">los</span> <span class="pre">píxeles</span> <span class="pre">de</span> <span class="pre">cada</span> <span class="pre">matriz</span></code> de mapas de características. Se puede emplear cualquiera de las no linealidades que se han comentado anteriormente. Actualmente, la <code class="docutils literal notranslate"><span class="pre">función</span> <span class="pre">de</span> <span class="pre">activación</span> <span class="pre">lineal</span> <span class="pre">rectificada,</span> <span class="pre">ReLU,</span> <span class="pre">parece</span> <span class="pre">ser</span> <span class="pre">la</span> <span class="pre">más</span> <span class="pre">popular</span></code>. La <a class="reference internal" href="#relu-activ-fn-numref"><span class="std std-numref">Fig. 49</span></a>A muestra la imagen obtenida después de <code class="docutils literal notranslate"><span class="pre">filtrar</span> <span class="pre">la</span> <span class="pre">imagen</span> <span class="pre">original</span> <span class="pre">del</span> <span class="pre">barco</span> <span class="pre">con</span> <span class="pre">el</span> <span class="pre">detector</span> <span class="pre">de</span> <span class="pre">bordes</span> <span class="pre">en</span> <span class="pre">la</span></code> <a class="reference internal" href="#equation-h-filter-conv-eq">(62)</a> y la <a class="reference internal" href="#relu-activ-fn-numref"><span class="std std-numref">Fig. 49</span></a>B muestra el resultado que se obtiene tras la <code class="docutils literal notranslate"><span class="pre">aplicación</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">no</span> <span class="pre">linealidad</span> <span class="pre">en</span> <span class="pre">cada</span> <span class="pre">píxel</span> <span class="pre">individual</span></code>.</p></li>
</ul>
<figure class="align-center" id="relu-activ-fn-numref">
<a class="reference internal image-reference" href="_images/relu_activ_fn.png"><img alt="_images/relu_activ_fn.png" src="_images/relu_activ_fn.png" style="width: 630.4000000000001px; height: 340.8px;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 49 </span><span class="caption-text">(A) Imagen donde se han extraído los bordes y (B) imagen resultante tras aplicar el en cada uno de los píxeles. Fuente <span id="id14">[<a class="reference internal" href="biblio.html#id17" title="S. Theodoridis. Machine Learning: A Bayesian and Optimization Perspective. Elsevier Science, 2020. ISBN 9780128188040. URL: https://books.google.com.co/books?id=l-nEDwAAQBAJ.">Theodoridis, 2020</a>]</span>.</span><a class="headerlink" href="#relu-activ-fn-numref" title="Link to this image">#</a></p>
</figcaption>
</figure>
</section>
<section id="la-etapa-de-agrupacion">
<h3>La etapa de agrupación<a class="headerlink" href="#la-etapa-de-agrupacion" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>El objetivo de este paso es <code class="docutils literal notranslate"><span class="pre">reducir</span> <span class="pre">la</span> <span class="pre">dimensionalidad</span> <span class="pre">de</span> <span class="pre">cada</span> <span class="pre">matriz</span> <span class="pre">de</span> <span class="pre">mapas</span> <span class="pre">de</span> <span class="pre">características</span></code>. A veces, el paso también se denomina <code class="docutils literal notranslate"><span class="pre">pooling</span> <span class="pre">espacial</span></code>. Para ello, <code class="docutils literal notranslate"><span class="pre">se</span> <span class="pre">define</span> <span class="pre">una</span> <span class="pre">ventana</span> <span class="pre">y</span> <span class="pre">se</span> <span class="pre">desliza</span> <span class="pre">sobre</span> <span class="pre">la</span> <span class="pre">matriz</span> <span class="pre">correspondiente</span></code>. El deslizamiento puede realizarse <code class="docutils literal notranslate"><span class="pre">adoptando</span> <span class="pre">un</span> <span class="pre">valor</span> <span class="pre">para</span> <span class="pre">el</span> <span class="pre">respectivo</span> <span class="pre">parámetro</span> <span class="pre">stride,</span></code> <span class="math notranslate nohighlight">\(s\)</span>. La operación de pooling consiste en <code class="docutils literal notranslate"><span class="pre">elegir</span> <span class="pre">un</span> <span class="pre">único</span> <span class="pre">valor</span> <span class="pre">para</span> <span class="pre">representar</span> <span class="pre">todos</span> <span class="pre">los</span> <span class="pre">píxeles</span> <span class="pre">que</span> <span class="pre">se</span> <span class="pre">encuentran</span> <span class="pre">dentro</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">ventana</span></code>. La operación más utilizada es la <code class="docutils literal notranslate"><span class="pre">agrupación</span> <span class="pre">máxima;</span> <span class="pre">es</span> <span class="pre">decir,</span> <span class="pre">entre</span> <span class="pre">todos</span> <span class="pre">los</span> <span class="pre">píxeles</span> <span class="pre">que</span> <span class="pre">se</span> <span class="pre">encuentran</span> <span class="pre">dentro</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">ventana,</span> <span class="pre">el</span> <span class="pre">que</span> <span class="pre">tiene</span> <span class="pre">el</span> <span class="pre">valor</span> <span class="pre">más</span> <span class="pre">alto</span> <span class="pre">es</span> <span class="pre">seleccionado</span></code>. Otra posibilidad es la <code class="docutils literal notranslate"><span class="pre">agrupación</span> <span class="pre">en</span> <span class="pre">la</span> <span class="pre">que</span> <span class="pre">se</span> <span class="pre">selecciona</span> <span class="pre">el</span> <span class="pre">valor</span> <span class="pre">medio</span> <span class="pre">de</span> <span class="pre">todos</span> <span class="pre">los</span> <span class="pre">píxeles</span></code>; a veces se denomina pooling de suma. La operación de pooling se ilustra en la <a class="reference internal" href="#pooling-step-conv-numref"><span class="std std-numref">Fig. 50</span></a>. La matriz de la <code class="docutils literal notranslate"><span class="pre">imagen</span> <span class="pre">original</span> <span class="pre">es</span> <span class="pre">de</span> <span class="pre">6</span> <span class="pre">×</span> <span class="pre">6</span> <span class="pre">y</span> <span class="pre">la</span> <span class="pre">ventana</span> <span class="pre">es</span> <span class="pre">de</span> <span class="pre">tamaño</span> <span class="pre">2</span> <span class="pre">×</span> <span class="pre">2</span></code>. Hemos elegido que el stride sea igual a <span class="math notranslate nohighlight">\(s = 2\)</span>.</p></li>
</ul>
<figure class="align-center" id="pooling-step-conv-numref">
<a class="reference internal image-reference" href="_images/pooling_step_conv.png"><img alt="_images/pooling_step_conv.png" src="_images/pooling_step_conv.png" style="width: 333.6px; height: 207.20000000000002px;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 50 </span><span class="caption-text">(A) Matriz original de tamaño de 6 × 6. Agrupación mediante una ventana de 2 × 2 y un intervalo <span class="math notranslate nohighlight">\(s = 2\)</span>. Valor máximo por ubicación de la ventana se indica en negrita. (B) Matriz 3 × 3 resultante tras la agrupación máxima. Fuente <span id="id15">[<a class="reference internal" href="biblio.html#id17" title="S. Theodoridis. Machine Learning: A Bayesian and Optimization Perspective. Elsevier Science, 2020. ISBN 9780128188040. URL: https://books.google.com.co/books?id=l-nEDwAAQBAJ.">Theodoridis, 2020</a>]</span>.</span><a class="headerlink" href="#pooling-step-conv-numref" title="Link to this image">#</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p>Se puede utilizar la misma fórmula que en la Eq. <a class="reference internal" href="#equation-resulting-matrix-size">(63)</a> para <code class="docutils literal notranslate"><span class="pre">calcular</span> <span class="pre">el</span> <span class="pre">tamaño</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">matriz</span> <span class="pre">resultante</span> <span class="pre">en</span> <span class="pre">el</span> <span class="pre">caso</span> <span class="pre">general</span></code>. Por lo tanto, el efecto de la agrupación es <code class="docutils literal notranslate"><span class="pre">reducir</span> <span class="pre">(a</span> <span class="pre">través</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">reducción</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">muestra)</span> <span class="pre">la</span> <span class="pre">dimensionalidad</span> <span class="pre">y</span> <span class="pre">reducir</span> <span class="pre">el</span> <span class="pre">tamaño</span> <span class="pre">de</span> <span class="pre">las</span> <span class="pre">matrices</span></code>. Esto es importante porque la <code class="docutils literal notranslate"><span class="pre">salida</span> <span class="pre">de</span> <span class="pre">cada</span> <span class="pre">capa</span> <span class="pre">se</span> <span class="pre">presenta</span> <span class="pre">como</span> <span class="pre">la</span> <span class="pre">entrada</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">siguiente</span></code>. Por lo tanto, <code class="docutils literal notranslate"><span class="pre">controlar</span> <span class="pre">el</span> <span class="pre">tamaño</span> <span class="pre">de</span> <span class="pre">las</span> <span class="pre">matrices</span> <span class="pre">es</span> <span class="pre">de</span> <span class="pre">vital</span> <span class="pre">importancia</span> <span class="pre">para</span> <span class="pre">controlar</span> <span class="pre">el</span> <span class="pre">número</span> <span class="pre">de</span> <span class="pre">parámetros</span> <span class="pre">implicados</span></code>. Por supuesto, la reducción de tamaño debe hacerse de tal manera que la <code class="docutils literal notranslate"><span class="pre">pérdida</span> <span class="pre">de</span> <span class="pre">información</span> <span class="pre">sea</span> <span class="pre">la</span> <span class="pre">menor</span> <span class="pre">posible</span></code>.</p></li>
</ul>
<figure class="align-center" id="pooling-invariant-conv-numref">
<a class="reference internal image-reference" href="_images/pooling_invariant_conv.png"><img alt="_images/pooling_invariant_conv.png" src="_images/pooling_invariant_conv.png" style="width: 607.2px; height: 375.20000000000005px;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 51 </span><span class="caption-text">(A) Bordes de la imagen del barco tras la aplicación de <code class="docutils literal notranslate"><span class="pre">ReLu</span></code> (B) Imagen resultante tras aplicar <code class="docutils literal notranslate"><span class="pre">max-pooling</span></code> utilizando una ventana de 8 × 8. Fuente <span id="id16">[<a class="reference internal" href="biblio.html#id17" title="S. Theodoridis. Machine Learning: A Bayesian and Optimization Perspective. Elsevier Science, 2020. ISBN 9780128188040. URL: https://books.google.com.co/books?id=l-nEDwAAQBAJ.">Theodoridis, 2020</a>]</span>.</span><a class="headerlink" href="#pooling-invariant-conv-numref" title="Link to this image">#</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p><a class="reference internal" href="#pooling-invariant-conv-numref"><span class="std std-numref">Fig. 51</span></a> muestra el efecto de <code class="docutils literal notranslate"><span class="pre">aplicar</span> <span class="pre">el</span> <span class="pre">pooling</span> <span class="pre">a</span> <span class="pre">la</span> <span class="pre">imagen</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">izquierda</span></code>. Sin duda, <code class="docutils literal notranslate"><span class="pre">los</span> <span class="pre">bordes</span> <span class="pre">se</span> <span class="pre">vuelven</span> <span class="pre">más</span> <span class="pre">gruesos,</span> <span class="pre">pero</span> <span class="pre">la</span> <span class="pre">información</span> <span class="pre">relacionada</span> <span class="pre">con</span> <span class="pre">los</span> <span class="pre">bordes</span> <span class="pre">puede</span> <span class="pre">extraerse</span></code>. Nótese que después de la agrupación, el tamaño de la matriz imagen es reducido. Desde otro punto de vista, <code class="docutils literal notranslate"><span class="pre">el</span> <span class="pre">polling</span> <span class="pre">resume</span> <span class="pre">las</span> <span class="pre">estadísticas</span> <span class="pre">dentro</span> <span class="pre">del</span> <span class="pre">área</span> <span class="pre">pooling</span></code>. El pooling puede considerarse un <code class="docutils literal notranslate"><span class="pre">tipo</span> <span class="pre">especial</span> <span class="pre">de</span> <span class="pre">filtrado,</span> <span class="pre">en</span> <span class="pre">el</span> <span class="pre">que,</span> <span class="pre">en</span> <span class="pre">lugar</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">convolución,</span> <span class="pre">se</span> <span class="pre">selecciona</span> <span class="pre">el</span> <span class="pre">valor</span> <span class="pre">máximo</span> <span class="pre">(o</span> <span class="pre">medio)</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">imagen</span></code>. El pooling ayuda a que la representación sea aproximadamente invariante a pequeñas traslaciones de la entrada.</p></li>
</ul>
</section>
<section id="convolucion-sobre-volumenes">
<h3>Convolución sobre volúmenes<a class="headerlink" href="#convolucion-sobre-volumenes" title="Link to this heading">#</a></h3>
<div class="proof observation admonition" id="observation_ann4">
<p class="admonition-title"><span class="caption-number">Observation 12 </span></p>
<section class="observation-content" id="proof-content">
<p>En la <a class="reference internal" href="#feature-maps-inp-img-numref"><span class="std std-numref">Fig. 46</span></a>, <code class="docutils literal notranslate"><span class="pre">la</span> <span class="pre">salida</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">primera</span> <span class="pre">capa</span> <span class="pre">oculta</span> <span class="pre">comprende</span> <span class="pre">tres</span> <span class="pre">matrices</span> <span class="pre">de</span> <span class="pre">imágenes</span></code>. Éstas constituirán la entrada de la capa siguiente. Tal configuración de entrada que consiste en múltiples imágenes es también el caso cuando la <code class="docutils literal notranslate"><span class="pre">imagen</span> <span class="pre">de</span> <span class="pre">entrada</span> <span class="pre">es</span> <span class="pre">en</span> <span class="pre">color</span></code> y su representación se da en términos de una <code class="docutils literal notranslate"><span class="pre">representación</span> <span class="pre">RGB</span></code>; es decir, la entrada consta de <code class="docutils literal notranslate"><span class="pre">tres</span> <span class="pre">matrices,</span> <span class="pre">una</span> <span class="pre">por</span> <span class="pre">color</span></code>. Así, en general, las entradas no son matrices bidimensionales, sino <code class="docutils literal notranslate"><span class="pre">conjuntos</span> <span class="pre">de</span> <span class="pre">matrices</span> <span class="pre">bidimensionales</span></code>. En matemáticas, estas entidades se conocen como <code class="docutils literal notranslate"><span class="pre">matrices</span> <span class="pre">multilineales,</span> <span class="pre">matrices</span> <span class="pre">tridimensionales,</span> <span class="pre">tensores</span> <span class="pre">tridimensionales</span> <span class="pre">o</span> <span class="pre">volúmenes</span></code>. Nos ceñiremos a este último término, porque recuerda a la geometría asociada, del mismo modo que pensamos en una imagen como un cuadrado bidimensional. La cuestión ahora es ver <code class="docutils literal notranslate"><span class="pre">cómo</span> <span class="pre">se</span> <span class="pre">pueden</span> <span class="pre">realizar</span> <span class="pre">convoluciones</span> <span class="pre">cuando</span> <span class="pre">hay</span> <span class="pre">volúmenes</span> <span class="pre">implicados</span></code>.</p>
</section>
</div><figure class="align-center" id="matrix-to-volume-conv-numref">
<a class="reference internal image-reference" href="_images/matrix_to_volume_conv.png"><img alt="_images/matrix_to_volume_conv.png" src="_images/matrix_to_volume_conv.png" style="width: 433.6px; height: 172.0px;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 52 </span><span class="caption-text">Se apilan <span class="math notranslate nohighlight">\(d\)</span> matrices de tamaño <span class="math notranslate nohighlight">\(h\times w\)</span> cada una para formar un volumen de tamaño <span class="math notranslate nohighlight">\(h \times w\times d\)</span>. En este caso, <span class="math notranslate nohighlight">\(h = w = 5\)</span> y <span class="math notranslate nohighlight">\(d = 3\)</span>. Fuente <span id="id17">[<a class="reference internal" href="biblio.html#id17" title="S. Theodoridis. Machine Learning: A Bayesian and Optimization Perspective. Elsevier Science, 2020. ISBN 9780128188040. URL: https://books.google.com.co/books?id=l-nEDwAAQBAJ.">Theodoridis, 2020</a>]</span>.</span><a class="headerlink" href="#matrix-to-volume-conv-numref" title="Link to this image">#</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p>Por convención, las tres dimensiones de un volumen se representarán como <span class="math notranslate nohighlight">\(h\)</span> <code class="docutils literal notranslate"><span class="pre">para</span> <span class="pre">la</span> <span class="pre">altura,</span></code> <span class="math notranslate nohighlight">\(w\)</span> <code class="docutils literal notranslate"><span class="pre">para</span> <span class="pre">la</span> <span class="pre">anchura</span></code> y <span class="math notranslate nohighlight">\(d\)</span> <code class="docutils literal notranslate"><span class="pre">para</span> <span class="pre">la</span> <span class="pre">profundidad</span></code>. Nótese que la profundidad <span class="math notranslate nohighlight">\(d\)</span> <code class="docutils literal notranslate"><span class="pre">corresponde</span> <span class="pre">al</span> <span class="pre">número</span> <span class="pre">de</span> <span class="pre">imágenes</span> <span class="pre">implicadas</span></code>. Así pues, si tenemos <code class="docutils literal notranslate"><span class="pre">tres</span> <span class="pre">imágenes</span> <span class="pre">de</span> <span class="pre">256</span> <span class="pre">×</span> <span class="pre">256</span></code>, entonces <span class="math notranslate nohighlight">\(h = w = 256\)</span> y <span class="math notranslate nohighlight">\(d = 3\)</span> y diremos que el volumen es de <code class="docutils literal notranslate"><span class="pre">tamaño</span> <span class="pre">(dimensión)</span> <span class="pre">256</span> <span class="pre">×</span> <span class="pre">256</span> <span class="pre">×</span> <span class="pre">3</span></code>. <a class="reference internal" href="#matrix-to-volume-conv-numref"><span class="std std-numref">Fig. 52</span></a> ilustra la geometría asociada a las respectivas definiciones.</p></li>
</ul>
<div class="proof definition admonition" id="definition-6">
<p class="admonition-title"><span class="caption-number">Definition 10 </span></p>
<section class="definition-content" id="proof-content">
<ul class="simple">
<li><p>Sea la entrada de una capa un volumen <span class="math notranslate nohighlight">\(h\times w\times d\)</span>. <code class="docutils literal notranslate"><span class="pre">Cuando</span> <span class="pre">se</span> <span class="pre">trata</span> <span class="pre">de</span> <span class="pre">volúmenes,</span> <span class="pre">las</span> <span class="pre">capas</span> <span class="pre">ocultas</span> <span class="pre">están</span> <span class="pre">formadas</span> <span class="pre">por</span> <span class="pre">volúmenes</span> <span class="pre">de</span> <span class="pre">filtro/núcleo.</span> <span class="pre">Sin</span> <span class="pre">embargo,</span> <span class="pre">aquí</span> <span class="pre">hay</span> <span class="pre">un</span> <span class="pre">punto</span> <span class="pre">crucial</span></code>. El <code class="docutils literal notranslate"><span class="pre">volumen</span> <span class="pre">de</span> <span class="pre">filtro</span> <span class="pre">asociado</span> <span class="pre">con</span> <span class="pre">la</span> <span class="pre">capa</span> <span class="pre">oculta</span></code> debe tener la <code class="docutils literal notranslate"><span class="pre">misma</span> <span class="pre">profundidad</span> <span class="pre">que</span> <span class="pre">el</span> <span class="pre">volumen</span> <span class="pre">de</span> <span class="pre">entrada</span></code>. Las dimensiones de <code class="docutils literal notranslate"><span class="pre">altura</span> <span class="pre">y</span> <span class="pre">anchura</span> <span class="pre">pueden</span> <span class="pre">ser</span> <span class="pre">(y</span> <span class="pre">en</span> <span class="pre">la</span> <span class="pre">práctica</span> <span class="pre">suelen</span> <span class="pre">ser)</span> <span class="pre">diferentes</span></code>. Utilizaremos letras <code class="docutils literal notranslate"><span class="pre">mayúsculas</span> <span class="pre">en</span> <span class="pre">negrita</span> <span class="pre">para</span> <span class="pre">indicar</span> <span class="pre">los</span> <span class="pre">volúmenes</span></code>.</p></li>
<li><p>Supongamos que <code class="docutils literal notranslate"><span class="pre">la</span> <span class="pre">entrada</span> <span class="pre">es</span> <span class="pre">un</span> <span class="pre">volumen</span></code> <span class="math notranslate nohighlight">\(\boldsymbol{I}\)</span> de <span class="math notranslate nohighlight">\(l\times l\times d\)</span>. Nótese que, éste comprende <span class="math notranslate nohighlight">\(d\)</span> imágenes, digamos, <span class="math notranslate nohighlight">\(I_{r}, r = 1, 2,\dots, d\)</span>, cada una de ellas de <code class="docutils literal notranslate"><span class="pre">dimensiones</span></code> <span class="math notranslate nohighlight">\(l\times l\)</span>. Sea <span class="math notranslate nohighlight">\(\boldsymbol{H}\)</span> el filtro volumen de <span class="math notranslate nohighlight">\(m\times m\times d\)</span>. Este último comprende el conjunto de <span class="math notranslate nohighlight">\(d\)</span> <code class="docutils literal notranslate"><span class="pre">imágenes</span></code>, <span class="math notranslate nohighlight">\(H_{r}, r = 1, 2,\dots, d\)</span>, cada una de dimensiones <span class="math notranslate nohighlight">\(m\times m\)</span>. A continuación, la <code class="docutils literal notranslate"><span class="pre">operación</span> <span class="pre">de</span> <span class="pre">convolución</span> <span class="pre">se</span> <span class="pre">define</span> <span class="pre">mediante</span> <span class="pre">los</span> <span class="pre">siguientes</span> <span class="pre">pasos</span></code>:</p></li>
</ul>
<ol class="arabic simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Convolucionar</span> <span class="pre">las</span> <span class="pre">correspondientes</span> <span class="pre">matrices</span> <span class="pre">de</span> <span class="pre">imágenes</span> <span class="pre">bidimensionales</span> <span class="pre">para</span> <span class="pre">generar</span></code> <span class="math notranslate nohighlight">\(d\)</span> <code class="docutils literal notranslate"><span class="pre">matrices</span> <span class="pre">bidimensionales</span> <span class="pre">de</span> <span class="pre">salida</span></code>, es decir</p></li>
</ol>
<div class="math notranslate nohighlight">
\[
O_{r}=I_{r}\star H_{r},\quad r=1,2,\dots,d.
\]</div>
<ol class="arabic" start="2">
<li><p>La <code class="docutils literal notranslate"><span class="pre">convolución</span> <span class="pre">de</span> <span class="pre">los</span> <span class="pre">dos</span> <span class="pre">volúmenes</span></code>, <span class="math notranslate nohighlight">\(\boldsymbol{I}\)</span> y <span class="math notranslate nohighlight">\(\boldsymbol{H}\)</span>, se define como</p>
<div class="math notranslate nohighlight">
\[
    O=\sum_{r=1}^{d}O_{r}.
    \]</div>
<p>En otras palabras, la <code class="docutils literal notranslate"><span class="pre">convolución</span> <span class="pre">(denotada</span> <span class="pre">por</span></code> <span class="math notranslate nohighlight">\(\star\)</span><code class="docutils literal notranslate"><span class="pre">)</span> <span class="pre">de</span> <span class="pre">dos</span> <span class="pre">volúmenes</span> <span class="pre">es</span> <span class="pre">una</span> <span class="pre">matriz</span> <span class="pre">bidimensional</span></code>, es decir,</p>
<div class="math notranslate nohighlight">
\[
    \text{3D volume}\star\text{3D volume}=\text{2D array}.
    \]</div>
</li>
</ol>
</section>
</div><figure class="align-center" id="volume-conv-3dto2d-numref">
<a class="reference internal image-reference" href="_images/volume_conv_3Dto2D.png"><img alt="_images/volume_conv_3Dto2D.png" src="_images/volume_conv_3Dto2D.png" style="width: 749.4px; height: 158.4px;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 53 </span><span class="caption-text">Convolución <span class="math notranslate nohighlight">\(\text{3D volume}\star\text{3D volume}=\text{2D array}\)</span>. <span class="math notranslate nohighlight">\(h = w = l, h = w = m\)</span> y <span class="math notranslate nohighlight">\(d = 3\)</span>.</span><a class="headerlink" href="#volume-conv-3dto2d-numref" title="Link to this image">#</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p>La operación se ilustra en la <a class="reference internal" href="#volume-conv-3dto2d-numref"><span class="std std-numref">Fig. 53</span></a>. Las <code class="docutils literal notranslate"><span class="pre">matrices</span> <span class="pre">correspondientes</span> <span class="pre">(mostradas</span> <span class="pre">por</span> <span class="pre">diferentes</span> <span class="pre">colores</span> <span class="pre">y</span> <span class="pre">tipos</span> <span class="pre">de</span> <span class="pre">líneas)</span></code>. Las <code class="docutils literal notranslate"><span class="pre">tres</span> <span class="pre">matrices</span> <span class="pre">de</span> <span class="pre">salida</span></code> (<span class="math notranslate nohighlight">\(d = 3\)</span>) <code class="docutils literal notranslate"><span class="pre">se</span> <span class="pre">suman</span> <span class="pre">posteriormente</span> <span class="pre">para</span> <span class="pre">formar</span> <span class="pre">la</span> <span class="pre">convolución</span> <span class="pre">de</span> <span class="pre">los</span> <span class="pre">dos</span> <span class="pre">volúmenes</span></code>. La dimensión <span class="math notranslate nohighlight">\(k\)</span> de la salida depende de los valores de <span class="math notranslate nohighlight">\(l\)</span> y <span class="math notranslate nohighlight">\(m\)</span>, del intervalo <span class="math notranslate nohighlight">\(s\)</span> y del relleno relleno <span class="math notranslate nohighlight">\(p\)</span>, si se utiliza, según la Eq. <a class="reference internal" href="#equation-resulting-matrix-size">(63)</a>. En la práctica, <code class="docutils literal notranslate"><span class="pre">cada</span> <span class="pre">capa</span> <span class="pre">de</span> <span class="pre">una</span> <span class="pre">red</span> <span class="pre">convolucional</span> <span class="pre">comprende</span> <span class="pre">varios</span> <span class="pre">de</span> <span class="pre">estos</span> <span class="pre">volúmenes</span> <span class="pre">de</span> <span class="pre">filtrado</span></code>. Por ejemplo, si la entrada a una capa es un volumen <span class="math notranslate nohighlight">\(l\times l\times d\)</span>, y hay, digamos, <span class="math notranslate nohighlight">\(c\)</span> volúmenes de núcleo, cada uno de dimensiones <span class="math notranslate nohighlight">\(m\times m\times d\)</span>, la salida de la capa será un volumen <span class="math notranslate nohighlight">\(k\times k\times c\)</span>, donde <span class="math notranslate nohighlight">\(k\)</span> se determina la Eq. <a class="reference internal" href="#equation-resulting-matrix-size">(63)</a>.</p></li>
</ul>
</section>
<section id="red-en-red-y-convolucion-1-1">
<h3>Red en red y convolución 1 × 1<a class="headerlink" href="#red-en-red-y-convolucion-1-1" title="Link to this heading">#</a></h3>
<div class="proof observation admonition" id="observation_ann5">
<p class="admonition-title"><span class="caption-number">Observation 13 </span></p>
<section class="observation-content" id="proof-content">
<ul class="simple">
<li><p>La convolución 1 × 1 no tiene sentido cuando se trata de matrices bidimensionales. En efecto <code class="docutils literal notranslate"><span class="pre">una</span> <span class="pre">matriz</span> <span class="pre">de</span> <span class="pre">filtro</span> <span class="pre">1</span> <span class="pre">×</span> <span class="pre">1</span> <span class="pre">es</span> <span class="pre">un</span> <span class="pre">escalar</span></code>. <code class="docutils literal notranslate"><span class="pre">Convolucionar</span> <span class="pre">una</span> <span class="pre">matriz</span></code> <span class="math notranslate nohighlight">\(I\)</span> <code class="docutils literal notranslate"><span class="pre">de</span></code> <span class="math notranslate nohighlight">\(l\times l\)</span> <code class="docutils literal notranslate"><span class="pre">con</span> <span class="pre">un</span> <span class="pre">escalar</span></code> <span class="math notranslate nohighlight">\(a\)</span> <code class="docutils literal notranslate"><span class="pre">equivale</span> <span class="pre">a</span> <span class="pre">deslizar</span> <span class="pre">el</span> <span class="pre">valor</span> <span class="pre">escalar</span> <span class="pre">sobre</span> <span class="pre">todos</span> <span class="pre">los</span> <span class="pre">píxeles</span> <span class="pre">y</span> <span class="pre">multiplicar</span> <span class="pre">cada</span> <span class="pre">uno</span> <span class="pre">de</span> <span class="pre">ellos</span> <span class="pre">por</span></code> <span class="math notranslate nohighlight">\(a\)</span>. El resultado es la trivial <span class="math notranslate nohighlight">\(aI\)</span> .</p></li>
</ul>
</section>
</div><ul>
<li><p>Sin embargo, <code class="docutils literal notranslate"><span class="pre">cuando</span> <span class="pre">se</span> <span class="pre">trata</span> <span class="pre">de</span> <span class="pre">volúmenes,</span> <span class="pre">la</span> <span class="pre">convolución</span> <span class="pre">1</span> <span class="pre">×</span> <span class="pre">1</span> <span class="pre">tiene</span> <span class="pre">sentido</span></code>. En este caso, el filtro correspondiente, <span class="math notranslate nohighlight">\(\boldsymbol{H}\)</span>, es un volumen de tamaño <span class="math notranslate nohighlight">\(1\times 1\times d\)</span>. <code class="docutils literal notranslate"><span class="pre">Geométricamente,</span> <span class="pre">se</span> <span class="pre">trata</span> <span class="pre">de</span> <span class="pre">un</span> <span class="pre">&quot;tubo&quot;</span></code>, con <span class="math notranslate nohighlight">\(h = w = 1\)</span> y <span class="math notranslate nohighlight">\(d\)</span> elementos en profundidad, <span class="math notranslate nohighlight">\(h(1, 1, r), r = 1, 2,\dots,d\)</span>. Por lo tanto, <code class="docutils literal notranslate"><span class="pre">el</span> <span class="pre">resultado</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">convolución</span> <span class="pre">de</span> <span class="pre">un</span> <span class="pre">volumen</span></code> <span class="math notranslate nohighlight">\(\boldsymbol{I}\)</span> de <span class="math notranslate nohighlight">\(l\times l\times d\)</span> con un <span class="math notranslate nohighlight">\(1\times 1\times d\)</span> volumen <span class="math notranslate nohighlight">\(H\)</span> <code class="docutils literal notranslate"><span class="pre">es</span> <span class="pre">la</span> <span class="pre">media</span> <span class="pre">ponderada</span></code>,</p>
<div class="math notranslate nohighlight">
\[
    O=\boldsymbol{I}\star\boldsymbol{H}=\sum_{r=1}^{d}h(1, 1, r)I_{r}
    \]</div>
<p>donde <span class="math notranslate nohighlight">\(I_{r},~r=1,2,\dots,d,\)</span> son las <span class="math notranslate nohighlight">\(d\)</span> matrices, cada una de dimensiones <span class="math notranslate nohighlight">\(l\times l\)</span>, que comprende <span class="math notranslate nohighlight">\(\boldsymbol{I}\)</span>.</p>
</li>
</ul>
<div class="proof observation admonition" id="observation_ann6">
<p class="admonition-title"><span class="caption-number">Observation 14 </span></p>
<section class="observation-content" id="proof-content">
<ul>
<li><p>Ahora bien, cabe preguntarse <code class="docutils literal notranslate"><span class="pre">por</span> <span class="pre">qué</span> <span class="pre">necesitamos</span> <span class="pre">una</span> <span class="pre">operación</span> <span class="pre">de</span> <span class="pre">este</span> <span class="pre">tipo</span> <span class="pre">en</span> <span class="pre">la</span> <span class="pre">práctica</span></code>. La respuesta está relacionada con el <code class="docutils literal notranslate"><span class="pre">tamaño</span> <span class="pre">de</span> <span class="pre">los</span> <span class="pre">volúmenes</span> <span class="pre">implicados</span></code>; mediante el uso de convoluciones 1 × 1, <code class="docutils literal notranslate"><span class="pre">se</span> <span class="pre">puede</span> <span class="pre">controlar</span> <span class="pre">y</span> <span class="pre">cambiar</span> <span class="pre">su</span> <span class="pre">tamaño</span> <span class="pre">para</span> <span class="pre">adaptarlo</span> <span class="pre">a</span> <span class="pre">las</span> <span class="pre">necesidades</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">red</span></code>.</p></li>
<li><p>Supongamos que en una <code class="docutils literal notranslate"><span class="pre">etapa/capa</span></code> de una red profunda hemos obtenido un volumen <span class="math notranslate nohighlight">\(\boldsymbol{I}\)</span> de dimensiones <span class="math notranslate nohighlight">\(k\times k\times d\)</span>. <code class="docutils literal notranslate"><span class="pre">Para</span> <span class="pre">cambiar</span> <span class="pre">la</span> <span class="pre">profundidad</span> <span class="pre">de</span></code> <span class="math notranslate nohighlight">\(d\)</span> a <span class="math notranslate nohighlight">\(c\)</span><code class="docutils literal notranslate"><span class="pre">,</span> <span class="pre">conservando</span> <span class="pre">el</span> <span class="pre">mismo</span> <span class="pre">tamaño</span></code> <span class="math notranslate nohighlight">\(k\)</span>, para la altura y la anchura, <code class="docutils literal notranslate"><span class="pre">empleamos</span></code> <span class="math notranslate nohighlight">\(c\)</span> <code class="docutils literal notranslate"><span class="pre">volúmenes,</span></code> <span class="math notranslate nohighlight">\(H_{t}, t = 1, 2,\dots,c\)</span>``, cada uno de dimensiones` <span class="math notranslate nohighlight">\(1\times 1\times d\)</span>. Al realizar las <span class="math notranslate nohighlight">\(c\)</span> convoluciones obtenemos</p>
<div class="math notranslate nohighlight">
\[
    O_{t}=\boldsymbol{I}\star\boldsymbol{H}_{t}=\sum_{r=1}^{d}h_{t}(1, 1, r)I_{r},~t=1,2,\dots,c.
    \]</div>
<p>Apilando <span class="math notranslate nohighlight">\(O_{t}, t = 1, 2,\dots,c\)</span>, obtenemos el volumen <span class="math notranslate nohighlight">\(\boldsymbol{O}\)</span> de dimensión <span class="math notranslate nohighlight">\(k\times k\times c\)</span> (ver <a class="reference internal" href="#x1conv-dim-reduction-numref"><span class="std std-numref">Fig. 54</span></a>).</p>
</li>
<li><p>La <code class="docutils literal notranslate"><span class="pre">información</span> <span class="pre">original</span> <span class="pre">se</span> <span class="pre">sigue</span> <span class="pre">conservando</span> <span class="pre">en</span> <span class="pre">el</span> <span class="pre">nuevo</span> <span class="pre">volumen,</span> <span class="pre">de</span> <span class="pre">forma</span> <span class="pre">promediada</span></code>. A menudo, una vez obtenido el nuevo volumen <span class="math notranslate nohighlight">\(\boldsymbol{O}\)</span>, <code class="docutils literal notranslate"><span class="pre">sus</span> <span class="pre">elementos</span> <span class="pre">se</span> <span class="pre">&quot;empujan&quot;</span> <span class="pre">a</span> <span class="pre">través</span> <span class="pre">de</span> <span class="pre">una</span> <span class="pre">no</span> <span class="pre">linealidad</span></code>, por ejemplo, <code class="docutils literal notranslate"><span class="pre">ReLU</span></code>. La convolución <span class="math notranslate nohighlight">\(1\times 1\)</span> seguida de la no linealidad se denomina <strong><code class="docutils literal notranslate"><span class="pre">operación</span> <span class="pre">de</span> <span class="pre">red</span> <span class="pre">en</span> <span class="pre">red</span></code></strong> y su finalidad es <code class="docutils literal notranslate"><span class="pre">añadir</span> <span class="pre">una</span> <span class="pre">etapa</span> <span class="pre">de</span> <span class="pre">no</span> <span class="pre">linealidad</span> <span class="pre">adicional</span> <span class="pre">en</span> <span class="pre">el</span> <span class="pre">flujo</span> <span class="pre">de</span> <span class="pre">operaciones</span> <span class="pre">a</span> <span class="pre">través</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">red</span></code>. Por lo tanto, en este contexto, si <span class="math notranslate nohighlight">\(c&lt;d\)</span>, <code class="docutils literal notranslate"><span class="pre">la</span> <span class="pre">operación</span> <span class="pre">de</span> <span class="pre">red</span> <span class="pre">en</span> <span class="pre">red</span> <span class="pre">puede</span> <span class="pre">considerarse</span> <span class="pre">una</span> <span class="pre">técnica</span> <span class="pre">de</span> <span class="pre">reducción</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">dimensionalidad</span> <span class="pre">no</span> <span class="pre">lineal</span></code>.</p></li>
</ul>
</section>
</div><figure class="align-center" id="x1conv-dim-reduction-numref">
<a class="reference internal image-reference" href="_images/1x1conv_dim_reduction.png"><img alt="_images/1x1conv_dim_reduction.png" src="_images/1x1conv_dim_reduction.png" style="width: 706.3px; height: 274.4px;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 54 </span><span class="caption-text">Convolución <span class="math notranslate nohighlight">\(1\times 1\)</span>, con <span class="math notranslate nohighlight">\(c\)</span> tubos de dimensión <span class="math notranslate nohighlight">\(1\times 1\times d\)</span>, donde <span class="math notranslate nohighlight">\(d\)</span> es la profundidad del volumen de entrada. Fuente <span id="id18">[<a class="reference internal" href="biblio.html#id17" title="S. Theodoridis. Machine Learning: A Bayesian and Optimization Perspective. Elsevier Science, 2020. ISBN 9780128188040. URL: https://books.google.com.co/books?id=l-nEDwAAQBAJ.">Theodoridis, 2020</a>]</span>.</span><a class="headerlink" href="#x1conv-dim-reduction-numref" title="Link to this image">#</a></p>
</figcaption>
</figure>
<div class="proof example admonition" id="bottleneck_example_1x1conv_prfref">
<p class="admonition-title"><span class="caption-number">Example 3 </span></p>
<section class="example-content" id="proof-content">
<ul class="simple">
<li><p>Consideremos que la <code class="docutils literal notranslate"><span class="pre">entrada</span> <span class="pre">de</span> <span class="pre">una</span> <span class="pre">capa</span> <span class="pre">es</span> <span class="pre">un</span> <span class="pre">volumen</span></code> <span class="math notranslate nohighlight">\(\boldsymbol{I}\)</span> de 28 × 28 × 192. El objetivo es <code class="docutils literal notranslate"><span class="pre">producir</span> <span class="pre">a</span> <span class="pre">la</span> <span class="pre">salida</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">capa</span> <span class="pre">un</span> <span class="pre">volumen,</span></code> <span class="math notranslate nohighlight">\(O\)</span><code class="docutils literal notranslate"><span class="pre">,</span> <span class="pre">de</span> <span class="pre">dimensión</span></code> 28 × 28 × 32. Para ello <code class="docutils literal notranslate"><span class="pre">emplear</span> <span class="pre">5</span> <span class="pre">×</span> <span class="pre">5</span> <span class="pre">convoluciones</span> <span class="pre">iguales</span></code> y un volumen intermedio <span class="math notranslate nohighlight">\(\boldsymbol{O}'\)</span> de dimensiones <span class="math notranslate nohighlight">\(28\times 28\times 16\)</span>.</p></li>
<li><p>Verifique <code class="docutils literal notranslate"><span class="pre">directamente</span></code> que, rellenando todas las matrices apiladas en <span class="math notranslate nohighlight">\(\boldsymbol{I}\)</span> con <span class="math notranslate nohighlight">\(p\)</span> cero columnas y filas, se tiene que el <code class="docutils literal notranslate"><span class="pre">número</span> <span class="pre">de</span> <span class="pre">multiplicaciones</span> <span class="pre">y</span> <span class="pre">adiciones</span> <span class="pre">(MADS)</span></code> es <span class="math notranslate nohighlight">\(3.7\times 10^{6}\times 32\approx 120~\)</span> millones MADS. Además, <code class="docutils literal notranslate"><span class="pre">usando</span> <span class="pre">convoluciones</span></code> <span class="math notranslate nohighlight">\(1\times 1\)</span><code class="docutils literal notranslate"><span class="pre">,</span> <span class="pre">este</span> <span class="pre">número</span> <span class="pre">se</span> <span class="pre">reduce</span> <span class="pre">a</span></code> <span class="math notranslate nohighlight">\(28^{2}\times 25\times 16\times 32\approx 10\)</span> millones MADS (ver <span id="id19">[<a class="reference internal" href="biblio.html#id17" title="S. Theodoridis. Machine Learning: A Bayesian and Optimization Perspective. Elsevier Science, 2020. ISBN 9780128188040. URL: https://books.google.com.co/books?id=l-nEDwAAQBAJ.">Theodoridis, 2020</a>]</span>).</p></li>
<li><p>A menudo, el volumen intermedio, <span class="math notranslate nohighlight">\(\boldsymbol{O}'\)</span>, se conoce como <code class="docutils literal notranslate"><span class="pre">capa</span> <span class="pre">cuello</span> <span class="pre">de</span> <span class="pre">botella</span> <span class="pre">(bottleneck</span> <span class="pre">layer)</span></code>; <code class="docutils literal notranslate"><span class="pre">su</span> <span class="pre">función</span> <span class="pre">es</span> <span class="pre">&quot;reducir&quot;</span> <span class="pre">primero</span> <span class="pre">el</span> <span class="pre">tamaño</span> <span class="pre">del</span> <span class="pre">volumen</span> <span class="pre">de</span> <span class="pre">entrada,</span> <span class="pre">antes</span> <span class="pre">de</span> <span class="pre">obtener</span> <span class="pre">el</span> <span class="pre">volumen</span> <span class="pre">de</span> <span class="pre">salida</span> <span class="pre">final</span></code> (ver <a class="reference internal" href="#bottleneck-layer-1x1conv-numref"><span class="std std-numref">Fig. 55</span></a>).</p></li>
</ul>
</section>
</div><figure class="align-center" id="bottleneck-layer-1x1conv-numref">
<a class="reference internal image-reference" href="_images/bottleneck_layer_1x1conv.png"><img alt="_images/bottleneck_layer_1x1conv.png" src="_images/bottleneck_layer_1x1conv.png" style="width: 665.6px; height: 239.20000000000002px;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 55 </span><span class="caption-text">Capa cuello de botella (ver <a class="reference internal" href="#bottleneck_example_1x1conv_prfref">Example 3</a>). Fuente <span id="id20">[<a class="reference internal" href="biblio.html#id17" title="S. Theodoridis. Machine Learning: A Bayesian and Optimization Perspective. Elsevier Science, 2020. ISBN 9780128188040. URL: https://books.google.com.co/books?id=l-nEDwAAQBAJ.">Theodoridis, 2020</a>]</span>.</span><a class="headerlink" href="#bottleneck-layer-1x1conv-numref" title="Link to this image">#</a></p>
</figcaption>
</figure>
</section>
<section id="arquitectura-cnn-completa">
<h3>Arquitectura CNN completa<a class="headerlink" href="#arquitectura-cnn-completa" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>La forma típica de una red convolucional completa consiste en una <code class="docutils literal notranslate"><span class="pre">secuencia</span> <span class="pre">de</span> <span class="pre">capas</span> <span class="pre">convolucionales,</span> <span class="pre">cada</span> <span class="pre">una</span> <span class="pre">de</span> <span class="pre">las</span> <span class="pre">cuales</span> <span class="pre">que</span> <span class="pre">comprende</span> <span class="pre">los</span> <span class="pre">tres</span> <span class="pre">pasos</span> <span class="pre">básicos</span></code>, a saber, <code class="docutils literal notranslate"><span class="pre">convolución,</span> <span class="pre">no</span> <span class="pre">linealidad</span> <span class="pre">y</span> <span class="pre">agrupación</span></code>, como se describe al principio de esta sección. <code class="docutils literal notranslate"><span class="pre">Dependiendo</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">aplicación,</span> <span class="pre">se</span> <span class="pre">pueden</span> <span class="pre">apilar</span> <span class="pre">tantas</span> <span class="pre">capas</span> <span class="pre">como</span> <span class="pre">sea</span> <span class="pre">necesario</span></code>, donde la salida de una capa se convierte en la entrada de la siguiente. Las <code class="docutils literal notranslate"><span class="pre">entradas</span> <span class="pre">y</span> <span class="pre">salidas</span> <span class="pre">de</span> <span class="pre">cada</span> <span class="pre">capa</span> <span class="pre">son</span> <span class="pre">volúmenes</span></code>, como se ha descrito anteriormente.</p></li>
</ul>
<figure class="align-center" id="complete-cnnarq-numref">
<a class="reference internal image-reference" href="_images/complete_cnnarq.png"><img alt="_images/complete_cnnarq.png" src="_images/complete_cnnarq.png" style="width: 667.2px; height: 375.20000000000005px;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 56 </span><span class="caption-text">Arquitectura CNN completa. Fuente <span id="id21">[<a class="reference internal" href="biblio.html#id17" title="S. Theodoridis. Machine Learning: A Bayesian and Optimization Perspective. Elsevier Science, 2020. ISBN 9780128188040. URL: https://books.google.com.co/books?id=l-nEDwAAQBAJ.">Theodoridis, 2020</a>]</span>.</span><a class="headerlink" href="#complete-cnnarq-numref" title="Link to this image">#</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p>En la <code class="docutils literal notranslate"><span class="pre">primera</span> <span class="pre">capa</span> <span class="pre">se</span> <span class="pre">emplea</span> <span class="pre">un</span> <span class="pre">número</span> <span class="pre">de</span> <span class="pre">volúmenes</span> <span class="pre">de</span> <span class="pre">filtro</span> <span class="pre">(canales)</span></code> para realizar <code class="docutils literal notranslate"><span class="pre">convoluciones</span></code> seguidas de la <code class="docutils literal notranslate"><span class="pre">operación</span> <span class="pre">no</span> <span class="pre">lineal</span> <span class="pre">almente)</span></code>. A continuación, <code class="docutils literal notranslate"><span class="pre">la</span> <span class="pre">etapa</span> <span class="pre">de</span> <span class="pre">pooling</span> <span class="pre">toma</span> <span class="pre">el</span> <span class="pre">relevo</span> <span class="pre">para</span> <span class="pre">reducir</span> <span class="pre">la</span> <span class="pre">altura</span> <span class="pre">y</span> <span class="pre">la</span> <span class="pre">anchura</span> <span class="pre">de</span> <span class="pre">cada</span> <span class="pre">volumen</span> <span class="pre">de</span> <span class="pre">salida,</span> <span class="pre">que</span> <span class="pre">se</span> <span class="pre">utiliza</span> <span class="pre">como</span> <span class="pre">entrada</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">segunda</span> <span class="pre">capa,</span> <span class="pre">y</span> <span class="pre">así</span> <span class="pre">sucesivamente</span></code>. Por último, <code class="docutils literal notranslate"><span class="pre">el</span> <span class="pre">volumen</span> <span class="pre">de</span> <span class="pre">salida</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">última</span> <span class="pre">capa</span> <span class="pre">se</span> <span class="pre">vectoriza</span></code>. A veces, esto también se denomina <code class="docutils literal notranslate"><span class="pre">operación</span> <span class="pre">de</span> <span class="pre">aplanamiento</span> <span class="pre">(flattening)</span></code>.</p></li>
<li><p>En otras palabras, <code class="docutils literal notranslate"><span class="pre">todos</span> <span class="pre">los</span> <span class="pre">elementos</span> <span class="pre">del</span> <span class="pre">volumen</span> <span class="pre">de</span> <span class="pre">salida</span> <span class="pre">se</span> <span class="pre">apilan</span> <span class="pre">uno</span> <span class="pre">debajo</span> <span class="pre">de</span> <span class="pre">otro</span> <span class="pre">para</span> <span class="pre">formar</span> <span class="pre">un</span> <span class="pre">vector</span></code>. La vectorización puede realizarse mediante varias estrategias. De hecho, <code class="docutils literal notranslate"><span class="pre">el</span> <span class="pre">vector</span> <span class="pre">obtenido</span> <span class="pre">forma</span> <span class="pre">el</span> <span class="pre">vector</span> <span class="pre">de</span> <span class="pre">características</span> <span class="pre">que</span> <span class="pre">finalmente</span> <span class="pre">se</span> <span class="pre">ha</span> <span class="pre">generado</span> <span class="pre">mediante</span> <span class="pre">las</span> <span class="pre">diversas</span> <span class="pre">transformaciones</span> <span class="pre">que</span> <span class="pre">las</span> <span class="pre">convoluciones</span> <span class="pre">aplican</span> <span class="pre">capa</span> <span class="pre">tras</span> <span class="pre">capa</span></code>. Este vector de características <code class="docutils literal notranslate"><span class="pre">se</span> <span class="pre">utilizará</span> <span class="pre">como</span> <span class="pre">entrada</span> <span class="pre">para</span> <span class="pre">un</span> <span class="pre">aprendiz,</span> <span class="pre">por</span> <span class="pre">ejemplo,</span> <span class="pre">para</span> <span class="pre">una</span> <span class="pre">red</span> <span class="pre">neuronal</span> <span class="pre">totalmente</span> <span class="pre">conectada</span></code> (ver <a class="reference internal" href="#complete-cnnarq-numref"><span class="std std-numref">Fig. 56</span></a>) <code class="docutils literal notranslate"><span class="pre">o</span> <span class="pre">a</span> <span class="pre">cualquier</span> <span class="pre">otro</span> <span class="pre">predictor,</span> <span class="pre">como</span> <span class="pre">una</span> <span class="pre">máquina</span> <span class="pre">kernel</span></code>.</p></li>
</ul>
<div class="proof observation admonition" id="observation_ann7">
<p class="admonition-title"><span class="caption-number">Observation 15 </span></p>
<section class="observation-content" id="proof-content">
<ul class="simple">
<li><p>La estrategia general consiste en ir <code class="docutils literal notranslate"><span class="pre">reduciendo</span> <span class="pre">la</span> <span class="pre">altura</span> <span class="pre">y</span> <span class="pre">la</span> <span class="pre">anchura</span> <span class="pre">mientras</span> <span class="pre">se</span> <span class="pre">aumenta</span> <span class="pre">la</span> <span class="pre">profundidad</span> <span class="pre">de</span> <span class="pre">los</span> <span class="pre">volúmenes</span></code>. Una <code class="docutils literal notranslate"><span class="pre">mayor</span> <span class="pre">profundidad</span></code> corresponde a más filtros por etapa, lo que se traduce en <code class="docutils literal notranslate"><span class="pre">más</span> <span class="pre">características</span></code>. Tanto tanto el <code class="docutils literal notranslate"><span class="pre">número</span> <span class="pre">de</span> <span class="pre">capas</span> <span class="pre">convolucionales</span></code> como el <code class="docutils literal notranslate"><span class="pre">número</span> <span class="pre">de</span> <span class="pre">capas</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">red</span> <span class="pre">totalmente</span> <span class="pre">conectada</span> <span class="pre">dependen</span> <span class="pre">en</span> <span class="pre">gran</span> <span class="pre">medida</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">aplicación</span></code>, hasta ahora, <code class="docutils literal notranslate"><span class="pre">no</span> <span class="pre">existe</span> <span class="pre">un</span> <span class="pre">método</span> <span class="pre">formal</span> <span class="pre">para</span> <span class="pre">determinar</span> <span class="pre">automáticamente</span> <span class="pre">el</span> <span class="pre">número</span> <span class="pre">de</span> <span class="pre">capas,</span> <span class="pre">así</span> <span class="pre">como</span> <span class="pre">el</span> <span class="pre">número</span> <span class="pre">de</span> <span class="pre">filtros</span> <span class="pre">o</span> <span class="pre">nodos</span> <span class="pre">por</span> <span class="pre">capa</span></code>. La elección es una cuestión de “ingeniería” y <code class="docutils literal notranslate"><span class="pre">evaluación</span> <span class="pre">de</span> <span class="pre">diferentes</span> <span class="pre">combinaciones</span> <span class="pre">para</span> <span class="pre">seleccionar</span> <span class="pre">la</span> <span class="pre">mejor</span></code>.</p></li>
<li><p>Una buena práctica es <code class="docutils literal notranslate"><span class="pre">seleccionar</span> <span class="pre">una</span> <span class="pre">arquitectura</span> <span class="pre">existente</span> <span class="pre">que</span> <span class="pre">se</span> <span class="pre">haya</span> <span class="pre">utilizado</span> <span class="pre">antes</span> <span class="pre">en</span> <span class="pre">la</span> <span class="pre">aplicación</span> <span class="pre">relacionada</span> <span class="pre">y</span> <span class="pre">empezar</span> <span class="pre">desde</span> <span class="pre">ahí</span></code>. Una vía de <code class="docutils literal notranslate"><span class="pre">investigación</span> <span class="pre">más</span> <span class="pre">reciente</span></code> para desarrollar formas más sistemáticas de <code class="docutils literal notranslate"><span class="pre">aprender</span> <span class="pre">el</span> <span class="pre">número</span> <span class="pre">de</span> <span class="pre">nodos/filtros</span> <span class="pre">por</span> <span class="pre">capa</span> <span class="pre">es</span> <span class="pre">el</span> <span class="pre">aprendizaje</span> <span class="pre">Bayesiano</span></code>.</p></li>
</ul>
</section>
</div><div class="admonition-que-aprenden-las-redes-neuronales-profundas admonition">
<p class="admonition-title">Qué aprenden las redes neuronales profundas</p>
<ul class="simple">
<li><p>Ya está demostrado que <code class="docutils literal notranslate"><span class="pre">las</span> <span class="pre">redes</span> <span class="pre">convolucionales</span> <span class="pre">funcionan</span> <span class="pre">bien</span> <span class="pre">y,</span> <span class="pre">el</span> <span class="pre">estado</span> <span class="pre">del</span> <span class="pre">arte</span> <span class="pre">constituye</span> <span class="pre">en</span> <span class="pre">un</span> <span class="pre">gran</span> <span class="pre">número</span> <span class="pre">de</span> <span class="pre">aplicaciones</span> <span class="pre">diversas</span></code>. Sin embargo, una cuestión crítica es: <code class="docutils literal notranslate"><span class="pre">¿qué</span> <span class="pre">tipo</span> <span class="pre">de</span> <span class="pre">características</span> <span class="pre">aprende</span> <span class="pre">una</span> <span class="pre">CNN?</span></code> En otras palabras, <code class="docutils literal notranslate"><span class="pre">¿cuál</span> <span class="pre">es</span> <span class="pre">la</span> <span class="pre">información</span> <span class="pre">que</span> <span class="pre">se</span> <span class="pre">propaga</span> <span class="pre">de</span> <span class="pre">una</span> <span class="pre">capa</span> <span class="pre">a</span> <span class="pre">otra?</span></code>. Esto es crucial para entender por qué funcionan tan bien. La <code class="docutils literal notranslate"><span class="pre">respuesta</span> <span class="pre">a</span> <span class="pre">esta</span> <span class="pre">pregunta</span> <span class="pre">podría</span> <span class="pre">facilitar</span> <span class="pre">su</span> <span class="pre">interpretabilidad,</span> <span class="pre">que</span> <span class="pre">es</span> <span class="pre">de</span> <span class="pre">suma</span> <span class="pre">importancia</span> <span class="pre">en</span> <span class="pre">aplicaciones</span> <span class="pre">específicas,</span> <span class="pre">como</span> <span class="pre">en</span> <span class="pre">los</span> <span class="pre">ámbitos</span> <span class="pre">médico</span> <span class="pre">y</span> <span class="pre">financiero</span></code>. Además, esa comprensión podría <code class="docutils literal notranslate"><span class="pre">ayudar</span> <span class="pre">a</span> <span class="pre">desarrollar</span> <span class="pre">modelos</span> <span class="pre">mejorados</span></code>.</p></li>
<li><p>Con este fin, se han utilizado <code class="docutils literal notranslate"><span class="pre">técnicas</span> <span class="pre">de</span> <span class="pre">visualización</span> <span class="pre">para</span> <span class="pre">revelar</span> <span class="pre">los</span> <span class="pre">estímulos</span> <span class="pre">de</span> <span class="pre">entrada</span> <span class="pre">específicos</span></code> que excitan los mapas de características individuales en cualquier capa, <code class="docutils literal notranslate"><span class="pre">en</span> <span class="pre">el</span> <span class="pre">contexto</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">visión</span> <span class="pre">por</span> <span class="pre">computador</span></code>. Los resultados revelan una <code class="docutils literal notranslate"><span class="pre">naturaleza</span> <span class="pre">jerárquica</span> <span class="pre">de</span> <span class="pre">los</span> <span class="pre">rasgos</span> <span class="pre">producidos</span></code>, a medida que se pasa de la entrada a la salida final. Por ejemplo,</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">La</span> <span class="pre">capa</span> <span class="pre">2</span> <span class="pre">parece</span> <span class="pre">responder</span> <span class="pre">a</span> <span class="pre">las</span> <span class="pre">esquinas</span> <span class="pre">y</span> <span class="pre">otras</span> <span class="pre">conjunciones</span> <span class="pre">borde/color</span> <span class="pre">asociadas</span> <span class="pre">a</span> <span class="pre">los</span> <span class="pre">objetos</span> <span class="pre">presentes</span> <span class="pre">en</span> <span class="pre">la</span> <span class="pre">imagen</span> <span class="pre">de</span> <span class="pre">entrada</span></code>.</p></li>
<li><p>La <code class="docutils literal notranslate"><span class="pre">capa</span> <span class="pre">3</span> <span class="pre">presenta</span> <span class="pre">invarianzas</span> <span class="pre">más</span> <span class="pre">complejas,</span> <span class="pre">capturando</span> <span class="pre">texturas</span> <span class="pre">similares</span></code>.</p></li>
<li><p>Las <code class="docutils literal notranslate"><span class="pre">capas</span> <span class="pre">superiores</span> <span class="pre">revelan</span> <span class="pre">información</span> <span class="pre">más</span> <span class="pre">específica</span> <span class="pre">de</span> <span class="pre">clase,</span> <span class="pre">por</span> <span class="pre">ejemplo,</span> <span class="pre">caras</span> <span class="pre">de</span> <span class="pre">perros,</span> <span class="pre">longitudes</span> <span class="pre">de</span> <span class="pre">pájaros,</span> <span class="pre">etc</span></code> (ver <a class="reference internal" href="#complete-cnnarq-numref"><span class="std std-numref">Fig. 56</span></a>).</p></li>
</ul>
</li>
</ul>
</div>
</section>
<section id="arquitecturas-de-redes-neuronales-convolucionales">
<h3>Arquitecturas de Redes Neuronales Convolucionales<a class="headerlink" href="#arquitecturas-de-redes-neuronales-convolucionales" title="Link to this heading">#</a></h3>
<div class="proof observation admonition" id="observation_ann8">
<p class="admonition-title"><span class="caption-number">Observation 16 </span></p>
<section class="observation-content" id="proof-content">
<ul class="simple">
<li><p>Lo que hemos descrito en la última subsección son los <code class="docutils literal notranslate"><span class="pre">pasos</span> <span class="pre">básicos</span> <span class="pre">que</span> <span class="pre">se</span> <span class="pre">utilizan</span> <span class="pre">para</span> <span class="pre">diseñar</span> <span class="pre">una</span> <span class="pre">CNN</span></code>. Hay una serie de <code class="docutils literal notranslate"><span class="pre">variantes</span> <span class="pre">en</span> <span class="pre">torno</span> <span class="pre">a</span> <span class="pre">la</span> <span class="pre">arquitectura</span> <span class="pre">dada</span> <span class="pre">en</span> <span class="pre">la</span></code> <a class="reference internal" href="#complete-cnnarq-numref"><span class="std std-numref">Fig. 56</span></a>. Además, hay diferentes trucos y algoritmos que se pueden utilizar para realizar cálculos, por ejemplo, para el <code class="docutils literal notranslate"><span class="pre">cálculo</span> <span class="pre">eficiente</span> <span class="pre">de</span> <span class="pre">las</span> <span class="pre">convoluciones</span> <span class="pre">implicadas</span></code>.  Sin duda, hay mucha “ingeniería” implicada para hacer que <code class="docutils literal notranslate"><span class="pre">redes</span> <span class="pre">tan</span> <span class="pre">grandes</span> <span class="pre">aprendan</span> <span class="pre">los</span> <span class="pre">parámetros</span> <span class="pre">y</span> <span class="pre">funcionar</span> <span class="pre">con</span> <span class="pre">eficacia</span> <span class="pre">en</span> <span class="pre">aplicaciones</span> <span class="pre">prácticas</span></code>.</p></li>
<li><p>A continuación se describen brevemente <code class="docutils literal notranslate"><span class="pre">algunas</span> <span class="pre">redes</span> <span class="pre">convolucionales</span> <span class="pre">clásicas</span></code>. Se recomienda al lector que <code class="docutils literal notranslate"><span class="pre">desee</span> <span class="pre">familiarizarse</span> <span class="pre">y</span> <span class="pre">profundizar</span> <span class="pre">en</span> <span class="pre">el</span> <span class="pre">conocimiento</span> <span class="pre">de</span> <span class="pre">las</span> <span class="pre">CNN</span> <span class="pre">que</span> <span class="pre">se</span> <span class="pre">familiarice</span> <span class="pre">con</span> <span class="pre">ellas</span></code>. Aunque algunos de los trucos de implementación adoptados allí pueden no estar en uso hoy en día, <code class="docutils literal notranslate"><span class="pre">los</span> <span class="pre">papers</span> <span class="pre">citados</span> <span class="pre">pueden</span> <span class="pre">ayudar</span> <span class="pre">al</span> <span class="pre">lector</span> <span class="pre">a</span> <span class="pre">obtener</span> <span class="pre">una</span> <span class="pre">comprensión</span> <span class="pre">de</span> <span class="pre">las</span> <span class="pre">CNN</span></code>.</p></li>
</ul>
</section>
</div><div class="tip admonition">
<p class="admonition-title">LeNet-5</p>
<ul class="simple">
<li><p>Este es un ejemplo típico de la <code class="docutils literal notranslate"><span class="pre">primera</span> <span class="pre">generación</span> <span class="pre">de</span> <span class="pre">CNNs</span> <span class="pre">y</span> <span class="pre">fue</span> <span class="pre">construido</span> <span class="pre">para</span> <span class="pre">reconocer</span> <span class="pre">dígitos</span> <span class="pre">de</span> <span class="pre">números</span></code> (ver <span id="id22">[<a class="reference internal" href="biblio.html#id31" title="Yann LeCun, Léon Bottou, Yoshua Bengio, and Patrick Haffner. Gradient-based learning applied to document recognition. Proceedings of the IEEE, 86(11):2278–2324, 1998.">LeCun <em>et al.</em>, 1998</a>]</span>). Por razones históricas, comentemos un poco su arquitectura. <code class="docutils literal notranslate"><span class="pre">La</span> <span class="pre">entrada</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">red</span> <span class="pre">consiste</span> <span class="pre">en</span> <span class="pre">imágenes</span> <span class="pre">en</span> <span class="pre">escala</span> <span class="pre">de</span> <span class="pre">grises</span> <span class="pre">de</span> <span class="pre">tamaño</span> <span class="pre">32</span> <span class="pre">×</span> <span class="pre">32</span> <span class="pre">×</span> <span class="pre">1</span></code>. La red emplea <code class="docutils literal notranslate"><span class="pre">dos</span> <span class="pre">capas</span> <span class="pre">de</span> <span class="pre">convolución</span></code>. En la primera capa, el <code class="docutils literal notranslate"><span class="pre">volumen</span> <span class="pre">de</span> <span class="pre">salida</span> <span class="pre">tiene</span> <span class="pre">un</span> <span class="pre">tamaño</span> <span class="pre">de</span> <span class="pre">28</span> <span class="pre">×</span> <span class="pre">28</span> <span class="pre">×</span> <span class="pre">6</span></code>, que tras la agrupación <code class="docutils literal notranslate"><span class="pre">se</span> <span class="pre">convierte</span> <span class="pre">en</span> <span class="pre">14</span> <span class="pre">×</span> <span class="pre">14</span> <span class="pre">×</span> <span class="pre">6</span></code>. Las <code class="docutils literal notranslate"><span class="pre">dimensiones</span> <span class="pre">del</span> <span class="pre">volumen</span> <span class="pre">en</span> <span class="pre">la</span> <span class="pre">segunda</span> <span class="pre">capa</span> <span class="pre">eran</span> <span class="pre">10</span> <span class="pre">×</span> <span class="pre">10</span> <span class="pre">×</span> <span class="pre">16</span> <span class="pre">y,</span> <span class="pre">tras</span> <span class="pre">la</span> <span class="pre">agrupación,</span> <span class="pre">5</span> <span class="pre">×</span> <span class="pre">5</span> <span class="pre">×</span> <span class="pre">16</span></code>. La <code class="docutils literal notranslate"><span class="pre">no</span> <span class="pre">linealidad</span> <span class="pre">utilizada</span> <span class="pre">entonces</span> <span class="pre">era</span> <span class="pre">de</span> <span class="pre">tipo</span> <span class="pre">sigmoid</span></code>. Nótese que la <code class="docutils literal notranslate"><span class="pre">altura</span> <span class="pre">y</span> <span class="pre">la</span> <span class="pre">anchura</span> <span class="pre">de</span> <span class="pre">los</span> <span class="pre">volúmenes</span> <span class="pre">disminuyen</span> <span class="pre">y</span> <span class="pre">la</span> <span class="pre">profundidad</span> <span class="pre">aumenta</span></code>, como se ha señalado antes. El <code class="docutils literal notranslate"><span class="pre">número</span> <span class="pre">de</span> <span class="pre">elementos</span> <span class="pre">del</span> <span class="pre">último</span> <span class="pre">volumen</span> <span class="pre">es</span> <span class="pre">igual</span> <span class="pre">a</span> <span class="pre">400</span></code>. Estos elementos se apilan en un vector y alimentan los correspondientes <code class="docutils literal notranslate"><span class="pre">nodos</span> <span class="pre">de</span> <span class="pre">entrada</span> <span class="pre">de</span> <span class="pre">una</span> <span class="pre">red</span> <span class="pre">totalmente</span> <span class="pre">conectada</span></code>. Esta última consta de <code class="docutils literal notranslate"><span class="pre">dos</span> <span class="pre">capas</span> <span class="pre">ocultas</span> <span class="pre">con</span> <span class="pre">120</span> <span class="pre">nodos</span> <span class="pre">en</span> <span class="pre">la</span> <span class="pre">primera</span> <span class="pre">y</span> <span class="pre">84</span> <span class="pre">nodos</span> <span class="pre">en</span> <span class="pre">la</span> <span class="pre">segunda</span></code>. Hay <code class="docutils literal notranslate"><span class="pre">10</span> <span class="pre">nodos</span> <span class="pre">de</span> <span class="pre">salida,</span> <span class="pre">uno</span> <span class="pre">por</span> <span class="pre">dígito,</span> <span class="pre">que</span> <span class="pre">utilizan</span> <span class="pre">una</span> <span class="pre">no</span> <span class="pre">linealidad</span> <span class="pre">softmax</span></code>. El número total de parámetros implicados es del orden de 60.000.</p></li>
</ul>
</div>
<figure class="align-center" id="letnet5-architecture-numref">
<img alt="_images/letnet5_architecture.jpeg" src="_images/letnet5_architecture.jpeg" />
<figcaption>
<p><span class="caption-number">Fig. 57 </span><span class="caption-text">Arquitectura LeNet-5. Fuente <span id="id23">[<a class="reference internal" href="biblio.html#id31" title="Yann LeCun, Léon Bottou, Yoshua Bengio, and Patrick Haffner. Gradient-based learning applied to document recognition. Proceedings of the IEEE, 86(11):2278–2324, 1998.">LeCun <em>et al.</em>, 1998</a>]</span>.</span><a class="headerlink" href="#letnet5-architecture-numref" title="Link to this image">#</a></p>
</figcaption>
</figure>
<div class="tip admonition">
<p class="admonition-title">AlexNet</p>
<ul class="simple">
<li><p>Esta red también es histórica ya que, <code class="docutils literal notranslate"><span class="pre">demostró</span> <span class="pre">que</span> <span class="pre">el</span> <span class="pre">punto</span> <span class="pre">crucial</span> <span class="pre">para</span> <span class="pre">hacer</span> <span class="pre">grandes</span> <span class="pre">redes</span> <span class="pre">es</span> <span class="pre">la</span> <span class="pre">disponibilidad</span> <span class="pre">de</span> <span class="pre">grandes</span> <span class="pre">conjuntos</span> <span class="pre">de</span> <span class="pre">entrenamiento</span></code> <span id="id24">[<a class="reference internal" href="biblio.html#id32" title="Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. Imagenet classification with deep convolutional neural networks. Advances in neural information processing systems, 2012.">Krizhevsky <em>et al.</em>, 2012</a>]</span>. El artículo relacionado es el que realmente hizo volver a las CNN y <code class="docutils literal notranslate"><span class="pre">actuó</span> <span class="pre">como</span> <span class="pre">catalizador</span> <span class="pre">para</span> <span class="pre">su</span> <span class="pre">adopción</span> <span class="pre">mucho</span> <span class="pre">más</span> <span class="pre">allá</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">tarea</span> <span class="pre">de</span> <span class="pre">reconocimiento</span> <span class="pre">de</span> <span class="pre">dígitos</span></code>. La <code class="docutils literal notranslate"><span class="pre">Alexnet</span> <span class="pre">es</span> <span class="pre">un</span> <span class="pre">desarrollo</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">LeNet-5,</span> <span class="pre">pero</span> <span class="pre">es</span> <span class="pre">mucho</span> <span class="pre">más</span> <span class="pre">grande</span> <span class="pre">e</span> <span class="pre">implica</span> <span class="pre">aproximadamente</span> <span class="pre">60</span> <span class="pre">millones</span> <span class="pre">de</span> <span class="pre">parámetros</span></code>.</p></li>
<li><p>Las <code class="docutils literal notranslate"><span class="pre">entradas</span> <span class="pre">a</span> <span class="pre">la</span> <span class="pre">red</span> <span class="pre">son</span> <span class="pre">imágenes</span> <span class="pre">RGB</span> <span class="pre">de</span> <span class="pre">tamaño</span> <span class="pre">227</span> <span class="pre">×</span> <span class="pre">227</span> <span class="pre">×</span> <span class="pre">3</span></code>. Comprende <code class="docutils literal notranslate"><span class="pre">cinco</span> <span class="pre">capas</span> <span class="pre">ocultas</span></code> y el <code class="docutils literal notranslate"><span class="pre">volumen</span> <span class="pre">final</span> <span class="pre">consta</span> <span class="pre">de</span> <span class="pre">9216</span> <span class="pre">elementos</span></code> que alimentan una red totalmente conectada con <code class="docutils literal notranslate"><span class="pre">dos</span> <span class="pre">capas</span> <span class="pre">ocultas</span> <span class="pre">de</span> <span class="pre">4096</span> <span class="pre">unidades</span> <span class="pre">cada</span> <span class="pre">una</span></code>. La <code class="docutils literal notranslate"><span class="pre">salida</span> <span class="pre">consta</span> <span class="pre">de</span> <span class="pre">1000</span> <span class="pre">nodos</span> <span class="pre">softmax</span> <span class="pre">(uno</span> <span class="pre">por</span> <span class="pre">clase)</span> <span class="pre">para</span> <span class="pre">reconocer</span> <span class="pre">imágenes</span> <span class="pre">del</span> <span class="pre">conjunto</span> <span class="pre">de</span> <span class="pre">datos</span> <span class="pre">ImageNet</span></code> para el reconocimiento de objetos. <code class="docutils literal notranslate"><span class="pre">ReLU</span></code> se ha utilizado como no linealidad en las capas ocultas.</p></li>
</ul>
</div>
<figure class="align-center" id="alexnet-architecture-numref">
<img alt="_images/alexnet_architecture.png" src="_images/alexnet_architecture.png" />
<figcaption>
<p><span class="caption-number">Fig. 58 </span><span class="caption-text">Arquitectura LeNet-5. Fuente <span id="id25">[<a class="reference internal" href="biblio.html#id32" title="Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. Imagenet classification with deep convolutional neural networks. Advances in neural information processing systems, 2012.">Krizhevsky <em>et al.</em>, 2012</a>]</span>.</span><a class="headerlink" href="#alexnet-architecture-numref" title="Link to this image">#</a></p>
</figcaption>
</figure>
<div class="admonition-vgg-16 admonition">
<p class="admonition-title">VGG-16</p>
<ul class="simple">
<li><p>Esta red <span id="id26">[<a class="reference internal" href="biblio.html#id33" title="Karen Simonyan and Andrew Zisserman. Very deep convolutional networks for large-scale image recognition. arXiv preprint arXiv:1409.1556, 2014.">Simonyan and Zisserman, 2014</a>]</span> es <code class="docutils literal notranslate"><span class="pre">mucho</span> <span class="pre">mayor</span> <span class="pre">que</span> <span class="pre">AlexNet</span></code>. Implica un total de aproximadamente <code class="docutils literal notranslate"><span class="pre">140</span> <span class="pre">millones</span> <span class="pre">de</span> <span class="pre">parámetros</span></code>. La principal característica de esta red es su <code class="docutils literal notranslate"><span class="pre">regularidad</span></code>. Involucra <code class="docutils literal notranslate"><span class="pre">filtros</span> <span class="pre">3</span> <span class="pre">×</span> <span class="pre">3</span> <span class="pre">para</span> <span class="pre">realizar</span> <span class="pre">las</span> <span class="pre">mismas</span> <span class="pre">convoluciones</span> <span class="pre">utilizando</span> <span class="pre">padding</span> <span class="pre">y</span> <span class="pre">stride</span></code> <span class="math notranslate nohighlight">\(s = 1\)</span> y <code class="docutils literal notranslate"><span class="pre">ventanas</span> <span class="pre">2</span> <span class="pre">×</span> <span class="pre">2</span> <span class="pre">para</span> <span class="pre">maxpooling</span></code> con stride <span class="math notranslate nohighlight">\(s = 2\)</span>. <code class="docutils literal notranslate"><span class="pre">Cada</span> <span class="pre">vez</span> <span class="pre">que</span> <span class="pre">se</span> <span class="pre">realiza</span> <span class="pre">un</span> <span class="pre">pooling,</span> <span class="pre">la</span> <span class="pre">altura</span> <span class="pre">y</span> <span class="pre">la</span> <span class="pre">anchura</span> <span class="pre">de</span> <span class="pre">los</span> <span class="pre">volúmenes</span> <span class="pre">se</span> <span class="pre">reducen</span> <span class="pre">a</span> <span class="pre">la</span> <span class="pre">mitad</span> <span class="pre">y</span> <span class="pre">la</span> <span class="pre">profundidad</span> <span class="pre">se</span> <span class="pre">multiplica</span> <span class="pre">por</span> <span class="pre">dos</span></code>. Partiendo de <code class="docutils literal notranslate"><span class="pre">224</span> <span class="pre">×</span> <span class="pre">224</span> <span class="pre">×</span> <span class="pre">3</span> <span class="pre">imagen</span> <span class="pre">de</span> <span class="pre">entrada</span></code> y después de <code class="docutils literal notranslate"><span class="pre">13</span> <span class="pre">capas</span></code> el <code class="docutils literal notranslate"><span class="pre">volumen</span> <span class="pre">final</span> <span class="pre">tiene</span> <span class="pre">un</span> <span class="pre">tamaño</span> <span class="pre">de</span> <span class="pre">7</span> <span class="pre">×</span> <span class="pre">7</span> <span class="pre">×</span> <span class="pre">512,</span> <span class="pre">un</span> <span class="pre">total</span> <span class="pre">de</span> <span class="pre">7168</span> <span class="pre">elementos</span></code>, que tras su vectorización <code class="docutils literal notranslate"><span class="pre">alimenta</span> <span class="pre">a</span> <span class="pre">una</span> <span class="pre">red</span> <span class="pre">totalmente</span> <span class="pre">conectada</span> <span class="pre">con</span> <span class="pre">2</span> <span class="pre">capas</span> <span class="pre">ocultas</span> <span class="pre">de</span> <span class="pre">4096</span> <span class="pre">nodos</span> <span class="pre">cada</span> <span class="pre">una</span></code>. Los <code class="docutils literal notranslate"><span class="pre">1000</span> <span class="pre">nodos</span> <span class="pre">de</span> <span class="pre">salida</span> <span class="pre">están</span> <span class="pre">construidos</span> <span class="pre">en</span> <span class="pre">torno</span> <span class="pre">a</span> <span class="pre">la</span> <span class="pre">no</span> <span class="pre">linealidad</span> <span class="pre">softmax</span> <span class="pre">y</span> <span class="pre">se</span> <span class="pre">ha</span> <span class="pre">utilizado</span> <span class="pre">ReLU</span> <span class="pre">para</span> <span class="pre">las</span> <span class="pre">unidades</span> <span class="pre">ocultas</span> <span class="pre">en</span> <span class="pre">toda</span> <span class="pre">la</span> <span class="pre">red</span></code>.</p></li>
</ul>
</div>
<figure class="align-center" id="vgg16-architecture-numref">
<a class="reference internal image-reference" href="_images/vgg16_architecture.png"><img alt="_images/vgg16_architecture.png" src="_images/vgg16_architecture.png" style="width: 564.0px; height: 331.2px;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 59 </span><span class="caption-text">Arquitectura VGG-16. Fuente <span id="id27">[<a class="reference internal" href="biblio.html#id33" title="Karen Simonyan and Andrew Zisserman. Very deep convolutional networks for large-scale image recognition. arXiv preprint arXiv:1409.1556, 2014.">Simonyan and Zisserman, 2014</a>]</span>.</span><a class="headerlink" href="#vgg16-architecture-numref" title="Link to this image">#</a></p>
</figcaption>
</figure>
<div class="admonition-googlenet-y-la-red-inception admonition">
<p class="admonition-title">GoogleNet y la red Inception</p>
<ul class="simple">
<li><p>La arquitectura utilizada en <code class="docutils literal notranslate"><span class="pre">esta</span> <span class="pre">red</span> <span class="pre">se</span> <span class="pre">desvía</span> <span class="pre">del</span> <span class="pre">&quot;arquetípico&quot;</span> <span class="pre">que</span> <span class="pre">se</span> <span class="pre">muestra</span> <span class="pre">en</span></code> <a class="reference internal" href="#complete-cnnarq-numref"><span class="std std-numref">Fig. 56</span></a>. En el corazón de esta red se encuentra el llamado módulo de inicio <span id="id28">[<a class="reference internal" href="biblio.html#id34" title="Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, and Andrew Rabinovich. Going deeper with convolutions. In Proceedings of the IEEE conference on computer vision and pattern recognition, 1–9. 2015.">Szegedy <em>et al.</em>, 2015</a>]</span>. Un <code class="docutils literal notranslate"><span class="pre">módulo</span> <span class="pre">de</span> <span class="pre">inicio</span> <span class="pre">consta</span> <span class="pre">de</span> <span class="pre">filtros</span> <span class="pre">de</span> <span class="pre">diferentes</span> <span class="pre">tamaños</span> <span class="pre">y</span> <span class="pre">profundidades</span></code>, así como de una <code class="docutils literal notranslate"><span class="pre">ruta</span> <span class="pre">de</span> <span class="pre">agrupación</span> <span class="pre">diferente</span></code>.</p></li>
<li><p>En la <a class="reference internal" href="#inception-architecture-numref"><span class="std std-numref">Fig. 60</span></a> s<code class="docutils literal notranslate"><span class="pre">muestra</span> <span class="pre">una</span></code>arquitectura típica de un modelo inception`` que proporciona su razón de ser. Observe que el <code class="docutils literal notranslate"><span class="pre">volumen</span> <span class="pre">de</span> <span class="pre">salida</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">capa</span> <span class="pre">anterior</span> <span class="pre">se</span> <span class="pre">convierte</span> <span class="pre">en</span> <span class="pre">la</span> <span class="pre">entrada</span> <span class="pre">de</span> <span class="pre">diferentes</span> <span class="pre">rutas</span></code>. Uno implica una <code class="docutils literal notranslate"><span class="pre">convolución</span> <span class="pre">1</span> <span class="pre">×</span> <span class="pre">1</span> <span class="pre">que</span> <span class="pre">actúa</span> <span class="pre">sobre</span> <span class="pre">la</span> <span class="pre">profundidad</span> <span class="pre">del</span> <span class="pre">volumen</span> <span class="pre">de</span> <span class="pre">entrada</span></code>. Otra ruta realiza un <code class="docutils literal notranslate"><span class="pre">pooling</span> <span class="pre">y</span> <span class="pre">luego</span> <span class="pre">alimenta</span> <span class="pre">una</span> <span class="pre">convolución</span> <span class="pre">5</span> <span class="pre">×</span> <span class="pre">5</span></code>. <code class="docutils literal notranslate"><span class="pre">Dos</span> <span class="pre">rutas</span> <span class="pre">alimentan</span> <span class="pre">por</span> <span class="pre">separado</span> <span class="pre">dos</span> <span class="pre">etapas</span> <span class="pre">de</span> <span class="pre">convolución</span> <span class="pre">diferentes</span></code>, <code class="docutils literal notranslate"><span class="pre">una</span> <span class="pre">basada</span> <span class="pre">en</span> <span class="pre">un</span> <span class="pre">filtro</span> <span class="pre">3</span> <span class="pre">×</span> <span class="pre">3</span> <span class="pre">y</span> <span class="pre">la</span> <span class="pre">otra</span> <span class="pre">en</span> <span class="pre">un</span> <span class="pre">filtro</span> <span class="pre">5</span> <span class="pre">×</span> <span class="pre">5</span></code>. Antes de las convoluciones, <code class="docutils literal notranslate"><span class="pre">se</span> <span class="pre">emplea</span> <span class="pre">una</span> <span class="pre">capa</span> <span class="pre">de</span> <span class="pre">cuello</span> <span class="pre">de</span> <span class="pre">botella,</span> <span class="pre">mediante</span> <span class="pre">una</span> <span class="pre">convolución</span> <span class="pre">de</span> <span class="pre">1</span> <span class="pre">×</span> <span class="pre">1</span></code>, para <code class="docutils literal notranslate"><span class="pre">reducir</span> <span class="pre">la</span> <span class="pre">carga</span> <span class="pre">computacional</span></code> respectiva.</p></li>
<li><p>A continuación, los <code class="docutils literal notranslate"><span class="pre">volúmenes</span> <span class="pre">de</span> <span class="pre">salida</span> <span class="pre">de</span> <span class="pre">todas</span> <span class="pre">estas</span> <span class="pre">trayectorias</span> <span class="pre">se</span> <span class="pre">concatenan</span> <span class="pre">para</span> <span class="pre">formar</span> <span class="pre">el</span> <span class="pre">resultado</span> <span class="pre">final</span></code> de esta etapa. La idea del <code class="docutils literal notranslate"><span class="pre">módulo</span> <span class="pre">de</span> <span class="pre">inicio</span> <span class="pre">es</span> <span class="pre">dejar</span> <span class="pre">que</span> <span class="pre">la</span> <span class="pre">red,</span> <span class="pre">durante</span> <span class="pre">la</span> <span class="pre">fase</span> <span class="pre">de</span> <span class="pre">entrenamiento,</span> <span class="pre">&quot;decida&quot;</span> <span class="pre">qué</span> <span class="pre">operaciones</span> <span class="pre">se</span> <span class="pre">ajustan</span> <span class="pre">mejor</span> <span class="pre">a</span> <span class="pre">las</span> <span class="pre">distintas</span> <span class="pre">capas</span> <span class="pre">y</span> <span class="pre">entradas</span></code>. Por ejemplo, como ya hemos comentado, los <code class="docutils literal notranslate"><span class="pre">rasgos</span> <span class="pre">de</span> <span class="pre">mayor</span> <span class="pre">abstracción</span> <span class="pre">los</span> <span class="pre">captan</span> <span class="pre">las</span> <span class="pre">capas</span> <span class="pre">más</span> <span class="pre">cercanas</span> <span class="pre">a</span> <span class="pre">la</span> <span class="pre">salida</span></code>. Por lo tanto, se espera que la <code class="docutils literal notranslate"><span class="pre">concentración</span> <span class="pre">espacial</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">información</span> <span class="pre">respectiva</span> <span class="pre">disminuya</span></code>. Esto sugiere que la <code class="docutils literal notranslate"><span class="pre">proporción</span> <span class="pre">de</span> <span class="pre">convoluciones</span> <span class="pre">3</span> <span class="pre">×</span> <span class="pre">3</span> <span class="pre">y</span> <span class="pre">5</span> <span class="pre">×</span> <span class="pre">5</span> <span class="pre">debería</span> <span class="pre">aumentar</span> <span class="pre">a</span> <span class="pre">medida</span> <span class="pre">que</span> <span class="pre">avanzamos</span></code> hacia capas superiores. El <code class="docutils literal notranslate"><span class="pre">número</span> <span class="pre">de</span> <span class="pre">capas</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">red</span> <span class="pre">fue</span> <span class="pre">de</span> <span class="pre">22</span> <span class="pre">y</span> <span class="pre">el</span> <span class="pre">número</span> <span class="pre">total</span> <span class="pre">de</span> <span class="pre">parámetros</span> <span class="pre">indicados</span> <span class="pre">en</span> <span class="pre">el</span> <span class="pre">artículo</span> <span class="pre">fue</span> <span class="pre">del</span> <span class="pre">orden</span> <span class="pre">de</span> <span class="pre">6</span> <span class="pre">millones</span></code>.</p></li>
</ul>
</div>
<figure class="align-center" id="inception-architecture-numref">
<a class="reference internal image-reference" href="_images/inception_architecture.png"><img alt="_images/inception_architecture.png" src="_images/inception_architecture.png" style="width: 666.4000000000001px; height: 445.6px;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 60 </span><span class="caption-text">Arquitectura Inception. Fuente <span id="id29">[<a class="reference internal" href="biblio.html#id34" title="Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, and Andrew Rabinovich. Going deeper with convolutions. In Proceedings of the IEEE conference on computer vision and pattern recognition, 1–9. 2015.">Szegedy <em>et al.</em>, 2015</a>]</span>.</span><a class="headerlink" href="#inception-architecture-numref" title="Link to this image">#</a></p>
</figcaption>
</figure>
<div class="tip admonition">
<p class="admonition-title">Redes residuales (ResNets)</p>
<ul class="simple">
<li><p>Ya hemos hablado de las ventajas de diseñar redes profundas. También abordamos la forma de <code class="docutils literal notranslate"><span class="pre">hacer</span> <span class="pre">frente</span> <span class="pre">al</span> <span class="pre">problema</span> <span class="pre">de</span> <span class="pre">los</span> <span class="pre">gradientes</span> <span class="pre">que</span> <span class="pre">se</span> <span class="pre">desvanecen/explotan</span></code> mediante una combinación de métodos y trucos que permiten que el <code class="docutils literal notranslate"><span class="pre">algoritmo</span> <span class="pre">backpropagation</span> <span class="pre">converja</span> <span class="pre">con</span> <span class="pre">suficiente</span> <span class="pre">rapidez</span></code>. Sin embargo, <code class="docutils literal notranslate"><span class="pre">una</span> <span class="pre">vez</span> <span class="pre">que</span> <span class="pre">empezamos</span> <span class="pre">a</span> <span class="pre">construir</span> <span class="pre">redes</span> <span class="pre">muy</span> <span class="pre">profundas</span> <span class="pre">(del</span> <span class="pre">orden</span> <span class="pre">de</span> <span class="pre">decenas</span> <span class="pre">o</span> <span class="pre">incluso</span> <span class="pre">centenares</span> <span class="pre">de</span> <span class="pre">capas)</span> <span class="pre">nos</span> <span class="pre">encontramos</span> <span class="pre">con</span> <span class="pre">el</span> <span class="pre">siguiente</span> <span class="pre">comportamiento</span> <span class="pre">&quot;poco</span> <span class="pre">ortodoxo&quot;</span></code>.</p></li>
<li><p>Cabría esperar que, <code class="docutils literal notranslate"><span class="pre">añadiendo</span> <span class="pre">más</span> <span class="pre">y</span> <span class="pre">más</span> <span class="pre">capas,</span> <span class="pre">el</span> <span class="pre">error</span> <span class="pre">de</span> <span class="pre">entrenamiento</span> <span class="pre">mejore</span> <span class="pre">o</span> <span class="pre">al</span> <span class="pre">menos</span> <span class="pre">no</span> <span class="pre">aumenta</span></code>. Sin embargo, lo que se observa en la práctica es que <code class="docutils literal notranslate"><span class="pre">a</span> <span class="pre">partir</span> <span class="pre">de</span> <span class="pre">un</span> <span class="pre">cierto</span> <span class="pre">número</span> <span class="pre">de</span> <span class="pre">capas,</span> <span class="pre">el</span> <span class="pre">error</span> <span class="pre">de</span> <span class="pre">entrenamiento</span> <span class="pre">empieza</span> <span class="pre">a</span> <span class="pre">aumentar</span></code>. Esto se ilustra gráficamente en la <a class="reference internal" href="#residual-net-architecture-numref"><span class="std std-numref">Fig. 61</span></a>. Este fenómeno <code class="docutils literal notranslate"><span class="pre">no</span> <span class="pre">tiene</span> <span class="pre">nada</span> <span class="pre">que</span> <span class="pre">ver</span> <span class="pre">con</span> <span class="pre">el</span> <span class="pre">sobreajuste</span></code>. Después de todo, estamos hablando del <code class="docutils literal notranslate"><span class="pre">error</span> <span class="pre">de</span> <span class="pre">entrenamiento</span> <span class="pre">y</span> <span class="pre">no</span> <span class="pre">del</span> <span class="pre">de</span> <span class="pre">generalización</span></code>. Parece que esto puede deberse a <code class="docutils literal notranslate"><span class="pre">la</span> <span class="pre">tarea</span> <span class="pre">de</span> <span class="pre">optimización</span> <span class="pre">que</span> <span class="pre">se</span> <span class="pre">vuelve</span> <span class="pre">más</span> <span class="pre">y</span> <span class="pre">más</span> <span class="pre">difícil</span> <span class="pre">a</span> <span class="pre">medida</span> <span class="pre">que</span> <span class="pre">se</span> <span class="pre">añaden</span> <span class="pre">más</span> <span class="pre">y</span> <span class="pre">más</span> <span class="pre">capas</span></code>.</p></li>
</ul>
</div>
<figure class="align-center" id="residual-net-architecture-numref">
<a class="reference internal image-reference" href="_images/residual_net_architecture.png"><img alt="_images/residual_net_architecture.png" src="_images/residual_net_architecture.png" style="width: 490.40000000000003px; height: 274.40000000000003px;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 61 </span><span class="caption-text"><code class="docutils literal notranslate"><span class="pre">Aumento</span> <span class="pre">en</span> <span class="pre">lugar</span> <span class="pre">de</span> <span class="pre">disminución</span> <span class="pre">del</span> <span class="pre">error</span></code> cuando el número de capas supera cierto número, en una red muy profunda. <code class="docutils literal notranslate"><span class="pre">(curva</span> <span class="pre">roja)</span> <span class="pre">como</span> <span class="pre">se</span> <span class="pre">esperaba</span> <span class="pre">a</span> <span class="pre">partir</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">teoría.</span></code></span><a class="headerlink" href="#residual-net-architecture-numref" title="Link to this image">#</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p>Matemáticamente, <code class="docutils literal notranslate"><span class="pre">cualquier</span> <span class="pre">capa,</span> <span class="pre">por</span> <span class="pre">ejemplo,</span> <span class="pre">la</span> <span class="pre">capa</span></code> <span class="math notranslate nohighlight">\(r\)</span><code class="docutils literal notranslate"><span class="pre">,</span> <span class="pre">puede</span> <span class="pre">verse</span> <span class="pre">como</span> <span class="pre">un</span> <span class="pre">mapeo</span> <span class="pre">que</span> <span class="pre">asigna</span> <span class="pre">la</span> <span class="pre">entrada</span> <span class="pre">correspondiente,</span> <span class="pre">por</span> <span class="pre">ejemplo,</span></code> <span class="math notranslate nohighlight">\(\boldsymbol{y}_{r-1}\)</span><code class="docutils literal notranslate"><span class="pre">,</span> <span class="pre">a</span> <span class="pre">la</span> <span class="pre">salida,</span> <span class="pre">por</span> <span class="pre">ejemplo,</span></code> <span class="math notranslate nohighlight">\(\boldsymbol{y}_{r}\)</span>. Denotemos el mapeo respectivo como</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\boldsymbol{y}^{r}=H(\boldsymbol{y}^{r-1}).
\]</div>
<ul class="simple">
<li><p>Desde este punto de vista, <code class="docutils literal notranslate"><span class="pre">es</span> <span class="pre">fácil</span> <span class="pre">ver</span> <span class="pre">por</span> <span class="pre">qué,</span> <span class="pre">al</span> <span class="pre">añadir</span> <span class="pre">más</span> <span class="pre">capas,</span> <span class="pre">el</span> <span class="pre">error</span> <span class="pre">de</span> <span class="pre">entrenamiento</span> <span class="pre">no</span> <span class="pre">debería</span> <span class="pre">aumentar</span></code>. En el peor de los casos, en el que toda la información se ha extraído hasta una capa <span class="math notranslate nohighlight">\(r\)</span>, <code class="docutils literal notranslate"><span class="pre">esperamos</span> <span class="pre">que</span> <span class="pre">añadiendo</span> <span class="pre">una</span> <span class="pre">capa</span> <span class="pre">más,</span> <span class="pre">ésta</span> <span class="pre">debería</span> <span class="pre">implementar</span> <span class="pre">el</span> <span class="pre">mapeo</span> <span class="pre">de</span> <span class="pre">identidad,</span> <span class="pre">es</span> <span class="pre">decir,</span></code> <span class="math notranslate nohighlight">\(y^{r}=H(y^{r-1})-y^{r-1}\)</span>. Es decir, <code class="docutils literal notranslate"><span class="pre">la</span> <span class="pre">capa</span> <span class="pre">extra</span> <span class="pre">no</span> <span class="pre">añade</span> <span class="pre">información</span> <span class="pre">y</span> <span class="pre">simplemente</span> <span class="pre">copia</span> <span class="pre">la</span> <span class="pre">entrada</span> <span class="pre">a</span> <span class="pre">la</span> <span class="pre">salida</span></code>.</p></li>
<li><p>Sin embargo, parece que <code class="docutils literal notranslate"><span class="pre">una</span> <span class="pre">vez</span> <span class="pre">que</span> <span class="pre">la</span> <span class="pre">red</span> <span class="pre">empieza</span> <span class="pre">a</span> <span class="pre">ser</span> <span class="pre">muy</span> <span class="pre">profunda,</span> <span class="pre">la</span> <span class="pre">precisión</span> <span class="pre">se</span> <span class="pre">&quot;satura&quot;</span></code> y <code class="docutils literal notranslate"><span class="pre">las</span> <span class="pre">herramientas</span> <span class="pre">de</span> <span class="pre">optimización</span> <span class="pre">tienen</span> <span class="pre">dificultades</span> <span class="pre">para</span> <span class="pre">encontrar</span> <span class="pre">una</span> <span class="pre">solución</span> <span class="pre">lo</span> <span class="pre">suficientemente</span> <span class="pre">precisa</span> <span class="pre">a</span> <span class="pre">este</span> <span class="pre">mapeo</span> <span class="pre">de</span> <span class="pre">identidad</span></code>, al menos en un tiempo factible. En <span id="id30">[<a class="reference internal" href="biblio.html#id35" title="Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition, 770–778. 2016.">He <em>et al.</em>, 2016</a>]</span> se propone una forma de sortear esta dificultad. La idea es <code class="docutils literal notranslate"><span class="pre">ajustar</span> <span class="pre">un</span> <span class="pre">mapeo</span> <span class="pre">alternativo</span> <span class="pre">equivalente</span></code>, es decir</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
F(\boldsymbol{y}^{r})=H(\boldsymbol{y}^{r-1})-\boldsymbol{y}^{r-1}.
\]</div>
<ul class="simple">
<li><p>Entonces el mapeo original, <span class="math notranslate nohighlight">\(H(\boldsymbol{y}^{r-1})\)</span>, pasa a ser igual a <span class="math notranslate nohighlight">\(F(\boldsymbol{y}^{r-1}) + \boldsymbol{y}^{r-1}\)</span>. En la práctica, la <code class="docutils literal notranslate"><span class="pre">optimización</span> <span class="pre">con</span> <span class="pre">respecto</span> <span class="pre">al</span> <span class="pre">mapeo</span> <span class="pre">residual,</span></code> <span class="math notranslate nohighlight">\(F\)</span><code class="docutils literal notranslate"><span class="pre">,</span> <span class="pre">es</span> <span class="pre">más</span> <span class="pre">fácil</span> <span class="pre">que</span> <span class="pre">la</span> <span class="pre">optimización</span> <span class="pre">con</span> <span class="pre">respecto</span> <span class="pre">al</span> <span class="pre">mapeo</span> <span class="pre">original,</span></code> <span class="math notranslate nohighlight">\(H\)</span>. En el caso extremo, cuando se debe realizar un mapeo de identidad, parece ser <code class="docutils literal notranslate"><span class="pre">más</span> <span class="pre">fácil</span> <span class="pre">empujar</span> <span class="pre">el</span> <span class="pre">residual</span> <span class="pre">a</span> <span class="pre">cero,</span> <span class="pre">que</span> <span class="pre">ajustar</span> <span class="pre">el</span> <span class="pre">mapeo</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">identidad</span></code>.</p></li>
</ul>
<ul class="simple">
<li><p>El uso de la <code class="docutils literal notranslate"><span class="pre">representación</span> <span class="pre">residual</span></code> no es nuevo y ya <code class="docutils literal notranslate"><span class="pre">se</span> <span class="pre">ha</span> <span class="pre">utilizado</span> <span class="pre">anteriormente</span> <span class="pre">en</span> <span class="pre">el</span> <span class="pre">contexto</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">cuantificación</span> <span class="pre">vectorial</span></code>. La esencia del aprendizaje residual es <code class="docutils literal notranslate"><span class="pre">introducir</span> <span class="pre">el</span> <span class="pre">llamado</span> <span class="pre">bloque</span> <span class="pre">de</span> <span class="pre">construcción</span> <span class="pre">residual</span></code>, que se muestra en la <a class="reference internal" href="#residual-architecture-cnn-numref"><span class="std std-numref">Fig. 62</span></a>.</p></li>
</ul>
<figure class="align-center" id="residual-architecture-cnn-numref">
<a class="reference internal image-reference" href="_images/residual_architecture_cnn.png"><img alt="_images/residual_architecture_cnn.png" src="_images/residual_architecture_cnn.png" style="width: 363.20000000000005px; height: 398.40000000000003px;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 62 </span><span class="caption-text">Bloque de construcción residual. Fuente <span id="id31">[<a class="reference internal" href="biblio.html#id17" title="S. Theodoridis. Machine Learning: A Bayesian and Optimization Perspective. Elsevier Science, 2020. ISBN 9780128188040. URL: https://books.google.com.co/books?id=l-nEDwAAQBAJ.">Theodoridis, 2020</a>]</span>.</span><a class="headerlink" href="#residual-architecture-cnn-numref" title="Link to this image">#</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p>De esta manera, un número de capas, digamos, dos, como en el caso de la <a class="reference internal" href="#residual-architecture-cnn-numref"><span class="std std-numref">Fig. 62</span></a>, <code class="docutils literal notranslate"><span class="pre">se</span> <span class="pre">apilan</span></code> y dejamos que estas capas se <code class="docutils literal notranslate"><span class="pre">ajusten</span> <span class="pre">explícitamente</span> <span class="pre">al</span> <span class="pre">mapeo</span> <span class="pre">residual,</span> <span class="pre">a</span> <span class="pre">través</span> <span class="pre">de</span> <span class="pre">las</span> <span class="pre">llamadas</span> <span class="pre">conexiones</span> <span class="pre">de</span> <span class="pre">atajo</span> <span class="pre">u</span> <span class="pre">omisión</span></code>. Cada capa de pesos realiza una transformación sobre su entrada, por ejemplo, convoluciones. Si <span class="math notranslate nohighlight">\(\boldsymbol{y}^{r}\)</span> e <span class="math notranslate nohighlight">\(\boldsymbol{y}^{r-1}\)</span> son de dimensiones diferentes, el <code class="docutils literal notranslate"><span class="pre">atajo</span> <span class="pre">de</span> <span class="pre">mapeo</span> <span class="pre">de</span> <span class="pre">identidad</span> <span class="pre">se</span> <span class="pre">modifica</span> <span class="pre">a</span></code> <span class="math notranslate nohighlight">\(W\boldsymbol{y}^{r-1}\)</span>, donde <span class="math notranslate nohighlight">\(W\)</span> es una matriz de dimensiones apropiadas.</p></li>
</ul>
</section>
<section id="reconocimiento-facial-de-emociones">
<h3>Reconocimiento facial de emociones<a class="headerlink" href="#reconocimiento-facial-de-emociones" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">keras.preprocessing.image</span> <span class="kn">import</span> <span class="n">ImageDataGenerator</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.utils</span> <span class="kn">import</span> <span class="n">load_img</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">Conv2D</span><span class="p">,</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">BatchNormalization</span><span class="p">,</span> <span class="n">Activation</span><span class="p">,</span> <span class="n">Dropout</span><span class="p">,</span> <span class="n">MaxPooling2D</span><span class="p">,</span> <span class="n">Flatten</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.optimizers</span> <span class="kn">import</span> <span class="n">Adam</span><span class="p">,</span> <span class="n">RMSprop</span><span class="p">,</span> <span class="n">SGD</span>
<span class="kn">from</span> <span class="nn">keras.callbacks</span> <span class="kn">import</span> <span class="n">ModelCheckpoint</span><span class="p">,</span><span class="n">EarlyStopping</span>
<span class="kn">import</span> <span class="nn">datetime</span>
<span class="kn">from</span> <span class="nn">keras</span> <span class="kn">import</span> <span class="n">regularizers</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">keras.utils.vis_utils</span> <span class="kn">import</span> <span class="n">plot_model</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">ImportError</span><span class="g g-Whitespace">                               </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">66</span><span class="p">],</span> <span class="n">line</span> <span class="mi">5</span>
<span class="g g-Whitespace">      </span><span class="mi">3</span> <span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="g g-Whitespace">      </span><span class="mi">4</span> <span class="kn">import</span> <span class="nn">os</span>
<span class="ne">----&gt; </span><span class="mi">5</span> <span class="kn">from</span> <span class="nn">keras.preprocessing.image</span> <span class="kn">import</span> <span class="n">ImageDataGenerator</span>
<span class="g g-Whitespace">      </span><span class="mi">6</span> <span class="kn">from</span> <span class="nn">tensorflow.keras.utils</span> <span class="kn">import</span> <span class="n">load_img</span>
<span class="g g-Whitespace">      </span><span class="mi">7</span> <span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">Conv2D</span><span class="p">,</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">BatchNormalization</span><span class="p">,</span> <span class="n">Activation</span><span class="p">,</span> <span class="n">Dropout</span><span class="p">,</span> <span class="n">MaxPooling2D</span><span class="p">,</span> <span class="n">Flatten</span>

<span class="ne">ImportError</span>: cannot import name &#39;ImageDataGenerator&#39; from &#39;keras.preprocessing.image&#39; (C:\Users\USER\miniconda3\envs\ml_tf\lib\site-packages\keras\api\preprocessing\image\__init__.py)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_dir</span> <span class="o">=</span> <span class="s1">&#39;C:/Data/GitHub/Data/face_sentiment_detection/train/&#39;</span>
<span class="n">test_dir</span>  <span class="o">=</span> <span class="s1">&#39;C:/Data/GitHub/Data/face_sentiment_detection/test/&#39;</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">row</span><span class="p">,</span> <span class="n">col</span> <span class="o">=</span> <span class="mi">48</span><span class="p">,</span> <span class="mi">48</span>
<span class="n">classes</span> <span class="o">=</span> <span class="mi">7</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">count_exp</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">set_</span><span class="p">):</span>
    <span class="n">dict_</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">expression</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">path</span><span class="p">):</span>
        <span class="n">dir_</span> <span class="o">=</span> <span class="n">path</span> <span class="o">+</span> <span class="n">expression</span>
        <span class="n">dict_</span><span class="p">[</span><span class="n">expression</span><span class="p">]</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">dir_</span><span class="p">))</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">dict_</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="p">[</span><span class="n">set_</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">df</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_count</span> <span class="o">=</span> <span class="n">count_exp</span><span class="p">(</span><span class="n">train_dir</span><span class="p">,</span> <span class="s1">&#39;train&#39;</span><span class="p">)</span>
<span class="n">test_count</span> <span class="o">=</span> <span class="n">count_exp</span><span class="p">(</span><span class="n">test_dir</span><span class="p">,</span> <span class="s1">&#39;test&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">train_count</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">test_count</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>       angry  disgust  fear  happy  neutral   sad  surprise
train   3995      436  4097   7215     4965  4830      3171
      angry  disgust  fear  happy  neutral   sad  surprise
test    958      111  1024   1774     1233  1247       831
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_count</span><span class="o">.</span><span class="n">transpose</span><span class="p">()</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s1">&#39;bar&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;Axes: &gt;
</pre></div>
</div>
<img alt="_images/d014d32cd9acadcccf370636ed9127735d8b5b6f1d3ccfb37c57e2c6f54288e1.png" src="_images/d014d32cd9acadcccf370636ed9127735d8b5b6f1d3ccfb37c57e2c6f54288e1.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">test_count</span><span class="o">.</span><span class="n">transpose</span><span class="p">()</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s1">&#39;bar&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;Axes: &gt;
</pre></div>
</div>
<img alt="_images/0ab43b644e794bad17f3b661e6266b11b47891f7c0c886918dc8fe68e04b9e20.png" src="_images/0ab43b644e794bad17f3b661e6266b11b47891f7c0c886918dc8fe68e04b9e20.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">14</span><span class="p">,</span><span class="mi">22</span><span class="p">))</span>
<span class="n">i</span> <span class="o">=</span> <span class="mi">1</span>
<span class="k">for</span> <span class="n">expression</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">train_dir</span><span class="p">):</span>
    <span class="n">img</span> <span class="o">=</span> <span class="n">load_img</span><span class="p">((</span><span class="n">train_dir</span> <span class="o">+</span> <span class="n">expression</span> <span class="o">+</span><span class="s1">&#39;/&#39;</span><span class="o">+</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">train_dir</span> <span class="o">+</span> <span class="n">expression</span><span class="p">)[</span><span class="mi">5</span><span class="p">]))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">7</span><span class="p">,</span><span class="n">i</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">expression</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
    <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/12219db042ad06a153cdc4ae412ffc6a84d8c8bc9d0e88156abd00a4b42b4809.png" src="_images/12219db042ad06a153cdc4ae412ffc6a84d8c8bc9d0e88156abd00a4b42b4809.png" />
</div>
</div>
<ul class="simple">
<li><p>Creación de conjuntos de datos de <code class="docutils literal notranslate"><span class="pre">entrenamiento,</span> <span class="pre">prueba</span> <span class="pre">y</span> <span class="pre">validación</span></code></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_datagen</span> <span class="o">=</span> <span class="n">ImageDataGenerator</span><span class="p">(</span><span class="n">rescale</span><span class="o">=</span><span class="mf">1.</span><span class="o">/</span><span class="mi">255</span><span class="p">,</span>
                                   <span class="n">horizontal_flip</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                   <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>

<span class="n">training_set</span> <span class="o">=</span> <span class="n">train_datagen</span><span class="o">.</span><span class="n">flow_from_directory</span><span class="p">(</span><span class="n">train_dir</span><span class="p">,</span>
                                                <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
                                                <span class="n">target_size</span><span class="o">=</span><span class="p">(</span><span class="mi">48</span><span class="p">,</span><span class="mi">48</span><span class="p">),</span>
                                                <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                                <span class="n">color_mode</span><span class="o">=</span><span class="s1">&#39;grayscale&#39;</span><span class="p">,</span>
                                                <span class="n">class_mode</span><span class="o">=</span><span class="s1">&#39;categorical&#39;</span><span class="p">,</span>
                                                <span class="n">subset</span><span class="o">=</span><span class="s1">&#39;training&#39;</span><span class="p">)</span>
<span class="n">validation_set</span> <span class="o">=</span> <span class="n">train_datagen</span><span class="o">.</span><span class="n">flow_from_directory</span><span class="p">(</span><span class="n">train_dir</span><span class="p">,</span>
                                                <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
                                                <span class="n">target_size</span><span class="o">=</span><span class="p">(</span><span class="mi">48</span><span class="p">,</span><span class="mi">48</span><span class="p">),</span>
                                                <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                                <span class="n">color_mode</span><span class="o">=</span><span class="s1">&#39;grayscale&#39;</span><span class="p">,</span>
                                                <span class="n">class_mode</span><span class="o">=</span><span class="s1">&#39;categorical&#39;</span><span class="p">,</span>
                                                <span class="n">subset</span><span class="o">=</span><span class="s1">&#39;validation&#39;</span><span class="p">)</span>

<span class="n">test_datagen</span> <span class="o">=</span> <span class="n">ImageDataGenerator</span><span class="p">(</span><span class="n">rescale</span><span class="o">=</span><span class="mf">1.</span><span class="o">/</span><span class="mi">255</span><span class="p">,</span>
                                   <span class="n">horizontal_flip</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">test_set</span> <span class="o">=</span> <span class="n">test_datagen</span><span class="o">.</span><span class="n">flow_from_directory</span><span class="p">(</span><span class="n">test_dir</span><span class="p">,</span>
                                                <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
                                                <span class="n">target_size</span><span class="o">=</span><span class="p">(</span><span class="mi">48</span><span class="p">,</span><span class="mi">48</span><span class="p">),</span>
                                                <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                                <span class="n">color_mode</span><span class="o">=</span><span class="s1">&#39;grayscale&#39;</span><span class="p">,</span>
                                                <span class="n">class_mode</span><span class="o">=</span><span class="s1">&#39;categorical&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Found 22968 images belonging to 7 classes.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Found 5741 images belonging to 7 classes.
Found 7178 images belonging to 7 classes.
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">training_set</span><span class="o">.</span><span class="n">class_indices</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;angry&#39;: 0,
 &#39;disgust&#39;: 1,
 &#39;fear&#39;: 2,
 &#39;happy&#39;: 3,
 &#39;neutral&#39;: 4,
 &#39;sad&#39;: 5,
 &#39;surprise&#39;: 6}
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Arquitectura del modelo</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">weight_decay</span> <span class="o">=</span> <span class="mf">1e-4</span>

<span class="n">num_classes</span> <span class="o">=</span> <span class="mi">7</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>

<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="mi">4</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span> <span class="n">kernel_regularizer</span><span class="o">=</span><span class="n">regularizers</span><span class="o">.</span><span class="n">l2</span><span class="p">(</span><span class="n">weight_decay</span><span class="p">),</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">48</span><span class="p">,</span><span class="mi">48</span><span class="p">,</span><span class="mi">1</span><span class="p">)))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;elu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">BatchNormalization</span><span class="p">())</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="mi">4</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span> <span class="n">kernel_regularizer</span><span class="o">=</span><span class="n">regularizers</span><span class="o">.</span><span class="n">l2</span><span class="p">(</span><span class="n">weight_decay</span><span class="p">)))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;elu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">BatchNormalization</span><span class="p">())</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">)))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.2</span><span class="p">))</span>
 
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="mi">4</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span> <span class="n">kernel_regularizer</span><span class="o">=</span><span class="n">regularizers</span><span class="o">.</span><span class="n">l2</span><span class="p">(</span><span class="n">weight_decay</span><span class="p">)))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;elu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">BatchNormalization</span><span class="p">())</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">)))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.3</span><span class="p">))</span>
 
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="mi">4</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span> <span class="n">kernel_regularizer</span><span class="o">=</span><span class="n">regularizers</span><span class="o">.</span><span class="n">l2</span><span class="p">(</span><span class="n">weight_decay</span><span class="p">)))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;elu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">BatchNormalization</span><span class="p">())</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="mi">4</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span> <span class="n">kernel_regularizer</span><span class="o">=</span><span class="n">regularizers</span><span class="o">.</span><span class="n">l2</span><span class="p">(</span><span class="n">weight_decay</span><span class="p">)))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;elu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">BatchNormalization</span><span class="p">())</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">)))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.4</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Flatten</span><span class="p">())</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;linear&quot;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;elu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">))</span>

<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">Adam</span><span class="p">(</span><span class="mf">0.0003</span><span class="p">),</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Model: &quot;sequential&quot;
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv2d (Conv2D)             (None, 48, 48, 64)        1088      
                                                                 
 activation (Activation)     (None, 48, 48, 64)        0         
                                                                 
 batch_normalization (BatchN  (None, 48, 48, 64)       256       
 ormalization)                                                   
                                                                 
 conv2d_1 (Conv2D)           (None, 48, 48, 64)        65600     
                                                                 
 activation_1 (Activation)   (None, 48, 48, 64)        0         
                                                                 
 batch_normalization_1 (Batc  (None, 48, 48, 64)       256       
 hNormalization)                                                 
                                                                 
 max_pooling2d (MaxPooling2D  (None, 24, 24, 64)       0         
 )                                                               
                                                                 
 dropout (Dropout)           (None, 24, 24, 64)        0         
                                                                 
 conv2d_2 (Conv2D)           (None, 24, 24, 128)       131200    
                                                                 
 activation_2 (Activation)   (None, 24, 24, 128)       0         
                                                                 
 batch_normalization_2 (Batc  (None, 24, 24, 128)      512       
 hNormalization)                                                 
                                                                 
 max_pooling2d_1 (MaxPooling  (None, 12, 12, 128)      0         
 2D)                                                             
                                                                 
 dropout_1 (Dropout)         (None, 12, 12, 128)       0         
                                                                 
 conv2d_3 (Conv2D)           (None, 12, 12, 128)       262272    
                                                                 
 activation_3 (Activation)   (None, 12, 12, 128)       0         
                                                                 
 batch_normalization_3 (Batc  (None, 12, 12, 128)      512       
 hNormalization)                                                 
                                                                 
 conv2d_4 (Conv2D)           (None, 12, 12, 128)       262272    
                                                                 
 activation_4 (Activation)   (None, 12, 12, 128)       0         
                                                                 
 batch_normalization_4 (Batc  (None, 12, 12, 128)      512       
 hNormalization)                                                 
                                                                 
 max_pooling2d_2 (MaxPooling  (None, 6, 6, 128)        0         
 2D)                                                             
                                                                 
 dropout_2 (Dropout)         (None, 6, 6, 128)         0         
                                                                 
 flatten (Flatten)           (None, 4608)              0         
                                                                 
 dense (Dense)               (None, 128)               589952    
                                                                 
 activation_5 (Activation)   (None, 128)               0         
                                                                 
 dense_1 (Dense)             (None, 7)                 903       
                                                                 
=================================================================
Total params: 1,315,335
Trainable params: 1,314,311
Non-trainable params: 1,024
_________________________________________________________________
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">to_file</span><span class="o">=</span><span class="s1">&#39;model_cnn.png&#39;</span><span class="p">,</span> <span class="n">show_shapes</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">show_layer_names</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">checkpointer</span> <span class="o">=</span> <span class="p">[</span><span class="n">EarlyStopping</span><span class="p">(</span><span class="n">monitor</span> <span class="o">=</span> <span class="s1">&#39;val_accuracy&#39;</span><span class="p">,</span> <span class="n">verbose</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">restore_best_weights</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">mode</span><span class="o">=</span><span class="s2">&quot;max&quot;</span><span class="p">,</span><span class="n">patience</span> <span class="o">=</span> <span class="mi">10</span><span class="p">),</span>
                <span class="n">ModelCheckpoint</span><span class="p">(</span>
                    <span class="n">filepath</span><span class="o">=</span><span class="s1">&#39;model.weights.best.hdf5&#39;</span><span class="p">,</span>
                    <span class="n">monitor</span><span class="o">=</span><span class="s2">&quot;val_accuracy&quot;</span><span class="p">,</span>
                    <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                    <span class="n">save_best_only</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;max&quot;</span><span class="p">)]</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Entrenamiento del modelo</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">steps_per_epoch</span> <span class="o">=</span> <span class="n">training_set</span><span class="o">.</span><span class="n">n</span> <span class="o">//</span> <span class="n">training_set</span><span class="o">.</span><span class="n">batch_size</span>
<span class="n">validation_steps</span> <span class="o">=</span> <span class="n">validation_set</span><span class="o">.</span><span class="n">n</span> <span class="o">//</span> <span class="n">validation_set</span><span class="o">.</span><span class="n">batch_size</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">training_set</span><span class="p">,</span>
                 <span class="n">validation_data</span><span class="o">=</span><span class="n">validation_set</span><span class="p">,</span>
                 <span class="n">epochs</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span>
                 <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">checkpointer</span><span class="p">],</span>
                 <span class="n">steps_per_epoch</span><span class="o">=</span><span class="n">steps_per_epoch</span><span class="p">,</span>
                 <span class="n">validation_steps</span><span class="o">=</span><span class="n">validation_steps</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/200
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>357/358 [============================&gt;.] - ETA: 0s - loss: 1.7800 - accuracy: 0.3314
Epoch 1: val_accuracy improved from -inf to 0.29670, saving model to model.weights.best.hdf5
358/358 [==============================] - 21s 44ms/step - loss: 1.7790 - accuracy: 0.3317 - val_loss: 2.0642 - val_accuracy: 0.2967
Epoch 2/200
357/358 [============================&gt;.] - ETA: 0s - loss: 1.5317 - accuracy: 0.4235
Epoch 2: val_accuracy improved from 0.29670 to 0.44751, saving model to model.weights.best.hdf5
358/358 [==============================] - 9s 24ms/step - loss: 1.5311 - accuracy: 0.4238 - val_loss: 1.4773 - val_accuracy: 0.4475
Epoch 3/200
358/358 [==============================] - ETA: 0s - loss: 1.4022 - accuracy: 0.4789
Epoch 3: val_accuracy improved from 0.44751 to 0.49579, saving model to model.weights.best.hdf5
358/358 [==============================] - 9s 24ms/step - loss: 1.4022 - accuracy: 0.4789 - val_loss: 1.3460 - val_accuracy: 0.4958
Epoch 4/200
358/358 [==============================] - ETA: 0s - loss: 1.3194 - accuracy: 0.5129
Epoch 4: val_accuracy improved from 0.49579 to 0.51527, saving model to model.weights.best.hdf5
358/358 [==============================] - 8s 23ms/step - loss: 1.3194 - accuracy: 0.5129 - val_loss: 1.3173 - val_accuracy: 0.5153
Epoch 5/200
358/358 [==============================] - ETA: 0s - loss: 1.2523 - accuracy: 0.5419
Epoch 5: val_accuracy improved from 0.51527 to 0.53739, saving model to model.weights.best.hdf5
358/358 [==============================] - 9s 24ms/step - loss: 1.2523 - accuracy: 0.5419 - val_loss: 1.2620 - val_accuracy: 0.5374
Epoch 6/200
358/358 [==============================] - ETA: 0s - loss: 1.2091 - accuracy: 0.5554
Epoch 6: val_accuracy improved from 0.53739 to 0.55618, saving model to model.weights.best.hdf5
358/358 [==============================] - 9s 24ms/step - loss: 1.2091 - accuracy: 0.5554 - val_loss: 1.2375 - val_accuracy: 0.5562
Epoch 7/200
358/358 [==============================] - ETA: 0s - loss: 1.1582 - accuracy: 0.5782
Epoch 7: val_accuracy improved from 0.55618 to 0.55829, saving model to model.weights.best.hdf5
358/358 [==============================] - 9s 24ms/step - loss: 1.1582 - accuracy: 0.5782 - val_loss: 1.2446 - val_accuracy: 0.5583
Epoch 8/200
358/358 [==============================] - ETA: 0s - loss: 1.1242 - accuracy: 0.5914
Epoch 8: val_accuracy improved from 0.55829 to 0.56671, saving model to model.weights.best.hdf5
358/358 [==============================] - 9s 24ms/step - loss: 1.1242 - accuracy: 0.5914 - val_loss: 1.1888 - val_accuracy: 0.5667
Epoch 9/200
358/358 [==============================] - ETA: 0s - loss: 1.0857 - accuracy: 0.6058
Epoch 9: val_accuracy improved from 0.56671 to 0.57602, saving model to model.weights.best.hdf5
358/358 [==============================] - 9s 25ms/step - loss: 1.0857 - accuracy: 0.6058 - val_loss: 1.1846 - val_accuracy: 0.5760
Epoch 10/200
358/358 [==============================] - ETA: 0s - loss: 1.0608 - accuracy: 0.6207
Epoch 10: val_accuracy did not improve from 0.57602
358/358 [==============================] - 9s 24ms/step - loss: 1.0608 - accuracy: 0.6207 - val_loss: 1.1696 - val_accuracy: 0.5723
Epoch 11/200
358/358 [==============================] - ETA: 0s - loss: 1.0284 - accuracy: 0.6326
Epoch 11: val_accuracy improved from 0.57602 to 0.58006, saving model to model.weights.best.hdf5
358/358 [==============================] - 9s 25ms/step - loss: 1.0284 - accuracy: 0.6326 - val_loss: 1.2098 - val_accuracy: 0.5801
Epoch 12/200
358/358 [==============================] - ETA: 0s - loss: 0.9979 - accuracy: 0.6452
Epoch 12: val_accuracy improved from 0.58006 to 0.59515, saving model to model.weights.best.hdf5
358/358 [==============================] - 9s 24ms/step - loss: 0.9979 - accuracy: 0.6452 - val_loss: 1.1488 - val_accuracy: 0.5952
Epoch 13/200
358/358 [==============================] - ETA: 0s - loss: 0.9632 - accuracy: 0.6578
Epoch 13: val_accuracy did not improve from 0.59515
358/358 [==============================] - 8s 24ms/step - loss: 0.9632 - accuracy: 0.6578 - val_loss: 1.1816 - val_accuracy: 0.5866
Epoch 14/200
357/358 [============================&gt;.] - ETA: 0s - loss: 0.9375 - accuracy: 0.6689
Epoch 14: val_accuracy did not improve from 0.59515
358/358 [==============================] - 9s 25ms/step - loss: 0.9375 - accuracy: 0.6688 - val_loss: 1.1931 - val_accuracy: 0.5880
Epoch 15/200
356/358 [============================&gt;.] - ETA: 0s - loss: 0.9148 - accuracy: 0.6804
Epoch 15: val_accuracy improved from 0.59515 to 0.60692, saving model to model.weights.best.hdf5
358/358 [==============================] - 9s 25ms/step - loss: 0.9142 - accuracy: 0.6808 - val_loss: 1.1411 - val_accuracy: 0.6069
Epoch 16/200
357/358 [============================&gt;.] - ETA: 0s - loss: 0.8925 - accuracy: 0.6873
Epoch 16: val_accuracy did not improve from 0.60692
358/358 [==============================] - 16s 44ms/step - loss: 0.8927 - accuracy: 0.6871 - val_loss: 1.1375 - val_accuracy: 0.6067
Epoch 17/200
358/358 [==============================] - ETA: 0s - loss: 0.8564 - accuracy: 0.7023
Epoch 17: val_accuracy improved from 0.60692 to 0.61025, saving model to model.weights.best.hdf5
358/358 [==============================] - 18s 49ms/step - loss: 0.8564 - accuracy: 0.7023 - val_loss: 1.1632 - val_accuracy: 0.6103
Epoch 18/200
357/358 [============================&gt;.] - ETA: 0s - loss: 0.8269 - accuracy: 0.7130
Epoch 18: val_accuracy improved from 0.61025 to 0.61447, saving model to model.weights.best.hdf5
358/358 [==============================] - 15s 41ms/step - loss: 0.8274 - accuracy: 0.7128 - val_loss: 1.1538 - val_accuracy: 0.6145
Epoch 19/200
358/358 [==============================] - ETA: 0s - loss: 0.8018 - accuracy: 0.7263
Epoch 19: val_accuracy did not improve from 0.61447
358/358 [==============================] - 9s 25ms/step - loss: 0.8018 - accuracy: 0.7263 - val_loss: 1.2324 - val_accuracy: 0.5976
Epoch 20/200
358/358 [==============================] - ETA: 0s - loss: 0.7834 - accuracy: 0.7339
Epoch 20: val_accuracy improved from 0.61447 to 0.61552, saving model to model.weights.best.hdf5
358/358 [==============================] - 8s 23ms/step - loss: 0.7834 - accuracy: 0.7339 - val_loss: 1.1748 - val_accuracy: 0.6155
Epoch 21/200
358/358 [==============================] - ETA: 0s - loss: 0.7548 - accuracy: 0.7457
Epoch 21: val_accuracy improved from 0.61552 to 0.61675, saving model to model.weights.best.hdf5
358/358 [==============================] - 8s 23ms/step - loss: 0.7548 - accuracy: 0.7457 - val_loss: 1.1902 - val_accuracy: 0.6167
Epoch 22/200
358/358 [==============================] - ETA: 0s - loss: 0.7327 - accuracy: 0.7548
Epoch 22: val_accuracy did not improve from 0.61675
358/358 [==============================] - 8s 23ms/step - loss: 0.7327 - accuracy: 0.7548 - val_loss: 1.2109 - val_accuracy: 0.6110
Epoch 23/200
358/358 [==============================] - ETA: 0s - loss: 0.7059 - accuracy: 0.7683
Epoch 23: val_accuracy did not improve from 0.61675
358/358 [==============================] - 8s 23ms/step - loss: 0.7059 - accuracy: 0.7683 - val_loss: 1.2439 - val_accuracy: 0.6103
Epoch 24/200
357/358 [============================&gt;.] - ETA: 0s - loss: 0.6870 - accuracy: 0.7748
Epoch 24: val_accuracy improved from 0.61675 to 0.62184, saving model to model.weights.best.hdf5
358/358 [==============================] - 8s 23ms/step - loss: 0.6875 - accuracy: 0.7746 - val_loss: 1.2534 - val_accuracy: 0.6218
Epoch 25/200
358/358 [==============================] - ETA: 0s - loss: 0.6579 - accuracy: 0.7864
Epoch 25: val_accuracy did not improve from 0.62184
358/358 [==============================] - 8s 23ms/step - loss: 0.6579 - accuracy: 0.7864 - val_loss: 1.2654 - val_accuracy: 0.6145
Epoch 26/200
358/358 [==============================] - ETA: 0s - loss: 0.6395 - accuracy: 0.7934
Epoch 26: val_accuracy did not improve from 0.62184
358/358 [==============================] - 8s 24ms/step - loss: 0.6395 - accuracy: 0.7934 - val_loss: 1.3351 - val_accuracy: 0.6025
Epoch 27/200
357/358 [============================&gt;.] - ETA: 0s - loss: 0.6253 - accuracy: 0.8017
Epoch 27: val_accuracy did not improve from 0.62184
358/358 [==============================] - 8s 24ms/step - loss: 0.6255 - accuracy: 0.8015 - val_loss: 1.2959 - val_accuracy: 0.6129
Epoch 28/200
358/358 [==============================] - ETA: 0s - loss: 0.6032 - accuracy: 0.8078
Epoch 28: val_accuracy improved from 0.62184 to 0.62377, saving model to model.weights.best.hdf5
358/358 [==============================] - 8s 24ms/step - loss: 0.6032 - accuracy: 0.8078 - val_loss: 1.2656 - val_accuracy: 0.6238
Epoch 29/200
357/358 [============================&gt;.] - ETA: 0s - loss: 0.5924 - accuracy: 0.8156
Epoch 29: val_accuracy did not improve from 0.62377
358/358 [==============================] - 14s 39ms/step - loss: 0.5925 - accuracy: 0.8156 - val_loss: 1.3062 - val_accuracy: 0.6157
Epoch 30/200
358/358 [==============================] - ETA: 0s - loss: 0.5678 - accuracy: 0.8252
Epoch 30: val_accuracy did not improve from 0.62377
358/358 [==============================] - 19s 54ms/step - loss: 0.5678 - accuracy: 0.8252 - val_loss: 1.3187 - val_accuracy: 0.6194
Epoch 31/200
358/358 [==============================] - ETA: 0s - loss: 0.5629 - accuracy: 0.8248
Epoch 31: val_accuracy did not improve from 0.62377
358/358 [==============================] - 17s 47ms/step - loss: 0.5629 - accuracy: 0.8248 - val_loss: 1.3731 - val_accuracy: 0.6162
Epoch 32/200
358/358 [==============================] - ETA: 0s - loss: 0.5412 - accuracy: 0.8342
Epoch 32: val_accuracy did not improve from 0.62377
358/358 [==============================] - 16s 43ms/step - loss: 0.5412 - accuracy: 0.8342 - val_loss: 1.4011 - val_accuracy: 0.6152
Epoch 33/200
357/358 [============================&gt;.] - ETA: 0s - loss: 0.5325 - accuracy: 0.8385
Epoch 33: val_accuracy did not improve from 0.62377
358/358 [==============================] - 16s 43ms/step - loss: 0.5331 - accuracy: 0.8382 - val_loss: 1.4587 - val_accuracy: 0.6190
Epoch 34/200
357/358 [============================&gt;.] - ETA: 0s - loss: 0.5229 - accuracy: 0.8429
Epoch 34: val_accuracy did not improve from 0.62377
358/358 [==============================] - 10s 28ms/step - loss: 0.5226 - accuracy: 0.8430 - val_loss: 1.3929 - val_accuracy: 0.6143
Epoch 35/200
357/358 [============================&gt;.] - ETA: 0s - loss: 0.5082 - accuracy: 0.8460
Epoch 35: val_accuracy did not improve from 0.62377
358/358 [==============================] - 9s 24ms/step - loss: 0.5086 - accuracy: 0.8461 - val_loss: 1.4448 - val_accuracy: 0.6157
Epoch 36/200
358/358 [==============================] - ETA: 0s - loss: 0.4860 - accuracy: 0.8589
Epoch 36: val_accuracy did not improve from 0.62377
358/358 [==============================] - 9s 24ms/step - loss: 0.4860 - accuracy: 0.8589 - val_loss: 1.4591 - val_accuracy: 0.6106
Epoch 37/200
357/358 [============================&gt;.] - ETA: 0s - loss: 0.4815 - accuracy: 0.8593
Epoch 37: val_accuracy did not improve from 0.62377
358/358 [==============================] - 9s 24ms/step - loss: 0.4815 - accuracy: 0.8593 - val_loss: 1.4723 - val_accuracy: 0.6155
Epoch 38/200
356/358 [============================&gt;.] - ETA: 0s - loss: 0.4835 - accuracy: 0.8573Restoring model weights from the end of the best epoch: 28.

Epoch 38: val_accuracy did not improve from 0.62377
358/358 [==============================] - 9s 24ms/step - loss: 0.4834 - accuracy: 0.8574 - val_loss: 1.4725 - val_accuracy: 0.6185
Epoch 38: early stopping
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Rendimiento del modelo</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">training_loss</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span>
<span class="n">val_loss</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">]</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.figsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">]</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">([</span><span class="s1">&#39;default&#39;</span><span class="p">])</span>
<span class="c1"># Create count of the number of epochs</span>
<span class="n">epoch_count</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">training_loss</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

<span class="c1"># Visualize loss history</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epoch_count</span><span class="p">,</span> <span class="n">training_loss</span><span class="p">,</span> <span class="s1">&#39;r--&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epoch_count</span><span class="p">,</span> <span class="n">val_loss</span><span class="p">,</span> <span class="s1">&#39;b-&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">&#39;Training Loss&#39;</span><span class="p">,</span> <span class="s1">&#39;Val Loss&#39;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Epoch&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Text(0, 0.5, &#39;Loss&#39;)
</pre></div>
</div>
<img alt="_images/1b638596aa71995cd08bb44f4218e7dbc5766fca55836029d8c27a58f36b9f7b.png" src="_images/1b638596aa71995cd08bb44f4218e7dbc5766fca55836029d8c27a58f36b9f7b.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">training_accuracy</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span>
<span class="n">val_accuracy</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_accuracy&#39;</span><span class="p">]</span>

<span class="c1"># Create count of the number of epochs</span>
<span class="n">epoch_count</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">training_accuracy</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

<span class="c1"># Visualize loss history</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epoch_count</span><span class="p">,</span> <span class="n">training_accuracy</span><span class="p">,</span> <span class="s1">&#39;r--&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epoch_count</span><span class="p">,</span> <span class="n">val_accuracy</span><span class="p">,</span> <span class="s1">&#39;b-&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">&#39;Training Accuracy&#39;</span><span class="p">,</span> <span class="s1">&#39;Val Accuracy&#39;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Epoch&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="n">top</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(0.26857029646635056, 1.0)
</pre></div>
</div>
<img alt="_images/0d3ba6020c035b4e07f299b34c89e38e9dfbb553f282d3bc417c6ebb118cfa82.png" src="_images/0d3ba6020c035b4e07f299b34c89e38e9dfbb553f282d3bc417c6ebb118cfa82.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;cnn_model.h5&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Pruebas de precisión</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Test accuracy = </span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">test_set</span><span class="w"> </span><span class="p">,</span><span class="n">batch_size</span><span class="o">=</span><span class="n">test_set</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span><span class="n">steps</span><span class="o">=</span><span class="n">test_set</span><span class="o">.</span><span class="n">n</span><span class="w"> </span><span class="o">//</span><span class="w"> </span><span class="n">test_set</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="mi">100</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  3/112 [..............................] - ETA: 8s - loss: 1.4046 - accuracy: 0.6042
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>112/112 [==============================] - 4s 34ms/step - loss: 1.2545 - accuracy: 0.6300
Test accuracy = 63.00223469734192%
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Matriz de confusión del <code class="docutils literal notranslate"><span class="pre">conjunto</span> <span class="pre">de</span> <span class="pre">entrenamiento</span></code></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">training_set</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">class_labels</span> <span class="o">=</span> <span class="n">test_set</span><span class="o">.</span><span class="n">class_indices</span>
<span class="n">class_labels</span> <span class="o">=</span> <span class="p">{</span><span class="n">v</span><span class="p">:</span><span class="n">k</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span><span class="n">v</span> <span class="ow">in</span> <span class="n">class_labels</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>

<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">classification_report</span><span class="p">,</span> <span class="n">confusion_matrix</span>
<span class="n">cm_train</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">training_set</span><span class="o">.</span><span class="n">classes</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Confusion Matrix&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">cm_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Classification Report&#39;</span><span class="p">)</span>
<span class="n">target_names</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">class_labels</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">training_set</span><span class="o">.</span><span class="n">classes</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">target_names</span><span class="o">=</span><span class="n">target_names</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">cm_train</span><span class="p">,</span> <span class="n">interpolation</span><span class="o">=</span><span class="s1">&#39;nearest&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">()</span>
<span class="n">tick_mark</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">target_names</span><span class="p">))</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">tick_mark</span><span class="p">,</span> <span class="n">target_names</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">90</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span><span class="n">tick_mark</span><span class="p">,</span> <span class="n">target_names</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  1/359 [..............................] - ETA: 35s
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>359/359 [==============================] - 5s 13ms/step
Confusion Matrix
[[ 486   44  414  826  574  508  344]
 [  48    5   42   89   65   66   34]
 [ 521   58  404  817  546  586  346]
 [ 882  103  750 1469 1019  953  596]
 [ 578   50  503 1059  710  659  413]
 [ 581   51  494 1005  654  657  422]
 [ 391   38  326  676  459  387  260]]
Classification Report
              precision    recall  f1-score   support

       angry       0.14      0.15      0.15      3196
     disgust       0.01      0.01      0.01       349
        fear       0.14      0.12      0.13      3278
       happy       0.25      0.25      0.25      5772
     neutral       0.18      0.18      0.18      3972
         sad       0.17      0.17      0.17      3864
    surprise       0.11      0.10      0.11      2537

    accuracy                           0.17     22968
   macro avg       0.14      0.14      0.14     22968
weighted avg       0.17      0.17      0.17     22968
</pre></div>
</div>
<img alt="_images/689cfe1ca50a17fbf88df5e6249f1e65a08d265bfbedc929a82dacb3d93f06e0.png" src="_images/689cfe1ca50a17fbf88df5e6249f1e65a08d265bfbedc929a82dacb3d93f06e0.png" />
</div>
</div>
<ul class="simple">
<li><p>Matriz de confusión en el conjunto de <code class="docutils literal notranslate"><span class="pre">datos</span> <span class="pre">de</span> <span class="pre">validación</span></code></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">training_set</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">class_labels</span> <span class="o">=</span> <span class="n">test_set</span><span class="o">.</span><span class="n">class_indices</span>
<span class="n">class_labels</span> <span class="o">=</span> <span class="p">{</span><span class="n">v</span><span class="p">:</span><span class="n">k</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span><span class="n">v</span> <span class="ow">in</span> <span class="n">class_labels</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>

<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">classification_report</span><span class="p">,</span> <span class="n">confusion_matrix</span>
<span class="n">cm_train</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">training_set</span><span class="o">.</span><span class="n">classes</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Confusion Matrix&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">cm_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Classification Report&#39;</span><span class="p">)</span>
<span class="n">target_names</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">class_labels</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">training_set</span><span class="o">.</span><span class="n">classes</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">target_names</span><span class="o">=</span><span class="n">target_names</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">cm_train</span><span class="p">,</span> <span class="n">interpolation</span><span class="o">=</span><span class="s1">&#39;nearest&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">()</span>
<span class="n">tick_mark</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">target_names</span><span class="p">))</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">tick_mark</span><span class="p">,</span> <span class="n">target_names</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">90</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span><span class="n">tick_mark</span><span class="p">,</span> <span class="n">target_names</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 11/359 [..............................] - ETA: 3s
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>359/359 [==============================] - 4s 10ms/step
Confusion Matrix
[[ 554   47  375  804  580  533  303]
 [  58    3   52   89   62   55   30]
 [ 511   53  386  820  568  567  373]
 [ 865   98  726 1537  993  959  594]
 [ 588   60  517 1035  709  618  445]
 [ 558   66  497  997  683  673  390]
 [ 371   33  327  657  443  432  274]]
Classification Report
              precision    recall  f1-score   support

       angry       0.16      0.17      0.17      3196
     disgust       0.01      0.01      0.01       349
        fear       0.13      0.12      0.13      3278
       happy       0.26      0.27      0.26      5772
     neutral       0.18      0.18      0.18      3972
         sad       0.18      0.17      0.17      3864
    surprise       0.11      0.11      0.11      2537

    accuracy                           0.18     22968
   macro avg       0.15      0.15      0.15     22968
weighted avg       0.18      0.18      0.18     22968
</pre></div>
</div>
<img alt="_images/546f9f0f8610d2a1272dfd837435c4b90c2f177c8d790a5d3d99e530db867867.png" src="_images/546f9f0f8610d2a1272dfd837435c4b90c2f177c8d790a5d3d99e530db867867.png" />
</div>
</div>
<ul class="simple">
<li><p>Matriz de confusión en el conjunto de <code class="docutils literal notranslate"><span class="pre">datos</span> <span class="pre">de</span> <span class="pre">validación</span></code></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">validation_set</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">cm_val</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">validation_set</span><span class="o">.</span><span class="n">classes</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Confusion Matrix&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">cm_val</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Classification Report&#39;</span><span class="p">)</span>
<span class="n">target_names</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">class_labels</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">validation_set</span><span class="o">.</span><span class="n">classes</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">target_names</span><span class="o">=</span><span class="n">target_names</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">cm_train</span><span class="p">,</span> <span class="n">interpolation</span><span class="o">=</span><span class="s1">&#39;nearest&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">()</span>
<span class="n">tick_mark</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">target_names</span><span class="p">))</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">tick_mark</span><span class="p">,</span> <span class="n">target_names</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">90</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span><span class="n">tick_mark</span><span class="p">,</span> <span class="n">target_names</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 4/90 [&gt;.............................] - ETA: 1s
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>90/90 [==============================] - 2s 20ms/step
Confusion Matrix
[[118  11  97 208 150 146  69]
 [ 16   0   9  25  15  17   5]
 [134   8  85 235 165 123  69]
 [219  21 149 387 268 240 159]
 [153  13 101 261 196 172  97]
 [169   7 104 230 185 163 108]
 [ 88   5  73 192 104 108  64]]
Classification Report
              precision    recall  f1-score   support

       angry       0.13      0.15      0.14       799
     disgust       0.00      0.00      0.00        87
        fear       0.14      0.10      0.12       819
       happy       0.25      0.27      0.26      1443
     neutral       0.18      0.20      0.19       993
         sad       0.17      0.17      0.17       966
    surprise       0.11      0.10      0.11       634

    accuracy                           0.18      5741
   macro avg       0.14      0.14      0.14      5741
weighted avg       0.17      0.18      0.17      5741
</pre></div>
</div>
<img alt="_images/546f9f0f8610d2a1272dfd837435c4b90c2f177c8d790a5d3d99e530db867867.png" src="_images/546f9f0f8610d2a1272dfd837435c4b90c2f177c8d790a5d3d99e530db867867.png" />
</div>
</div>
<ul class="simple">
<li><p>Matriz de confusión del conjunto de <code class="docutils literal notranslate"><span class="pre">datos</span> <span class="pre">de</span> <span class="pre">prueba</span></code></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_set</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">cm_test</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">test_set</span><span class="o">.</span><span class="n">classes</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Confusion Matrix&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">cm_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Classification Report&#39;</span><span class="p">)</span>
<span class="n">target_names</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">class_labels</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">test_set</span><span class="o">.</span><span class="n">classes</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">target_names</span><span class="o">=</span><span class="n">target_names</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">cm_test</span><span class="p">,</span> <span class="n">interpolation</span><span class="o">=</span><span class="s1">&#39;nearest&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">()</span>
<span class="n">tick_mark</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">target_names</span><span class="p">))</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">tick_mark</span><span class="p">,</span> <span class="n">target_names</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">90</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span><span class="n">tick_mark</span><span class="p">,</span> <span class="n">target_names</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  6/113 [&gt;.............................] - ETA: 1s
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>113/113 [==============================] - 1s 11ms/step
Confusion Matrix
[[163   9  86 227 171 184 118]
 [ 17   0  16  32  19  15  12]
 [155  13 114 267 171 188 116]
 [280  27 193 467 333 305 169]
 [183  10 132 327 243 215 123]
 [200  14 156 323 236 196 122]
 [118  14  97 227 157 135  83]]
Classification Report
              precision    recall  f1-score   support

       angry       0.15      0.17      0.16       958
     disgust       0.00      0.00      0.00       111
        fear       0.14      0.11      0.13      1024
       happy       0.25      0.26      0.26      1774
     neutral       0.18      0.20      0.19      1233
         sad       0.16      0.16      0.16      1247
    surprise       0.11      0.10      0.11       831

    accuracy                           0.18      7178
   macro avg       0.14      0.14      0.14      7178
weighted avg       0.17      0.18      0.17      7178
</pre></div>
</div>
<img alt="_images/38d25c97360bf5bc6ba67d2b9f8d5e8dfad74bf4c757dea8db56d289033c0bfd.png" src="_images/38d25c97360bf5bc6ba67d2b9f8d5e8dfad74bf4c757dea8db56d289033c0bfd.png" />
</div>
</div>
<ul class="simple">
<li><p>Grafico de predicciones</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># next function assigns one batch to variables, i.e x_test,y_test will have 64 images</span>
<span class="n">x_test</span><span class="p">,</span><span class="n">y_test</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">test_set</span><span class="p">)</span>
<span class="n">predict</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2/2 [==============================] - 0s 3ms/step
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">figure</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">index</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">x_test</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">size</span><span class="o">=</span><span class="mi">24</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)):</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">figure</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">xticks</span><span class="o">=</span><span class="p">[],</span> <span class="n">yticks</span><span class="o">=</span><span class="p">[])</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">x_test</span><span class="p">[</span><span class="n">index</span><span class="p">]))</span>
    <span class="n">predict_index</span> <span class="o">=</span> <span class="n">class_labels</span><span class="p">[(</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">predict</span><span class="p">[</span><span class="n">index</span><span class="p">]))]</span>
    <span class="n">true_index</span> <span class="o">=</span> <span class="n">class_labels</span><span class="p">[(</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_test</span><span class="p">[</span><span class="n">index</span><span class="p">]))]</span>
    
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{}</span><span class="s2"> (</span><span class="si">{}</span><span class="s2">)&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">((</span><span class="n">predict_index</span><span class="p">),</span> 
                                  <span class="p">(</span><span class="n">true_index</span><span class="p">)),</span>
                                  <span class="n">color</span><span class="o">=</span><span class="p">(</span><span class="s2">&quot;green&quot;</span> <span class="k">if</span> <span class="n">predict_index</span> <span class="o">==</span> <span class="n">true_index</span> <span class="k">else</span> <span class="s2">&quot;red&quot;</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/ed5959321532e084c9d440a5601ef2feed9a337b92b20294e592bcf8b3d8d517.png" src="_images/ed5959321532e084c9d440a5601ef2feed9a337b92b20294e592bcf8b3d8d517.png" />
</div>
</div>
</section>
</section>
<section id="redes-neuronales-recurrentes">
<h2>Redes Neuronales Recurrentes<a class="headerlink" href="#redes-neuronales-recurrentes" title="Link to this heading">#</a></h2>
<div class="admonition-introduccion admonition">
<p class="admonition-title">Introducción</p>
<ul class="simple">
<li><p>Recordemos de la sección anterior que en el corazón de las <code class="docutils literal notranslate"><span class="pre">redes</span> <span class="pre">convolucionales</span></code> se encuentra el concepto de <code class="docutils literal notranslate"><span class="pre">peso</span> <span class="pre">compartido</span></code>. Es decir, <code class="docutils literal notranslate"><span class="pre">la</span> <span class="pre">misma</span> <span class="pre">matriz</span> <span class="pre">de</span> <span class="pre">filtro</span> <span class="pre">se</span> <span class="pre">desliza</span> <span class="pre">sobre</span> <span class="pre">una</span> <span class="pre">matriz</span> <span class="pre">de</span> <span class="pre">imágenes</span> <span class="pre">en</span> <span class="pre">lugar</span> <span class="pre">de</span> <span class="pre">dedicar</span> <span class="pre">un</span> <span class="pre">peso</span> <span class="pre">específico</span> <span class="pre">a</span> <span class="pre">cada</span> <span class="pre">píxel</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">imagen</span></code>. De este modo, una <code class="docutils literal notranslate"><span class="pre">red</span> <span class="pre">neuronal</span></code> puede <code class="docutils literal notranslate"><span class="pre">escalarse</span> <span class="pre">fácilmente</span> <span class="pre">a</span> <span class="pre">imágenes</span> <span class="pre">de</span> <span class="pre">diferentes</span> <span class="pre">dimensiones</span></code>.</p></li>
<li><p>Nuestro interés en esta sección se centra en el caso de los <code class="docutils literal notranslate"><span class="pre">datos</span> <span class="pre">secuenciales</span></code>. Es decir, los <code class="docutils literal notranslate"><span class="pre">vectores</span> <span class="pre">de</span> <span class="pre">entrada</span> <span class="pre">no</span> <span class="pre">son</span> <span class="pre">independientes,</span> <span class="pre">sino</span> <span class="pre">que</span> <span class="pre">aparecen</span> <span class="pre">en</span> <span class="pre">secuencia</span></code>. Además, el <code class="docutils literal notranslate"><span class="pre">orden</span> <span class="pre">específico</span> <span class="pre">en</span> <span class="pre">que</span> <span class="pre">se</span> <span class="pre">producen</span> <span class="pre">encierra</span> <span class="pre">información</span> <span class="pre">importante</span></code>. Por ejemplo, este tipo de secuencias se dan en el <strong><code class="docutils literal notranslate"><span class="pre">reconocimiento</span> <span class="pre">del</span> <span class="pre">habla</span> <span class="pre">y</span> <span class="pre">en</span> <span class="pre">el</span> <span class="pre">procesamiento</span> <span class="pre">del</span> <span class="pre">lenguaje,</span> <span class="pre">como</span> <span class="pre">la</span> <span class="pre">traducción</span> <span class="pre">automática,</span> <span class="pre">así</span> <span class="pre">como</span> <span class="pre">también</span> <span class="pre">el</span> <span class="pre">pronostico</span> <span class="pre">de</span> <span class="pre">series</span> <span class="pre">de</span> <span class="pre">tiempo</span> <span class="pre">financieras</span></code></strong>. Sin duda, <code class="docutils literal notranslate"><span class="pre">la</span> <span class="pre">secuencia</span> <span class="pre">en</span> <span class="pre">la</span> <span class="pre">que</span> <span class="pre">se</span> <span class="pre">producen</span> <span class="pre">las</span> <span class="pre">palabras</span> <span class="pre">es</span> <span class="pre">de</span> <span class="pre">suma</span> <span class="pre">importancia</span></code>.</p></li>
<li><p>El <code class="docutils literal notranslate"><span class="pre">reparto</span> <span class="pre">de</span> <span class="pre">pesos</span> <span class="pre">mediante</span> <span class="pre">convoluciones</span> <span class="pre">también</span> <span class="pre">podría</span> <span class="pre">ser</span> <span class="pre">y</span> <span class="pre">ha</span> <span class="pre">sido</span> <span class="pre">utilizado</span> <span class="pre">para</span> <span class="pre">estos</span> <span class="pre">casos</span></code> <span id="id32">[<a class="reference internal" href="biblio.html#id36" title="Kevin J Lang, Alex H Waibel, and Geoffrey E Hinton. A time-delay neural network architecture for isolated word recognition. Neural networks, 3(1):23–43, 1990.">Lang <em>et al.</em>, 1990</a>]</span>. Tales redes se conocen como <code class="docutils literal notranslate"><span class="pre">redes</span> <span class="pre">neuronales</span> <span class="pre">de</span> <span class="pre">retardo</span> <span class="pre">temporal</span></code>. Sin embargo, <code class="docutils literal notranslate"><span class="pre">deslizar</span> <span class="pre">un</span> <span class="pre">filtro</span> <span class="pre">a</span> <span class="pre">través</span> <span class="pre">del</span> <span class="pre">tiempo</span></code> para formar convoluciones es una <code class="docutils literal notranslate"><span class="pre">operación</span> <span class="pre">de</span> <span class="pre">naturaleza</span> <span class="pre">local</span></code>. La salida es una función de las muestras de entrada dentro de una ventana temporal que abarca la <code class="docutils literal notranslate"><span class="pre">longitud</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">respuesta</span> <span class="pre">al</span> <span class="pre">impulso</span> <span class="pre">del</span> <span class="pre">filtro</span></code>, que por razones prácticas no puede ser muy larga.</p></li>
</ul>
</div>
<div class="admonition-redes-neuronales-recurrentes admonition">
<p class="admonition-title">Redes Neuronales Recurrentes</p>
<ul>
<li><p>Las variables que intervienen en una <code class="docutils literal notranslate"><span class="pre">RNN</span></code> son:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Vector</span> <span class="pre">de</span> <span class="pre">estado</span> <span class="pre">en</span> <span class="pre">el</span> <span class="pre">tiempo</span></code> <span class="math notranslate nohighlight">\(n\)</span><code class="docutils literal notranslate"><span class="pre">,</span> <span class="pre">denotado</span> <span class="pre">como</span></code> <span class="math notranslate nohighlight">\(\boldsymbol{h}_{n}\)</span>. El símbolo nos recuerda que <span class="math notranslate nohighlight">\(\boldsymbol{h}\)</span> es un vector de variables ocultas (capa oculta en la jerga de las redes neuronales); <code class="docutils literal notranslate"><span class="pre">el</span> <span class="pre">vector</span> <span class="pre">de</span> <span class="pre">estado</span> <span class="pre">constituye</span> <span class="pre">la</span> <span class="pre">memoria</span> <span class="pre">del</span> <span class="pre">sistema</span></code>,</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Vector</span> <span class="pre">de</span> <span class="pre">entrada</span> <span class="pre">en</span> <span class="pre">el</span> <span class="pre">momento</span></code> <span class="math notranslate nohighlight">\(n\)</span>, denominado <span class="math notranslate nohighlight">\(\boldsymbol{x}_{n}\)</span>,</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Vector</span> <span class="pre">de</span> <span class="pre">salida</span> <span class="pre">en</span> <span class="pre">el</span> <span class="pre">momento</span></code> <span class="math notranslate nohighlight">\(n\)</span>, <span class="math notranslate nohighlight">\(\hat{\boldsymbol{y}}_{n}\)</span>, y el vector de salida objetivo, <span class="math notranslate nohighlight">\(\boldsymbol{y}_{n}\)</span>.</p></li>
</ul>
</li>
<li><p>El modelo se describe mediante un <code class="docutils literal notranslate"><span class="pre">conjunto</span> <span class="pre">de</span> <span class="pre">matrices</span> <span class="pre">y</span> <span class="pre">vectores</span> <span class="pre">de</span> <span class="pre">parámetros</span> <span class="pre">desconocidos</span></code>, a saber, <span class="math notranslate nohighlight">\(U, W, V , \boldsymbol{b}\)</span> y <span class="math notranslate nohighlight">\(\boldsymbol{c}\)</span>, que <code class="docutils literal notranslate"><span class="pre">deben</span> <span class="pre">aprenderse</span> <span class="pre">durante</span> <span class="pre">el</span> <span class="pre">entrenamiento</span></code>.</p></li>
<li><p>Las <code class="docutils literal notranslate"><span class="pre">ecuaciones</span> <span class="pre">que</span> <span class="pre">describen</span> <span class="pre">un</span> <span class="pre">modelo</span> <span class="pre">RNN</span></code> son</p>
<div class="math notranslate nohighlight" id="equation-rnn-system-eq">
<span class="eqno">(64)<a class="headerlink" href="#equation-rnn-system-eq" title="Link to this equation">#</a></span>\[\begin{split}
    \begin{align*}
    \boldsymbol{h}_{n}&amp;=f(U\boldsymbol{x}_{n}+W\boldsymbol{h}_{n-1}+\boldsymbol{b})\\
    \hat{\boldsymbol{y}}_{n}&amp;=g(V\boldsymbol{h}_{n}+\boldsymbol{c}).
    \end{align*}
    \end{split}\]</div>
<p>donde <code class="docutils literal notranslate"><span class="pre">las</span> <span class="pre">funciones</span> <span class="pre">no</span> <span class="pre">lineales</span></code> <span class="math notranslate nohighlight">\(f\)</span> y <span class="math notranslate nohighlight">\(g\)</span><code class="docutils literal notranslate"> <span class="pre">actúan</span> <span class="pre">elemento</span> <span class="pre">a</span> <span class="pre">elemento</span> <span class="pre">(element-wise)</span></code> y <code class="docutils literal notranslate"><span class="pre">se</span> <span class="pre">aplican</span> <span class="pre">individualmente</span> <span class="pre">a</span> <span class="pre">cada</span> <span class="pre">elemento</span> <span class="pre">de</span> <span class="pre">sus</span> <span class="pre">argumentos</span> <span class="pre">vectoriales</span></code>.</p>
</li>
<li><p>En otras palabras, <code class="docutils literal notranslate"><span class="pre">una</span> <span class="pre">vez</span> <span class="pre">que</span> <span class="pre">se</span> <span class="pre">ha</span> <span class="pre">observado</span> <span class="pre">un</span> <span class="pre">nuevo</span> <span class="pre">vector</span> <span class="pre">de</span> <span class="pre">entrada,</span> <span class="pre">se</span> <span class="pre">actualiza</span> <span class="pre">el</span> <span class="pre">vector</span> <span class="pre">de</span> <span class="pre">estado</span></code>. Su nuevo valor <code class="docutils literal notranslate"><span class="pre">depende</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">información</span> <span class="pre">más</span> <span class="pre">reciente,</span> <span class="pre">transmitida</span> <span class="pre">por</span> <span class="pre">la</span> <span class="pre">entrada</span></code> <span class="math notranslate nohighlight">\(\boldsymbol{x}_{n}\)</span> así como de la <code class="docutils literal notranslate"><span class="pre">historia</span> <span class="pre">pasada,</span> <span class="pre">ya</span> <span class="pre">que</span> <span class="pre">ésta</span> <span class="pre">se</span> <span class="pre">ha</span> <span class="pre">acumulado</span> <span class="pre">en</span></code> <span class="math notranslate nohighlight">\(\boldsymbol{h}_{n-1}\)</span>. La salida depende del <code class="docutils literal notranslate"><span class="pre">vector</span> <span class="pre">de</span> <span class="pre">estado</span> <span class="pre">actualizado</span></code>, <span class="math notranslate nohighlight">\(\boldsymbol{h}_{n}\)</span>. Es decir, <code class="docutils literal notranslate"><span class="pre">depende</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">&quot;historia&quot;</span> <span class="pre">hasta</span> <span class="pre">el</span> <span class="pre">instante</span> <span class="pre">actual</span></code> <span class="math notranslate nohighlight">\(n\)</span>, tal y como se expresa en <span class="math notranslate nohighlight">\(\boldsymbol{h}_{n}\)</span>.</p></li>
<li><p>Las opciones típicas para <span class="math notranslate nohighlight">\(f\)</span> son la <code class="docutils literal notranslate"><span class="pre">tangente</span> <span class="pre">hiperbólica,</span> <span class="pre">tanh,</span> <span class="pre">o</span> <span class="pre">las</span> <span class="pre">no</span> <span class="pre">linealidades</span> <span class="pre">ReLU</span></code>. El valor inicial <span class="math notranslate nohighlight">\(\boldsymbol{h}_{0}\)</span> <code class="docutils literal notranslate"><span class="pre">suele</span> <span class="pre">ser</span> <span class="pre">igual</span> <span class="pre">al</span> <span class="pre">vector</span> <span class="pre">cero</span></code>. La <code class="docutils literal notranslate"><span class="pre">no</span> <span class="pre">linealidad</span> <span class="pre">de</span> <span class="pre">salida,</span></code> <span class="math notranslate nohighlight">\(g\)</span><code class="docutils literal notranslate"><span class="pre">,</span> <span class="pre">se</span> <span class="pre">elige</span> <span class="pre">a</span> <span class="pre">menudo</span> <span class="pre">para</span> <span class="pre">ser</span> <span class="pre">la</span> <span class="pre">función</span> <span class="pre">softmax</span></code>.</p></li>
</ul>
</div>
<figure class="align-center" id="recurrent-neural-network-arch-numref">
<a class="reference internal image-reference" href="_images/recurrent_neural_network_arch.png"><img alt="_images/recurrent_neural_network_arch.png" src="_images/recurrent_neural_network_arch.png" style="width: 552.0px; height: 304.8px;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 63 </span><span class="caption-text">Arquitectura de una <code class="docutils literal notranslate"><span class="pre">Red</span> <span class="pre">Neuronal</span> <span class="pre">Recurrente</span></code>. Fuente <span id="id33">[<a class="reference internal" href="biblio.html#id17" title="S. Theodoridis. Machine Learning: A Bayesian and Optimization Perspective. Elsevier Science, 2020. ISBN 9780128188040. URL: https://books.google.com.co/books?id=l-nEDwAAQBAJ.">Theodoridis, 2020</a>]</span>.</span><a class="headerlink" href="#recurrent-neural-network-arch-numref" title="Link to this image">#</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p>De las ecuaciones anteriores se deduce que las <code class="docutils literal notranslate"><span class="pre">matrices</span> <span class="pre">y</span> <span class="pre">vectores</span> <span class="pre">de</span> <span class="pre">parámetros</span> <span class="pre">se</span> <span class="pre">comparten</span> <span class="pre">en</span> <span class="pre">todos</span> <span class="pre">los</span> <span class="pre">instantes</span> <span class="pre">temporales</span></code>. Durante el entrenamiento, <code class="docutils literal notranslate"><span class="pre">se</span> <span class="pre">inicializan</span> <span class="pre">mediante</span> <span class="pre">números</span> <span class="pre">aleatorios</span></code>. El modelo gráfico
asociado con Eq. <a class="reference internal" href="#equation-rnn-system-eq">(64)</a> se muestra en la <a class="reference internal" href="#recurrent-neural-network-arch-numref"><span class="std std-numref">Fig. 63</span></a>A. En la <a class="reference internal" href="#recurrent-neural-network-arch-numref"><span class="std std-numref">Fig. 63</span></a>B, <code class="docutils literal notranslate"><span class="pre">el</span> <span class="pre">gráfico</span> <span class="pre">se</span> <span class="pre">despliega</span> <span class="pre">sobre</span> <span class="pre">los</span> <span class="pre">distintos</span> <span class="pre">instantes</span> <span class="pre">de</span> <span class="pre">tiempo</span></code> para los que se dispone de observaciones. Por ejemplo, <code class="docutils literal notranslate"><span class="pre">si</span> <span class="pre">la</span> <span class="pre">secuencia</span> <span class="pre">de</span> <span class="pre">interés</span> <span class="pre">es</span> <span class="pre">una</span> <span class="pre">frase</span> <span class="pre">de</span> <span class="pre">10</span> <span class="pre">palabras</span></code>, entonces <span class="math notranslate nohighlight">\(N\)</span> se establece igual a 10, mientras que <span class="math notranslate nohighlight">\(\boldsymbol{x}_{n}\)</span> es el <code class="docutils literal notranslate"><span class="pre">vector</span> <span class="pre">que</span> <span class="pre">codifica</span> <span class="pre">las</span> <span class="pre">respectivas</span> <span class="pre">palabras</span> <span class="pre">de</span> <span class="pre">entrada</span></code>.</p></li>
</ul>
<section id="backpropagation-en-tiempo">
<h3>Backpropagation en tiempo<a class="headerlink" href="#backpropagation-en-tiempo" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>El entrenamiento de las <code class="docutils literal notranslate"><span class="pre">RNN</span></code> sigue una <code class="docutils literal notranslate"><span class="pre">lógica</span> <span class="pre">similar</span> <span class="pre">a</span> <span class="pre">la</span> <span class="pre">del</span> <span class="pre">algoritmo</span> <span class="pre">backpropagation</span></code> para el entrenamiento de redes neuronales de avance. Después de todo, <code class="docutils literal notranslate"><span class="pre">una</span> <span class="pre">RNN</span> <span class="pre">puede</span> <span class="pre">verse</span> <span class="pre">como</span> <span class="pre">una</span> <span class="pre">red</span> <span class="pre">feed-forward</span> <span class="pre">con</span></code> <span class="math notranslate nohighlight">\(N\)</span> <code class="docutils literal notranslate"><span class="pre">capas</span></code>. La <code class="docutils literal notranslate"><span class="pre">capa</span> <span class="pre">superior</span> <span class="pre">es</span> <span class="pre">la</span> <span class="pre">del</span> <span class="pre">instante</span> <span class="pre">de</span> <span class="pre">tiempo</span></code> <span class="math notranslate nohighlight">\(N\)</span> y la <code class="docutils literal notranslate"><span class="pre">primera</span> <span class="pre">capa</span> <span class="pre">corresponde</span> <span class="pre">al</span> <span class="pre">instante</span> <span class="pre">de</span> <span class="pre">tiempo</span></code> <span class="math notranslate nohighlight">\(n = 1\)</span>. Una diferencia radica en que las <code class="docutils literal notranslate"><span class="pre">capas</span> <span class="pre">ocultas</span> <span class="pre">en</span> <span class="pre">una</span> <span class="pre">RNN</span> <span class="pre">también</span> <span class="pre">producen</span> <span class="pre">salidas</span></code>, es decir, <span class="math notranslate nohighlight">\(\hat{\boldsymbol{y}}_{n}\)</span>, y se alimentan directamente con entradas. Sin embargo, <code class="docutils literal notranslate"><span class="pre">en</span> <span class="pre">lo</span> <span class="pre">que</span> <span class="pre">respecta</span> <span class="pre">al</span> <span class="pre">entrenamiento,</span> <span class="pre">estas</span> <span class="pre">diferencias</span> <span class="pre">no</span> <span class="pre">afectan</span> <span class="pre">al</span> <span class="pre">razonamiento</span> <span class="pre">principal</span></code>.</p></li>
<li><p>El <code class="docutils literal notranslate"><span class="pre">aprendizaje</span> <span class="pre">de</span> <span class="pre">las</span> <span class="pre">matrices</span> <span class="pre">y</span> <span class="pre">vectores</span> <span class="pre">de</span> <span class="pre">parámetros</span> <span class="pre">desconocidos</span></code> se consigue mediante un esquema de gradiente descendiente, de acuerdo con Eq. <a class="reference internal" href="#equation-update-equations-gd">(53)</a>. Resulta que los <code class="docutils literal notranslate"><span class="pre">gradientes</span> <span class="pre">requeridos</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">función</span> <span class="pre">de</span> <span class="pre">coste</span></code>, con respecto a los parámetros desconocidos, <code class="docutils literal notranslate"><span class="pre">tienen</span> <span class="pre">lugar</span> <span class="pre">recursivamente,</span> <span class="pre">comenzando</span> <span class="pre">en</span> <span class="pre">el</span> <span class="pre">último</span> <span class="pre">instante</span> <span class="pre">de</span> <span class="pre">tiempo,</span></code> <span class="math notranslate nohighlight">\(N\)</span> , y retrocediendo en el tiempo, <span class="math notranslate nohighlight">\(n = N-1, N-2,\dots,1\)</span>. Esta es la razón por la que el algoritmo se conoce como <code class="docutils literal notranslate"><span class="pre">bakpropagation</span> <span class="pre">a</span> <span class="pre">traves</span> <span class="pre">del</span> <span class="pre">tiempo</span> <span class="pre">(BPTT)</span></code>.</p></li>
</ul>
<ul class="simple">
<li><p>La <code class="docutils literal notranslate"><span class="pre">función</span> <span class="pre">de</span> <span class="pre">coste</span> <span class="pre">es</span> <span class="pre">la</span> <span class="pre">suma</span> <span class="pre">a</span> <span class="pre">lo</span> <span class="pre">largo</span> <span class="pre">del</span> <span class="pre">tiempo,</span></code> <span class="math notranslate nohighlight">\(n\)</span>, de las correspondientes <code class="docutils literal notranslate"><span class="pre">contribuciones</span> <span class="pre">a</span> <span class="pre">la</span> <span class="pre">función</span> <span class="pre">de</span> <span class="pre">pérdida</span></code>, que dependen de los valores respectivos de <span class="math notranslate nohighlight">\(\boldsymbol{h}_{n}, \boldsymbol{x}_{n}\)</span>, es decir,</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
J(U, W, V, \boldsymbol{b}, \boldsymbol{c})=\sum_{n=1}^{N}J_{n}(U, W, V, \boldsymbol{b}, \boldsymbol{c}).
\]</div>
<ul>
<li><p>Por ejemplo, para el caso de la <code class="docutils literal notranslate"><span class="pre">función</span> <span class="pre">de</span> <span class="pre">pérdida</span> <span class="pre">de</span> <span class="pre">entropía</span> <span class="pre">cruzada</span></code>,</p>
<div class="math notranslate nohighlight">
\[
    J_{n}(U, W, V, \boldsymbol{b}, \boldsymbol{c}):=-\sum_{k}y_{nk}\ln\hat{y}_{nk},
    \]</div>
<p>donde <code class="docutils literal notranslate"><span class="pre">la</span> <span class="pre">suma</span> <span class="pre">es</span> <span class="pre">sobre</span> <span class="pre">la</span> <span class="pre">dimensionalidad</span> <span class="pre">de</span></code> <span class="math notranslate nohighlight">\(\boldsymbol{y}\)</span>, y</p>
<div class="math notranslate nohighlight">
\[
    \hat{\boldsymbol{y}}_{n}=g(\boldsymbol{h}_{n}, V, \boldsymbol{c})~\text{y}~\boldsymbol{h}_{n}=f(\boldsymbol{x}_{n}, \boldsymbol{h}_{n-1}, U, W, \boldsymbol{b}).
    \]</div>
</li>
</ul>
<ul>
<li><p>En el corazón del <code class="docutils literal notranslate"><span class="pre">cálculo</span> <span class="pre">de</span> <span class="pre">los</span> <span class="pre">gradientes</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">función</span> <span class="pre">de</span> <span class="pre">coste</span> <span class="pre">con</span> <span class="pre">respecto</span> <span class="pre">a</span> <span class="pre">las</span> <span class="pre">diversas</span> <span class="pre">matrices</span> <span class="pre">y</span> <span class="pre">vectores</span> <span class="pre">de</span> <span class="pre">parámetros</span></code> se encuentra el cálculo de los <code class="docutils literal notranslate"><span class="pre">gradientes</span> <span class="pre">de</span></code> <span class="math notranslate nohighlight">\(J\)</span> <code class="docutils literal notranslate"><span class="pre">con</span> <span class="pre">respecto</span> <span class="pre">a</span> <span class="pre">los</span> <span class="pre">vectores</span> <span class="pre">de</span> <span class="pre">estado,</span></code> <span class="math notranslate nohighlight">\(\boldsymbol{h}_{n}\)</span>. Una vez calculados estos últimos, el resto de los gradientes, con respecto a las <code class="docutils literal notranslate"><span class="pre">matrices</span> <span class="pre">y</span> <span class="pre">vectores</span> <span class="pre">de</span> <span class="pre">parámetros</span> <span class="pre">desconocidos</span></code>, es una tarea sencilla. Para ello, nótese que cada <span class="math notranslate nohighlight">\(h_{n},~n=1, 2,\dots,N-1\)</span>, afecta a <span class="math notranslate nohighlight">\(J\)</span> de dos maneras:</p>
<ul class="simple">
<li><p>Directamente, <code class="docutils literal notranslate"><span class="pre">a</span> <span class="pre">traves</span> <span class="pre">de</span></code> <span class="math notranslate nohighlight">\(J_{n}\)</span></p></li>
<li><p>Indirectamente, <code class="docutils literal notranslate"><span class="pre">a</span> <span class="pre">través</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">cadena</span> <span class="pre">que</span> <span class="pre">impone</span> <span class="pre">la</span> <span class="pre">estructura</span> <span class="pre">RNN</span></code>, es decir,</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
    \boldsymbol{h}_{n}\rightarrow\boldsymbol{h}_{n+1}\rightarrow\cdots\rightarrow\boldsymbol{h}_{N}.
    \]</div>
<p>Es decir, <span class="math notranslate nohighlight">\(\boldsymbol{h}_{n}\)</span>, además de <span class="math notranslate nohighlight">\(J_{n}\)</span>, <code class="docutils literal notranslate"><span class="pre">también</span> <span class="pre">afecta</span> <span class="pre">a</span> <span class="pre">todos</span> <span class="pre">los</span> <span class="pre">valores</span> <span class="pre">de</span> <span class="pre">coste</span> <span class="pre">posteriores</span></code>, <span class="math notranslate nohighlight">\(J_{n+1},\dots, J_{N}\)</span>. Nótese que, a traves de la cadena <span class="math notranslate nohighlight">\(\boldsymbol{h}_{n+1}=f(\boldsymbol{x}_{n+1}, \boldsymbol{h}_{n}, U, W, \boldsymbol{b}).\)</span></p>
</li>
</ul>
<ul>
<li><p>Empleando la <code class="docutils literal notranslate"><span class="pre">regla</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">cadena</span></code> para las derivadas, las <code class="docutils literal notranslate"><span class="pre">dependencias</span> <span class="pre">anteriores</span> <span class="pre">conducen</span> <span class="pre">al</span> <span class="pre">siguiente</span> <span class="pre">cálculo</span> <span class="pre">recursivo</span></code>:</p>
<div class="math notranslate nohighlight" id="equation-indirect-direct-rec-part">
<span class="eqno">(65)<a class="headerlink" href="#equation-indirect-direct-rec-part" title="Link to this equation">#</a></span>\[
    \frac{\partial J}{\partial\boldsymbol{h}_{n}}=\underbrace{{\left(\frac{\partial\boldsymbol{h}_{n+1}}{\partial\boldsymbol{h}_{n}}\right)^{T}}\frac{\partial J}{\partial\boldsymbol{h}_{n+1}}}_{\text{parte recursiva indirecta}}+\underbrace{\left(\frac{\partial\hat{\boldsymbol{y}}_{n}}{\partial\boldsymbol{h}_{n}}\right)^{T}\frac{\partial J}{\partial\hat{\boldsymbol{y}}_{n}}}_{\text{parte directa}},
    \]</div>
<p>donde, por definición, la <code class="docutils literal notranslate"><span class="pre">derivada</span> <span class="pre">de</span> <span class="pre">un</span> <span class="pre">vector</span></code>, digamos, <span class="math notranslate nohighlight">\(\boldsymbol{y}\)</span>, <code class="docutils literal notranslate"><span class="pre">con</span> <span class="pre">respecto</span> <span class="pre">a</span> <span class="pre">otro</span> <span class="pre">vector</span></code>, digamos, <span class="math notranslate nohighlight">\(\boldsymbol{x}\)</span>, se define como la matriz</p>
<div class="math notranslate nohighlight">
\[
    \left[\frac{\partial\boldsymbol{y}}{\partial\boldsymbol{x}}\right]_{ij}:=\frac{\partial y_{i}}{\partial x_{j}}.
    \]</div>
</li>
</ul>
<ul class="simple">
<li><p>Nótese que el <code class="docutils literal notranslate"><span class="pre">gradiente</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">función</span> <span class="pre">de</span> <span class="pre">coste</span></code>, con respecto a los <code class="docutils literal notranslate"><span class="pre">parámetros</span> <span class="pre">ocultos</span> <span class="pre">(vector</span> <span class="pre">de</span> <span class="pre">estado)</span></code> en la capa “<span class="math notranslate nohighlight">\(n\)</span>”, se da como una <code class="docutils literal notranslate"><span class="pre">función</span> <span class="pre">del</span> <span class="pre">gradiente</span> <span class="pre">respectivo</span> <span class="pre">en</span> <span class="pre">la</span> <span class="pre">capa</span> <span class="pre">anterior</span></code>, es decir, con respecto al <code class="docutils literal notranslate"><span class="pre">vector</span> <span class="pre">de</span> <span class="pre">estado</span> <span class="pre">en</span> <span class="pre">el</span> <span class="pre">tiempo</span></code> <span class="math notranslate nohighlight">\(n + 1\)</span>. Las dos <code class="docutils literal notranslate"><span class="pre">pasadas</span> <span class="pre">requeridas</span> <span class="pre">por</span> <span class="pre">backpropagation</span> <span class="pre">en</span> <span class="pre">el</span> <span class="pre">tiempo</span></code> se resumen a continuación.</p></li>
</ul>
<div class="admonition-pasadas-de-backpropagation-en-tiempo admonition">
<p class="admonition-title">Pasadas de Backpropagation en Tiempo</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">Paso</span> <span class="pre">hacia</span> <span class="pre">adelante</span></code>:</p>
<ul class="simple">
<li><p>Iniciando en <span class="math notranslate nohighlight">\(n=1\)</span> y <code class="docutils literal notranslate"><span class="pre">utilizando</span> <span class="pre">las</span> <span class="pre">estimaciones</span> <span class="pre">actuales</span> <span class="pre">de</span> <span class="pre">las</span> <span class="pre">matrices</span> <span class="pre">y</span> <span class="pre">vectores</span> <span class="pre">de</span> <span class="pre">parámetros</span> <span class="pre">implicados</span></code>, calcular en secuencia,</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
    (\boldsymbol{h}_{1}, \hat{\boldsymbol{y}}_{1})\rightarrow(\boldsymbol{h}_{2}, \hat{\boldsymbol{y}}_{2})\rightarrow\cdots\rightarrow(\boldsymbol{h}_{N}, \hat{\boldsymbol{y}}_{N}).
    \]</div>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">Paso</span> <span class="pre">hacia</span> <span class="pre">atrás</span></code>:</p>
<ul class="simple">
<li><p>Empezando en <span class="math notranslate nohighlight">\(n = N\)</span>, calcular en secuencia,</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
    \frac{\partial J}{\partial\boldsymbol{h}_{N}}\rightarrow\frac{\partial J}{\partial\boldsymbol{h}_{N-1}}\rightarrow\cdots\rightarrow\frac{\partial J}{\partial\boldsymbol{h}_{1}}.
    \]</div>
</li>
</ul>
</div>
<ul class="simple">
<li><p>Nótese que el <code class="docutils literal notranslate"><span class="pre">cálculo</span> <span class="pre">del</span> <span class="pre">gradiente</span></code> <span class="math notranslate nohighlight">\(\partial J/\partial\boldsymbol{h}_{N}\)</span> es sencillo, y <code class="docutils literal notranslate"><span class="pre">solo</span> <span class="pre">involucra</span> <span class="pre">la</span> <span class="pre">parte</span> <span class="pre">directa</span> <span class="pre">en</span></code> Eq. <a class="reference internal" href="#equation-indirect-direct-rec-part">(65)</a>.</p></li>
<li><p>Para la implementación de la <code class="docutils literal notranslate"><span class="pre">BPTT</span></code>, se procede a</p>
<ol class="arabic simple">
<li><p><code class="docutils literal notranslate"><span class="pre">inicializar</span> <span class="pre">aleatoriamente</span> <span class="pre">las</span> <span class="pre">matrices</span> <span class="pre">y</span> <span class="pre">vectores</span> <span class="pre">desconocidos</span> <span class="pre">implicados,</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">calcular</span> <span class="pre">todos</span> <span class="pre">los</span> <span class="pre">gradientes</span> <span class="pre">requeridos,</span> <span class="pre">siguiendo</span> <span class="pre">los</span> <span class="pre">pasos</span> <span class="pre">indicados</span> <span class="pre">anteriormente</span></code>, y</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">realizar</span> <span class="pre">las</span> <span class="pre">actualizaciones</span> <span class="pre">según</span> <span class="pre">el</span> <span class="pre">esquema</span> <span class="pre">de</span> <span class="pre">gradiente</span> <span class="pre">descendiente</span></code>.</p></li>
</ol>
</li>
<li><p>Los pasos <code class="docutils literal notranslate"><span class="pre">(2)</span> <span class="pre">y</span> <span class="pre">(3)</span> <span class="pre">se</span> <span class="pre">realizan</span> <span class="pre">de</span> <span class="pre">forma</span> <span class="pre">iterativa</span> <span class="pre">hasta</span> <span class="pre">que</span> <span class="pre">se</span> <span class="pre">cumple</span> <span class="pre">un</span> <span class="pre">criterio</span> <span class="pre">de</span> <span class="pre">convergencia</span></code>, de forma análoga al <code class="docutils literal notranslate"><span class="pre">algoritmo</span> <span class="pre">estándar</span> <span class="pre">de</span> <span class="pre">backpropagation</span></code>.</p></li>
</ul>
</section>
<section id="desvanecimiento-y-explosion-de-gradientes">
<h3>Desvanecimiento y explosión de gradientes<a class="headerlink" href="#desvanecimiento-y-explosion-de-gradientes" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>La tarea de <code class="docutils literal notranslate"><span class="pre">desvanecimiento</span> <span class="pre">y</span> <span class="pre">explosión</span> <span class="pre">de</span> <span class="pre">gradientes</span></code> se ha introducido y discutido en secciones anteriores, en el contexto del algoritmo de backpropagation. <code class="docutils literal notranslate"><span class="pre">Los</span> <span class="pre">mismos</span> <span class="pre">problemas</span> <span class="pre">se</span> <span class="pre">presentan</span> <span class="pre">en</span> <span class="pre">el</span> <span class="pre">algoritmo</span> <span class="pre">BPTT</span></code>, dado que, este último es una <code class="docutils literal notranslate"><span class="pre">forma</span> <span class="pre">específica</span> <span class="pre">del</span> <span class="pre">concepto</span> <span class="pre">de</span> <span class="pre">backpropagation</span></code> y, como se ha dicho, una <code class="docutils literal notranslate"><span class="pre">RNN</span></code> puede considerarse como una <code class="docutils literal notranslate"><span class="pre">red</span> <span class="pre">multicapa,</span> <span class="pre">donde</span> <span class="pre">cada</span> <span class="pre">instante</span> <span class="pre">de</span> <span class="pre">tiempo</span> <span class="pre">corresponde</span> <span class="pre">a</span> <span class="pre">una</span> <span class="pre">capa</span> <span class="pre">diferente</span></code>. De hecho en las <code class="docutils literal notranslate"><span class="pre">RNN</span></code>, el fenómeno de <code class="docutils literal notranslate"><span class="pre">desvanecimiento/explosión</span> <span class="pre">de</span> <span class="pre">gradiente</span> <span class="pre">aparece</span> <span class="pre">de</span> <span class="pre">una</span> <span class="pre">forma</span> <span class="pre">bastante</span> <span class="pre">&quot;agresiva&quot;</span></code>, teniendo en cuenta que <span class="math notranslate nohighlight">\(N\)</span> puede alcanzar valores grandes.</p></li>
</ul>
<ul class="simple">
<li><p>La naturaleza multiplicativa de la propagación de gradientes puede verse fácilmente en la Eq. <a class="reference internal" href="#equation-indirect-direct-rec-part">(65)</a>. Para ayudar a comprender el concepto principal, simplifiquemos el escenario y <code class="docutils literal notranslate"><span class="pre">supongamos</span> <span class="pre">que</span> <span class="pre">sólo</span> <span class="pre">interviene</span> <span class="pre">una</span> <span class="pre">variante</span> <span class="pre">de</span> <span class="pre">estado</span></code>. Entonces los vectores de estado se convierten en escalares, <span class="math notranslate nohighlight">\(h_{n}\)</span> , y la matriz <span class="math notranslate nohighlight">\(W\)</span> en un escalar <span class="math notranslate nohighlight">\(w\)</span>. Además, <code class="docutils literal notranslate"><span class="pre">supongamos</span> <span class="pre">que</span> <span class="pre">las</span> <span class="pre">salidas</span> <span class="pre">también</span> <span class="pre">son</span> <span class="pre">escalares</span></code>. Entonces la recursión en la Eq. <a class="reference internal" href="#equation-indirect-direct-rec-part">(65)</a> se simplifica como:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\frac{\partial J}{\partial h_{n}}=\frac{\partial h_{n+1}}{\partial h_{n}}\frac{\partial J}{\partial h_{n+1}}+\frac{\partial\hat{y}_{n}}{\partial h_{n}}\frac{\partial J}{\partial\hat{y}_{n}}.
\]</div>
<ul class="simple">
<li><p>Suponiendo en la Eq. <a class="reference internal" href="#equation-rnn-system-eq">(64)</a> que <span class="math notranslate nohighlight">\(f\)</span> <code class="docutils literal notranslate"><span class="pre">es</span> <span class="pre">la</span> <span class="pre">función</span></code> <span class="math notranslate nohighlight">\(\tanh(\cdot)\)</span> <code class="docutils literal notranslate"><span class="pre">estándar</span></code>, teniendo en cuenta que, <span class="math notranslate nohighlight">\(\text{sech}^2(\cdot)=1-\tanh^2(\cdot)\)</span> y <span class="math notranslate nohighlight">\(|\tanh(\cdot)|&lt;1\)</span>, sobre su dominio, se ve fácilmente que</p></li>
</ul>
<div class="math notranslate nohighlight" id="equation-partial-deriv-hn">
<span class="eqno">(66)<a class="headerlink" href="#equation-partial-deriv-hn" title="Link to this equation">#</a></span>\[
\frac{\partial h_{n+1}}{\partial h_{n}}=w(1-h_{n+1}^{2}).
\]</div>
<ul class="simple">
<li><p>Escribiendo la <code class="docutils literal notranslate"><span class="pre">recursión</span> <span class="pre">para</span> <span class="pre">dos</span> <span class="pre">pasos</span> <span class="pre">sucesivos</span></code>, repitiendo el proceso en Eq. <a class="reference internal" href="#equation-partial-deriv-hn">(66)</a>, por ejemplo, para <span class="math notranslate nohighlight">\(\partial h_{n+2}/\partial h_{n+1}\)</span> obtenemos que,</p></li>
</ul>
<div class="math notranslate nohighlight" id="equation-partialj-hn-eq">
<span class="eqno">(67)<a class="headerlink" href="#equation-partialj-hn-eq" title="Link to this equation">#</a></span>\[\begin{split}
\begin{align*}
\frac{\partial J}{\partial h_{n}}&amp;=\frac{\partial h_{n+1}}{\partial h_{n}}\frac{\partial J}{\partial h_{n+1}}+\frac{\partial\hat{y}_{n}}{\partial h_{n}}\frac{\partial J}{\partial\hat{y}_{n}}\\
&amp;=w^{2}(1-h_{n+1}^{2})(1-h_{n+2}^{2})\frac{\partial J}{\partial h_{n+2}}+\text{otro términos}
\end{align*}
\end{split}\]</div>
<ul class="simple">
<li><p>No es difícil ver que la <code class="docutils literal notranslate"><span class="pre">multiplicación</span> <span class="pre">de</span> <span class="pre">los</span> <span class="pre">términos</span> <span class="pre">menores</span> <span class="pre">que</span> <span class="pre">uno</span> <span class="pre">puede</span> <span class="pre">llevar</span> <span class="pre">a</span> <span class="pre">valores</span> <span class="pre">de</span> <span class="pre">desvanecimiento</span></code>, sobre todo si tenemos en cuenta que, en la práctica, las <code class="docutils literal notranslate"><span class="pre">secuencias</span> <span class="pre">pueden</span> <span class="pre">ser</span> <span class="pre">bastante</span> <span class="pre">grandes,</span> <span class="pre">por</span> <span class="pre">ejemplo,</span></code> <span class="math notranslate nohighlight">\(N = 100\)</span>. Por lo tanto <code class="docutils literal notranslate"><span class="pre">para</span> <span class="pre">instantes</span> <span class="pre">de</span> <span class="pre">tiempo</span> <span class="pre">cercanos</span> <span class="pre">a</span></code> <span class="math notranslate nohighlight">\(n = 1\)</span>, la <code class="docutils literal notranslate"><span class="pre">contribución</span> <span class="pre">al</span> <span class="pre">gradiente</span> <span class="pre">del</span> <span class="pre">primer</span> <span class="pre">término</span> <span class="pre">del</span> <span class="pre">lado</span> <span class="pre">derecho</span> <span class="pre">en</span> <span class="pre">la</span></code> Eq. <a class="reference internal" href="#equation-partialj-hn-eq">(67)</a> implicará un <code class="docutils literal notranslate"><span class="pre">gran</span> <span class="pre">número</span> <span class="pre">de</span> <span class="pre">productos</span> <span class="pre">de</span> <span class="pre">números</span> <span class="pre">menores</span> <span class="pre">que</span> <span class="pre">uno</span> <span class="pre">en</span> <span class="pre">magnitud</span></code>. Por otra parte, el valor de <span class="math notranslate nohighlight">\(w\)</span> estará contribuyendo en <span class="math notranslate nohighlight">\(w^{n}\)</span> potencia. Por lo tanto, <code class="docutils literal notranslate"><span class="pre">si</span> <span class="pre">su</span> <span class="pre">valor</span> <span class="pre">es</span> <span class="pre">mayor</span> <span class="pre">que</span> <span class="pre">uno,</span> <span class="pre">puede</span> <span class="pre">conducir</span> <span class="pre">a</span> <span class="pre">valores</span> <span class="pre">explosivos</span> <span class="pre">de</span> <span class="pre">los</span> <span class="pre">gradientes</span> <span class="pre">respectivos</span></code>.</p></li>
</ul>
<ul class="simple">
<li><p>En varios casos, <code class="docutils literal notranslate"><span class="pre">se</span> <span class="pre">puede</span> <span class="pre">truncar</span> <span class="pre">el</span> <span class="pre">algoritmo</span> <span class="pre">de</span> <span class="pre">backpropagation</span> <span class="pre">a</span> <span class="pre">unos</span> <span class="pre">pocos</span> <span class="pre">pasos</span> <span class="pre">de</span> <span class="pre">tiempo</span></code>. Otra forma, es <code class="docutils literal notranslate"><span class="pre">sustituir</span> <span class="pre">la</span> <span class="pre">no</span> <span class="pre">linealidad</span> <span class="pre">tanh</span> <span class="pre">por</span> <span class="pre">la</span> <span class="pre">ReLU</span></code>. Para el caso del <code class="docutils literal notranslate"><span class="pre">valor</span> <span class="pre">explosivo</span></code>, se puede <code class="docutils literal notranslate"><span class="pre">introducir</span> <span class="pre">una</span> <span class="pre">técnica</span> <span class="pre">que</span> <span class="pre">recorte</span> <span class="pre">los</span> <span class="pre">valores</span> <span class="pre">a</span> <span class="pre">un</span> <span class="pre">umbral</span> <span class="pre">predeterminado</span></code>, una vez que los <code class="docutils literal notranslate"><span class="pre">valores</span> <span class="pre">superen</span> <span class="pre">ese</span> <span class="pre">umbral</span></code>. Sin embargo, otra técnica que suele emplearse en la práctica es <code class="docutils literal notranslate"><span class="pre">sustituir</span> <span class="pre">la</span> <span class="pre">formulación</span> <span class="pre">RNN</span></code> estándar descrita anteriormente por una <code class="docutils literal notranslate"><span class="pre">estructura</span> <span class="pre">alternativa,</span> <span class="pre">que</span> <span class="pre">puede</span> <span class="pre">hacer</span> <span class="pre">mejor</span> <span class="pre">frente</span> <span class="pre">a</span> <span class="pre">estos</span> <span class="pre">fenómenos</span> <span class="pre">causados</span> <span class="pre">por</span> <span class="pre">la</span> <span class="pre">dependencia</span> <span class="pre">a</span> <span class="pre">largo</span> <span class="pre">plazo</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">RNN</span></code>.</p></li>
</ul>
<div class="proof observation admonition" id="observation_ann9">
<p class="admonition-title"><span class="caption-number">Observation 17 </span></p>
<section class="observation-content" id="proof-content">
<ul class="simple">
<li><p><strong><code class="docutils literal notranslate"><span class="pre">RNN</span> <span class="pre">profundas</span></code></strong>: Además de la red <code class="docutils literal notranslate"><span class="pre">RNN</span> <span class="pre">básica</span> <span class="pre">que</span> <span class="pre">comprende</span> <span class="pre">una</span> <span class="pre">sola</span> <span class="pre">capa</span> <span class="pre">de</span> <span class="pre">estados</span></code>, se han propuesto <code class="docutils literal notranslate"><span class="pre">extensiones</span> <span class="pre">que</span> <span class="pre">implican</span> <span class="pre">múltiples</span> <span class="pre">capas</span> <span class="pre">de</span> <span class="pre">estados</span></code>, una encima de otra (ver <span id="id34">[<a class="reference internal" href="biblio.html#id37" title="Razvan Pascanu, Caglar Gulcehre, Kyunghyun Cho, and Yoshua Bengio. How to construct deep recurrent neural networks. arXiv preprint arXiv:1312.6026, 2013.">Pascanu <em>et al.</em>, 2013</a>]</span>).</p></li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">RNN</span> <span class="pre">bidireccionales</span></code></strong>: Como su nombre indica, en las <code class="docutils literal notranslate"><span class="pre">RNN</span> <span class="pre">bidireccionales</span> <span class="pre">hay</span> <span class="pre">dos</span> <span class="pre">variables</span> <span class="pre">de</span> <span class="pre">estado</span></code>, es decir, una denotada como <span class="math notranslate nohighlight">\(\overset{\rightarrow}{\boldsymbol{h}}\)</span><code class="docutils literal notranslate"><span class="pre">,</span> <span class="pre">que</span> <span class="pre">se</span> <span class="pre">propaga</span> <span class="pre">hacia</span> <span class="pre">adelante</span></code>, y otra, <span class="math notranslate nohighlight">\(\overset{\leftarrow}{\boldsymbol{h}}\)</span><code class="docutils literal notranslate"><span class="pre">,</span> <span class="pre">que</span> <span class="pre">se</span> <span class="pre">propaga</span> <span class="pre">hacia</span> <span class="pre">atrás</span></code>. De este modo, <code class="docutils literal notranslate"><span class="pre">las</span> <span class="pre">salidas</span> <span class="pre">dependen</span> <span class="pre">tanto</span> <span class="pre">del</span> <span class="pre">pasado</span> <span class="pre">como</span> <span class="pre">del</span> <span class="pre">futuro</span></code> (ver <span id="id35">[<a class="reference internal" href="biblio.html#id38" title="Alex Graves, Abdel-rahman Mohamed, and Geoffrey Hinton. Speech recognition with deep recurrent neural networks. In 2013 IEEE international conference on acoustics, speech and signal processing, 6645–6649. Ieee, 2013.">Graves <em>et al.</em>, 2013</a>]</span>).</p></li>
</ul>
</section>
</div></section>
</section>
<section id="red-de-memoria-a-largo-plazo-lstm">
<h2>Red de memoria a largo plazo (LSTM)<a class="headerlink" href="#red-de-memoria-a-largo-plazo-lstm" title="Link to this heading">#</a></h2>
<div class="proof observation admonition" id="observation_ann10">
<p class="admonition-title"><span class="caption-number">Observation 18 </span></p>
<section class="observation-content" id="proof-content">
<ul class="simple">
<li><p>La <code class="docutils literal notranslate"><span class="pre">idea</span> <span class="pre">clave</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">red</span> <span class="pre">LSTM</span></code>, propuesta en el artículo seminal <span id="id36">[<a class="reference internal" href="biblio.html#id39" title="Sepp Hochreiter and Jürgen Schmidhuber. Long short-term memory. Neural computation, 9(8):1735–1780, 1997.">Hochreiter and Schmidhuber, 1997</a>]</span>, es el llamado <code class="docutils literal notranslate"><span class="pre">estado</span> <span class="pre">de</span> <span class="pre">celda</span></code>, que ayuda a <code class="docutils literal notranslate"><span class="pre">superar</span> <span class="pre">los</span> <span class="pre">problemas</span> <span class="pre">asociados</span> <span class="pre">con</span> <span class="pre">los</span> <span class="pre">fenómenos</span> <span class="pre">de</span> <span class="pre">desvanecimiento/explosión</span></code> que son causados por las <code class="docutils literal notranslate"><span class="pre">dependencias</span> <span class="pre">largo</span> <span class="pre">plazo</span></code> dentro de la red. Las <code class="docutils literal notranslate"><span class="pre">redes</span> <span class="pre">LSTM</span></code> tienen la capacidad incorporada de <code class="docutils literal notranslate"><span class="pre">controlar</span> <span class="pre">el</span> <span class="pre">flujo</span> <span class="pre">de</span> <span class="pre">información</span> <span class="pre">que</span> <span class="pre">entra</span> <span class="pre">y</span> <span class="pre">sale</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">memoria</span> <span class="pre">del</span> <span class="pre">sistema</span> <span class="pre">mediante</span> <span class="pre">algoritmos</span> <span class="pre">no</span> <span class="pre">lineales</span></code>. Estas puertas se implementan <code class="docutils literal notranslate"><span class="pre">mediante</span> <span class="pre">la</span> <span class="pre">no</span> <span class="pre">linealidad</span> <span class="pre">sigmoidea</span> <span class="pre">y</span> <span class="pre">un</span> <span class="pre">multiplicador</span></code>. Desde un punto de vista algorítmico, las puertas equivalen a <code class="docutils literal notranslate"><span class="pre">aplicar</span> <span class="pre">una</span> <span class="pre">ponderación</span> <span class="pre">al</span> <span class="pre">flujo</span> <span class="pre">de</span> <span class="pre">información</span> <span class="pre">correspondiente</span></code>. Los <code class="docutils literal notranslate"><span class="pre">pesos</span></code> se sitúan en el intervalo <span class="math notranslate nohighlight">\([0,1]\)</span> y <code class="docutils literal notranslate"><span class="pre">dependen</span> <span class="pre">de</span> <span class="pre">los</span> <span class="pre">valores</span> <span class="pre">de</span> <span class="pre">las</span> <span class="pre">variables</span> <span class="pre">implicadas</span> <span class="pre">que</span> <span class="pre">activan</span> <span class="pre">la</span> <span class="pre">no</span> <span class="pre">linealidad</span> <span class="pre">sigmoidea</span></code>.</p></li>
</ul>
</section>
</div><figure class="align-center" id="lstm-arch-rnn-numref">
<a class="reference internal image-reference" href="_images/lstm_arch_rnn.png"><img alt="_images/lstm_arch_rnn.png" src="_images/lstm_arch_rnn.png" style="width: 664.8000000000001px; height: 332.0px;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 64 </span><span class="caption-text">Arquitectura de unidad LSTM. Fuente <span id="id37">[<a class="reference internal" href="biblio.html#id17" title="S. Theodoridis. Machine Learning: A Bayesian and Optimization Perspective. Elsevier Science, 2020. ISBN 9780128188040. URL: https://books.google.com.co/books?id=l-nEDwAAQBAJ.">Theodoridis, 2020</a>]</span>.</span><a class="headerlink" href="#lstm-arch-rnn-numref" title="Link to this image">#</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p>En otras palabras, <code class="docutils literal notranslate"><span class="pre">la</span> <span class="pre">ponderación</span> <span class="pre">(control)</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">información</span></code> tiene lugar en el contexto. Según este razonamiento, <code class="docutils literal notranslate"><span class="pre">la</span> <span class="pre">red</span> <span class="pre">tiene</span> <span class="pre">la</span> <span class="pre">agilidad</span> <span class="pre">de</span> <span class="pre">olvidar</span> <span class="pre">la</span> <span class="pre">información</span> <span class="pre">que</span> <span class="pre">ya</span> <span class="pre">ha</span> <span class="pre">sido</span> <span class="pre">utilizada</span> <span class="pre">y</span> <span class="pre">ya</span> <span class="pre">no</span> <span class="pre">es</span> <span class="pre">necesaria</span></code>. La <code class="docutils literal notranslate"><span class="pre">célula/unidad</span> <span class="pre">LSTM</span> <span class="pre">básica</span></code> se
se muestra en la <a class="reference internal" href="#lstm-arch-rnn-numref"><span class="std std-numref">Fig. 64</span></a>. Se construye en torno a <code class="docutils literal notranslate"><span class="pre">dos</span> <span class="pre">conjuntos</span> <span class="pre">de</span> <span class="pre">variables,</span> <span class="pre">apiladas</span> <span class="pre">en</span> <span class="pre">el</span> <span class="pre">vector</span></code> <span class="math notranslate nohighlight">\(\boldsymbol{s}\)</span>, que se conoce como el <code class="docutils literal notranslate"><span class="pre">estado</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">célula</span> <span class="pre">o</span> <span class="pre">unidad</span></code>, y el vector <span class="math notranslate nohighlight">\(\boldsymbol{h}\)</span>, que se conoce como el <code class="docutils literal notranslate"><span class="pre">vector</span> <span class="pre">de</span> <span class="pre">variables</span> <span class="pre">ocultas</span></code>. Una <code class="docutils literal notranslate"><span class="pre">red</span> <span class="pre">LSTM</span></code> se construye a partir de la <code class="docutils literal notranslate"><span class="pre">concatenación</span> <span class="pre">sucesiva</span> <span class="pre">de</span> <span class="pre">esta</span> <span class="pre">unidad</span> <span class="pre">básica</span></code>. La unidad correspondiente al tiempo <span class="math notranslate nohighlight">\(n\)</span>, además del vector de entrada, <span class="math notranslate nohighlight">\(\boldsymbol{x}_{n}\)</span>, recibe <span class="math notranslate nohighlight">\(\boldsymbol{s}_{n-1}\)</span> y <span class="math notranslate nohighlight">\(\boldsymbol{h}_{n-1}\)</span> de la etapa anterior y pasa <span class="math notranslate nohighlight">\(\boldsymbol{s}_{n}\)</span> y <span class="math notranslate nohighlight">\(\boldsymbol{h}_{n}\)</span> a la siguiente.</p></li>
</ul>
<ul>
<li><p>A continuación se resumen las <code class="docutils literal notranslate"><span class="pre">ecuaciones</span> <span class="pre">de</span> <span class="pre">actualización</span> <span class="pre">asociadas</span></code>,</p>
<div class="math notranslate nohighlight">
\[\begin{split}
    \begin{align*}
    \boldsymbol{f}&amp;=\sigma(U^{f}\boldsymbol{x}_{n}+W^{f}\boldsymbol{h}_{n-1}+\boldsymbol{b}^{f}),\\
    \boldsymbol{i}&amp;=\sigma(U^{i}\boldsymbol{x}_{n}+W^{i}\boldsymbol{h}_{n-1}+\boldsymbol{b}^{i}),\\
    \tilde{\boldsymbol{s}}&amp;=\tanh(U^{s}\boldsymbol{x}_{n}+W^{s}\boldsymbol{h}_{n-1}+\boldsymbol{b}^{s}),\\
    \boldsymbol{o}&amp;=\sigma(U^{o}\boldsymbol{x}_{n}+W^{o}\boldsymbol{h}_{n-1}+\boldsymbol{b}^{o}),\\
    \boldsymbol{s}_{n}&amp;=\boldsymbol{s}_{n-1}\circ f+\boldsymbol{i}\circ\tilde{\boldsymbol{s}},\\
    \boldsymbol{h}_{n}&amp;=\boldsymbol{o}\circ\tanh(\boldsymbol{s}_{n}),
    \end{align*}
    \end{split}\]</div>
<p>donde <span class="math notranslate nohighlight">\(\circ\)</span> denota el <code class="docutils literal notranslate"><span class="pre">producto</span> <span class="pre">elemento</span> <span class="pre">a</span> <span class="pre">elemento</span> <span class="pre">entre</span> <span class="pre">vectores</span> <span class="pre">o</span> <span class="pre">matrices</span></code> (producto de <code class="docutils literal notranslate"><span class="pre">Hadamard</span></code>), es decir, <span class="math notranslate nohighlight">\((s\circ f)_{i} = s_{i}f_{i}\)</span>, y <span class="math notranslate nohighlight">\(\sigma\)</span> denota la <code class="docutils literal notranslate"><span class="pre">función</span> <span class="pre">sigmoidea</span> <span class="pre">logística</span></code>.</p>
</li>
</ul>
<div class="proof observation admonition" id="observation_ann11">
<p class="admonition-title"><span class="caption-number">Observation 19 </span></p>
<section class="observation-content" id="proof-content">
<ul class="simple">
<li><p>Nótese que el <code class="docutils literal notranslate"><span class="pre">estado</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">célula</span></code>, <span class="math notranslate nohighlight">\(\boldsymbol{s}\)</span>, <code class="docutils literal notranslate"><span class="pre">pasa</span> <span class="pre">información</span> <span class="pre">directa</span> <span class="pre">del</span> <span class="pre">instante</span> <span class="pre">anterior</span> <span class="pre">al</span> <span class="pre">siguiente</span></code>. Esta información es <code class="docutils literal notranslate"><span class="pre">controlada</span> <span class="pre">primero</span> <span class="pre">por</span> <span class="pre">la</span> <span class="pre">primera</span> <span class="pre">puerta</span></code>, según los elementos en <span class="math notranslate nohighlight">\(f\)</span>, que toman valores en el rango <span class="math notranslate nohighlight">\([0, 1]\)</span>, <code class="docutils literal notranslate"><span class="pre">dependiendo</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">entrada</span> <span class="pre">actual</span> <span class="pre">y</span> <span class="pre">de</span> <span class="pre">las</span> <span class="pre">variables</span> <span class="pre">ocultas</span> <span class="pre">que</span> <span class="pre">se</span> <span class="pre">reciben</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">etapa</span> <span class="pre">anterior</span></code>. Esto es lo que decíamos antes, es decir, que <code class="docutils literal notranslate"><span class="pre">la</span> <span class="pre">ponderación</span> <span class="pre">se</span> <span class="pre">ajusta</span> <span class="pre">en</span> <span class="pre">&quot;contexto&quot;</span></code>. A continuación, <code class="docutils literal notranslate"><span class="pre">se</span> <span class="pre">añade</span> <span class="pre">nueva</span> <span class="pre">información</span></code>, es decir, <span class="math notranslate nohighlight">\(\tilde{\boldsymbol{s}}\)</span>, a <span class="math notranslate nohighlight">\(\boldsymbol{s}_{n-1}\)</span>, que también está <code class="docutils literal notranslate"><span class="pre">controlada</span> <span class="pre">por</span> <span class="pre">la</span> <span class="pre">segunda</span> <span class="pre">red</span> <span class="pre">de</span> <span class="pre">puertas</span> <span class="pre">sigmoidales</span></code> (es decir, <span class="math notranslate nohighlight">\(\boldsymbol{i}\)</span>). Así se garantiza que la <code class="docutils literal notranslate"><span class="pre">información</span> <span class="pre">del</span> <span class="pre">pasado</span> <span class="pre">se</span> <span class="pre">transmita</span> <span class="pre">al</span> <span class="pre">futuro</span> <span class="pre">de</span> <span class="pre">forma</span> <span class="pre">directa,</span> <span class="pre">lo</span> <span class="pre">cual,</span> <span class="pre">ayuda</span> <span class="pre">a</span> <span class="pre">la</span> <span class="pre">red</span> <span class="pre">a</span> <span class="pre">memorizar</span> <span class="pre">información.</span></code>.</p></li>
<li><p>Resulta que este tipo de memoria <code class="docutils literal notranslate"><span class="pre">explota</span> <span class="pre">mejor</span> <span class="pre">las</span> <span class="pre">dependencias</span> <span class="pre">de</span> <span class="pre">largo</span> <span class="pre">alcance</span> <span class="pre">en</span> <span class="pre">los</span> <span class="pre">datos</span></code>, en comparación con la estructura <code class="docutils literal notranslate"><span class="pre">RNN</span> <span class="pre">básica</span></code>. El vector de variables ocultas <span class="math notranslate nohighlight">\(\boldsymbol{h}\)</span> <code class="docutils literal notranslate"><span class="pre">está</span> <span class="pre">controlado</span> <span class="pre">tanto</span> <span class="pre">por</span> <span class="pre">el</span> <span class="pre">estado</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">célula</span> <span class="pre">como</span> <span class="pre">por</span> <span class="pre">los</span> <span class="pre">valores</span> <span class="pre">actuales</span> <span class="pre">de</span> <span class="pre">las</span> <span class="pre">variables</span> <span class="pre">de</span> <span class="pre">entrada</span> <span class="pre">y</span> <span class="pre">de</span> <span class="pre">estados</span> <span class="pre">anteriores</span></code>. Todas las <code class="docutils literal notranslate"><span class="pre">matrices</span> <span class="pre">y</span> <span class="pre">vectores</span> <span class="pre">implicados</span> <span class="pre">se</span> <span class="pre">aprenden</span> <span class="pre">en</span> <span class="pre">la</span> <span class="pre">fase</span> <span class="pre">de</span> <span class="pre">entrenamiento</span></code>. Nótese que hay dos líneas asociadas a <span class="math notranslate nohighlight">\(\boldsymbol{h}_{n}\)</span>. La de <code class="docutils literal notranslate"><span class="pre">la</span> <span class="pre">derecha</span> <span class="pre">conduce</span> <span class="pre">a</span> <span class="pre">la</span> <span class="pre">siguiente</span> <span class="pre">etapa</span></code> y la de <code class="docutils literal notranslate"><span class="pre">la</span> <span class="pre">parte</span> <span class="pre">superior</span> <span class="pre">se</span> <span class="pre">utiliza</span> <span class="pre">para</span> <span class="pre">proporcionar</span> <span class="pre">la</span> <span class="pre">salida</span></code>, <span class="math notranslate nohighlight">\(\hat{\boldsymbol{y}}_{n}\)</span>, en el tiempo <span class="math notranslate nohighlight">\(n\)</span>, a <code class="docutils literal notranslate"><span class="pre">través</span> <span class="pre">de,</span> <span class="pre">digamos,</span> <span class="pre">la</span> <span class="pre">no</span> <span class="pre">linealidad</span> <span class="pre">softmax</span></code>, como en las RNN estándar en Eq. <a class="reference internal" href="#equation-rnn-system-eq">(64)</a>.</p></li>
</ul>
</section>
</div><div class="admonition-variantes-y-aplicaciones admonition">
<p class="admonition-title">Variantes y Aplicaciones</p>
<ul class="simple">
<li><p>Además de la estructura LSTM ya comentada, <code class="docutils literal notranslate"><span class="pre">se</span> <span class="pre">han</span> <span class="pre">propuesto</span> <span class="pre">diversas</span> <span class="pre">variantes</span></code>. Un extenso <code class="docutils literal notranslate"><span class="pre">estudio</span> <span class="pre">comparativo</span> <span class="pre">entre</span> <span class="pre">diferentes</span> <span class="pre">arquitecturas</span> <span class="pre">LSTM</span> <span class="pre">y</span> <span class="pre">RNN</span></code> se puede encontrar en <span id="id38">[<a class="reference internal" href="biblio.html#id40" title="Klaus Greff, Rupesh K Srivastava, Jan Koutník, Bas R Steunebrink, and Jürgen Schmidhuber. Lstm: a search space odyssey. IEEE transactions on neural networks and learning systems, 28(10):2222–2232, 2016.">Greff <em>et al.</em>, 2016</a>, <a class="reference internal" href="biblio.html#id41" title="Rafal Jozefowicz, Wojciech Zaremba, and Ilya Sutskever. An empirical exploration of recurrent network architectures. In International conference on machine learning, 2342–2350. PMLR, 2015.">Jozefowicz <em>et al.</em>, 2015</a>]</span>. Las <code class="docutils literal notranslate"><span class="pre">RNNs</span> <span class="pre">y</span> <span class="pre">las</span> <span class="pre">LSTMs</span></code> se han utilizado con éxito en una <code class="docutils literal notranslate"><span class="pre">amplia</span> <span class="pre">gama</span> <span class="pre">de</span> <span class="pre">aplicaciones</span></code>, tales como:</p>
<ul>
<li><p>el <code class="docutils literal notranslate"><span class="pre">modelado</span> <span class="pre">del</span> <span class="pre">lenguaje</span></code> <span id="id39">[<a class="reference internal" href="biblio.html#id42" title="Ilya Sutskever, James Martens, and Geoffrey E Hinton. Generating text with recurrent neural networks. In Proceedings of the 28th international conference on machine learning (ICML-11), 1017–1024. 2011.">Sutskever <em>et al.</em>, 2011</a>]</span>,</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">traducción</span> <span class="pre">de</span> <span class="pre">máquinas</span></code> <span id="id40">[<a class="reference internal" href="biblio.html#id43" title="Shujie Liu, Nan Yang, Mu Li, and Ming Zhou. A recursive recurrent neural network for statistical machine translation. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), 1491–1500. 2014.">Liu <em>et al.</em>, 2014</a>]</span>,</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">reconocimiento</span> <span class="pre">del</span> <span class="pre">habla</span></code> <span id="id41">[<a class="reference internal" href="biblio.html#id44" title="Alex Graves and Navdeep Jaitly. Towards end-to-end speech recognition with recurrent neural networks. In International conference on machine learning, 1764–1772. PMLR, 2014.">Graves and Jaitly, 2014</a>]</span>,</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">visión</span> <span class="pre">artificial</span></code> para la generación de descriptores de imágenes <span id="id42">[<a class="reference internal" href="biblio.html#id45" title="Andrej Karpathy and Li Fei-Fei. Deep visual-semantic alignments for generating image descriptions. In Proceedings of the IEEE conference on computer vision and pattern recognition, 3128–3137. 2015.">Karpathy and Fei-Fei, 2015</a>]</span>,</p></li>
<li><p>análisis de datos de fMRI para comprender la <code class="docutils literal notranslate"><span class="pre">dinámica</span> <span class="pre">temporal</span> <span class="pre">de</span> <span class="pre">las</span> <span class="pre">redes</span> <span class="pre">cerebrales</span></code> asociadas <span id="id43">[<a class="reference internal" href="biblio.html#id46" title="Youngjoo Seo, Manuel Morante, Yannis Kopsinis, and Sergios Theodoridis. Unsupervised pre-training of the brain connectivity dynamic using residual d-net. In Neural Information Processing: 26th International Conference, ICONIP 2019, Sydney, NSW, Australia, December 12–15, 2019, Proceedings, Part III 26, 608–620. Springer, 2019.">Seo <em>et al.</em>, 2019</a>]</span>.</p></li>
<li><p>pronostico de <code class="docutils literal notranslate"><span class="pre">volatilidad</span> <span class="pre">de</span> <span class="pre">Bitcoin</span></code> <span id="id44">[<a class="reference internal" href="biblio.html#id47" title="Tiago E Pratas, Filipe R Ramos, and Lihki Rubio. Forecasting bitcoin volatility: exploring the potential of deep learning. Eurasian Economic Review, pages 1–21, 2023.">Pratas <em>et al.</em>, 2023</a>]</span></p></li>
</ul>
</li>
<li><p>Por ejemplo, en el <code class="docutils literal notranslate"><span class="pre">procesamiento</span> <span class="pre">del</span> <span class="pre">lenguaje</span></code> la <code class="docutils literal notranslate"><span class="pre">entrada</span> <span class="pre">suele</span> <span class="pre">ser</span> <span class="pre">una</span> <span class="pre">secuencia</span> <span class="pre">de</span> <span class="pre">palabras,</span> <span class="pre">que</span> <span class="pre">se</span> <span class="pre">codifican</span> <span class="pre">como</span> <span class="pre">números</span></code> (son punteros al diccionario disponible). La <code class="docutils literal notranslate"><span class="pre">salida</span> <span class="pre">es</span> <span class="pre">la</span> <span class="pre">secuencia</span> <span class="pre">de</span> <span class="pre">palabras</span> <span class="pre">que</span> <span class="pre">hay</span> <span class="pre">que</span> <span class="pre">predecir</span></code>. Durante el entrenamiento, se establece <span class="math notranslate nohighlight">\(\boldsymbol{y}_{n} = \boldsymbol{x}_{n+1}\)</span>. Es decir, <code class="docutils literal notranslate"><span class="pre">la</span> <span class="pre">red</span> <span class="pre">se</span> <span class="pre">entrena</span> <span class="pre">como</span> <span class="pre">un</span> <span class="pre">predictor</span> <span class="pre">no</span> <span class="pre">lineal</span></code>.</p></li>
</ul>
</div>
</section>
<section id="atencion-y-memoria">
<h2>Atención y Memoria<a class="headerlink" href="#atencion-y-memoria" title="Link to this heading">#</a></h2>
<div class="admonition-introduccion admonition">
<p class="admonition-title">Introducción</p>
<ul class="simple">
<li><p>El uso histórico de <code class="docutils literal notranslate"><span class="pre">esquemas</span> <span class="pre">de</span> <span class="pre">atención</span> <span class="pre">en</span> <span class="pre">redes</span> <span class="pre">neuronales</span></code> se inspira en el <code class="docutils literal notranslate"><span class="pre">mecanismo</span> <span class="pre">de</span> <span class="pre">atención</span> <span class="pre">humana</span></code>. En la visión humana, <code class="docutils literal notranslate"><span class="pre">nos</span> <span class="pre">centramos</span> <span class="pre">en</span> <span class="pre">información</span> <span class="pre">contextual</span> <span class="pre">importante</span></code> cuando observamos escenas. En el aprendizaje automático, los <code class="docutils literal notranslate"><span class="pre">modelos</span> <span class="pre">de</span> <span class="pre">atención</span> <span class="pre">implementan</span> <span class="pre">este</span> <span class="pre">concepto</span> <span class="pre">asignando</span> <span class="pre">pesos</span> <span class="pre">a</span> <span class="pre">las</span> <span class="pre">variables</span> <span class="pre">que</span> <span class="pre">influyen</span> <span class="pre">en</span> <span class="pre">la</span> <span class="pre">salida</span></code>. Por ejemplo, en una <code class="docutils literal notranslate"><span class="pre">RNN</span></code>, la salida <span class="math notranslate nohighlight">\(\hat{\boldsymbol{y}}_{n}\)</span> depende del vector de estado <span class="math notranslate nohighlight">\(\boldsymbol{h}_{n}\)</span>, pero <code class="docutils literal notranslate"><span class="pre">no</span> <span class="pre">siempre</span> <span class="pre">es</span> <span class="pre">la</span> <span class="pre">información</span> <span class="pre">más</span> <span class="pre">importante</span> <span class="pre">para</span> <span class="pre">tareas</span></code> como la traducción de idiomas (aunque el estado codifica la memoria hasta el tiempo más reciente, <span class="math notranslate nohighlight">\(n\)</span>.).</p></li>
</ul>
</div>
<div class="proof observation admonition" id="observation_ann12">
<p class="admonition-title"><span class="caption-number">Observation 20 </span> (Caso típico)</p>
<section class="observation-content" id="proof-content">
<ul class="simple">
<li><p>En la <code class="docutils literal notranslate"><span class="pre">traducción</span> <span class="pre">del</span> <span class="pre">japonés</span> <span class="pre">al</span> <span class="pre">inglés,</span> <span class="pre">la</span> <span class="pre">última</span> <span class="pre">palabra</span> <span class="pre">de</span> <span class="pre">una</span> <span class="pre">frase</span> <span class="pre">japonesa</span> <span class="pre">puede</span> <span class="pre">influir</span> <span class="pre">mucho</span> <span class="pre">en</span> <span class="pre">la</span> <span class="pre">primera</span> <span class="pre">palabra</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">traducción</span> <span class="pre">inglesa</span></code>. Del mismo modo, en la <code class="docutils literal notranslate"><span class="pre">toma</span> <span class="pre">de</span> <span class="pre">decisiones,</span> <span class="pre">nuestras</span> <span class="pre">acciones</span> <span class="pre">dependen</span> <span class="pre">de</span> <span class="pre">las</span> <span class="pre">experiencias</span> <span class="pre">pasadas</span> <span class="pre">acumuladas</span></code>, y algunas <code class="docutils literal notranslate"><span class="pre">experiencias</span> <span class="pre">pasadas</span> <span class="pre">específicas</span> <span class="pre">ejercen</span> <span class="pre">más</span> <span class="pre">influencia</span> <span class="pre">que</span> <span class="pre">las</span> <span class="pre">recientes</span></code>.</p></li>
</ul>
</section>
</div><ul class="simple">
<li><p>Para solucionar este problema, <code class="docutils literal notranslate"><span class="pre">los</span> <span class="pre">mecanismos</span> <span class="pre">de</span> <span class="pre">atención</span> <span class="pre">asignan</span> <span class="pre">pesos</span> <span class="pre">a</span> <span class="pre">los</span> <span class="pre">vectores</span> <span class="pre">de</span> <span class="pre">estado</span> <span class="pre">anteriores</span></code>, lo que permite que <code class="docutils literal notranslate"><span class="pre">la</span> <span class="pre">salida</span> <span class="pre">dependa</span> <span class="pre">de</span> <span class="pre">una</span> <span class="pre">combinación</span> <span class="pre">ponderada</span> <span class="pre">de</span> <span class="pre">información</span> <span class="pre">previa</span></code>. Estas ponderaciones se aprenden durante el entrenamiento, lo que <code class="docutils literal notranslate"><span class="pre">permite</span> <span class="pre">al</span> <span class="pre">sistema</span> <span class="pre">dar</span> <span class="pre">prioridad</span> <span class="pre">a</span> <span class="pre">detalles</span> <span class="pre">contextuales</span> <span class="pre">significativos</span></code> a la hora de tomar decisiones o generar resultados.</p></li>
</ul>
<ul>
<li><p>Por ejemplo, el <code class="docutils literal notranslate"><span class="pre">vector</span> <span class="pre">de</span> <span class="pre">salida</span></code> puede modificarse para que <code class="docutils literal notranslate"><span class="pre">dependa</span> <span class="pre">de</span> <span class="pre">todos</span> <span class="pre">los</span> <span class="pre">vectores</span> <span class="pre">de</span> <span class="pre">estado</span> <span class="pre">calculados</span> <span class="pre">anteriormente</span></code></p>
<div class="math notranslate nohighlight">
\[
    \hat{\boldsymbol{y}}_{n}=f\left(\sum_{i=1}^{n}\alpha_{ni}\boldsymbol{h}_{i}+\boldsymbol{c}\right),
    \]</div>
<p>donde <span class="math notranslate nohighlight">\(\alpha_{ni}\)</span> son los <code class="docutils literal notranslate"><span class="pre">correspondientes</span> <span class="pre">pesos</span> <span class="pre">en</span> <span class="pre">el</span> <span class="pre">tiempo</span></code> <span class="math notranslate nohighlight">\(n\)</span>.</p>
</li>
<li><p>La idea anterior de <code class="docutils literal notranslate"><span class="pre">combinar</span> <span class="pre">todos</span> <span class="pre">los</span> <span class="pre">vectores</span> <span class="pre">de</span> <span class="pre">estado</span></code> ha sido empleada, en una formulación algo diferente, en el <code class="docutils literal notranslate"><span class="pre">sistema</span> <span class="pre">de</span> <span class="pre">traducción</span> <span class="pre">automática</span></code> (ver <span id="id45">[<a class="reference internal" href="biblio.html#id48" title="Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. Neural machine translation by jointly learning to align and translate. arXiv preprint arXiv:1409.0473, 2014.">Bahdanau <em>et al.</em>, 2014</a>]</span>)</p></li>
</ul>
<figure class="align-center" id="attention-weights-grayscale-numref">
<a class="reference internal image-reference" href="_images/attention_weights_grayscale.png"><img alt="_images/attention_weights_grayscale.png" src="_images/attention_weights_grayscale.png" style="width: 381.6px; height: 434.40000000000003px;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 65 </span><span class="caption-text">Valores de los pesos de atención en escala de grises. <a class="reference internal" href="#attention_example_grayscale">Example 4</a></span><a class="headerlink" href="#attention-weights-grayscale-numref" title="Link to this image">#</a></p>
</figcaption>
</figure>
<div class="proof example admonition" id="attention_example_grayscale">
<p class="admonition-title"><span class="caption-number">Example 4 </span></p>
<section class="example-content" id="proof-content">
<p>La <a class="reference internal" href="#attention-weights-grayscale-numref"><span class="std std-numref">Fig. 65</span></a> demuestra el razonamiento que subyace a la <code class="docutils literal notranslate"><span class="pre">utilización</span> <span class="pre">de</span> <span class="pre">un</span> <span class="pre">mecanismo</span> <span class="pre">de</span> <span class="pre">ponderación</span></code>. La <code class="docutils literal notranslate"><span class="pre">entrada</span></code> está representada por las <code class="docutils literal notranslate"><span class="pre">palabras</span> <span class="pre">en</span> <span class="pre">francés</span></code>, mientras que las secuencias de <code class="docutils literal notranslate"><span class="pre">salida</span></code> correspondientes están representadas por las <code class="docutils literal notranslate"><span class="pre">palabras</span> <span class="pre">en</span> <span class="pre">inglés</span></code>. <code class="docutils literal notranslate"><span class="pre">La</span> <span class="pre">visualización</span> <span class="pre">representa</span> <span class="pre">los</span> <span class="pre">pesos</span> <span class="pre">de</span> <span class="pre">atención</span> <span class="pre">como</span> <span class="pre">píxeles</span></code>, donde los <code class="docutils literal notranslate"><span class="pre">pesos</span> <span class="pre">más</span> <span class="pre">altos</span> <span class="pre">se</span> <span class="pre">representan</span> <span class="pre">como</span> <span class="pre">píxeles</span> <span class="pre">más</span> <span class="pre">blancos</span></code>. En particular, el <code class="docutils literal notranslate"><span class="pre">término</span> <span class="pre">&quot;produce&quot;</span> <span class="pre">en</span> <span class="pre">la</span> <span class="pre">salida</span></code> es consecuencia de <code class="docutils literal notranslate"><span class="pre">asignar</span> <span class="pre">peso</span> <span class="pre">a</span> <span class="pre">la</span> <span class="pre">información</span> <span class="pre">de</span> <span class="pre">tres</span> <span class="pre">puntos</span> <span class="pre">temporales</span> <span class="pre">consecutivos</span></code>, vinculados con las palabras <code class="docutils literal notranslate"><span class="pre">&quot;peut</span> <span class="pre">plus</span> <span class="pre">produire&quot;</span></code>, mientras que el término <code class="docutils literal notranslate"><span class="pre">&quot;destruction&quot;</span></code> está <code class="docutils literal notranslate"><span class="pre">asociado</span> <span class="pre">con</span> <span class="pre">dos</span> <span class="pre">palabras</span></code>, a saber, <code class="docutils literal notranslate"><span class="pre">&quot;la</span> <span class="pre">destruction&quot;</span></code>.</p>
</section>
</div><div class="proof observation admonition" id="observation_ann13">
<p class="admonition-title"><span class="caption-number">Observation 21 </span></p>
<section class="observation-content" id="proof-content">
<ul class="simple">
<li><p>Una ventaja notable de <code class="docutils literal notranslate"><span class="pre">incorporar</span> <span class="pre">un</span> <span class="pre">mecanismo</span> <span class="pre">de</span> <span class="pre">atención</span></code> al modelo es la <code class="docutils literal notranslate"><span class="pre">transparencia</span> <span class="pre">que</span> <span class="pre">aporta</span> <span class="pre">a</span> <span class="pre">las</span> <span class="pre">acciones</span> <span class="pre">del</span> <span class="pre">modelo</span></code> y a la formación de la información de salida. Esto resulta especialmente valioso cuando la <code class="docutils literal notranslate"><span class="pre">interpretabilidad</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">red</span> <span class="pre">es</span> <span class="pre">una</span> <span class="pre">preocupación</span></code>, ya que permite comprender el <code class="docutils literal notranslate"><span class="pre">&quot;por</span> <span class="pre">qué&quot;</span> <span class="pre">y</span> <span class="pre">el</span> <span class="pre">&quot;cómo&quot;</span> <span class="pre">del</span> <span class="pre">proceso</span> <span class="pre">de</span> <span class="pre">toma</span> <span class="pre">de</span> <span class="pre">decisiones</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">red</span></code>.</p></li>
</ul>
</section>
</div></section>
<section id="entrenamiento-adversario">
<h2>Entrenamiento adversario<a class="headerlink" href="#entrenamiento-adversario" title="Link to this heading">#</a></h2>
<div class="admonition-introduccion admonition">
<p class="admonition-title">Introducción</p>
<ul class="simple">
<li><p>Las <code class="docutils literal notranslate"><span class="pre">redes</span> <span class="pre">neuronales</span> <span class="pre">profundas</span></code> lideran en la obtención de un <code class="docutils literal notranslate"><span class="pre">rendimiento</span> <span class="pre">y</span> <span class="pre">precisión</span> <span class="pre">sobresalientes</span></code>, frecuentemente comparables e incluso en <code class="docutils literal notranslate"><span class="pre">algunos</span> <span class="pre">casos</span> <span class="pre">superiores</span> <span class="pre">a</span> <span class="pre">las</span> <span class="pre">habilidades</span> <span class="pre">humanas</span></code>. Sin embargo, persiste el <code class="docutils literal notranslate"><span class="pre">desafío</span> <span class="pre">de</span> <span class="pre">afirmar</span> <span class="pre">que</span> <span class="pre">estos</span> <span class="pre">modelos</span> <span class="pre">realmente</span> <span class="pre">&quot;comprenden&quot;</span> <span class="pre">las</span> <span class="pre">tareas</span> <span class="pre">que</span> <span class="pre">han</span> <span class="pre">&quot;aprendido&quot;</span> <span class="pre">a</span> <span class="pre">realizar</span></code>, a pesar de su habilidad para predecir etiquetas precisas en tareas de clasificación con una confianza considerablemente alta.</p></li>
<li><p>Es <code class="docutils literal notranslate"><span class="pre">viable</span> <span class="pre">generar</span> <span class="pre">ejemplos</span> <span class="pre">adversos</span> <span class="pre">que</span> <span class="pre">sistemáticamente</span> <span class="pre">engañan</span> <span class="pre">a</span> <span class="pre">los</span> <span class="pre">modelos</span> <span class="pre">de</span> <span class="pre">aprendizaje</span> <span class="pre">automático</span></code>. Aquí, <code class="docutils literal notranslate"><span class="pre">&quot;adversario&quot;</span> <span class="pre">denota</span> <span class="pre">la</span> <span class="pre">introducción</span> <span class="pre">intencional</span> <span class="pre">de</span> <span class="pre">pequeñas</span> <span class="pre">perturbaciones</span> <span class="pre">en</span> <span class="pre">los</span> <span class="pre">patrones</span> <span class="pre">dentro</span> <span class="pre">del</span> <span class="pre">conjunto</span> <span class="pre">de</span> <span class="pre">datos</span> <span class="pre">de</span> <span class="pre">entrada</span></code>, lo que resulta en una <code class="docutils literal notranslate"><span class="pre">alta</span> <span class="pre">probabilidad</span> <span class="pre">de</span> <span class="pre">clasificación</span> <span class="pre">incorrecta</span></code>. Notablemente, estas sutiles perturbaciones de ruido son <code class="docutils literal notranslate"><span class="pre">apenas</span> <span class="pre">detectables</span> <span class="pre">para</span> <span class="pre">los</span> <span class="pre">sentidos</span> <span class="pre">humanos</span></code>, ya sea en forma de imágenes o música.</p></li>
</ul>
</div>
<ul class="simple">
<li><p>La <a class="reference internal" href="#wrong-image-classification-numref"><span class="std std-numref">Fig. 66</span></a> muestra una serie de <code class="docutils literal notranslate"><span class="pre">nueve</span> <span class="pre">imágenes</span></code>. Se ha entrenado una <code class="docutils literal notranslate"><span class="pre">red</span> <span class="pre">neuronal</span> <span class="pre">(AlexNet)</span></code> para <code class="docutils literal notranslate"><span class="pre">discernir</span> <span class="pre">los</span> <span class="pre">contenidos</span> <span class="pre">de</span> <span class="pre">las</span> <span class="pre">imágenes</span></code>. El trío <code class="docutils literal notranslate"><span class="pre">izquierdo</span> <span class="pre">de</span> <span class="pre">imágenes</span></code>, tomadas del respectivo conjunto de pruebas, fueron <code class="docutils literal notranslate"><span class="pre">identificadas</span> <span class="pre">con</span> <span class="pre">precisión</span></code>. Las imágenes en el <code class="docutils literal notranslate"><span class="pre">centro</span> <span class="pre">son</span> <span class="pre">versiones</span> <span class="pre">ruidosas</span></code> añadidas a las originales de la izquierda. Las composiciones <code class="docutils literal notranslate"><span class="pre">resultantes</span> <span class="pre">se</span> <span class="pre">presentan</span> <span class="pre">a</span> <span class="pre">la</span> <span class="pre">derecha</span></code>. Mientras los seres <code class="docutils literal notranslate"><span class="pre">humanos</span> <span class="pre">anticipan</span> <span class="pre">sin</span> <span class="pre">dificultad</span> <span class="pre">las</span> <span class="pre">etiquetas</span> <span class="pre">correctas</span></code>, <code class="docutils literal notranslate"><span class="pre">AlexNet</span> <span class="pre">catalogó</span> <span class="pre">de</span> <span class="pre">forma</span> <span class="pre">errónea</span> <span class="pre">las</span> <span class="pre">tres</span> <span class="pre">imágenes</span> <span class="pre">como</span> <span class="pre">&quot;avestruz,</span> <span class="pre">struthio</span> <span class="pre">camelus&quot;</span></code>.</p></li>
</ul>
<figure class="align-center" id="wrong-image-classification-numref">
<a class="reference internal image-reference" href="_images/wrong_image_classification.png"><img alt="_images/wrong_image_classification.png" src="_images/wrong_image_classification.png" style="width: 672.0px; height: 661.6px;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 66 </span><span class="caption-text">Imágenes de la <code class="docutils literal notranslate"><span class="pre">izquierda</span></code> se han <code class="docutils literal notranslate"><span class="pre">clasificado</span> <span class="pre">correctamente</span></code>. Todas las <code class="docutils literal notranslate"><span class="pre">imágenes</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">derecha</span></code> han sido <code class="docutils literal notranslate"><span class="pre">clasificadas</span> <span class="pre">como</span> <span class="pre">&quot;avestruz,</span> <span class="pre">Struthio</span> <span class="pre">camelus&quot;</span></code>. Fuente <span id="id46">[<a class="reference internal" href="biblio.html#id17" title="S. Theodoridis. Machine Learning: A Bayesian and Optimization Perspective. Elsevier Science, 2020. ISBN 9780128188040. URL: https://books.google.com.co/books?id=l-nEDwAAQBAJ.">Theodoridis, 2020</a>]</span>.</span><a class="headerlink" href="#wrong-image-classification-numref" title="Link to this image">#</a></p>
</figcaption>
</figure>
<ul>
<li><p>La causa de este <code class="docutils literal notranslate"><span class="pre">comportamiento</span> <span class="pre">aparentemente</span> <span class="pre">&quot;peculiar&quot;</span></code> parece estar vinculada a la <code class="docutils literal notranslate"><span class="pre">naturaleza</span> <span class="pre">altamente</span> <span class="pre">dimensional</span> <span class="pre">del</span> <span class="pre">espacio</span> <span class="pre">de</span> <span class="pre">entrada</span></code>. Por lo general, en un contexto de aprendizaje, se cumple el <code class="docutils literal notranslate"><span class="pre">supuesto</span> <span class="pre">de</span> <span class="pre">suavidad</span></code>.  Esto implica que <code class="docutils literal notranslate"><span class="pre">para</span> <span class="pre">un</span> <span class="pre">valor</span> <span class="pre">positivo</span> <span class="pre">suficientemente</span> <span class="pre">pequeño</span></code> <span class="math notranslate nohighlight">\(\epsilon\)</span> y un <code class="docutils literal notranslate"><span class="pre">patrón</span> <span class="pre">de</span> <span class="pre">entrada</span></code> <span class="math notranslate nohighlight">\(\boldsymbol{x}\)</span>, se espera que el patrón</p>
<div class="math notranslate nohighlight">
\[
    \boldsymbol{x}':= \boldsymbol{x} + \boldsymbol{v},~\text{donde}~\boldsymbol{v} : \|\boldsymbol{v}\|\leq\epsilon,
    \]</div>
<p>se <code class="docutils literal notranslate"><span class="pre">clasifique</span> <span class="pre">en</span> <span class="pre">la</span> <span class="pre">misma</span> <span class="pre">categoría</span> <span class="pre">que</span></code> <span class="math notranslate nohighlight">\(\boldsymbol{x}\)</span> <code class="docutils literal notranslate"><span class="pre">con</span> <span class="pre">una</span> <span class="pre">alta</span> <span class="pre">probabilidad</span></code>.</p>
</li>
<li><p>El impacto de la <code class="docutils literal notranslate"><span class="pre">alta</span> <span class="pre">dimensionalidad</span> <span class="pre">(número</span> <span class="pre">de</span> <span class="pre">características</span> <span class="pre">igual</span> <span class="pre">o</span> <span class="pre">superior</span> <span class="pre">al</span> <span class="pre">número</span> <span class="pre">de</span> <span class="pre">observaciones)</span></code> en la condición de suavidad se hace evidente, sobre todo en el contexto de un <code class="docutils literal notranslate"><span class="pre">clasificador</span> <span class="pre">lineal</span></code>. Consideremos un <code class="docutils literal notranslate"><span class="pre">clasificador</span></code> entrenado <code class="docutils literal notranslate"><span class="pre">descrito</span> <span class="pre">por</span> <span class="pre">sus</span> <span class="pre">parámetros</span></code>, <span class="math notranslate nohighlight">\(\boldsymbol{\theta}\)</span>. Dado un <code class="docutils literal notranslate"><span class="pre">patrón</span> <span class="pre">de</span> <span class="pre">entrada</span></code>, <span class="math notranslate nohighlight">\(\boldsymbol{x}\)</span>, la <code class="docutils literal notranslate"><span class="pre">etiqueta</span> <span class="pre">se</span> <span class="pre">determina</span> <span class="pre">basándose</span> <span class="pre">en</span> <span class="pre">el</span> <span class="pre">signo</span> <span class="pre">del</span> <span class="pre">producto</span> <span class="pre">interior</span></code>, <span class="math notranslate nohighlight">\(\boldsymbol{\theta}^{T}\boldsymbol{x}\)</span>. Para el escenario en el que interviene <span class="math notranslate nohighlight">\(\boldsymbol{x}'\)</span>, el producto interior se expresa como</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\boldsymbol{\theta}^{T}\boldsymbol{x}' = \boldsymbol{\theta}^{T}\boldsymbol{x} + \boldsymbol{\theta}^{T}\boldsymbol{v}.
\]</div>
<ul class="simple">
<li><p>Si establecemos intencionadamente <span class="math notranslate nohighlight">\(\boldsymbol{v} = \pm\epsilon\cdot\text{sgn}(\boldsymbol{\theta})\)</span>, donde la <code class="docutils literal notranslate"><span class="pre">operación</span> <span class="pre">signo</span> <span class="pre">se</span> <span class="pre">aplica</span> <span class="pre">elemento</span> <span class="pre">a</span> <span class="pre">elemento</span></code>, se obtiene un resultado digno de mención. Entonces</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\boldsymbol{\theta}^{T}\boldsymbol{x}'=\boldsymbol{\theta}^{T}\boldsymbol{x}+\boldsymbol{\theta}^{T}\boldsymbol{v}=\boldsymbol{\theta}^{T}\pm\epsilon\sum_{i=1}^{l}|\theta_{i}|.
\]</div>
<ul class="simple">
<li><p>Por lo tanto, cuando la <code class="docutils literal notranslate"><span class="pre">dimensionalidad</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">entrada</span></code> <span class="math notranslate nohighlight">\(l\)</span> <code class="docutils literal notranslate"><span class="pre">es</span> <span class="pre">alta</span></code>, es probable que se produzcan <code class="docutils literal notranslate"><span class="pre">diferencias</span> <span class="pre">significativas</span> <span class="pre">en</span> <span class="pre">los</span> <span class="pre">valores</span> <span class="pre">del</span> <span class="pre">producto</span> <span class="pre">interno</span></code>, lo que podría causar etiquetas de <code class="docutils literal notranslate"><span class="pre">predicción</span> <span class="pre">distintas</span></code> tanto para <span class="math notranslate nohighlight">\(\boldsymbol{x}\)</span> como para <span class="math notranslate nohighlight">\(\boldsymbol{x}'\)</span>. En términos sencillos, la <code class="docutils literal notranslate"><span class="pre">interacción</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">linealidad</span> <span class="pre">y</span> <span class="pre">la</span> <span class="pre">alta</span> <span class="pre">dimensionalidad</span> <span class="pre">rompe</span> <span class="pre">el</span> <span class="pre">supuesto</span> <span class="pre">de</span> <span class="pre">suavidad</span></code>.</p></li>
</ul>
<div class="proof observation admonition" id="observation_ann14">
<p class="admonition-title"><span class="caption-number">Observation 22 </span></p>
<section class="observation-content" id="proof-content">
<ul class="simple">
<li><p>A pesar de que los <code class="docutils literal notranslate"><span class="pre">ejemplos</span> <span class="pre">adversos</span> <span class="pre">son</span> <span class="pre">poco</span> <span class="pre">frecuentes</span></code> en los datos de entrada (tanto en los conjuntos de <code class="docutils literal notranslate"><span class="pre">entrenamiento</span></code> como en los de <code class="docutils literal notranslate"><span class="pre">prueba</span></code>), <code class="docutils literal notranslate"><span class="pre">su</span> <span class="pre">existencia</span> <span class="pre">sigue</span> <span class="pre">siendo</span> <span class="pre">desconcertante</span></code>. Además, pueden aprovecharse para <code class="docutils literal notranslate"><span class="pre">engañar</span> <span class="pre">deliberadamente</span> <span class="pre">a</span> <span class="pre">las</span> <span class="pre">redes</span></code>. En consecuencia, han surgido varias <code class="docutils literal notranslate"><span class="pre">técnicas</span> <span class="pre">para</span> <span class="pre">reforzar</span> <span class="pre">la</span> <span class="pre">resistencia</span> <span class="pre">de</span> <span class="pre">las</span> <span class="pre">redes</span> <span class="pre">frente</span> <span class="pre">a</span> <span class="pre">adversarios</span></code>.</p></li>
</ul>
</section>
</div><ul class="simple">
<li><p>Uno estudio descrito en <span id="id47">[<a class="reference internal" href="biblio.html#id49" title="Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan, Ian Goodfellow, and Rob Fergus. Intriguing properties of neural networks. arXiv preprint arXiv:1312.6199, 2013.">Szegedy <em>et al.</em>, 2013</a>]</span>, consiste en <code class="docutils literal notranslate"><span class="pre">generar</span> <span class="pre">ejemplos</span> <span class="pre">adversos</span> <span class="pre">e</span> <span class="pre">incorporarlos</span> <span class="pre">de</span> <span class="pre">nuevo</span> <span class="pre">al</span> <span class="pre">conjunto</span> <span class="pre">de</span> <span class="pre">entrenamiento</span></code>. Esta estrategia funciona como una forma de <code class="docutils literal notranslate"><span class="pre">regularización</span> <span class="pre">a</span> <span class="pre">través</span> <span class="pre">del</span> <span class="pre">aumento</span> <span class="pre">de</span> <span class="pre">datos</span></code>. Sin embargo, una perspectiva alternativa presentada en <span id="id48">[<a class="reference internal" href="biblio.html#id50" title="Corey Kereliuk, Bob L Sturm, and Jan Larsen. Deep learning and music adversaries. IEEE Transactions on Multimedia, 17(11):2059–2071, 2015.">Kereliuk <em>et al.</em>, 2015</a>]</span> argumenta que este método <code class="docutils literal notranslate"><span class="pre">no</span> <span class="pre">mejoró</span> <span class="pre">notablemente</span> <span class="pre">el</span> <span class="pre">rendimiento</span> <span class="pre">cuando</span> <span class="pre">se</span> <span class="pre">aplicó</span> <span class="pre">a</span> <span class="pre">datos</span> <span class="pre">musicales</span></code>.</p></li>
</ul>
<ul>
<li><p>En <span id="id49">[<a class="reference internal" href="biblio.html#id51" title="Ian J Goodfellow, Jonathon Shlens, and Christian Szegedy. Explaining and harnessing adversarial examples. arXiv preprint arXiv:1412.6572, 2014.">Goodfellow <em>et al.</em>, 2014</a>]</span>, la <code class="docutils literal notranslate"><span class="pre">función</span> <span class="pre">de</span> <span class="pre">pérdida</span></code> <span class="math notranslate nohighlight">\(J\)</span> <code class="docutils literal notranslate"><span class="pre">se</span> <span class="pre">modifica</span> <span class="pre">adecuadamente</span></code> como</p>
<div class="math notranslate nohighlight">
\[
    J'(\boldsymbol{\theta}, \boldsymbol{x}, \boldsymbol{y})=\alpha J(\boldsymbol{\theta}, \boldsymbol{x}, \boldsymbol{y})+(1-\alpha)J(\boldsymbol{\theta}, \boldsymbol{x}+\Delta\boldsymbol{x}, \boldsymbol{y}),~0&lt;\alpha&lt;1,
    \]</div>
<p>donde</p>
<div class="math notranslate nohighlight">
\[
    \Delta\boldsymbol{x}=\epsilon\cdot\text{sgn}\left(\frac{\partial}{\partial\boldsymbol{x}}J(\boldsymbol{\theta}, \boldsymbol{x}, \boldsymbol{y})\right),~\epsilon&gt;0,
    \]</div>
<p>es una <code class="docutils literal notranslate"><span class="pre">dirección</span> <span class="pre">para</span> <span class="pre">la</span> <span class="pre">perturbación</span> <span class="pre">adversarial</span></code>.</p>
</li>
<li><p>Es importante señalar que los <code class="docutils literal notranslate"><span class="pre">ejemplos</span> <span class="pre">adversarios</span></code> siguen siendo un foco de investigación en evolución dinámica. Se subrayan los <code class="docutils literal notranslate"><span class="pre">peligros</span> <span class="pre">potenciales,</span> <span class="pre">como</span> <span class="pre">la</span> <span class="pre">manipulación</span> <span class="pre">de</span> <span class="pre">vehículos</span> <span class="pre">autónomos</span> <span class="pre">utilizando</span> <span class="pre">muestras</span> <span class="pre">adversarios</span></code>, entre otros (ver <span id="id50">[<a class="reference internal" href="biblio.html#id53" title="Alexey Kurakin, Ian J Goodfellow, and Samy Bengio. Adversarial examples in the physical world. In Artificial intelligence safety and security, pages 99–112. Chapman and Hall/CRC, 2018.">Kurakin <em>et al.</em>, 2018</a>, <a class="reference internal" href="biblio.html#id52" title="Nicolas Papernot, Patrick McDaniel, Ian Goodfellow, Somesh Jha, Z Berkay Celik, and Ananthram Swami. Practical black-box attacks against machine learning. In Proceedings of the 2017 ACM on Asia conference on computer and communications security, 506–519. 2017.">Papernot <em>et al.</em>, 2017</a>, <a class="reference internal" href="biblio.html#id54" title="Nicolas Papernot, Patrick McDaniel, Arunesh Sinha, and Michael Wellman. Towards the science of security and privacy in machine learning. arXiv preprint arXiv:1611.03814, 2016.">Papernot <em>et al.</em>, 2016</a>]</span>).</p></li>
</ul>
</section>
<section id="modelos-generativos-profundos">
<h2>Modelos Generativos Profundos<a class="headerlink" href="#modelos-generativos-profundos" title="Link to this heading">#</a></h2>
<section id="maquina-de-boltzmann-restringida">
<h3>Máquina de Boltzmann Restringida<a class="headerlink" href="#maquina-de-boltzmann-restringida" title="Link to this heading">#</a></h3>
<div class="admonition-introduccion admonition">
<p class="admonition-title">Introducción</p>
<ul class="simple">
<li><p>Una <code class="docutils literal notranslate"><span class="pre">máquina</span> <span class="pre">de</span> <span class="pre">Boltzmann</span> <span class="pre">restringida</span> <span class="pre">(RBM)</span></code> es una <code class="docutils literal notranslate"><span class="pre">red</span> <span class="pre">neuronal</span> <span class="pre">artificial</span> <span class="pre">estocástica</span> <span class="pre">generativa</span></code> que puede <code class="docutils literal notranslate"><span class="pre">aprender</span> <span class="pre">una</span> <span class="pre">distribución</span> <span class="pre">de</span> <span class="pre">probabilidad</span> <span class="pre">sobre</span> <span class="pre">su</span> <span class="pre">conjunto</span> <span class="pre">de</span> <span class="pre">entradas</span></code> bajo ajuste de parámetros. Las RBM fueron estudiadas inicialmente con el nombre de <code class="docutils literal notranslate"><span class="pre">Harmonium</span> <span class="pre">por</span> <span class="pre">Paul</span> <span class="pre">Smolensky</span> <span class="pre">en</span> <span class="pre">1986</span></code>, y adquirieron prominencia después de que <code class="docutils literal notranslate"><span class="pre">Geoffrey</span> <span class="pre">Hinton</span></code> y sus colaboradores propusieron para estas, algoritmos de aprendizaje rápido a mediados de 2000.</p></li>
<li><p>Las <code class="docutils literal notranslate"><span class="pre">RBM</span></code> han encontrado <code class="docutils literal notranslate"><span class="pre">aplicaciones</span> <span class="pre">en</span> <span class="pre">la</span> <span class="pre">reducción</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">dimensionalidad,</span> <span class="pre">clasificación,</span> <span class="pre">filtrado,</span> <span class="pre">aprendizaje</span> <span class="pre">de</span> <span class="pre">funciones,</span> <span class="pre">modelado</span> <span class="pre">de</span> <span class="pre">temas</span> <span class="pre">e</span> <span class="pre">incluso</span> <span class="pre">en</span> <span class="pre">muchas</span> <span class="pre">mecánicas</span> <span class="pre">cuánticas</span> <span class="pre">corporales</span></code>. Pueden ser entrenados en <code class="docutils literal notranslate"><span class="pre">forma</span> <span class="pre">supervisada</span> <span class="pre">o</span> <span class="pre">no</span> <span class="pre">supervisada</span></code>, dependiendo de la tarea.</p></li>
</ul>
</div>
<ul>
<li><p>El modelo gráfico de la <a class="reference internal" href="#rboltzmann-model-numref"><span class="std std-numref">Fig. 67</span></a> ilustra una <code class="docutils literal notranslate"><span class="pre">máquina</span> <span class="pre">de</span> <span class="pre">Boltzmann</span> <span class="pre">restringida</span> <span class="pre">(RBM)</span></code>. La máquina de Boltzmann utiliza la siguiente <code class="docutils literal notranslate"><span class="pre">distribución</span> <span class="pre">de</span> <span class="pre">probabilidad</span> <span class="pre">conjunta</span> <span class="pre">de</span> <span class="pre">Boltzmann</span></code> definida como</p>
<div class="math notranslate nohighlight">
\[
    p(x_{1}, \dots, x_{l}):=p(\boldsymbol{x})=\frac{1}{Z}\exp\left(-\sum_{i}\left(\sum_{j&gt;i}\theta_{ij}x_{i}x_{j}+\theta_{i0}x_{i}\right)\right),
    \]</div>
<p>donde cada <code class="docutils literal notranslate"><span class="pre">variable</span> <span class="pre">aleatoria</span> <span class="pre">toma</span> <span class="pre">valores</span> <span class="pre">binarios</span></code> en <span class="math notranslate nohighlight">\(\{-1, 1\}\)</span>, <span class="math notranslate nohighlight">\(\theta_{ij}=0\)</span> si los <code class="docutils literal notranslate"><span class="pre">nodos</span> <span class="pre">respectivos</span> <span class="pre">no</span> <span class="pre">están</span> <span class="pre">conectados</span></code> y la constante <span class="math notranslate nohighlight">\(Z\)</span> se conoce como <code class="docutils literal notranslate"><span class="pre">función</span> <span class="pre">de</span> <span class="pre">partición</span></code> y es la <code class="docutils literal notranslate"><span class="pre">constante</span> <span class="pre">normalizadora</span></code> para <code class="docutils literal notranslate"><span class="pre">garantizar</span> <span class="pre">que</span></code> <span class="math notranslate nohighlight">\(p(x_{1}, \dots, x_{l})\)</span> <code class="docutils literal notranslate"><span class="pre">es</span> <span class="pre">una</span> <span class="pre">distribución</span> <span class="pre">de</span> <span class="pre">probabilidad</span></code>.</p>
</li>
<li><p>Es importante destacar que los <code class="docutils literal notranslate"><span class="pre">nodos</span> <span class="pre">dentro</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">misma</span> <span class="pre">capa</span> <span class="pre">carecen</span> <span class="pre">de</span> <span class="pre">interconexiones</span></code>. Esta arquitectura abarca <code class="docutils literal notranslate"><span class="pre">nodos</span> <span class="pre">visibles</span> <span class="pre">en</span> <span class="pre">la</span> <span class="pre">capa</span> <span class="pre">inferior</span></code> que reciben observaciones, mientras que la <code class="docutils literal notranslate"><span class="pre">capa</span> <span class="pre">superior</span> <span class="pre">contiene</span> <span class="pre">nodos</span> <span class="pre">vinculados</span> <span class="pre">a</span> <span class="pre">variables</span> <span class="pre">ocultas</span></code>. Cabe destacar que <code class="docutils literal notranslate"><span class="pre">sólo</span> <span class="pre">los</span> <span class="pre">nodos</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">capa</span> <span class="pre">inferior</span> <span class="pre">reciben</span> <span class="pre">observaciones</span></code>. Es posible construir <code class="docutils literal notranslate"><span class="pre">RBM</span> <span class="pre">profundos</span></code> apilando múltiples <code class="docutils literal notranslate"><span class="pre">RBM</span></code> unos sobre otros. De acuerdo con la <code class="docutils literal notranslate"><span class="pre">definición</span> <span class="pre">general</span> <span class="pre">de</span> <span class="pre">una</span> <span class="pre">máquina</span> <span class="pre">de</span> <span class="pre">Boltzmann</span></code>, la distribución conjunta de las variables aleatorias implicadas puede expresarse como:</p>
<div class="math notranslate nohighlight">
\[
    P(v_{1}, \dots, v_{J}, h_{1}, \dots, h_{I})=\frac{1}{Z}\exp(-E(\boldsymbol{v}, \boldsymbol{h})),
    \]</div>
<p>donde hemos utilizado símbolos diferentes para las <span class="math notranslate nohighlight">\(J\)</span> <code class="docutils literal notranslate"><span class="pre">variables</span> <span class="pre">visibles</span></code> (<span class="math notranslate nohighlight">\(v_{j},~j = 1, 2,\dots, J\)</span>) y las <span class="math notranslate nohighlight">\(I\)</span> <code class="docutils literal notranslate"><span class="pre">variables</span> <span class="pre">ocultas</span></code> (<span class="math notranslate nohighlight">\(h_{i},~i = 1, 2,\dots, I\)</span>).</p>
</li>
</ul>
<ul class="simple">
<li><p>La <code class="docutils literal notranslate"><span class="pre">función</span> <span class="pre">de</span> <span class="pre">energía</span> <span class="pre">no</span> <span class="pre">es</span> <span class="pre">la</span> <span class="pre">salida</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">RBM</span></code>, por lo contrario, es una métrica para medir la calidad de un modelo. Produce un <code class="docutils literal notranslate"><span class="pre">valor</span> <span class="pre">escalar</span> <span class="pre">que</span> <span class="pre">corresponde</span> <span class="pre">básicamente</span> <span class="pre">a</span> <span class="pre">la</span> <span class="pre">configuración</span> <span class="pre">del</span> <span class="pre">modelo</span></code> y es un <code class="docutils literal notranslate"><span class="pre">indicador</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">probabilidad</span> <span class="pre">de</span> <span class="pre">que</span> <span class="pre">el</span> <span class="pre">modelo</span> <span class="pre">esté</span> <span class="pre">en</span> <span class="pre">esa</span> <span class="pre">configuración</span></code>. Si el modelo está configurado para favorecer una energía baja, las <code class="docutils literal notranslate"><span class="pre">configuraciones</span> <span class="pre">que</span> <span class="pre">conduzcan</span> <span class="pre">a</span> <span class="pre">una</span> <span class="pre">energía</span> <span class="pre">baja</span> <span class="pre">tendrán</span> <span class="pre">una</span> <span class="pre">probabilidad</span> <span class="pre">más</span> <span class="pre">alta</span></code>.</p></li>
</ul>
<figure class="align-center" id="rboltzmann-model-numref">
<a class="reference internal image-reference" href="_images/rboltzmann_model.png"><img alt="_images/rboltzmann_model.png" src="_images/rboltzmann_model.png" style="width: 274.4px; height: 121.8px;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 67 </span><span class="caption-text">Arquitectura de <code class="docutils literal notranslate"><span class="pre">modelo</span> <span class="pre">(RBM)</span></code>. Fuente <span id="id51">[<a class="reference internal" href="biblio.html#id17" title="S. Theodoridis. Machine Learning: A Bayesian and Optimization Perspective. Elsevier Science, 2020. ISBN 9780128188040. URL: https://books.google.com.co/books?id=l-nEDwAAQBAJ.">Theodoridis, 2020</a>]</span>.</span><a class="headerlink" href="#rboltzmann-model-numref" title="Link to this image">#</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p>La <code class="docutils literal notranslate"><span class="pre">energía</span></code> se define en <code class="docutils literal notranslate"><span class="pre">función</span> <span class="pre">de</span> <span class="pre">un</span> <span class="pre">conjunto</span> <span class="pre">de</span> <span class="pre">parámetros</span> <span class="pre">desconocidos</span></code>, es decir,</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
E(\boldsymbol{v}, \boldsymbol{h})=-\sum_{i=1}^{I}\sum_{j=1}^{J}\theta_{ij}h_{i}v_{j}-\sum_{i=1}^{I}b_{i}h_{i}-\sum_{j=1}^{J}c_{j}v_{j}.                                                                                                                                                                              
\]</div>
<ul class="simple">
<li><p>La <code class="docutils literal notranslate"><span class="pre">constante</span> <span class="pre">de</span> <span class="pre">normalización</span></code> se obtiene como</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
Z=\sum_{v}\sum_{h}\exp(-E(\boldsymbol{v}, \boldsymbol{h})).
\]</div>
<ul class="simple">
<li><p>Nuestro enfoque será en <code class="docutils literal notranslate"><span class="pre">variables</span> <span class="pre">discretas</span></code>, lo que implica que las <code class="docutils literal notranslate"><span class="pre">distribuciones</span> <span class="pre">relacionadas</span> <span class="pre">son</span> <span class="pre">de</span> <span class="pre">carácter</span> <span class="pre">probabilístico</span></code>. Específicamente, nos centraremos en <code class="docutils literal notranslate"><span class="pre">variables</span> <span class="pre">de</span> <span class="pre">naturaleza</span> <span class="pre">binaria</span></code>, es decir, aquellas que poseen únicamente dos posibles valores, <span class="math notranslate nohighlight">\(v_{j}, h_{i}\in\{0, 1\},\)</span> <span class="math notranslate nohighlight">\(j=1,\dots,J\)</span>, <span class="math notranslate nohighlight">\(i=1,\dots,I\)</span>.</p></li>
</ul>
<ul>
<li><p>El objetivo al <code class="docutils literal notranslate"><span class="pre">entrenar</span> <span class="pre">una</span> <span class="pre">Máquina</span> <span class="pre">de</span> <span class="pre">Boltzmann</span> <span class="pre">Restringida</span> <span class="pre">(RBM)</span></code> consiste en <code class="docutils literal notranslate"><span class="pre">adquirir</span> <span class="pre">el</span> <span class="pre">conjunto</span> <span class="pre">de</span> <span class="pre">parámetros</span> <span class="pre">desconocidos</span></code> <span class="math notranslate nohighlight">\(\theta_{ij}, b_{i}, c_{j}\)</span>, los cuales serán designados colectivamente como, <span class="math notranslate nohighlight">\(\boldsymbol{\Theta},\boldsymbol{b}\)</span> y <span class="math notranslate nohighlight">\(\boldsymbol{c}\)</span> respectivamente. Un enfoque primordial para lograr esto es <code class="docutils literal notranslate"><span class="pre">maximizar</span> <span class="pre">la</span> <span class="pre">log-verosimilitud</span></code>, utilizando <span class="math notranslate nohighlight">\(N\)</span> observaciones de las <code class="docutils literal notranslate"><span class="pre">variables</span> <span class="pre">visibles</span></code>, representadas como <span class="math notranslate nohighlight">\(v_{n},~n=1,\dots, N\)</span>, donde</p>
<div class="math notranslate nohighlight">
\[
    \boldsymbol{v}_{n}=[v_{1n}, \dots, v_{Jn}]^{T},
    \]</div>
<p>es el vector que contiene las <code class="docutils literal notranslate"><span class="pre">observaciones</span></code> correspondientes en el <code class="docutils literal notranslate"><span class="pre">momento</span></code> <span class="math notranslate nohighlight">\(n\)</span>.</p>
</li>
</ul>
<ul>
<li><p>Diremos que los <code class="docutils literal notranslate"><span class="pre">nodos</span> <span class="pre">visibles</span> <span class="pre">están</span> <span class="pre">fijados</span> <span class="pre">en</span> <span class="pre">las</span> <span class="pre">observaciones</span> <span class="pre">respectivas</span></code>. La correspondiente <code class="docutils literal notranslate"><span class="pre">log-verosimilitud</span> <span class="pre">(promedio)</span> </code> se expresa como sigue:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
    \begin{align*}
    L(\boldsymbol{\Theta}, \boldsymbol{b}, \boldsymbol{c})&amp;=\frac{1}{N}\sum_{n=1}^{N}\ln P(\boldsymbol{v}_{n};\boldsymbol{\Theta}, \boldsymbol{b}, \boldsymbol{c})\\
    &amp;=\frac{1}{N}\sum_{n=1}^{N}\ln\left(\frac{1}{Z}\sum_{\boldsymbol{h}}\exp(-E(\boldsymbol{v}_{n}, \boldsymbol{h}; \boldsymbol{\Theta}, \boldsymbol{b}, \boldsymbol{c}))\right)\\
    &amp;=\frac{1}{N}\sum_{n=1}^{N}\ln\left(\sum_{\boldsymbol{h}}\exp(-E(\boldsymbol{v}_{n}, \boldsymbol{h}; \boldsymbol{\Theta}, \boldsymbol{b}, \boldsymbol{c}))\right)-\ln\sum_{\boldsymbol{v}}\sum_{\boldsymbol{h}}\exp\left(-E(\boldsymbol{v}, \boldsymbol{h})\right),
    \end{align*}
    \end{split}\]</div>
<p>donde el índice “<span class="math notranslate nohighlight">\(n\)</span>” en la energía se refiere a las <code class="docutils literal notranslate"><span class="pre">observaciones</span> <span class="pre">respectivas</span> <span class="pre">en</span> <span class="pre">las</span> <span class="pre">cuales</span> <span class="pre">los</span> <span class="pre">nodos</span> <span class="pre">visibles</span> <span class="pre">han</span> <span class="pre">sido</span> <span class="pre">fijados</span></code>, y el símbolo “<span class="math notranslate nohighlight">\(\Theta\)</span>” ha sido <code class="docutils literal notranslate"><span class="pre">incluido</span> <span class="pre">explícitamente</span> <span class="pre">en</span> <span class="pre">la</span> <span class="pre">notación</span></code>.</p>
</li>
</ul>
<ul>
<li><p>Tomando la derivada de <span class="math notranslate nohighlight">\(L(\boldsymbol{\Theta}, \boldsymbol{b}, \boldsymbol{c})\)</span> respecto a <span class="math notranslate nohighlight">\(\theta_{ij}\)</span> (similar es el caso de las derivadas respecto a respecto a <span class="math notranslate nohighlight">\(b_{i}\)</span> y <span class="math notranslate nohighlight">\(c_{j}\)</span>) y aplicando las <code class="docutils literal notranslate"><span class="pre">propiedades</span> <span class="pre">estándar</span> <span class="pre">de</span> <span class="pre">las</span> <span class="pre">derivadas</span></code>, se tiene que (<code class="docutils literal notranslate"><span class="pre">verifíquelo</span></code>)</p>
<div class="math notranslate nohighlight" id="equation-gradient-boltzmann-eq">
<span class="eqno">(68)<a class="headerlink" href="#equation-gradient-boltzmann-eq" title="Link to this equation">#</a></span>\[
    \frac{\partial L(\boldsymbol{\Theta}, \boldsymbol{b}, \boldsymbol{c})}{\partial\theta_{ij}}=\frac{1}{N}\sum_{n=1}^{N}\left(\sum_{\boldsymbol{h}}P(\boldsymbol{h}|\boldsymbol{v}_{n})h_{i}v_{jn}\right)-\sum_{\boldsymbol{v}}\sum_{\boldsymbol{h}}P(\boldsymbol{v}, \boldsymbol{h})h_{i}v_{j},
    \]</div>
<p>donde</p>
<div class="math notranslate nohighlight">
\[
    P(\boldsymbol{h}|\boldsymbol{v})=\frac{P(\boldsymbol{v}|\boldsymbol{h})}{\sum_{\boldsymbol{h}'}P(\boldsymbol{v}, \boldsymbol{h}')}.
    \]</div>
</li>
</ul>
<ul class="simple">
<li><p>El gradiente en la Eq. <a class="reference internal" href="#equation-gradient-boltzmann-eq">(68)</a> consta de <code class="docutils literal notranslate"><span class="pre">dos</span> <span class="pre">términos</span></code>. El primero puede ser <code class="docutils literal notranslate"><span class="pre">calculado</span> <span class="pre">una</span> <span class="pre">vez</span> <span class="pre">que</span></code> <span class="math notranslate nohighlight">\(P(\boldsymbol{h}|\boldsymbol{v})\)</span> <code class="docutils literal notranslate"><span class="pre">está</span> <span class="pre">disponible</span></code>. Básicamente, este término es la <code class="docutils literal notranslate"><span class="pre">tasa</span> <span class="pre">media</span> <span class="pre">de</span> <span class="pre">disparo</span> <span class="pre">o</span> <span class="pre">correlación</span></code> cuando la Máquina de Boltzmann Restringida <code class="docutils literal notranslate"><span class="pre">(RBM)</span> <span class="pre">está</span> <span class="pre">operando</span> <span class="pre">en</span> <span class="pre">su</span> <span class="pre">fase</span> <span class="pre">fijada</span></code>; a menudo, nos referimos a esto como la <code class="docutils literal notranslate"><span class="pre">fase</span> <span class="pre">positiva</span></code> (<code class="docutils literal notranslate"><span class="pre">regla</span> <span class="pre">de</span> <span class="pre">aprendizaje</span> <span class="pre">de</span> <span class="pre">Hebb</span></code> <span id="id52">[<a class="reference internal" href="biblio.html#id55" title="Donald Olding Hebb. The organization of behavior: A neuropsychological theory. Psychology press, 2005.">Hebb, 2005</a>]</span>), y el término se denota como <span class="math notranslate nohighlight">\(\langle h{i}v_{j}\rangle^{+}\)</span>. El segundo término es la <code class="docutils literal notranslate"><span class="pre">correlación</span> <span class="pre">correspondiente</span> <span class="pre">cuando</span> <span class="pre">la</span> <span class="pre">RBM</span> <span class="pre">está</span> <span class="pre">funcionando</span> <span class="pre">en</span> <span class="pre">su</span> <span class="pre">llamada</span> <span class="pre">fase</span> <span class="pre">libre</span> <span class="pre">o</span> <span class="pre">negativa</span></code>, y se denota como <span class="math notranslate nohighlight">\(\langle h_{i}v_{j}\rangle^{-}\)</span>. Por lo tanto, un <code class="docutils literal notranslate"><span class="pre">esquema</span> <span class="pre">de</span> <span class="pre">aumento</span> <span class="pre">de</span> <span class="pre">gradiente</span></code> para maximizar la log-verosimilitud tendrá la forma:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\theta_{ij}(\text{new})=\theta_{ij}(old)+\mu(\langle h{i}v_{j}\rangle^{+}-\langle h_{i}v_{j}\rangle^{-}).
\]</div>
</section>
</section>
<section id="autoencoders">
<h2>Autoencoders<a class="headerlink" href="#autoencoders" title="Link to this heading">#</a></h2>
<ul>
<li><p>Los <code class="docutils literal notranslate"><span class="pre">autoencoders</span></code> han sido propuestos como <code class="docutils literal notranslate"><span class="pre">métodos</span> <span class="pre">para</span> <span class="pre">la</span> <span class="pre">reducción</span> <span class="pre">de</span> <span class="pre">dimensionalidad</span></code>. Un <code class="docutils literal notranslate"><span class="pre">autoencoder</span></code> consta de dos partes, el <code class="docutils literal notranslate"><span class="pre">codificador</span></code> y el <code class="docutils literal notranslate"><span class="pre">decodificador</span></code>. La <code class="docutils literal notranslate"><span class="pre">salida</span> <span class="pre">del</span> <span class="pre">codificador</span> <span class="pre">es</span> <span class="pre">la</span> <span class="pre">representación</span> <span class="pre">reducida</span> <span class="pre">del</span> <span class="pre">patrón</span> <span class="pre">de</span> <span class="pre">entrada</span></code>, y se define en términos de una función vectorial</p>
<div class="math notranslate nohighlight">
\[
    \boldsymbol{f}:~\boldsymbol{x}\in\mathbb{R}^{l}\longmapsto\boldsymbol{h}\in\mathbb{R}^{m},
    \]</div>
<p>donde</p>
<div class="math notranslate nohighlight">
\[
    h_{i}:=f_{i}(\boldsymbol{x})=\phi_{e}(\boldsymbol{\theta}_{i}^{T}\boldsymbol{x}+b_{i}),\quad i=1,2,\dots,m,
    \]</div>
<p>con <span class="math notranslate nohighlight">\(\phi_{e}\)</span> función de <code class="docutils literal notranslate"><span class="pre">activación</span></code>; esta última suele tomarse como la función <code class="docutils literal notranslate"><span class="pre">sigmoidea</span> <span class="pre">logística</span></code> <span class="math notranslate nohighlight">\(\phi_{e}(\cdot)=\sigma(\cdot)\)</span>. En otras palabras, el <code class="docutils literal notranslate"><span class="pre">codificador</span> <span class="pre">es</span> <span class="pre">una</span> <span class="pre">red</span> <span class="pre">neuronal</span> <span class="pre">feed-forward</span> <span class="pre">de</span> <span class="pre">una</span> <span class="pre">sola</span> <span class="pre">capa</span> <span class="pre">oculta</span></code></p>
</li>
</ul>
<ul>
<li><p>El <code class="docutils literal notranslate"><span class="pre">decodificador</span></code> es otra función <span class="math notranslate nohighlight">\(\boldsymbol{g}\)</span>.</p>
<div class="math notranslate nohighlight">
\[
    \boldsymbol{g}:~\boldsymbol{h}\in\mathbb{R}^{m}\longmapsto\hat{\boldsymbol{x}}\in\mathbb{R}^{l},
    \]</div>
<p>donde</p>
<div class="math notranslate nohighlight">
\[
    \hat{x}_{j}=g_{j}(\boldsymbol{h})=\phi_{d}(\boldsymbol{\theta}'^{T}\boldsymbol{h}+b_{j}'),\quad j=1,\dots,l.
    \]</div>
<p>La función de <code class="docutils literal notranslate"><span class="pre">activación</span></code> <span class="math notranslate nohighlight">\(\phi_{d}\)</span> suele ser la identidad (<code class="docutils literal notranslate"><span class="pre">reconstrucción</span> <span class="pre">lineal</span></code>) o la <code class="docutils literal notranslate"><span class="pre">sigmoidea</span> <span class="pre">logística</span></code>.</p>
</li>
</ul>
<ul class="simple">
<li><p>La tarea de entrenamiento consiste en <code class="docutils literal notranslate"><span class="pre">estimar</span> <span class="pre">los</span> <span class="pre">parámetros</span></code></p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\Theta:=[\boldsymbol{\theta}_{1},\dots,\boldsymbol{\theta}_{m}],~\boldsymbol{b},~\Theta':=[\boldsymbol{\theta}_{1}',\dots,\boldsymbol{\theta}_{l}'],~\boldsymbol{b}'.
\]</div>
<ul class="simple">
<li><p>Es habitual suponer que <span class="math notranslate nohighlight">\(\Theta'=\Theta^{T}\)</span>. Los parámetros se estiman para que el <code class="docutils literal notranslate"><span class="pre">error</span> <span class="pre">de</span> <span class="pre">reconstrucción</span></code> <span class="math notranslate nohighlight">\(\boldsymbol{e}=\boldsymbol{x}-\hat{\boldsymbol{x}}\)</span>, sobre las muestras de entrada disponibles sea <code class="docutils literal notranslate"><span class="pre">mínimo</span></code>. Normalmente, se utiliza el <code class="docutils literal notranslate"><span class="pre">coste</span> <span class="pre">por</span> <span class="pre">mínimos</span> <span class="pre">cuadrados</span></code> pero también son posibles otras opciones. Las <code class="docutils literal notranslate"><span class="pre">versiones</span> <span class="pre">regularizadas</span></code>, que implican una norma de los parámetros, también es una posibilidad. Si se elige que la activación <span class="math notranslate nohighlight">\(\phi_{e}\)</span> sea la identidad (representación lineal) y <span class="math notranslate nohighlight">\(m &lt; l\)</span> (para evitar la trivialidad), el <code class="docutils literal notranslate"><span class="pre">autoencoder</span> <span class="pre">es</span> <span class="pre">equivalente</span> <span class="pre">a</span> <span class="pre">la</span> <span class="pre">técnica</span> <span class="pre">PCA</span></code>.</p></li>
</ul>
</section>
<section id="aplicacion-procesamiento-del-lenguaje-natural">
<h2>Aplicación: Procesamiento del Lenguaje Natural<a class="headerlink" href="#aplicacion-procesamiento-del-lenguaje-natural" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">tensorflow.keras</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">sklearn</span> <span class="k">as</span> <span class="nn">sk</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Iniciamos verificando que <code class="docutils literal notranslate"><span class="pre">Tensorflow</span></code> está correctamente instalado, y que, además, <code class="docutils literal notranslate"><span class="pre">puede</span> <span class="pre">utilizar</span> <span class="pre">la</span> <span class="pre">GPU</span> <span class="pre">disponible</span> <span class="pre">en</span> <span class="pre">su</span> <span class="pre">computadora</span></code>. En este caso corresponde a una tarjeta de video dedicada <code class="docutils literal notranslate"><span class="pre">GTX</span> <span class="pre">4070</span> <span class="pre">Maxq</span> <span class="pre">12G</span></code></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Tensor Flow Version: </span><span class="si">{</span><span class="n">tf</span><span class="o">.</span><span class="n">__version__</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">);</span>
<span class="nb">print</span><span class="p">();</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Python </span><span class="si">{</span><span class="n">sys</span><span class="o">.</span><span class="n">version</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">);</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Pandas </span><span class="si">{</span><span class="n">pd</span><span class="o">.</span><span class="n">__version__</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">);</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Scikit-Learn </span><span class="si">{</span><span class="n">sk</span><span class="o">.</span><span class="n">__version__</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">);</span>
<span class="n">gpu</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">list_physical_devices</span><span class="p">(</span><span class="s1">&#39;GPU&#39;</span><span class="p">))</span><span class="o">&gt;</span><span class="mi">0</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;GPU is&quot;</span><span class="p">,</span> <span class="s2">&quot;available&quot;</span> <span class="k">if</span> <span class="n">gpu</span> <span class="k">else</span> <span class="s2">&quot;NOT AVAILABLE&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Tensor Flow Version: 2.10.1

Python 3.9.18 (main, Sep 11 2023, 14:09:26) [MSC v.1916 64 bit (AMD64)]
Pandas 2.0.3
Scikit-Learn 1.3.0
GPU is available
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>La librería <code class="docutils literal notranslate"><span class="pre">gensim</span></code> utilizada en la presente implementación, debe ser instalada en su <code class="docutils literal notranslate"><span class="pre">versión</span> <span class="pre">3.8.3</span></code> usando la orden. Además, debe instalar <code class="docutils literal notranslate"><span class="pre">graphviz</span></code> del siguiente sitio web (ver <a class="reference external" href="https://graphviz.org/download/">GraphViz</a>)</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="n">gensim</span><span class="o">==</span><span class="mf">3.8.3</span>
</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>
<span class="kn">from</span> <span class="nn">keras.preprocessing.text</span> <span class="kn">import</span> <span class="n">Tokenizer</span>
<span class="n">tqdm</span><span class="o">.</span><span class="n">pandas</span><span class="p">(</span><span class="n">desc</span><span class="o">=</span><span class="s2">&quot;progress-bar&quot;</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">gensim.models</span> <span class="kn">import</span> <span class="n">Doc2Vec</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">utils</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">keras_preprocessing.sequence</span> <span class="kn">import</span> <span class="n">pad_sequences</span>
<span class="kn">import</span> <span class="nn">gensim</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="nn">gensim.models.doc2vec</span> <span class="kn">import</span> <span class="n">TaggedDocument</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;https://raw.githubusercontent.com/lihkir/Data/main/spam_text_class.csv&#39;</span><span class="p">,</span><span class="n">delimiter</span><span class="o">=</span><span class="s1">&#39;,&#39;</span><span class="p">,</span><span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;latin-1&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="s1">&#39;Category&#39;</span><span class="p">,</span><span class="s1">&#39;Message&#39;</span><span class="p">]]</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">pd</span><span class="o">.</span><span class="n">notnull</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;Message&#39;</span><span class="p">])]</span>
<span class="n">df</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;Message&#39;</span><span class="p">:</span><span class="s1">&#39;Message&#39;</span><span class="p">},</span> <span class="n">inplace</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Category</th>
      <th>Message</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>ham</td>
      <td>Go until jurong point, crazy.. Available only ...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>ham</td>
      <td>Ok lar... Joking wif u oni...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>spam</td>
      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>ham</td>
      <td>U dun say so early hor... U c already then say...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>ham</td>
      <td>Nah I don't think he goes to usf, he lives aro...</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(5572, 2)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">index</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5572</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;Message&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39; &#39;</span><span class="p">)))</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>87265
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib</span>
<span class="n">matplotlib</span><span class="o">.</span><span class="n">rc_file_defaults</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cnt_pro</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Category&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
<span class="n">sns</span><span class="o">.</span><span class="n">barplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">cnt_pro</span><span class="o">.</span><span class="n">index</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">cnt_pro</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Number of Occurrences&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Category&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">rotation</span><span class="o">=</span><span class="mi">90</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">();</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/efae96e0871817653fe838d2bcef62f120bf1a565a61fbb2f364355d4f48c6e6.png" src="_images/efae96e0871817653fe838d2bcef62f120bf1a565a61fbb2f364355d4f48c6e6.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">print_message</span><span class="p">(</span><span class="n">index</span><span class="p">):</span>
    <span class="n">example</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="o">.</span><span class="n">index</span> <span class="o">==</span> <span class="n">index</span><span class="p">][[</span><span class="s1">&#39;Message&#39;</span><span class="p">,</span> <span class="s1">&#39;Category&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">example</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">example</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Message:&#39;</span><span class="p">,</span> <span class="n">example</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">print_message</span><span class="p">(</span><span class="mi">12</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>URGENT! You have won a 1 week FREE membership in our Â£100,000 Prize Jackpot! Txt the word: CLAIM to No: 81010 T&amp;C www.dbuk.net LCCLTD POBOX 4403LDNW1A7RW18
Message: spam
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">print_message</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...
Message: ham
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Preprocesamiento</span> <span class="pre">de</span> <span class="pre">Texto</span></code>: A continuación, establecemos una función para <code class="docutils literal notranslate"><span class="pre">transformar</span> <span class="pre">el</span> <span class="pre">texto</span> <span class="pre">a</span> <span class="pre">minúsculas</span> <span class="pre">y</span> <span class="pre">eliminar</span> <span class="pre">signos</span> <span class="pre">de</span> <span class="pre">puntuación/símbolos</span> <span class="pre">de</span> <span class="pre">las</span> <span class="pre">palabras</span></code>.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">bs4</span> <span class="kn">import</span> <span class="n">BeautifulSoup</span>

<span class="k">def</span> <span class="nf">cleanText</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="s2">&quot;lxml&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">text</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;\|\|\|&#39;</span><span class="p">,</span> <span class="sa">r</span><span class="s1">&#39; &#39;</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span> 
    <span class="n">text</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;http\S+&#39;</span><span class="p">,</span> <span class="sa">r</span><span class="s1">&#39;&lt;URL&gt;&#39;</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">text</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;Message&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Message&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">cleanText</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;Message&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Message&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">cleanText</span><span class="p">)</span>
<span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.000001</span> <span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">nltk</span>
<span class="kn">from</span> <span class="nn">nltk.corpus</span> <span class="kn">import</span> <span class="n">stopwords</span>
<span class="n">nltk</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="s1">&#39;punkt&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[nltk_data] Downloading package punkt to
[nltk_data]     C:\Users\RYZEN\AppData\Roaming\nltk_data...
[nltk_data]   Package punkt is already up-to-date!
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>True
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">tokenize_text</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="n">tokens</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">sent</span> <span class="ow">in</span> <span class="n">nltk</span><span class="o">.</span><span class="n">sent_tokenize</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">nltk</span><span class="o">.</span><span class="n">word_tokenize</span><span class="p">(</span><span class="n">sent</span><span class="p">):</span>
            <span class="c1">#if len(word) &lt; 0:</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">word</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">continue</span>
            <span class="n">tokens</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">word</span><span class="o">.</span><span class="n">lower</span><span class="p">())</span>
    <span class="k">return</span> <span class="n">tokens</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_tagged</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">r</span><span class="p">:</span> <span class="n">TaggedDocument</span><span class="p">(</span><span class="n">words</span><span class="o">=</span><span class="n">tokenize_text</span><span class="p">(</span><span class="n">r</span><span class="p">[</span><span class="s1">&#39;Message&#39;</span><span class="p">]),</span> <span class="n">tags</span><span class="o">=</span><span class="p">[</span><span class="n">r</span><span class="o">.</span><span class="n">Category</span><span class="p">]),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">test_tagged</span> <span class="o">=</span> <span class="n">test</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">r</span><span class="p">:</span> <span class="n">TaggedDocument</span><span class="p">(</span><span class="n">words</span><span class="o">=</span><span class="n">tokenize_text</span><span class="p">(</span><span class="n">r</span><span class="p">[</span><span class="s1">&#39;Message&#39;</span><span class="p">]),</span> <span class="n">tags</span><span class="o">=</span><span class="p">[</span><span class="n">r</span><span class="o">.</span><span class="n">Category</span><span class="p">]),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Número máximo de palabras a utilizar (<code class="docutils literal notranslate"><span class="pre">más</span> <span class="pre">frecuentes</span></code>)</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">max_fatures</span> <span class="o">=</span> <span class="mi">500000</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Número máximo de palabras en cada reclamación.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">MAX_SEQUENCE_LENGTH</span> <span class="o">=</span> <span class="mi">50</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">(</span><span class="n">num_words</span><span class="o">=</span><span class="n">max_fatures</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s1">&#39; &#39;</span><span class="p">,</span> <span class="n">filters</span><span class="o">=</span><span class="s1">&#39;!&quot;#$%&amp;()*+,-./:;&lt;=&gt;?@[\]^_`{|}~&#39;</span><span class="p">,</span> <span class="n">lower</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">tokenizer</span><span class="o">.</span><span class="n">fit_on_texts</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;Message&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">texts_to_sequences</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;Message&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">pad_sequences</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Found </span><span class="si">%s</span><span class="s1"> unique tokens.&#39;</span> <span class="o">%</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Found 5572 unique tokens.
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">texts_to_sequences</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;Message&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">pad_sequences</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">maxlen</span><span class="o">=</span><span class="n">MAX_SEQUENCE_LENGTH</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Shape of data tensor:&#39;</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Shape of data tensor: (5572, 50)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_tagged</span><span class="o">.</span><span class="n">values</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([TaggedDocument(words=[&#39;and&#39;, &#39;also&#39;, &#39;i&#39;, &quot;&#39;ve&quot;, &#39;sorta&#39;, &#39;blown&#39;, &#39;him&#39;, &#39;off&#39;, &#39;a&#39;, &#39;couple&#39;, &#39;times&#39;, &#39;recently&#39;, &#39;so&#39;, &#39;id&#39;, &#39;rather&#39;, &#39;not&#39;, &#39;tet&#39;, &#39;him&#39;, &#39;out&#39;, &#39;of&#39;, &#39;the&#39;, &#39;blue&#39;, &#39;looking&#39;, &#39;for&#39;, &#39;weed&#39;], tags=[&#39;ham&#39;]),
       TaggedDocument(words=[&#39;mmm&#39;, &#39;thats&#39;, &#39;better&#39;, &#39;now&#39;, &#39;i&#39;, &#39;got&#39;, &#39;a&#39;, &#39;roast&#39;, &#39;down&#39;, &#39;me&#39;, &#39;!&#39;, &#39;iâ\x92d&#39;, &#39;b&#39;, &#39;better&#39;, &#39;if&#39;, &#39;i&#39;, &#39;had&#39;, &#39;a&#39;, &#39;few&#39;, &#39;drinks&#39;, &#39;down&#39;, &#39;me&#39;, &#39;2&#39;, &#39;!&#39;, &#39;good&#39;, &#39;indian&#39;, &#39;?&#39;], tags=[&#39;ham&#39;]),
       TaggedDocument(words=[&#39;mm&#39;, &#39;have&#39;, &#39;some&#39;, &#39;kanji&#39;, &#39;dont&#39;, &#39;eat&#39;, &#39;anything&#39;, &#39;heavy&#39;, &#39;ok&#39;], tags=[&#39;ham&#39;]),
       ...,
       TaggedDocument(words=[&#39;prabha&#39;, &#39;..&#39;, &#39;i&#39;, &quot;&#39;m&quot;, &#39;soryda&#39;, &#39;..&#39;, &#39;realy&#39;, &#39;..&#39;, &#39;frm&#39;, &#39;heart&#39;, &#39;i&#39;, &quot;&#39;m&quot;, &#39;sory&#39;], tags=[&#39;ham&#39;]),
       TaggedDocument(words=[&#39;nt&#39;, &#39;joking&#39;, &#39;seriously&#39;, &#39;i&#39;, &#39;told&#39;], tags=[&#39;ham&#39;]),
       TaggedDocument(words=[&#39;did&#39;, &#39;he&#39;, &#39;just&#39;, &#39;say&#39;, &#39;somebody&#39;, &#39;is&#39;, &#39;named&#39;, &#39;tampa&#39;], tags=[&#39;ham&#39;])],
      dtype=object)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">d2v_model</span> <span class="o">=</span> <span class="n">Doc2Vec</span><span class="p">(</span><span class="n">dm</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dm_mean</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">vector_size</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">window</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">min_count</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.065</span><span class="p">,</span> <span class="n">min_alpha</span><span class="o">=</span><span class="mf">0.065</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">d2v_model</span><span class="o">.</span><span class="n">build_vocab</span><span class="p">([</span><span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">train_tagged</span><span class="o">.</span><span class="n">values</span><span class="p">)])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>100%|██████████| 5571/5571 [00:00&lt;00:00, 5568748.23it/s]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%time</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">30</span><span class="p">):</span>
    <span class="n">d2v_model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">utils</span><span class="o">.</span><span class="n">shuffle</span><span class="p">([</span><span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">train_tagged</span><span class="o">.</span><span class="n">values</span><span class="p">)]),</span> <span class="n">total_examples</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">train_tagged</span><span class="o">.</span><span class="n">values</span><span class="p">),</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">d2v_model</span><span class="o">.</span><span class="n">alpha</span> <span class="o">-=</span> <span class="mf">0.002</span>
    <span class="n">d2v_model</span><span class="o">.</span><span class="n">min_alpha</span> <span class="o">=</span> <span class="n">d2v_model</span><span class="o">.</span><span class="n">alpha</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>100%|██████████| 5571/5571 [00:00&lt;00:00, 5567421.39it/s]
100%|██████████| 5571/5571 [00:00&lt;00:00, 5566095.18it/s]
100%|██████████| 5571/5571 [00:00&lt;00:00, 5576722.57it/s]
100%|██████████| 5571/5571 [00:00&lt;00:00, 5560796.66it/s]
100%|██████████| 5571/5571 [00:00&lt;00:00, 5578053.85it/s]
100%|██████████| 5571/5571 [00:00&lt;00:00, 5580718.31it/s]
100%|██████████| 5571/5571 [00:00&lt;00:00, 5575391.93it/s]
100%|██████████| 5571/5571 [00:00&lt;00:00, 5571403.81it/s]
100%|██████████| 5571/5571 [00:00&lt;00:00, 5575391.93it/s]
100%|██████████| 5571/5571 [00:00&lt;00:00, 5568748.23it/s]
100%|██████████| 5571/5571 [00:00&lt;00:00, 5571403.81it/s]
100%|██████████| 5571/5571 [00:00&lt;00:00, 5582051.50it/s]
100%|██████████| 5571/5571 [00:00&lt;00:00, 5578053.85it/s]
100%|██████████| 5571/5571 [00:00&lt;?, ?it/s]
100%|██████████| 5571/5571 [00:00&lt;00:00, 989517.56it/s]
100%|██████████| 5571/5571 [00:00&lt;?, ?it/s]
100%|██████████| 5571/5571 [00:00&lt;?, ?it/s]
100%|██████████| 5571/5571 [00:00&lt;?, ?it/s]
100%|██████████| 5571/5571 [00:00&lt;?, ?it/s]
100%|██████████| 5571/5571 [00:00&lt;?, ?it/s]
100%|██████████| 5571/5571 [00:00&lt;00:00, 982114.47it/s]
100%|██████████| 5571/5571 [00:00&lt;?, ?it/s]
100%|██████████| 5571/5571 [00:00&lt;?, ?it/s]
100%|██████████| 5571/5571 [00:00&lt;?, ?it/s]
100%|██████████| 5571/5571 [00:00&lt;?, ?it/s]
100%|██████████| 5571/5571 [00:00&lt;?, ?it/s]
100%|██████████| 5571/5571 [00:00&lt;?, ?it/s]
100%|██████████| 5571/5571 [00:00&lt;?, ?it/s]
100%|██████████| 5571/5571 [00:00&lt;?, ?it/s]
100%|██████████| 5571/5571 [00:00&lt;00:00, 12931083.33it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>CPU times: total: 156 ms
Wall time: 3.62 s
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">d2v_model</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Doc2Vec(dm/m,d20,n5,w8,s0.001)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="n">d2v_model</span><span class="o">.</span><span class="n">wv</span><span class="o">.</span><span class="n">vocab</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>9361
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">embedding_matrix</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">d2v_model</span><span class="o">.</span><span class="n">wv</span><span class="o">.</span><span class="n">vocab</span><span class="p">)</span><span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">20</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">vec</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">d2v_model</span><span class="o">.</span><span class="n">docvecs</span><span class="o">.</span><span class="n">vectors_docs</span><span class="p">):</span>
    <span class="k">while</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">vec</span> <span class="o">&lt;=</span> <span class="mi">1000</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">docvecs</span><span class="p">)</span>
        <span class="n">embedding_matrix</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">=</span><span class="n">vec</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">vec</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">vec</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">d2v_model</span><span class="o">.</span><span class="n">wv</span><span class="o">.</span><span class="n">most_similar</span><span class="p">(</span><span class="n">positive</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;urgent&#39;</span><span class="p">],</span> <span class="n">topn</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[(&#39;callertune&#39;, 0.7417731285095215),
 (&#39;complimentary&#39;, 0.7257477641105652),
 (&#39;callers&#39;, 0.7241694927215576),
 (&#39;too.pray&#39;, 0.7053099274635315),
 (&#39;having&#39;, 0.7046895027160645),
 (&#39;kr&#39;, 0.6934264898300171),
 (&#39;11mths+&#39;, 0.6931026577949524),
 (&#39;recorded&#39;, 0.6915187239646912),
 (&#39;02&#39;, 0.6887190341949463),
 (&#39;inshah&#39;, 0.6864621639251709)]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">d2v_model</span><span class="o">.</span><span class="n">wv</span><span class="o">.</span><span class="n">most_similar</span><span class="p">(</span><span class="n">positive</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;cherish&#39;</span><span class="p">],</span> <span class="n">topn</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[(&#39;okors&#39;, 0.8226171135902405),
 (&#39;wishing&#39;, 0.759000301361084),
 (&#39;importantly&#39;, 0.7066915035247803),
 (&#39;stranger&#39;, 0.6922898292541504),
 (&#39;mojibiola&#39;, 0.686636209487915),
 (&#39;reached&#39;, 0.6843720078468323),
 (&#39;thank&#39;, 0.680390477180481),
 (&#39;fried&#39;, 0.6772780418395996),
 (&#39;arent&#39;, 0.6753636598587036),
 (&#39;intrepid&#39;, 0.6706898212432861)]
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Modelo <code class="docutils literal notranslate"><span class="pre">LSTM</span></code></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">LSTM</span><span class="p">,</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">Embedding</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.optimizers.legacy</span> <span class="kn">import</span> <span class="n">Adam</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Layer inicial</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Vectores de palabras emmbed</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Embedding</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">d2v_model</span><span class="o">.</span><span class="n">wv</span><span class="o">.</span><span class="n">vocab</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span><span class="mi">20</span><span class="p">,</span><span class="n">input_length</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">weights</span><span class="o">=</span><span class="p">[</span><span class="n">embedding_matrix</span><span class="p">],</span><span class="n">trainable</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Aprender las correlaciones</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">split_input</span><span class="p">(</span><span class="n">sequence</span><span class="p">):</span>
     <span class="k">return</span> <span class="n">sequence</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">sequence</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">LSTM</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span><span class="n">return_sequences</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="s2">&quot;softmax&quot;</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Esqueleto del modelo de salida</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Model: &quot;sequential_1&quot;
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 embedding (Embedding)       (None, 50, 20)            187240    
                                                                 
 lstm (LSTM)                 (None, 50)                14200     
                                                                 
 dense_2 (Dense)             (None, 2)                 102       
                                                                 
=================================================================
Total params: 201,542
Trainable params: 201,542
Non-trainable params: 0
_________________________________________________________________
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">Adam</span><span class="p">(),</span><span class="n">loss</span><span class="o">=</span><span class="s2">&quot;binary_crossentropy&quot;</span><span class="p">,</span><span class="n">metrics</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">keras.utils</span> <span class="kn">import</span> <span class="n">plot_model</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">to_file</span><span class="o">=</span><span class="s1">&#39;model.png&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Y</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;Category&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">values</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">,</span> <span class="n">Y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">Y</span><span class="p">,</span> <span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.15</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">42</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span><span class="n">Y_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span><span class="n">Y_test</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(4736, 50) (4736, 2)
(836, 50) (836, 2)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">32</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">history</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">,</span> <span class="n">epochs</span> <span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">verbose</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/50
148/148 - 2s - loss: 0.3152 - accuracy: 0.8999 - 2s/epoch - 14ms/step
Epoch 2/50
148/148 - 1s - loss: 0.0614 - accuracy: 0.9848 - 719ms/epoch - 5ms/step
Epoch 3/50
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>148/148 - 1s - loss: 0.0231 - accuracy: 0.9945 - 711ms/epoch - 5ms/step
Epoch 4/50
148/148 - 1s - loss: 0.0127 - accuracy: 0.9977 - 631ms/epoch - 4ms/step
Epoch 5/50
148/148 - 1s - loss: 0.0086 - accuracy: 0.9979 - 625ms/epoch - 4ms/step
Epoch 6/50
148/148 - 1s - loss: 0.0047 - accuracy: 0.9987 - 636ms/epoch - 4ms/step
Epoch 7/50
148/148 - 1s - loss: 0.0030 - accuracy: 0.9992 - 638ms/epoch - 4ms/step
Epoch 8/50
148/148 - 1s - loss: 0.0016 - accuracy: 0.9996 - 687ms/epoch - 5ms/step
Epoch 9/50
148/148 - 1s - loss: 0.0012 - accuracy: 0.9996 - 632ms/epoch - 4ms/step
Epoch 10/50
148/148 - 1s - loss: 8.2196e-04 - accuracy: 0.9998 - 681ms/epoch - 5ms/step
Epoch 11/50
148/148 - 1s - loss: 7.4159e-04 - accuracy: 0.9998 - 620ms/epoch - 4ms/step
Epoch 12/50
148/148 - 1s - loss: 0.0042 - accuracy: 0.9992 - 665ms/epoch - 4ms/step
Epoch 13/50
148/148 - 1s - loss: 0.0016 - accuracy: 0.9992 - 711ms/epoch - 5ms/step
Epoch 14/50
148/148 - 1s - loss: 6.7957e-04 - accuracy: 0.9998 - 621ms/epoch - 4ms/step
Epoch 15/50
148/148 - 1s - loss: 4.9438e-04 - accuracy: 1.0000 - 612ms/epoch - 4ms/step
Epoch 16/50
148/148 - 1s - loss: 3.3065e-04 - accuracy: 1.0000 - 663ms/epoch - 4ms/step
Epoch 17/50
148/148 - 1s - loss: 2.3817e-04 - accuracy: 1.0000 - 673ms/epoch - 5ms/step
Epoch 18/50
148/148 - 1s - loss: 1.6767e-04 - accuracy: 1.0000 - 669ms/epoch - 5ms/step
Epoch 19/50
148/148 - 1s - loss: 1.5303e-04 - accuracy: 1.0000 - 626ms/epoch - 4ms/step
Epoch 20/50
148/148 - 1s - loss: 1.1743e-04 - accuracy: 1.0000 - 637ms/epoch - 4ms/step
Epoch 21/50
148/148 - 1s - loss: 9.7130e-05 - accuracy: 1.0000 - 583ms/epoch - 4ms/step
Epoch 22/50
148/148 - 1s - loss: 8.1414e-05 - accuracy: 1.0000 - 593ms/epoch - 4ms/step
Epoch 23/50
148/148 - 1s - loss: 7.4646e-05 - accuracy: 1.0000 - 598ms/epoch - 4ms/step
Epoch 24/50
148/148 - 1s - loss: 6.1895e-05 - accuracy: 1.0000 - 587ms/epoch - 4ms/step
Epoch 25/50
148/148 - 1s - loss: 5.2738e-05 - accuracy: 1.0000 - 596ms/epoch - 4ms/step
Epoch 26/50
148/148 - 1s - loss: 4.6148e-05 - accuracy: 1.0000 - 590ms/epoch - 4ms/step
Epoch 27/50
148/148 - 1s - loss: 4.2166e-05 - accuracy: 1.0000 - 693ms/epoch - 5ms/step
Epoch 28/50
148/148 - 1s - loss: 3.8991e-05 - accuracy: 1.0000 - 662ms/epoch - 4ms/step
Epoch 29/50
148/148 - 1s - loss: 4.4513e-05 - accuracy: 1.0000 - 709ms/epoch - 5ms/step
Epoch 30/50
148/148 - 1s - loss: 3.7906e-05 - accuracy: 1.0000 - 644ms/epoch - 4ms/step
Epoch 31/50
148/148 - 1s - loss: 2.9044e-05 - accuracy: 1.0000 - 649ms/epoch - 4ms/step
Epoch 32/50
148/148 - 1s - loss: 2.6507e-05 - accuracy: 1.0000 - 614ms/epoch - 4ms/step
Epoch 33/50
148/148 - 1s - loss: 2.1705e-05 - accuracy: 1.0000 - 686ms/epoch - 5ms/step
Epoch 34/50
148/148 - 1s - loss: 2.1052e-05 - accuracy: 1.0000 - 621ms/epoch - 4ms/step
Epoch 35/50
148/148 - 1s - loss: 1.8606e-05 - accuracy: 1.0000 - 731ms/epoch - 5ms/step
Epoch 36/50
148/148 - 1s - loss: 0.0018 - accuracy: 0.9996 - 669ms/epoch - 5ms/step
Epoch 37/50
148/148 - 1s - loss: 0.0071 - accuracy: 0.9989 - 699ms/epoch - 5ms/step
Epoch 38/50
148/148 - 1s - loss: 0.0032 - accuracy: 0.9989 - 719ms/epoch - 5ms/step
Epoch 39/50
148/148 - 1s - loss: 2.1758e-04 - accuracy: 1.0000 - 709ms/epoch - 5ms/step
Epoch 40/50
148/148 - 1s - loss: 1.3199e-04 - accuracy: 1.0000 - 619ms/epoch - 4ms/step
Epoch 41/50
148/148 - 1s - loss: 9.7160e-05 - accuracy: 1.0000 - 660ms/epoch - 4ms/step
Epoch 42/50
148/148 - 1s - loss: 7.6061e-05 - accuracy: 1.0000 - 615ms/epoch - 4ms/step
Epoch 43/50
148/148 - 1s - loss: 6.1429e-05 - accuracy: 1.0000 - 599ms/epoch - 4ms/step
Epoch 44/50
148/148 - 1s - loss: 5.0968e-05 - accuracy: 1.0000 - 595ms/epoch - 4ms/step
Epoch 45/50
148/148 - 1s - loss: 4.3189e-05 - accuracy: 1.0000 - 579ms/epoch - 4ms/step
Epoch 46/50
148/148 - 1s - loss: 3.6979e-05 - accuracy: 1.0000 - 611ms/epoch - 4ms/step
Epoch 47/50
148/148 - 1s - loss: 3.2034e-05 - accuracy: 1.0000 - 645ms/epoch - 4ms/step
Epoch 48/50
148/148 - 1s - loss: 2.7916e-05 - accuracy: 1.0000 - 652ms/epoch - 4ms/step
Epoch 49/50
148/148 - 1s - loss: 2.4466e-05 - accuracy: 1.0000 - 710ms/epoch - 5ms/step
Epoch 50/50
148/148 - 1s - loss: 2.1630e-05 - accuracy: 1.0000 - 760ms/epoch - 5ms/step
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;model accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;acc&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;epochs&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="s1">&#39;test&#39;</span><span class="p">],</span> <span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper left&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;matplotlib.legend.Legend at 0x27d1440b7f0&gt;
</pre></div>
</div>
<img alt="_images/394aa176b915927c9db8f5e98b3e48835716649c30d730bdbb9c29e49820bffd.png" src="_images/394aa176b915927c9db8f5e98b3e48835716649c30d730bdbb9c29e49820bffd.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;model loss&#39;</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;loss&#39;</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;epochs&#39;</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="s1">&#39;test&#39;</span><span class="p">],</span> <span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper left&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/5c16ccb3a378a315f960dad0c102f02e3c624124bb9839a8688f388b80e04d88.png" src="_images/5c16ccb3a378a315f960dad0c102f02e3c624124bb9839a8688f388b80e04d88.png" />
</div>
</div>
<ul class="simple">
<li><p>Evaluar el modelo</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">_</span><span class="p">,</span> <span class="n">train_acc</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">_</span><span class="p">,</span> <span class="n">test_acc</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Train: </span><span class="si">%.3f</span><span class="s1">, Test: </span><span class="si">%.4f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">train_acc</span><span class="p">,</span> <span class="n">test_acc</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>148/148 - 1s - loss: 2.0078e-05 - accuracy: 1.0000 - 506ms/epoch - 3ms/step
27/27 - 0s - loss: 0.0810 - accuracy: 0.9868 - 290ms/epoch - 11ms/step
Train: 1.000, Test: 0.9868
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Predecir probabilidades para el conjunto de prueba</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">yhat_probs</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">yhat_probs</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[[1.0000000e+00 1.1301586e-12]
 [1.0000000e+00 5.7517641e-10]
 [1.0000000e+00 1.9218569e-11]
 ...
 [1.0000000e+00 2.7485768e-12]
 [1.0000000e+00 7.8390181e-13]
 [1.0000000e+00 3.4388992e-11]]
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Predecir clases crisp para el conjunto de prueba</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">yhat_classes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">yhat_probs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">yhat_classes</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1 1
 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0
 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0
 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0
 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0
 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0
 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0
 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 1 1 0 0 0 0 0 1 1 0 0
 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0
 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0
 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0
 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0]
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Reducir a matriz 1d</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">yhat_probs</span> <span class="o">=</span> <span class="n">yhat_probs</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rounded_labels</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">Y_test</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">rounded_labels</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,
       0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,
       0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0,
       0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,
       0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,
       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,
       1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,
       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,
       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0,
       1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,
       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,
       0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,
       0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0],
      dtype=int64)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cm</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">rounded_labels</span><span class="p">,</span> <span class="n">yhat_classes</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cm</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[725,   4],
       [  7, 100]], dtype=int64)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">lstm_val</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">rounded_labels</span><span class="p">,</span> <span class="n">yhat_classes</span><span class="p">)</span>
<span class="n">f</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">lstm_val</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">linecolor</span><span class="o">=</span><span class="s1">&#39;cyan&#39;</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s1">&#39;g&#39;</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;BuPu&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;LSTM Classification Confusion Matrix&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Y predict&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Y test&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/2112f620fe5de50f1e5491dfd223b964e3eaab681ab6e954cc59c3c70d44b774.png" src="_images/2112f620fe5de50f1e5491dfd223b964e3eaab681ab6e954cc59c3c70d44b774.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">validation_size</span> <span class="o">=</span> <span class="mi">200</span>

<span class="n">X_validate</span> <span class="o">=</span> <span class="n">X_test</span><span class="p">[</span><span class="o">-</span><span class="n">validation_size</span><span class="p">:]</span>
<span class="n">Y_validate</span> <span class="o">=</span> <span class="n">Y_test</span><span class="p">[</span><span class="o">-</span><span class="n">validation_size</span><span class="p">:]</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">X_test</span><span class="p">[:</span><span class="o">-</span><span class="n">validation_size</span><span class="p">]</span>
<span class="n">Y_test</span> <span class="o">=</span> <span class="n">Y_test</span><span class="p">[:</span><span class="o">-</span><span class="n">validation_size</span><span class="p">]</span>
<span class="n">score</span><span class="p">,</span><span class="n">acc</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">,</span> <span class="n">verbose</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;score: </span><span class="si">%.2f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">score</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;acc: </span><span class="si">%.2f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">acc</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>20/20 [==============================] - 0s 4ms/step - loss: 0.0980 - accuracy: 0.9843
score: 0.10
acc: 0.98
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;Mymodel.h5&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Pruebas con conjuntos de datos nuevos y diferentes de los datos para construir el modelo.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">message</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Congratulations! you have won a $1,000 Walmart gift card. Go to http://bit.ly/123456 to claim now.&#39;</span><span class="p">]</span>
<span class="n">seq</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">texts_to_sequences</span><span class="p">(</span><span class="n">message</span><span class="p">)</span>

<span class="n">padded</span> <span class="o">=</span> <span class="n">pad_sequences</span><span class="p">(</span><span class="n">seq</span><span class="p">,</span> <span class="n">maxlen</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;int32&#39;</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">padded</span><span class="p">)</span>

<span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;ham&#39;</span><span class="p">,</span><span class="s1">&#39;spam&#39;</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">labels</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">pred</span><span class="p">)])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1/1 [==============================] - 0s 13ms/step
[[2.5199483e-06 9.9999750e-01]] spam
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">message</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;thanks for accepting my request to connect&#39;</span><span class="p">]</span>
<span class="n">seq</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">texts_to_sequences</span><span class="p">(</span><span class="n">message</span><span class="p">)</span>

<span class="n">padded</span> <span class="o">=</span> <span class="n">pad_sequences</span><span class="p">(</span><span class="n">seq</span><span class="p">,</span> <span class="n">maxlen</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;int32&#39;</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">padded</span><span class="p">)</span>

<span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;ham&#39;</span><span class="p">,</span><span class="s1">&#39;spam&#39;</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">labels</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">pred</span><span class="p">)])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1/1 [==============================] - 0s 13ms/step
[[1.0000000e+00 1.7864337e-11]] ham
</pre></div>
</div>
</div>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="svm_model.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Máquinas de vectores de soporte</p>
      </div>
    </a>
    <a class="right-next"
       href="practical_pca.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Análisis de Componentes Principales</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gradiente-descendiente">Gradiente descendiente</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#redes-neuronales">Redes neuronales</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#el-perceptron">El perceptrón</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#redes-neuronales-multicapa-feed-forward">Redes Neuronales Multicapa Feed-Forward</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#redes-totalmente-conectadas">Redes Totalmente Conectadas</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#el-algoritmo-de-backpropagation">El Algoritmo De Backpropagation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#el-esquema-de-backpropagation-para-gradiente-descendiente">El Esquema De Backpropagation Para Gradiente Descendiente</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#calculo-de-gradientes">Cálculo de gradientes</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#calculo-de-delta-nj-r">Cálculo de <span class="math notranslate nohighlight">\(\delta_{nj}^{r}\)</span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tuning-de-redes-neuronales">Tuning de Redes Neuronales</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#analisis-de-malware-por-api-calls">Análisis de Malware por API calls</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#redes-neuronales-convolucionales">Redes Neuronales Convolucionales</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#la-necesidad-de-convoluciones">La necesidad de convoluciones</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#la-etapa-de-convolucion">La etapa de convolución</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#el-paso-de-la-no-linealidad">El paso de la no linealidad</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#la-etapa-de-agrupacion">La etapa de agrupación</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#convolucion-sobre-volumenes">Convolución sobre volúmenes</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#red-en-red-y-convolucion-1-1">Red en red y convolución 1 × 1</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#arquitectura-cnn-completa">Arquitectura CNN completa</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#arquitecturas-de-redes-neuronales-convolucionales">Arquitecturas de Redes Neuronales Convolucionales</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#reconocimiento-facial-de-emociones">Reconocimiento facial de emociones</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#redes-neuronales-recurrentes">Redes Neuronales Recurrentes</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#backpropagation-en-tiempo">Backpropagation en tiempo</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#desvanecimiento-y-explosion-de-gradientes">Desvanecimiento y explosión de gradientes</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#red-de-memoria-a-largo-plazo-lstm">Red de memoria a largo plazo (LSTM)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#atencion-y-memoria">Atención y Memoria</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#entrenamiento-adversario">Entrenamiento adversario</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#modelos-generativos-profundos">Modelos Generativos Profundos</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#maquina-de-boltzmann-restringida">Máquina de Boltzmann Restringida</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#autoencoders">Autoencoders</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#aplicacion-procesamiento-del-lenguaje-natural">Aplicación: Procesamiento del Lenguaje Natural</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Lihki Rubio, Ph.D.
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
<div class="extra_footer">
  <p>Lihki Rubio, Ph.D. All rights reserved.</p>
</div>
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>