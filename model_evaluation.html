
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>16. Evaluación de modelos &#8212; Machine Learning</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/proof.css?v=b4b7a797" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="_static/custom.css?v=530fe47d" />
    <link rel="stylesheet" type="text/css" href="_static/.ipynb_checkpoints/custom-checkpoint.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9bcbadda"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.0/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'model_evaluation';</script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="_static/custom.js?v=14184634"></script>
    <script src="_static/.ipynb_checkpoints/custom-checkpoint.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="17. Cadenas de Algoritmos y Pipelines" href="chains_pipelines.html" />
    <link rel="prev" title="15. Análisis de Componentes Principales" href="practical_pca.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/fotolihki.jpg" class="logo__image only-light" alt="Machine Learning - Home"/>
    <script>document.write(`<img src="_static/fotolihki.jpg" class="logo__image only-dark" alt="Machine Learning - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Profesor: Dr. Lihki Rubio
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="supervised_intro.html">1. Aprendizaje supervisado</a></li>
<li class="toctree-l1"><a class="reference internal" href="knn_model.html">2. <span class="math notranslate nohighlight">\(k\)</span>-vecinos más cercanos</a></li>
<li class="toctree-l1"><a class="reference internal" href="linear_model.html">3. Regresión Ridge y Lasso</a></li>
<li class="toctree-l1"><a class="reference internal" href="bayes_model.html">4. Clasificador Bayesiano</a></li>
<li class="toctree-l1"><a class="reference internal" href="decisiontree_model.html">5. Random Forest y XGBoost</a></li>


<li class="toctree-l1"><a class="reference internal" href="svm_model.html">8. Máquinas de vectores de soporte</a></li>
<li class="toctree-l1"><a class="reference internal" href="ann_model.html">9. Redes Neuronales y Deep Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="dl_computer_vision.html">10. Computer vision</a></li>




<li class="toctree-l1"><a class="reference internal" href="practical_pca.html">15. Análisis de Componentes Principales</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">16. Evaluación de modelos</a></li>
<li class="toctree-l1"><a class="reference internal" href="chains_pipelines.html">17. Cadenas de Algoritmos y Pipelines</a></li>
<li class="toctree-l1"><a class="reference internal" href="appendix.html">18. Apéndice</a></li>
<li class="toctree-l1"><a class="reference internal" href="biblio.html">19. Bibliografía</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/model_evaluation.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Evaluación de modelos</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cross-validation">16.1. Cross-Validation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#validacion-cruzada-en-scikit-learn">16.1.1. Validación cruzada en scikit-learn</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ventajas-de-la-validacion-cruzada">16.1.2. Ventajas de la validación cruzada</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#validacion-cruzada-estratificada-k-fold-y-otras-estrategias">16.1.3. Validación cruzada estratificada <span class="math notranslate nohighlight">\(k\)</span>-fold y otras estrategias</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mas-control-sobre-la-validacion-cruzada">16.1.4. Más control sobre la validación cruzada</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#validacion-cruzada-con-exclusion-leave-one-out">16.1.5. Validación cruzada con exclusión (<code class="docutils literal notranslate"><span class="pre">leave-one-out</span></code>)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#validacion-cruzada-aleatoria-y-dividida">16.1.6. Validación cruzada aleatoria y dividida</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#validacion-cruzada-con-grupos">16.1.7. Validación cruzada con grupos</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#grid-search">16.2. Grid Search</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#grid-search-simple">16.2.1. Grid Search simple</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#el-peligro-de-sobreajustar-los-parametros-y-el-conjunto-de-validacion">16.2.2. El peligro de sobreajustar los parámetros y el conjunto de validación</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#grid-search-con-validacion-cruzada">16.2.3. Grid Search con validación cruzada</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#analisis-del-resultado-de-la-validacion-cruzada">16.2.4. Análisis del resultado de la validación cruzada</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#busqueda-sobre-espacios-que-no-son-una-red">16.2.5. Búsqueda sobre espacios que no son una red</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#validacion-cruzada-anidada">16.2.6. Validación cruzada anidada</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#paralelizacion-de-la-validacion-cruzada-y-la-busqueda-en-red">16.2.7. Paralelización de la validación cruzada y la búsqueda en red</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#metricas-de-evaluacion-y-scoring">16.3. Métricas de evaluación y scoring</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#tenga-en-cuenta-el-objetivo-final">16.3.1. Tenga en cuenta el objetivo final</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#metricas-para-la-clasificacion-binaria">16.3.2. Métricas para la clasificación binaria</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#tipos-de-errores">16.3.3. Tipos de errores</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#conjuntos-de-datos-desequilibrados">16.3.4. Conjuntos de datos desequilibrados</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#matrices-de-confusion">16.3.5. Matrices de confusión</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#teniendo-en-cuenta-la-incertidumbre">16.3.6. Teniendo en cuenta la incertidumbre</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#curvas-precision-recall-y-roc">16.4. Curvas precision-recall y ROC</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#caracteristicas-operativas-del-receptor-roc-y-auc">16.4.1. Características operativas del receptor (ROC) y AUC</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#metricas-para-la-clasificacion-multiclase">16.5. Métricas para la clasificación multiclase</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#metricas-de-regresion">16.6. Métricas de regresión</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#uso-de-metricas-de-evaluacion-en-la-seleccion-de-modelos">16.6.1. Uso de métricas de evaluación en la selección de modelos</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="evaluacion-de-modelos">
<h1><span class="section-number">16. </span>Evaluación de modelos<a class="headerlink" href="#evaluacion-de-modelos" title="Link to this heading">#</a></h1>
<div class="tip admonition">
<p class="admonition-title">Introducción</p>
<ul class="simple">
<li><p>Después de discutir los <em><strong>fundamentos del aprendizaje supervisado y sus algoritmos</strong></em>, abordaremos la <em><strong>evaluación de modelos</strong></em> y la <em><strong>selección de parámetros</strong></em>. Nos enfocaremos en modelos supervisados, específicamente en <em><strong>regresión y clasificación</strong></em>, ya que la evaluación en aprendizaje no supervisado es más cualitativa.</p></li>
<li><p>Para evaluar modelos supervisados, dividimos el conjunto de datos en <em><strong>entrenamiento y prueba</strong></em> usando <code class="docutils literal notranslate"><span class="pre">train_test_split</span></code>, construimos un modelo con <code class="docutils literal notranslate"><span class="pre">fit</span></code>, y lo evaluamos en el conjunto de prueba con <code class="docutils literal notranslate"><span class="pre">score</span></code>, que calcula la fracción de muestras correctamente clasificadas.</p></li>
</ul>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_blobs</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Creamos un conjunto de <em><strong>datos sintético</strong></em></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_blobs</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p><em><strong>Dividimos</strong></em> los datos y las etiquetas en un <em><strong>conjunto de entrenamiento y otro de prueba</strong></em></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p><em><strong>Instanciar</strong></em> el modelo y <em><strong>ajustarlo al conjunto de entrenamiento</strong></em></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">logreg</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p><em><strong>Evaluar</strong></em> el modelo en el <em><strong>conjunto de prueba</strong></em></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test set score: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">logreg</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Test set score: 0.88
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p><em><strong>Evaluar</strong></em> el modelo en el <em><strong>conjunto de entrenamiento</strong></em></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Train set score: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">logreg</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Train set score: 0.91
</pre></div>
</div>
</div>
</div>
<div class="tip admonition">
<p class="admonition-title">Observación</p>
<ul class="simple">
<li><p>Recuerde que la razón por la que dividimos nuestros datos en conjuntos de entrenamiento y de prueba, es que estamos interesados en medir lo bien que nuestro modelo se generaliza a nuevos datos (<em>no vistos anteriormente</em>).</p></li>
<li><p><em><strong>No nos interesa lo bien que nuestro modelo se ajusta al conjunto de entrenamiento, sino lo bien que puede hacer predicciones sobre datos no observados durante el entrenamiento</strong></em>.</p></li>
</ul>
</div>
<ul class="simple">
<li><p>En esta sección, ampliaremos dos aspectos de esta evaluación. En primer lugar, introduciremos la <em><strong>validación cruzada</strong></em> (<code class="docutils literal notranslate"><span class="pre">cross-validation</span></code>), una forma más sólida de <em><strong>evaluar el rendimiento de la generalización</strong></em>, y discutiremos los <em><strong>métodos para evaluar el rendimiento de la clasificación y la regresión</strong></em> que van más allá de las medidas por defecto <code class="docutils literal notranslate"><span class="pre">accuracy</span></code> y <span class="math notranslate nohighlight">\(R^2\)</span> proporcionadas por el método <code class="docutils literal notranslate"><span class="pre">score</span></code>.</p></li>
<li><p>También hablaremos del <code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code>, un método eficaz para ajustar los parámetros de los modelos supervisados y obtener el <em><strong>mejor rendimiento de la generalización</strong></em>.</p></li>
</ul>
<section id="cross-validation">
<h2><span class="section-number">16.1. </span>Cross-Validation<a class="headerlink" href="#cross-validation" title="Link to this heading">#</a></h2>
<div class="tip admonition">
<p class="admonition-title">Introducción</p>
<ul class="simple">
<li><p>La <em><strong>validación cruzada</strong></em> (<code class="docutils literal notranslate"><span class="pre">cross-validation</span></code>) es un <em><strong>método estadístico para evaluar el rendimiento de la generalización</strong></em> que es <em>más estable y exhaustivo que el uso de una división en un conjunto de entrenamiento y otro de prueba</em>.</p></li>
<li><p>En la validación cruzada, <em><strong>los datos se dividen repetidamente y se entrenan múltiples modelos</strong></em>. La versión más utilizada de la validación cruzada es <code class="docutils literal notranslate"><span class="pre">k-fold</span> <span class="pre">cross-validation</span></code>, donde <code class="docutils literal notranslate"><span class="pre">k</span></code> es un número <em><strong>especificado por el usuario, normalmente 5 o 10</strong></em>.</p></li>
</ul>
</div>
<ul class="simple">
<li><p>Cuando se realiza la validación cruzada <code class="docutils literal notranslate"><span class="pre">five-fold</span></code>, <em><strong>los datos se dividen primero en cinco partes de tamaño (aproximadamente) igual, llamadas pliegues (<code class="docutils literal notranslate"><span class="pre">folds</span></code>)</strong></em>. A continuación, se entrena una secuencia de modelos. <em><strong>El primer modelo se entrena utilizando el primer pliegue como conjunto de prueba, y los pliegues restantes (2-5) se utilizan como conjunto de entrenamiento. El modelo se construye utilizando los datos de los pliegues 2-5, y luego se evalúa accuracy en el pliegue 1</strong></em>.</p></li>
<li><p>A continuación, luego se construye otro modelo, esta vez utilizando el <em><strong>pliegue 2 como conjunto de prueba y los datos de los pliegues 1, 3, 4 y 5 como conjunto de entrenamiento</strong></em>. Este proceso se repite utilizando los pliegues 3, 4 y 5 como conjuntos de prueba. <em><strong>Para cada una de estas cinco divisiones de los datos en conjuntos de entrenamiento y de prueba, calculamos</strong></em> <code class="docutils literal notranslate"><span class="pre">accuracy</span></code>. Al final, hemos recogido cinco valores de <code class="docutils literal notranslate"><span class="pre">accuracy</span></code>.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mglearn</span>
<span class="n">mglearn</span><span class="o">.</span><span class="n">plots</span><span class="o">.</span><span class="n">plot_cross_validation</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/464ba17b4c200310244bcd04b0b83810a15c15e388b3bdb0c2b90033a9130eb5.png" src="_images/464ba17b4c200310244bcd04b0b83810a15c15e388b3bdb0c2b90033a9130eb5.png" />
</div>
</div>
<ul class="simple">
<li><p>Normalmente, la primera quinta parte de los datos es conocida como el <em><strong>primer fold</strong></em>, la segunda quinta parte de los datos es el
<em><strong>segundo fold</strong></em>, y así sucesivamente.</p></li>
</ul>
<section id="validacion-cruzada-en-scikit-learn">
<h3><span class="section-number">16.1.1. </span>Validación cruzada en scikit-learn<a class="headerlink" href="#validacion-cruzada-en-scikit-learn" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>La validación cruzada se implementa en <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code> utilizando la función <code class="docutils literal notranslate"><span class="pre">cross_val_score</span></code> del módulo <code class="docutils literal notranslate"><span class="pre">model_selection</span></code>. <em><strong>Los parámetros de la función</strong></em> <code class="docutils literal notranslate"><span class="pre">cross_val_score</span></code> <em><strong>son, el modelo que queremos evaluar, los datos de entrenamiento y las etiquetas reales</strong></em>. Vamos a evaluar <code class="docutils literal notranslate"><span class="pre">LogisticRegression</span></code> en el conjunto de datos <code class="docutils literal notranslate"><span class="pre">iris</span></code>.</p></li>
<li><p>Utilizaremos los <em><strong>parámetros por defecto de este modelo</strong></em>, más adelante estudiaremos como conseguir los más óptimos por medio de <code class="docutils literal notranslate"><span class="pre">grid-search</span></code>, por ahora solo estamos interesados en <em><strong>evaluar el modelo por defecto usando</strong></em> <code class="docutils literal notranslate"><span class="pre">cross_val_score</span></code>. Para más información acerca de los argumentos del modelo (ver <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html">sklearn.linear_model.LogisticRegression</a>).</p></li>
</ul>
<div class="tip admonition">
<p class="admonition-title">Iris dataset</p>
<ul class="simple">
<li><p><strong>Objetivo Principal</strong>: <em>Predecir la especie de una flor <code class="docutils literal notranslate"><span class="pre">iris</span></code> basándose en medidas de sus características morfológicas</em>. El dataset contiene tres especies de <code class="docutils literal notranslate"><span class="pre">iris</span></code>: <code class="docutils literal notranslate"><span class="pre">setosa</span></code>, <code class="docutils literal notranslate"><span class="pre">versicolor</span></code> y <code class="docutils literal notranslate"><span class="pre">virginica</span></code>, y las características medidas son el largo y el ancho del sépalo y el pétalo.</p></li>
<li><p><em><strong>Uso</strong></em>: Este problema de clasificación permite evaluar la <em>capacidad de un modelo para diferenciar entre las especies basándose en características continuas</em>.</p></li>
</ul>
</div>
<figure class="align-center">
<a class="reference internal image-reference" href="_images/iris_dataset.png"><img alt="_images/iris_dataset.png" src="_images/iris_dataset.png" style="width: 700.0px; height: 524.8000000000001px;" /></a>
</figure>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_iris</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">iris</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(150, 4)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">iris</span><span class="o">.</span><span class="n">target</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(150,)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">feature</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">iris</span><span class="o">.</span><span class="n">feature_names</span><span class="p">):</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">feature</span><span class="si">}</span><span class="s2">:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Mean: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Std: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Min: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Max: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  25th percentile (Q1): </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="w"> </span><span class="mi">25</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Median (Q2): </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  75th percentile (Q3): </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="w"> </span><span class="mi">75</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>sepal length (cm):
  Mean: 5.843333333333334
  Std: 0.8253012917851409
  Min: 4.3
  Max: 7.9
  25th percentile (Q1): 5.1
  Median (Q2): 5.8
  75th percentile (Q3): 6.4

sepal width (cm):
  Mean: 3.0573333333333337
  Std: 0.4344109677354946
  Min: 2.0
  Max: 4.4
  25th percentile (Q1): 2.8
  Median (Q2): 3.0
  75th percentile (Q3): 3.3

petal length (cm):
  Mean: 3.7580000000000005
  Std: 1.759404065775303
  Min: 1.0
  Max: 6.9
  25th percentile (Q1): 1.6
  Median (Q2): 4.35
  75th percentile (Q3): 5.1

petal width (cm):
  Mean: 1.1993333333333336
  Std: 0.7596926279021594
  Min: 0.1
  Max: 2.5
  25th percentile (Q1): 0.3
  Median (Q2): 1.3
  75th percentile (Q3): 1.8
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Target (species):&quot;</span><span class="p">)</span>
<span class="n">unique</span><span class="p">,</span> <span class="n">counts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">iris</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> <span class="n">return_counts</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">count</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">unique</span><span class="p">,</span> <span class="n">counts</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  </span><span class="si">{</span><span class="n">iris</span><span class="o">.</span><span class="n">target_names</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">count</span><span class="si">}</span><span class="s2"> samples&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Target (species):
  setosa: 50 samples
  versicolor: 50 samples
  virginica: 50 samples
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Queda como <em>ejercicio para el estudiante, realizar un EDA exahustivo para el dataset</em>, teniendo en cuenta cada una de las variables y sus categorías. Evaluemos el <em><strong>uso de la función</strong></em> <code class="docutils literal notranslate"><span class="pre">cross_val_score</span></code></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">logreg</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">()</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">logreg</span><span class="p">,</span> <span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">iris</span><span class="o">.</span><span class="n">target</span><span class="p">);</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Cross-validation scores: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">scores</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cross-validation scores: [0.96666667 1.         0.93333333 0.96666667 1.        ]
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p><em><strong>Por defecto</strong></em>, <code class="docutils literal notranslate"><span class="pre">cross_val_score</span></code> <em><strong>realiza una</strong></em> <code class="docutils literal notranslate"><span class="pre">five-fold</span> <span class="pre">cross</span> <span class="pre">validation</span></code>, devolviendo cinco valores de <code class="docutils literal notranslate"><span class="pre">accuracy</span></code>. Podemos cambiar el número de pliegues <em><strong>(folds)</strong></em> utilizados, cambiando el parámetro <code class="docutils literal notranslate"><span class="pre">cv</span></code>:</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">logreg</span><span class="p">,</span> <span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">iris</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">);</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Cross-validation scores: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">scores</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cross-validation scores: [1.         0.93333333 1.         1.         0.93333333 0.93333333
 0.93333333 1.         1.         1.        ]
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Una forma habitual de <em><strong>resumir la precisión de la validación cruzada es calcular la media</strong></em></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Average cross-validation score: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">scores</span><span class="o">.</span><span class="n">mean</span><span class="p">()))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Average cross-validation score: 0.97
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Utilizando la <em><strong>validación cruzada media</strong></em> podemos concluir que, esperamos que el modelo sea de precisión en torno al 97% de media. Si observamos las cinco puntuaciones producidas por la validación cruzada de cinco pliegues <em><strong>five-fold cross validation</strong></em>, también podemos concluir que hay una <em><strong>varianza relativamente alta en la precisión entre pliegues, que va del 100% de precisión al 93.33% de precisión aproximadamente</strong></em>.</p></li>
<li><p>Esto podría implicar que <em><strong><code class="docutils literal notranslate"><span class="pre">el</span> <span class="pre">modelo</span> <span class="pre">es</span> <span class="pre">muy</span> <span class="pre">dependiente</span> <span class="pre">de</span> <span class="pre">los</span> <span class="pre">pliegues</span> <span class="pre">particulares</span> <span class="pre">utilizados</span> <span class="pre">para</span> <span class="pre">el</span> <span class="pre">entrenamiento</span></code></strong></em>, pero también podría ser simplemente una <em><strong>consecuencia del pequeño tamaño del conjunto de datos</strong></em>. Normalmente, <em><strong>si los resultados de</strong></em> <code class="docutils literal notranslate"><span class="pre">accuracy</span></code> <em><strong>varían considerablemente durante la validación cruzada de 5 pliegues</strong></em>, esto puede indicar <em><strong>problemas en el modelo, en los datos, o en el proceso de validación</strong></em>.</p></li>
</ul>
<div class="tip admonition">
<p class="admonition-title">Varianza alta de <em>accuracy</em> entre pliegues</p>
<ul class="simple">
<li><p><strong>Varianza en los datos</strong>: Si los datos no están bien distribuidos o existen diferencias significativas entre los pliegues, los resultados de accuracy pueden variar mucho entre cada uno. <em>Esto sucede comúnmente cuando los datos presentan sesgos o cuando ciertos pliegues contienen muestras que son más difíciles de clasificar</em>.</p></li>
<li><p><strong>Modelo inestable o de alta varianza</strong>: Algunos modelos, especialmente los que son complejos o sensibles a los datos de entrenamiento (como los árboles de decisión sin poda o redes neuronales profundas con pocos datos), pueden tener un rendimiento inconsistente en diferentes subconjuntos de los datos. <em>En estos casos, el modelo se ajusta demasiado a los pliegues específicos, produciendo fluctuaciones en el</em> <code class="docutils literal notranslate"><span class="pre">accuracy</span></code>.</p></li>
<li><p><strong>Tamaño de la muestra</strong>: <em>Si el conjunto de datos es pequeño, la variabilidad en los pliegues puede ser mayor, ya que cada subconjunto de datos tiene un peso proporcionalmente alto</em>. En estos casos, la validación cruzada puede reflejar variaciones amplificadas.</p></li>
<li><p><strong>Datos atípicos</strong>: <em>La presencia de datos atípicos (outliers) en algunos de los pliegues puede afectar el</em> <code class="docutils literal notranslate"><span class="pre">accuracy</span></code> <em>y producir resultados más dispares</em>. Es importante revisar si los pliegues contienen estos datos y considerar métodos para manejarlos.</p></li>
</ul>
</div>
</section>
<section id="ventajas-de-la-validacion-cruzada">
<h3><span class="section-number">16.1.2. </span>Ventajas de la validación cruzada<a class="headerlink" href="#ventajas-de-la-validacion-cruzada" title="Link to this heading">#</a></h3>
<div class="important admonition">
<p class="admonition-title">Observación</p>
<ul class="simple">
<li><p>Son varios los beneficios de utilizar la <em><strong>validación cruzada</strong></em> en lugar de una única división en un conjunto de entrenamiento y otro de prueba. En primer lugar, recuerde que <code class="docutils literal notranslate"><span class="pre">train_test_split</span></code> realiza una división aleatoria de los datos. Imaginemos que <em><strong>tenemos “suerte” al dividir aleatoriamente los datos, y todos los ejemplos que son difíciles de clasificar acaban en el conjunto de entrenamiento</strong></em>.</p></li>
<li><p>En ese caso, <em><strong>el conjunto de prueba sólo contendrá ejemplos “fáciles”, y nuestra precisión en el conjunto de prueba será irrealmente alto</strong></em>. Por el contrario, <em><strong>si tenemos “mala suerte”, es posible que pongamos al azar todos los ejemplos difíciles de clasificar en el conjunto de prueba y en consecuencia, obtener una score irrealmente bajo</strong></em>.</p></li>
</ul>
</div>
<ul class="simple">
<li><p>La <em><strong>validación cruzada garantiza que cada ejemplo esté en el conjunto de prueba una vez, obligando al modelo a generalizar bien en todo el conjunto</strong></em>. Proporciona un rango de precisión que muestra el rendimiento en el mejor y peor caso. A diferencia de dividir una sola vez, <em><strong>la validación cruzada usa más datos para entrenamiento</strong></em> (por ejemplo, 80% en cinco pliegues o 90% en diez pliegues), <em><strong>lo que mejora la precisión</strong></em>. Sin embargo, <em><strong>su desventaja es el mayor coste computacional</strong></em>, ya que se entrenan varios modelos en lugar de uno solo.</p></li>
</ul>
<div class="caution admonition">
<p class="admonition-title">Observación</p>
<ul class="simple">
<li><p>Es importante tener en cuenta que la <em><strong>validación cruzada no es una forma de construir un modelo que pueda aplicarse a nuevos datos. La validación cruzada no devuelve un modelo</strong></em>.</p></li>
<li><p>Cuando se llama a <code class="docutils literal notranslate"><span class="pre">cross_validation_score</span></code>, se construyen internamente múltiples modelos, pero <em><strong>el propósito de la validación cruzada es evaluar lo bien que un algoritmo determinado generalizará</strong></em> cuando es entrenado en un conjunto de datos específico.</p></li>
</ul>
</div>
</section>
<section id="validacion-cruzada-estratificada-k-fold-y-otras-estrategias">
<h3><span class="section-number">16.1.3. </span>Validación cruzada estratificada <span class="math notranslate nohighlight">\(k\)</span>-fold y otras estrategias<a class="headerlink" href="#validacion-cruzada-estratificada-k-fold-y-otras-estrategias" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>Dividir el conjunto de datos en <code class="docutils literal notranslate"><span class="pre">k</span></code> <em><strong>pliegues</strong></em> comenzando por la primera parte de los datos, como descrito en la sección anterior, <em><strong>puede no ser siempre una buena idea</strong></em>. Por ejemplo, veamos el conjunto de datos <code class="docutils literal notranslate"><span class="pre">iris</span></code></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_iris</span>
<span class="n">iris</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Iris labels:</span><span class="se">\n</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">iris</span><span class="o">.</span><span class="n">target</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Iris labels:
[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2
 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 2 2]
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>En este conjunto de datos, el <em><strong>primer tercio corresponde a la clase 0, el segundo a la clase 1 y el último a la clase 2</strong></em>. Al realizar una <em><strong>validación cruzada de 3 pliegues, cada pliegue contendría solo una clase en el conjunto de prueba</strong></em> y <em><strong>las otras dos en el conjunto de entrenamiento</strong></em>. Esto causaría que la precisión fuera del 0%, ya que las clases en entrenamiento y prueba no coincidirían en ninguna división, lo cual es ineficaz para evaluar el modelo.</p></li>
<li><p>Como la estrategia simple de <code class="docutils literal notranslate"><span class="pre">k-fold</span></code> falla aquí, <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code> <em><strong>no la utiliza para clasificación, sino que utiliza la <code class="docutils literal notranslate"><span class="pre">validación</span> <span class="pre">cruzada</span> <span class="pre">estratificada</span> <span class="pre">k-fold</span></code></strong></em>. En la validación cruzada estratificada, dividimos los datos de forma que las <em><strong>proporciones entre las clases sean las mismas en cada pliegue como en todo el conjunto de datos</strong></em>.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mglearn</span><span class="o">.</span><span class="n">plots</span><span class="o">.</span><span class="n">plot_stratified_cross_validation</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/16c4a06a1cbc231a522754d8efdd1a866821b29bdc053e9632c382dce6612dac.png" src="_images/16c4a06a1cbc231a522754d8efdd1a866821b29bdc053e9632c382dce6612dac.png" />
</div>
</div>
<ul class="simple">
<li><p>La validación cruzada estratificada de <code class="docutils literal notranslate"><span class="pre">k</span></code> pliegues <em><strong>distribuye las clases en cada pliegue según su proporción en el conjunto de datos, evitando que un pliegue carezca de muestras de alguna clase</strong></em>. Esto ofrece <em><strong>estimaciones más fiables del rendimiento del clasificador</strong></em> en comparación con la validación cruzada estándar de <code class="docutils literal notranslate"><span class="pre">k</span></code> pliegues, especialmente en conjuntos de datos desbalanceados.</p></li>
<li><p>Para la regresión, <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code> utiliza la validación cruzada <code class="docutils literal notranslate"><span class="pre">k-fold</span></code> estándar por defecto. Sería posible también tratar de hacer cada pliegue representativo de los diferentes valores objetivo de la regresión, pero esta no es una estrategia comúnmente utilizada.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">StratifiedKFold</span>
<span class="n">stratified_kfold</span> <span class="o">=</span> <span class="n">StratifiedKFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">logreg</span><span class="p">,</span> <span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">iris</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">stratified_kfold</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Cross-validation scores:</span><span class="se">\n</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">scores</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cross-validation scores:
[0.98 0.96 0.98]
</pre></div>
</div>
</div>
</div>
</section>
<section id="mas-control-sobre-la-validacion-cruzada">
<h3><span class="section-number">16.1.4. </span>Más control sobre la validación cruzada<a class="headerlink" href="#mas-control-sobre-la-validacion-cruzada" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>Podemos <em><strong>ajustar el número de pliegues en</strong></em> <code class="docutils literal notranslate"><span class="pre">cross_val_score</span></code> <em><strong>con el parámetro</strong></em> <code class="docutils literal notranslate"><span class="pre">cv</span></code>. No obstante, <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code> permite mayor control al aceptar un divisor de validación cruzada como parámetro <code class="docutils literal notranslate"><span class="pre">cv</span></code>. Aunque <em><strong>los valores predeterminados suelen ser adecuados, en ciertos casos puede ser útil una estrategia diferente</strong></em>.</p></li>
<li><p>Por ejemplo, para replicar resultados con validación cruzada <code class="docutils literal notranslate"><span class="pre">k-fold</span></code> en clasificación, se puede importar la clase <code class="docutils literal notranslate"><span class="pre">KFold</span></code> de <code class="docutils literal notranslate"><span class="pre">model_selection</span></code> e instanciarla con el número deseado de pliegues.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">KFold</span>
<span class="n">kfold</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Entonces, podemos pasar el objeto <code class="docutils literal notranslate"><span class="pre">kfold</span> <span class="pre">splitter</span></code> como el parámetro <code class="docutils literal notranslate"><span class="pre">cv</span></code> a <code class="docutils literal notranslate"><span class="pre">cross_val_score</span></code>:</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Cross-validation scores:</span><span class="se">\n</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">logreg</span><span class="p">,</span> <span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">iris</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">kfold</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cross-validation scores:
[0. 0. 0.]
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Usar <em><strong>validación cruzada triple (no estratificada) en el conjunto de datos iris es ineficaz</strong></em>, ya que cada pliegue corresponde a una clase, impidiendo el aprendizaje. Para evitarlo, <em><strong>se recomienda aleatorizar los datos en lugar de estratificarlos, configurando</strong></em> <code class="docutils literal notranslate"><span class="pre">shuffle=True</span></code> en <code class="docutils literal notranslate"><span class="pre">KFold</span></code> <em><strong>y fijando</strong></em> <code class="docutils literal notranslate"><span class="pre">random_state</span></code> para obtener resultados reproducibles. Esta aleatorización mejora significativamente los resultados.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">kfold</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Cross-validation scores:</span><span class="se">\n</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">logreg</span><span class="p">,</span> <span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">iris</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">kfold</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cross-validation scores:
[0.98 0.96 0.96]
</pre></div>
</div>
</div>
</div>
</section>
<section id="validacion-cruzada-con-exclusion-leave-one-out">
<h3><span class="section-number">16.1.5. </span>Validación cruzada con exclusión (<code class="docutils literal notranslate"><span class="pre">leave-one-out</span></code>)<a class="headerlink" href="#validacion-cruzada-con-exclusion-leave-one-out" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>El método de <em><strong>validación cruzada</strong></em> <code class="docutils literal notranslate"><span class="pre">leave-one-out</span></code> <em><strong>es una variante de</strong></em> <code class="docutils literal notranslate"><span class="pre">k</span></code> <em><strong>pliegues</strong></em> donde <em><strong>cada pliegue de prueba contiene solo una muestra</strong></em>. Aunque es más lento en conjuntos de datos grandes, puede ofrecer <em><strong><code class="docutils literal notranslate"><span class="pre">mejores</span> <span class="pre">estimaciones</span> <span class="pre">en</span> <span class="pre">conjuntos</span> <span class="pre">de</span> <span class="pre">datos</span> <span class="pre">pequeños</span></code></strong></em>.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">LeaveOneOut</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">loo</span> <span class="o">=</span> <span class="n">LeaveOneOut</span><span class="p">()</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">logreg</span><span class="p">,</span> <span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">iris</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">loo</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Number of cv iterations: &quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">scores</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Mean accuracy: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">scores</span><span class="o">.</span><span class="n">mean</span><span class="p">()))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Number of cv iterations:  150
Mean accuracy: 0.97
</pre></div>
</div>
</div>
</div>
</section>
<section id="validacion-cruzada-aleatoria-y-dividida">
<h3><span class="section-number">16.1.6. </span>Validación cruzada aleatoria y dividida<a class="headerlink" href="#validacion-cruzada-aleatoria-y-dividida" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>Otra estrategia muy flexible para la validación cruzada es <em><strong>la validación cruzada aleatoria</strong></em> (<code class="docutils literal notranslate"><span class="pre">shuffle-split</span> <span class="pre">cross-validation</span></code>). En la validación cruzada de división aleatoria, cada división (<code class="docutils literal notranslate"><span class="pre">split</span></code>) está compuesta de tantos <code class="docutils literal notranslate"><span class="pre">train_size</span></code> <em><strong>puntos (disyuntos)</strong></em> para el conjunto de entrenamiento y tantos <code class="docutils literal notranslate"><span class="pre">test_size</span></code> <em><strong>puntos (disjuntos)</strong></em> para el conjunto de prueba, se fijen inicialmente.</p></li>
<li><p>Esta división se repite <code class="docutils literal notranslate"><span class="pre">n_iter</span></code> veces, de forma aleatoria. A continuación se muestra <em><strong>la ejecución de cuatro iteraciones de división de un conjunto de datos que consta de <code class="docutils literal notranslate"><span class="pre">10</span> <span class="pre">puntos</span></code>, con un conjunto de entrenamiento de <code class="docutils literal notranslate"><span class="pre">5</span> <span class="pre">puntos</span></code> y conjuntos de prueba de <code class="docutils literal notranslate"><span class="pre">2</span> <span class="pre">puntos</span></code> cada uno</strong></em></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mglearn</span><span class="o">.</span><span class="n">plots</span><span class="o">.</span><span class="n">plot_shuffle_split</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/3da0128faf4cd0ca1231184ff81f1016555701727260db26519d838bb1c4c5a1.png" src="_images/3da0128faf4cd0ca1231184ff81f1016555701727260db26519d838bb1c4c5a1.png" />
</div>
</div>
<ul class="simple">
<li><p><em>Puede usar enteros para <code class="docutils literal notranslate"><span class="pre">train_size</span></code> y <code class="docutils literal notranslate"><span class="pre">test_size</span></code> para asignarles sus tamaños absolutos, o números de tipo flotante para usar fracciones del conjunto de datos</em>. El siguiente código divide el conjunto de datos en un <em><strong>50% de entrenamiento y un 50% de prueba para 10 iteraciones</strong></em></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">ShuffleSplit</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">shuffle_split</span> <span class="o">=</span> <span class="n">ShuffleSplit</span><span class="p">(</span><span class="n">test_size</span><span class="o">=</span><span class="mf">.5</span><span class="p">,</span> <span class="n">train_size</span><span class="o">=</span><span class="mf">.5</span><span class="p">,</span> <span class="n">n_splits</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">logreg</span><span class="p">,</span> <span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">iris</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">shuffle_split</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Cross-validation scores:</span><span class="se">\n</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">scores</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cross-validation scores:
[0.97333333 0.93333333 0.98666667 0.96       0.92       0.94666667
 0.98666667 0.96       0.96       0.98666667]
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>La <em><strong>validación cruzada aleatoria permite ajustar el número de iteraciones y <code class="docutils literal notranslate"><span class="pre">usar</span> <span class="pre">solo</span> <span class="pre">una</span> <span class="pre">parte</span> <span class="pre">de</span> <span class="pre">los</span> <span class="pre">datos</span> <span class="pre">en</span> <span class="pre">cada</span> <span class="pre">iteración,</span> <span class="pre">lo</span> <span class="pre">cual</span> <span class="pre">es</span> <span class="pre">útil</span> <span class="pre">para</span> <span class="pre">grandes</span> <span class="pre">conjuntos</span> <span class="pre">de</span> <span class="pre">datos</span></code></strong></em>. La variante estratificada, <code class="docutils literal notranslate"><span class="pre">StratifiedShuffleSplit</span></code>, <em><strong>ofrece resultados más fiables en tareas de clasificación</strong></em>.</p></li>
</ul>
</section>
<section id="validacion-cruzada-con-grupos">
<h3><span class="section-number">16.1.7. </span>Validación cruzada con grupos<a class="headerlink" href="#validacion-cruzada-con-grupos" title="Link to this heading">#</a></h3>
<div class="admonition-groupkfold admonition">
<p class="admonition-title">GroupKFold</p>
<ul class="simple">
<li><p>Digamos que quieres construir un sistema para <em><strong>reconocer emociones a partir de imágenes de rostros (o imágenes médicas)</strong></em>, y se recopila un conjunto de datos con imágenes de 100 personas, donde cada persona es capturada varias veces, mostrando varias emociones.</p></li>
<li><p>El objetivo es construir un clasificador que pueda <em><strong>identificar correctamente las emociones de las personas que no están en el conjunto de datos</strong></em>. <code class="docutils literal notranslate"><span class="pre">GroupKFold</span></code> es una variación de <code class="docutils literal notranslate"><span class="pre">k-fold</span></code> que <em><strong>garantiza que el mismo grupo no esté representado en los conjuntos de prueba y de entrenamiento</strong></em>.</p></li>
</ul>
</div>
<div class="tip admonition">
<p class="admonition-title">Observación</p>
<ul class="simple">
<li><p>La validación cruzada estratificada puede medir el rendimiento de un clasificador, pero <em><strong>si hay imágenes de la misma persona en los conjuntos de entrenamiento y prueba, el modelo reconocerá más fácilmente emociones en rostros ya vistos</strong></em>. Para <em><strong>evaluar mejor la generalización a nuevas caras, es recomendable usar</strong></em> <code class="docutils literal notranslate"><span class="pre">GroupKFold</span></code>, que permite <em><strong><code class="docutils literal notranslate"><span class="pre">separar</span> <span class="pre">las</span> <span class="pre">imágenes</span> <span class="pre">por</span> <span class="pre">persona</span> <span class="pre">en</span> <span class="pre">los</span> <span class="pre">conjuntos</span> <span class="pre">de</span> <span class="pre">entrenamiento</span> <span class="pre">y</span> <span class="pre">prueba</span></code></strong></em>.</p></li>
</ul>
</div>
<ul class="simple">
<li><p>Este ejemplo ilustra el uso de la validación cruzada en un conjunto de datos sintético con agrupación definida por la matriz groups. El conjunto tiene <em><strong>12 datos, organizados en cuatro grupos: los primeros tres puntos pertenecen al primer grupo, los siguientes cuatro al segundo, y así sucesivamente</strong></em>.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GroupKFold</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_blobs</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Creamos nuestro conjunto de datos sintético, y la lista de grupos <code class="docutils literal notranslate"><span class="pre">groups</span></code></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_blobs</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([1, 0, 2, 0, 0, 1, 1, 2, 0, 2, 2, 1])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">groups</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">gkf</span> <span class="o">=</span> <span class="n">GroupKFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="k">for</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="ow">in</span> <span class="n">gkf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="n">groups</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;GroupKFold: </span><span class="si">%s</span><span class="s2"> </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">test</span><span class="p">))</span>
    <span class="n">Xtrain</span><span class="p">,</span> <span class="n">Xtest</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">train</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">test</span><span class="p">]</span>
    <span class="n">ytrain</span><span class="p">,</span> <span class="n">ytest</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">train</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">test</span><span class="p">]</span>
    <span class="n">logreg</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">()</span>
    <span class="n">logreg</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xtrain</span><span class="p">,</span> <span class="n">ytrain</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;LogisticRegression Score: &quot;</span><span class="p">,</span> <span class="n">logreg</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">Xtest</span><span class="p">,</span> <span class="n">ytest</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>GroupKFold: [ 0  1  2  7  8  9 10 11] [3 4 5 6]
LogisticRegression Score:  0.75
GroupKFold: [0 1 2 3 4 5 6] [ 7  8  9 10 11]
LogisticRegression Score:  0.6
GroupKFold: [ 3  4  5  6  7  8  9 10 11] [0 1 2]
LogisticRegression Score:  0.6666666666666666
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>No es necesario que las muestras estén ordenadas por grupos; sólo lo hemos hecho con fines ilustrativos. <em><strong>Como puede ver, para cada división, cada grupo está completamente en el conjunto de entrenamiento o completamente en el conjunto de prueba</strong></em>. Ademas, <em><strong>observe que los pliegues no tienen exactamente el mismo tamaño debido al desequilibrio de los datos</strong></em>.</p></li>
<li><p>Hay más estrategias de división para la validación cruzada en <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code>, que pueden utilizarse para una variedad aún mayor de casos (ver <a class="reference external" href="https://scikit-learn.org/stable/modules/cross_validation.html">Cross-validation: evaluating estimator performance</a>). Sin embargo, el <code class="docutils literal notranslate"><span class="pre">KFold</span></code> estándar, el <code class="docutils literal notranslate"><span class="pre">StratifiedKFold</span></code> y el <code class="docutils literal notranslate"><span class="pre">GroupKFold</span></code> son, como mucho, los más utilizados. En el siguiente link puede encontrar la documentición relacionada con el uso de cada parámetro de la función <code class="docutils literal notranslate"><span class="pre">sklearn.model_selection.cross_val_score</span></code> (ver <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html">Evaluate a score by cross-validation</a>).</p></li>
</ul>
</section>
</section>
<section id="grid-search">
<h2><span class="section-number">16.2. </span>Grid Search<a class="headerlink" href="#grid-search" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Ahora que sabemos cómo evaluar el grado de generalización de un modelo, podemos dar el siguiente paso y <em><strong>mejorar el rendimiento de la generalización del modelo ajustando sus parámetros</strong></em>. Es importante <em><strong>entender lo que significan los parámetros antes de intentar ajustarlos</strong></em>. Encontrar los valores de los parámetros relevantes de un modelo (<em><strong>los que proporcionan el mejor rendimiento de generalización</strong></em>) es una tarea complicada, pero necesaria para casi todos los modelos y conjuntos de datos.</p></li>
<li><p>Al ser una tarea tan común, existen métodos estándar en <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code> para ayudarle con ello. El método más utilizado es la <code class="docutils literal notranslate"><span class="pre">grid</span> <span class="pre">search</span></code>, que básicamente significa <em><strong>probar todas las combinaciones posibles de los parámetros de interés</strong></em>. Considere el caso de un SVM con un <code class="docutils literal notranslate"><span class="pre">kernel</span> <span class="pre">RBF</span></code> (función de base radial), como implementado en la clase <code class="docutils literal notranslate"><span class="pre">SVC</span></code>. Hay dos parámetros importantes: el <em><strong>ancho de banda del kernel</strong></em>, <code class="docutils literal notranslate"><span class="pre">gamma</span></code>, y el <em><strong>parámetro de regularización</strong></em>, <code class="docutils literal notranslate"><span class="pre">C</span></code>.</p></li>
<li><p>Digamos que queremos probar los valores <em><strong>0.001, 0.01, 0.1, 1, 10 y 100 para el parámetro</strong></em> <code class="docutils literal notranslate"><span class="pre">C</span></code>, <em><strong>y lo mismo para</strong></em> <code class="docutils literal notranslate"><span class="pre">gamma</span></code>. Como tenemos seis ajustes diferentes para <code class="docutils literal notranslate"><span class="pre">C</span></code> y <code class="docutils literal notranslate"><span class="pre">gamma</span></code> que queremos probar, tenemos <em><strong>36 combinaciones de parámetros en total</strong></em>. Al ver todas las combinaciones posibles, <em><strong>se crea una tabla (o red) de parámetros para</strong></em> `SVM, como se muestra aquí:</p></li>
</ul>
<figure class="align-center" id="grid-search-svm">
<a class="reference internal image-reference" href="_images/grid_search_svm.png"><img alt="_images/grid_search_svm.png" src="_images/grid_search_svm.png" style="width: 698.5999999999999px; height: 138.6px;" /></a>
</figure>
<section id="grid-search-simple">
<h3><span class="section-number">16.2.1. </span>Grid Search simple<a class="headerlink" href="#grid-search-simple" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>Podemos implementar un <code class="docutils literal notranslate"><span class="pre">grid</span> <span class="pre">search</span></code> sobre los dos parámetros usando un par de <em><strong>ciclos for</strong></em>, entrenando y evaluando un clasificador para cada combinación</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">iris</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Size of training set: </span><span class="si">{}</span><span class="s2"> size of test set: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
<span class="n">best_score</span> <span class="o">=</span> <span class="mi">0</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Size of training set: 112 size of test set: 38
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">gamma</span> <span class="ow">in</span> <span class="p">[</span><span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">]:</span>
    <span class="k">for</span> <span class="n">C</span> <span class="ow">in</span> <span class="p">[</span><span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">]:</span>
        <span class="n">svm</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">(</span><span class="n">gamma</span><span class="o">=</span><span class="n">gamma</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="n">C</span><span class="p">)</span>
        <span class="n">svm</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
        <span class="n">score</span> <span class="o">=</span> <span class="n">svm</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">score</span> <span class="o">&gt;</span> <span class="n">best_score</span><span class="p">:</span>
            <span class="n">best_score</span> <span class="o">=</span> <span class="n">score</span>
            <span class="n">best_parameters</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;C&#39;</span><span class="p">:</span> <span class="n">C</span><span class="p">,</span> <span class="s1">&#39;gamma&#39;</span><span class="p">:</span> <span class="n">gamma</span><span class="p">}</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best score: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">best_score</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best parameters: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">best_parameters</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Best score: 0.97
Best parameters: {&#39;C&#39;: 100, &#39;gamma&#39;: 0.001}
</pre></div>
</div>
</div>
</div>
</section>
<section id="el-peligro-de-sobreajustar-los-parametros-y-el-conjunto-de-validacion">
<h3><span class="section-number">16.2.2. </span>El peligro de sobreajustar los parámetros y el conjunto de validación<a class="headerlink" href="#el-peligro-de-sobreajustar-los-parametros-y-el-conjunto-de-validacion" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>Teniendo en cuenta este resultado, podríamos tener la <em><strong>tentación de decir que hemos encontrado un modelo que funciona con un 97% de precisión</strong></em> en nuestro conjunto de datos. Sin embargo, esta afirmación podría ser demasiado optimista (o simplemente errónea), por la siguiente razón: <em><strong>hemos probado muchos parámetros diferentes y se seleccionó el que tenía la mejor precisión en el conjunto de prueba, pero <code class="docutils literal notranslate"><span class="pre">esta</span> <span class="pre">precisión</span> <span class="pre">no</span> <span class="pre">necesariamente</span> <span class="pre">la</span> <span class="pre">obtendremos</span> <span class="pre">con</span> <span class="pre">nuevos</span> <span class="pre">datos</span></code></strong></em>.</p></li>
<li><p><em><strong>Como hemos utilizado los datos de prueba para ajustar los parámetros, ya no podemos utilizarlos para evaluar la calidad del modelo</strong></em>. Esta es la misma razón por la que necesitamos dividir los datos en conjuntos de entrenamiento y de prueba; <em><strong><code class="docutils literal notranslate"><span class="pre">necesitamos</span> <span class="pre">un</span> <span class="pre">conjunto</span> <span class="pre">de</span> <span class="pre">datos</span> <span class="pre">independiente</span> <span class="pre">para</span> <span class="pre">evaluar,</span> <span class="pre">uno</span> <span class="pre">que</span> <span class="pre">no</span> <span class="pre">se</span> <span class="pre">haya</span> <span class="pre">utilizado</span> <span class="pre">para</span> <span class="pre">crear</span> <span class="pre">el</span> <span class="pre">modelo</span></code></strong></em>.</p></li>
<li><p>Una forma de resolver este problema es <em><strong>dividir los datos de nuevo, de modo que tengamos tres conjuntos</strong></em>: el <em><strong>conjunto de entrenamiento</strong></em> para construir el modelo, el <em><strong>conjunto de validación</strong></em> (o desarrollo) para seleccionar los parámetros del modelo, y el <em><strong>conjunto de prueba</strong></em> para evaluar el rendimiento de los parámetros seleccionados</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mglearn</span><span class="o">.</span><span class="n">plots</span><span class="o">.</span><span class="n">plot_threefold_split</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/7652fbcbf2450303a0cada32aed703b023faeaed06625753c52144946c766fe1.png" src="_images/7652fbcbf2450303a0cada32aed703b023faeaed06625753c52144946c766fe1.png" />
</div>
</div>
<ul class="simple">
<li><p>Después de seleccionar los mejores parámetros utilizando el <em><strong>conjunto de validación</strong></em>, podemos <em><strong>reconstruir un modelo utilizando los parámetros ajustados</strong></em> que encontramos, pero ahora <em><strong>entrenado tanto en los datos de entrenamiento y los datos de validación</strong></em>. De esta forma, podemos utilizar tantos datos como sea posible para construir nuestro modelo. Esto nos lleva a la siguiente implementación</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Dividimos los datos en conjunto de <em><strong>entrenamiento+validación</strong></em> y conjunto de <em><strong>prueba</strong></em></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_trainval</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_trainval</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">iris</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Dividimos el conjunto de <em><strong>entrenamiento+validación</strong></em> en conjuntos de <em><strong>entrenamiento</strong></em> y <em><strong>validación</strong></em></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_valid</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_valid</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X_trainval</span><span class="p">,</span> <span class="n">y_trainval</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Size of training set: </span><span class="si">{}</span><span class="s2"> size of validation set: </span><span class="si">{}</span><span class="s2"> size of test set: </span><span class="si">{}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span>
      <span class="nb">format</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">X_valid</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Size of training set: 84 size of validation set: 28 size of test set: 38
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">best_score</span> <span class="o">=</span> <span class="mi">0</span>

<span class="k">for</span> <span class="n">gamma</span> <span class="ow">in</span> <span class="p">[</span><span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">]:</span>
    <span class="k">for</span> <span class="n">C</span> <span class="ow">in</span> <span class="p">[</span><span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">]:</span>
        <span class="n">svm</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">(</span><span class="n">gamma</span><span class="o">=</span><span class="n">gamma</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="n">C</span><span class="p">)</span>
        <span class="n">svm</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span> <span class="c1"># Ajuste del modelo SVC</span>
        <span class="n">score</span> <span class="o">=</span> <span class="n">svm</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_valid</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">)</span> <span class="c1"># Score para selección de parámetros</span>
        <span class="k">if</span> <span class="n">score</span> <span class="o">&gt;</span> <span class="n">best_score</span><span class="p">:</span>
            <span class="n">best_score</span> <span class="o">=</span> <span class="n">score</span>
            <span class="n">best_parameters</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;C&#39;</span><span class="p">:</span> <span class="n">C</span><span class="p">,</span> <span class="s1">&#39;gamma&#39;</span><span class="p">:</span> <span class="n">gamma</span><span class="p">}</span> <span class="c1"># Almacenamos el mejor score y sus parámetros</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p><em><strong>Reconstruimos el modelo en el conjunto combinado de entrenamiento y validación</strong></em>, y lo <em><strong>evaluamos en el conjunto de prueba</strong></em></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">svm</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">(</span><span class="o">**</span><span class="n">best_parameters</span><span class="p">)</span>
<span class="n">svm</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_trainval</span><span class="p">,</span> <span class="n">y_trainval</span><span class="p">)</span>
<span class="n">test_score</span> <span class="o">=</span> <span class="n">svm</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best score on validation set: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">best_score</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best parameters: &quot;</span><span class="p">,</span> <span class="n">best_parameters</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test set score with best parameters: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">test_score</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Best score on validation set: 0.96
Best parameters:  {&#39;C&#39;: 10, &#39;gamma&#39;: 0.001}
Test set score with best parameters: 0.92
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p><em><strong>El mejor score en el conjunto de validación es del 96%</strong></em>: ligeramente inferior a la anterior, probablemente porque utilizamos menos datos para entrenar el modelo (<em><strong>X_train es menor ahora porque dividimos nuestro conjunto de datos dos veces</strong></em>). Sin embargo, el score en el conjunto de prueba, el que realmente nos dice que tan buena es la generalización, es aún más bajo, un 92%. Así que <em><strong>solo podemos afirmar que clasificamos los nuevos datos con un 92% de acierto, y no con un 97% como pensábamos antes</strong></em>.</p></li>
<li><p><em><strong>La distinción entre el conjunto de entrenamiento, el conjunto de validación y el conjunto de prueba es fundamentalmente importante</strong></em> para aplicar los métodos de aprendizaje automático en la práctica. <em><strong>Cualquier decisión tomada basada en la precisión del conjunto de prueba <code class="docutils literal notranslate"><span class="pre">“filtra”</span> <span class="pre">información</span> <span class="pre">del</span> <span class="pre">conjunto</span> <span class="pre">de</span> <span class="pre">prueba</span> <span class="pre">al</span> <span class="pre">modelo</span></code></strong></em>. Por lo tanto, es fundamental mantener un conjunto de prueba separado, que solo se utiliza para la evaluación final.</p></li>
<li><p>Es una buena práctica <em><strong>realizar todo el análisis exploratorio (EDA) y la selección del modelo utilizando la combinación de entrenamiento y validación, y reservar el conjunto de prueba para la evaluación final</strong></em>, incluso en el caso de la visualización exploratoria. En sentido estricto, <em><strong>evaluar más de un modelo en el conjunto de prueba y elegir el mejor de los dos resultará en una estimación demasiado optimista</strong></em> de la precisión del modelo.</p></li>
</ul>
</section>
<section id="grid-search-con-validacion-cruzada">
<h3><span class="section-number">16.2.3. </span>Grid Search con validación cruzada<a class="headerlink" href="#grid-search-con-validacion-cruzada" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p><em><strong>Aunque el método de dividir los datos en un conjunto de entrenamiento, uno de validación y otro de prueba que acabamos de ver es factible y se utiliza con relativa frecuencia, es bastante sensible a la forma en que se dividen los datos</strong></em>. De la salida del fragmento de código anterior podemos ver que el <code class="docutils literal notranslate"><span class="pre">grid-search</span></code> selecciona <code class="docutils literal notranslate"><span class="pre">'C':</span> <span class="pre">10,</span> <span class="pre">'gamma':</span> <span class="pre">0.001</span></code>, como los mejores parámetros, mientras que la salida del código de la sección anterior selecciona <code class="docutils literal notranslate"><span class="pre">'C':</span> <span class="pre">100,</span> <span class="pre">'gamma':</span> <span class="pre">0.001</span></code> como los mejores parámetros.</p></li>
<li><p>Para una mejor estimación del rendimiento de la generalización, <em><strong>en lugar de usar una única división en un conjunto de entrenamiento y otro de validación, podemos usar la validación cruzada para evaluar el rendimiento de cada combinación de parámetros</strong></em>. Este método puede codificarse como sigue:</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">gamma</span> <span class="ow">in</span> <span class="p">[</span><span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">]:</span>
    <span class="k">for</span> <span class="n">C</span> <span class="ow">in</span> <span class="p">[</span><span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">]:</span>
        <span class="n">svm</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">(</span><span class="n">gamma</span><span class="o">=</span><span class="n">gamma</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="n">C</span><span class="p">)</span> <span class="c1"># Entrena SVC para cada parámetro</span>
        <span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">svm</span><span class="p">,</span> <span class="n">X_trainval</span><span class="p">,</span> <span class="n">y_trainval</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span> <span class="c1"># Calcula validación cruzada</span>
        <span class="n">score</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span> <span class="c1"># Calcula media de la validación cruzada para precisión</span>
        <span class="k">if</span> <span class="n">score</span> <span class="o">&gt;</span> <span class="n">best_score</span><span class="p">:</span>
            <span class="n">best_score</span> <span class="o">=</span> <span class="n">score</span>
            <span class="n">best_parameters</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;C&#39;</span><span class="p">:</span> <span class="n">C</span><span class="p">,</span> <span class="s1">&#39;gamma&#39;</span><span class="p">:</span> <span class="n">gamma</span><span class="p">}</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p><em><strong>Reconstruimos el modelo en el conjunto combinado de entrenamiento y validación</strong></em></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">svm</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">(</span><span class="o">**</span><span class="n">best_parameters</span><span class="p">)</span>
<span class="n">svm</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_trainval</span><span class="p">,</span> <span class="n">y_trainval</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><style>#sk-container-id-1 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: black;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;

  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-icon: #696969;

  @media (prefers-color-scheme: dark) {
    /* Redefinition of color scheme for dark theme */
    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-icon: #878787;
  }
}

#sk-container-id-1 {
  color: var(--sklearn-color-text);
}

#sk-container-id-1 pre {
  padding: 0;
}

#sk-container-id-1 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-1 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-1 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-1 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-1 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-1 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-1 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-1 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-1 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-1 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-1 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-1 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-1 label.sk-toggleable__label {
  cursor: pointer;
  display: block;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
}

#sk-container-id-1 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "▸";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-1 div.sk-toggleable__content {
  max-height: 0;
  max-width: 0;
  overflow: hidden;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-1 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-1 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-1 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  max-height: 200px;
  max-width: 100%;
  overflow: auto;
}

#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "▾";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-1 div.sk-label label.sk-toggleable__label,
#sk-container-id-1 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-1 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  display: inline-block;
  line-height: 1.2em;
}

#sk-container-id-1 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-1 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-1 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-1 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-1 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 1ex;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
  color: var(--sklearn-color-unfitted-level-1);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-1 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-1 a.estimator_doc_link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-1 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-1 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}
</style><div id="sk-container-id-1" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>SVC(C=10, gamma=0.1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-1" type="checkbox" checked><label for="sk-estimator-id-1" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;&nbsp;SVC<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.svm.SVC.html">?<span>Documentation for SVC</span></a><span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span></label><div class="sk-toggleable__content fitted"><pre>SVC(C=10, gamma=0.1)</pre></div> </div></div></div></div></div></div>
</div>
<ul class="simple">
<li><p>Para evaluar la precisión de <code class="docutils literal notranslate"><span class="pre">SVM</span></code> utilizando un ajuste particular de <code class="docutils literal notranslate"><span class="pre">C</span></code> y <code class="docutils literal notranslate"><span class="pre">gamma</span></code> con <code class="docutils literal notranslate"><span class="pre">5-fold</span></code> validación cruzada, necesitamos entrenar <em><strong>36 * 5 = 180 modelos</strong></em>. Como puede imaginarse el <em><strong>principal inconveniente del uso de la validación cruzada es el tiempo que lleva entrenar todos estos modelos</strong></em>. La siguiente visualización ilustra cómo se selecciona la mejor configuración de parámetros en el código anterior</p></li>
</ul>
<figure class="align-center" id="best-params-cv">
<img alt="_images/best_params_cv.png" src="_images/best_params_cv.png" />
</figure>
<ul class="simple">
<li><p>Para cada ajuste de parámetros (sólo se muestra un subconjunto), <em><strong>se calculan cinco valores de precisión</strong></em>, uno para cada división en la validación cruzada. A continuación, <em><strong>se calcula la precisión media</strong></em> de la validación para cada parámetro. <em><strong>Se eligen los parámetros con la mayor precisión media de validación, marcados con un círculo</strong></em>.</p></li>
</ul>
<div class="tip admonition">
<p class="admonition-title">Observación</p>
<p>Como hemos dicho antes, <em><strong>la validación cruzada es una forma de evaluar un determinado algoritmo en un conjunto de datos específico</strong></em>. Sin embargo, a menudo se utiliza junto con métodos de búsqueda de parámetros como <code class="docutils literal notranslate"><span class="pre">Grid</span> <span class="pre">Search</span></code>. Por esta razón, normalmente se utiliza el término <em><strong>validación cruzada</strong></em> coloquialmente para referirse a un <code class="docutils literal notranslate"><span class="pre">Grid</span> <span class="pre">Search</span></code> con <em><strong>validación cruzada</strong></em>.</p>
</div>
<ul class="simple">
<li><p>El proceso general de división de los datos, la ejecución de <code class="docutils literal notranslate"><span class="pre">grid</span> <span class="pre">search</span></code> y la evaluación de los parámetros finales se ilustra en la siguiente figura</p></li>
</ul>
<figure class="align-center" id="kfold-validation">
<a class="reference internal image-reference" href="_images/kfold_validation.png"><img alt="_images/kfold_validation.png" src="_images/kfold_validation.png" style="width: 525.0px; height: 351.4px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 16.1 </span><span class="caption-text">Resumen del proceso de selección de parámetros y evaluación de modelos con <code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code>.</span><a class="headerlink" href="#kfold-validation" title="Link to this image">#</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p>Debido a que <code class="docutils literal notranslate"><span class="pre">grid</span> <span class="pre">search</span></code> con <em><strong>validación cruzada</strong></em> es un método tan comúnmente utilizado para ajustar parámetros, <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code> proporciona la clase <code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code>, que lo implementa en la forma de un estimador. Para utilizar la clase <code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code>, primero hay que especificar los parámetros sobre los que se quiere buscar utilizando un <em><strong>diccionario</strong></em>.</p></li>
<li><p>A continuación, <code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code> realizará todos los ajustes necesarios del modelo. Las <em><strong>claves</strong></em> (keys) del diccionario son los <em><strong>nombres de los parámetros que queremos ajustar</strong></em> (tal y como se indican cuando se construye el modelo, en este caso, <code class="docutils literal notranslate"><span class="pre">C</span></code> y <code class="docutils literal notranslate"><span class="pre">gamma</span></code>), y los <em><strong>valores</strong></em> (values) son los ajustes de los parámetros que queremos probar. Probar los valores <em><strong>0,001, 0,01, 0,1, 1, 10 y 100 para</strong></em> <code class="docutils literal notranslate"><span class="pre">C</span></code> y <code class="docutils literal notranslate"><span class="pre">gamma</span></code> se traduce en lo siguiente diccionario</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;C&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">],</span>
              <span class="s1">&#39;gamma&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">]}</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Parameter grid:</span><span class="se">\n</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">param_grid</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Parameter grid:
{&#39;C&#39;: [0.001, 0.01, 0.1, 1, 10, 100], &#39;gamma&#39;: [0.001, 0.01, 0.1, 1, 10, 100]}
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Ahora podemos instanciar la clase <code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code> con el modelo <code class="docutils literal notranslate"><span class="pre">(SVC)</span></code>, el parámetro a buscar (<code class="docutils literal notranslate"><span class="pre">param_grid</span></code>), y la estrategia de validación cruzada que queremos utilizar (digamos <em><strong>validación cruzada estratificada 5-fold</strong></em>):</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>
<span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">grid_search</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">SVC</span><span class="p">(),</span> <span class="n">param_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code> utilizará la validación cruzada en lugar de la división en un conjunto de entrenamiento y de prueba que utilizábamos antes. <em><strong>Sin embargo, todavía tenemos que dividir los datos en un conjunto de entrenamiento y otro de prueba, para evitar el sobreajuste de los parámetros</strong></em></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">iris</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>El objeto <code class="docutils literal notranslate"><span class="pre">grid_search</span></code> que hemos creado <em><strong>se comporta como un clasificador</strong></em>; podemos llamar a los métodos estándar <code class="docutils literal notranslate"><span class="pre">fit,</span> <span class="pre">predict</span></code> y <code class="docutils literal notranslate"><span class="pre">score</span></code>. Sin embargo, <em><strong>cuando llamamos a fit, se ejecutará una validación cruzada para cada combinación de parámetros que hayamos especificado</strong></em> en <code class="docutils literal notranslate"><span class="pre">param_grid</span></code></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">grid_search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><style>#sk-container-id-2 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: black;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;

  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-icon: #696969;

  @media (prefers-color-scheme: dark) {
    /* Redefinition of color scheme for dark theme */
    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-icon: #878787;
  }
}

#sk-container-id-2 {
  color: var(--sklearn-color-text);
}

#sk-container-id-2 pre {
  padding: 0;
}

#sk-container-id-2 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-2 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-2 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-2 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-2 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-2 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-2 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-2 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-2 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-2 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-2 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-2 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-2 label.sk-toggleable__label {
  cursor: pointer;
  display: block;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
}

#sk-container-id-2 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "▸";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-2 div.sk-toggleable__content {
  max-height: 0;
  max-width: 0;
  overflow: hidden;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-2 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-2 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-2 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  max-height: 200px;
  max-width: 100%;
  overflow: auto;
}

#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "▾";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-2 div.sk-label label.sk-toggleable__label,
#sk-container-id-2 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-2 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  display: inline-block;
  line-height: 1.2em;
}

#sk-container-id-2 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-2 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-2 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-2 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-2 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 1ex;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
  color: var(--sklearn-color-unfitted-level-1);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-2 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-2 a.estimator_doc_link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-2 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-2 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}
</style><div id="sk-container-id-2" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>GridSearchCV(cv=5, estimator=SVC(),
             param_grid={&#x27;C&#x27;: [0.001, 0.01, 0.1, 1, 10, 100],
                         &#x27;gamma&#x27;: [0.001, 0.01, 0.1, 1, 10, 100]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-2" type="checkbox" ><label for="sk-estimator-id-2" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;&nbsp;GridSearchCV<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.GridSearchCV.html">?<span>Documentation for GridSearchCV</span></a><span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span></label><div class="sk-toggleable__content fitted"><pre>GridSearchCV(cv=5, estimator=SVC(),
             param_grid={&#x27;C&#x27;: [0.001, 0.01, 0.1, 1, 10, 100],
                         &#x27;gamma&#x27;: [0.001, 0.01, 0.1, 1, 10, 100]})</pre></div> </div></div><div class="sk-parallel"><div class="sk-parallel-item"><div class="sk-item"><div class="sk-label-container"><div class="sk-label fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-3" type="checkbox" ><label for="sk-estimator-id-3" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">best_estimator_: SVC</label><div class="sk-toggleable__content fitted"><pre>SVC(C=10, gamma=0.1)</pre></div> </div></div><div class="sk-serial"><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-4" type="checkbox" ><label for="sk-estimator-id-4" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;SVC<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.svm.SVC.html">?<span>Documentation for SVC</span></a></label><div class="sk-toggleable__content fitted"><pre>SVC(C=10, gamma=0.1)</pre></div> </div></div></div></div></div></div></div></div></div></div></div>
</div>
<ul class="simple">
<li><p>El objeto <code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code> no solo busca los mejores parámetros, sino que también automáticamente un <em><strong>nuevo modelo en todo el conjunto de datos de entrenamiento con los parámetros que han dado el mejor rendimiento en la validación cruzada</strong></em>. La clase <code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code> proporciona una interfaz muy conveniente para acceder al modelo reentrenado utilizando los métodos <code class="docutils literal notranslate"><span class="pre">predict</span></code> y <code class="docutils literal notranslate"><span class="pre">score</span></code>. Para <em><strong>evaluar lo bien que generalizan los mejores parámetros encontrados</strong></em>, podemos llamar a <code class="docutils literal notranslate"><span class="pre">score</span></code> en el conjunto de prueba</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test set score: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">grid_search</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Test set score: 0.97
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Al elegir los parámetros mediante la validación cruzada, <em><strong>encontramos un modelo que alcanza el 97% de precisión en el conjunto de prueba</strong></em>. <em><strong>Lo importante aquí es que no utilizamos el conjunto de prueba para elegir los parámetros</strong></em>. Los parámetros encontrados se anotan en el atributo <code class="docutils literal notranslate"><span class="pre">best_params_</span></code> y la mejor precisión de la validación cruzada (la precisión media sobre las diferentes divisiones para esta configuración de parámetros) se almacena en <code class="docutils literal notranslate"><span class="pre">best_score_</span></code></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best parameters: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">grid_search</span><span class="o">.</span><span class="n">best_params_</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best cross-validation score: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">grid_search</span><span class="o">.</span><span class="n">best_score_</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Best parameters: {&#39;C&#39;: 10, &#39;gamma&#39;: 0.1}
Best cross-validation score: 0.97
</pre></div>
</div>
</div>
</div>
<div class="tip admonition">
<p class="admonition-title">Observación</p>
<p>De nuevo, tenga cuidado de no confundir <code class="docutils literal notranslate"><span class="pre">best_score_</span></code> con el rendimiento de generalización del modelo calculado por el método score en el conjunto de prueba. El uso del método score (o la evaluación de la salida del método de predicción) emplea un modelo entrenado en todo el conjunto de entrenamiento. <em><strong>El atributo</strong></em> <code class="docutils literal notranslate"><span class="pre">best_score_</span></code> <em><strong>almacena la precisión media de la validación cruzada, con la validación cruzada realizada en el conjunto de entrenamiento</strong></em>.</p>
</div>
<ul class="simple">
<li><p>A veces es útil tener <em><strong>acceso al modelo real que se encontró</strong></em>, por ejemplo, para ver los <em><strong>coeficientes o la importancia de las características</strong></em>. Puede acceder al modelo con los mejores parámetros entrenados en todo el conjunto de entrenamiento utilizando el atributo <code class="docutils literal notranslate"><span class="pre">best_estimator_</span></code></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best estimator:</span><span class="se">\n</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">grid_search</span><span class="o">.</span><span class="n">best_estimator_</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Best estimator:
SVC(C=10, gamma=0.1)
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Como el propio <code class="docutils literal notranslate"><span class="pre">grid_search</span></code> tiene métodos de predicción y score, no es necesario utilizar <code class="docutils literal notranslate"><span class="pre">best_estimator_</span></code> para hacer predicciones o evaluar el modelo.</p></li>
</ul>
</section>
<section id="analisis-del-resultado-de-la-validacion-cruzada">
<h3><span class="section-number">16.2.4. </span>Análisis del resultado de la validación cruzada<a class="headerlink" href="#analisis-del-resultado-de-la-validacion-cruzada" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>A menudo es útil visualizar los resultados de la validación cruzada, para entender cómo la generalización del modelo depende de los parámetros que estamos buscando. Como los <code class="docutils literal notranslate"><span class="pre">grid</span> <span class="pre">search</span></code> son bastante costosos desde el punto de vista computacional, <em><strong>a menudo es una buena idea empezar con grids de múltiples medidas, ya sean grandes o pequeños</strong></em>.</p></li>
<li><p>A continuación, podemos inspeccionar los resultados del <code class="docutils literal notranslate"><span class="pre">grid</span> <span class="pre">search</span></code> validado, y posiblemente ampliar nuestra búsqueda. Los resultados de un <code class="docutils literal notranslate"><span class="pre">grid</span> <span class="pre">search</span></code> se pueden encontrar en el atributo <code class="docutils literal notranslate"><span class="pre">cv_results_</span></code>, que es un diccionario que almacena todos los aspectos de la búsqueda. Este contiene muchos detalles, como se puede ver en la siguiente salida, y es mejor verlo después de convertirlo en un <code class="docutils literal notranslate"><span class="pre">DataFrame</span></code> de <code class="docutils literal notranslate"><span class="pre">pandas</span></code>.</p></li>
<li><p>Mostramos solo algunas columnas, para que se puedan diferenciar en el <em>jbook</em>, pero en su máquina puede visualizarla todas usando la orden <code class="docutils literal notranslate"><span class="pre">results.head()</span></code>. <code class="docutils literal notranslate"><span class="pre">GridSearchCV.cv_results_</span></code> incluye los <em><strong>resultados de tiempo para scoring y ajuste de parámetros en cada pliegue</strong></em>. Por ejemplo <code class="docutils literal notranslate"><span class="pre">mean_score_time</span></code> es la cantidad media de tiempo que se necesita para scoring en los datos de cada pliegue <code class="docutils literal notranslate"><span class="pre">cv</span></code>, para cada conjunto de parámetros que definió en el <code class="docutils literal notranslate"><span class="pre">grid-search</span></code>.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">results</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">grid_search</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">)</span>
<span class="n">results</span><span class="p">[[</span><span class="s1">&#39;mean_fit_time&#39;</span><span class="p">,</span> <span class="s1">&#39;std_fit_time&#39;</span><span class="p">,</span> <span class="s1">&#39;mean_score_time&#39;</span><span class="p">,</span>
         <span class="s1">&#39;std_score_time&#39;</span><span class="p">,</span> <span class="s1">&#39;param_C&#39;</span><span class="p">,</span> <span class="s1">&#39;param_gamma&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>mean_fit_time</th>
      <th>std_fit_time</th>
      <th>mean_score_time</th>
      <th>std_score_time</th>
      <th>param_C</th>
      <th>param_gamma</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.000426</td>
      <td>0.000063</td>
      <td>0.000230</td>
      <td>0.000017</td>
      <td>0.001</td>
      <td>0.001</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.000374</td>
      <td>0.000030</td>
      <td>0.000217</td>
      <td>0.000007</td>
      <td>0.001</td>
      <td>0.010</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.000418</td>
      <td>0.000068</td>
      <td>0.000224</td>
      <td>0.000015</td>
      <td>0.001</td>
      <td>0.100</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.000431</td>
      <td>0.000090</td>
      <td>0.000260</td>
      <td>0.000059</td>
      <td>0.001</td>
      <td>1.000</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.000368</td>
      <td>0.000006</td>
      <td>0.000221</td>
      <td>0.000012</td>
      <td>0.001</td>
      <td>10.000</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<ul class="simple">
<li><p>Cada fila de resultados corresponde a un ajuste de parámetros concreto. <em><strong>Para cada ajuste, se registran los resultados de todas las divisiones de validación cruzada, así como la media y la desviación estándar de todas las divisiones</strong></em>. Como buscamos una red bidimensional de parámetros (<code class="docutils literal notranslate"><span class="pre">C</span> <span class="pre">y</span> <span class="pre">gamma</span></code>), esto se visualiza mejor como un <em><strong>mapa de calor</strong></em>. Primero <em><strong>extraemos las puntuaciones medias de la validación</strong></em> y luego las reformamos para que los ejes correspondan a <code class="docutils literal notranslate"><span class="pre">C</span> <span class="pre">y</span> <span class="pre">gamma</span></code>.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">results</span><span class="o">.</span><span class="n">mean_test_score</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s2">&quot;.2f&quot;</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;viridis&quot;</span><span class="p">,</span> 
            <span class="n">xticklabels</span><span class="o">=</span><span class="n">param_grid</span><span class="p">[</span><span class="s1">&#39;gamma&#39;</span><span class="p">],</span> <span class="n">yticklabels</span><span class="o">=</span><span class="n">param_grid</span><span class="p">[</span><span class="s1">&#39;C&#39;</span><span class="p">])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;gamma&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;C&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Grid Search Scores&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/5719b38eb7be209a30c2089442dad9517c3dca41a20c11ae81e21a4239cb90bf.png" src="_images/5719b38eb7be209a30c2089442dad9517c3dca41a20c11ae81e21a4239cb90bf.png" />
</div>
</div>
<ul class="simple">
<li><p>Cada punto del mapa de calor corresponde a una ejecución de validación cruzada, con un parámetro en particular. <em><strong>El color codifica la precisión de la validación cruzada</strong></em>, siendo los colores claros los relacionados con alta precisión y los colores oscuros con baja precisión. Se puede ver que <em><strong>SVC es muy sensible a la configuración de los parámetros</strong></em>. Para muchos de los ajustes de los parámetros, la precisión está en torno al 37%, lo que es bastante malo; para otros ajustes, la precisión está en torno al 96%.</p></li>
<li><p>De este gráfico se desprenden varias cosas. En primer lugar, <em><strong>los parámetros que ajustamos son muy importantes para obtener un buen rendimiento</strong></em>. Ambos parámetros <em><strong>(C y gamma)</strong></em> son muy importantes, ya que su ajuste puede cambiar la precisión del 37% al 96%. Además, <em><strong>los rangos que elegimos para los parámetros son rangos en los que vemos cambios significativos en el resultado</strong></em>. También es importante tener en cuenta que <em><strong>los rangos de los parámetros son lo suficientemente amplios: los valores óptimos de cada parámetro no están en los bordes del gráfico</strong></em>.</p></li>
<li><p>Veamos algunos gráficos en los que <em><strong>el resultado es menos ideal</strong></em>, porque los rangos de búsqueda no fueron elegidos correctamente</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>
<span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>
<span class="kn">import</span> <span class="nn">mglearn</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>
<span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>

<span class="c1"># Definir los grids de hiperparámetros</span>
<span class="n">param_grid_linear</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;C&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span> <span class="s1">&#39;gamma&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">6</span><span class="p">)}</span>
<span class="n">param_grid_one_log</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;C&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span> <span class="s1">&#39;gamma&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">6</span><span class="p">)}</span>
<span class="n">param_grid_range</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;C&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span> <span class="s1">&#39;gamma&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="o">-</span><span class="mi">7</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">6</span><span class="p">)}</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>

<span class="k">for</span> <span class="n">param_grid</span><span class="p">,</span> <span class="n">ax</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">([</span><span class="n">param_grid_linear</span><span class="p">,</span> <span class="n">param_grid_one_log</span><span class="p">,</span> <span class="n">param_grid_range</span><span class="p">],</span> <span class="n">axes</span><span class="p">):</span>
    <span class="n">grid_search</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">SVC</span><span class="p">(),</span> <span class="n">param_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
    <span class="n">grid_search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">scores</span> <span class="o">=</span> <span class="n">grid_search</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s1">&#39;mean_test_score&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">format_tick</span><span class="p">(</span><span class="n">val</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Formatea el número con notación científica si tiene más de 4 cifras decimales&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">val</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">if</span> <span class="nb">abs</span><span class="p">(</span><span class="n">val</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mf">0.001</span> <span class="k">else</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">val</span><span class="si">:</span><span class="s2">.1e</span><span class="si">}</span><span class="s2">&quot;</span>

    <span class="n">xticklabels</span> <span class="o">=</span> <span class="p">[</span><span class="n">format_tick</span><span class="p">(</span><span class="n">val</span><span class="p">)</span> <span class="k">for</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">param_grid</span><span class="p">[</span><span class="s1">&#39;gamma&#39;</span><span class="p">]]</span>
    <span class="n">yticklabels</span> <span class="o">=</span> <span class="p">[</span><span class="n">format_tick</span><span class="p">(</span><span class="n">val</span><span class="p">)</span> <span class="k">for</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">param_grid</span><span class="p">[</span><span class="s1">&#39;C&#39;</span><span class="p">]]</span>

    <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s2">&quot;.2f&quot;</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;viridis&quot;</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>

    <span class="n">ax</span><span class="o">.</span><span class="n">set_xticklabels</span><span class="p">(</span><span class="n">xticklabels</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_yticklabels</span><span class="p">(</span><span class="n">yticklabels</span><span class="p">)</span>

    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;gamma&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;C&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/6d98b0e248786ef6be1df2c7800e8f341ee0c5ec480bdf2ca33718a48a2d9fcb.png" src="_images/6d98b0e248786ef6be1df2c7800e8f341ee0c5ec480bdf2ca33718a48a2d9fcb.png" />
</div>
</div>
<ul class="simple">
<li><p>El primer panel no muestra ningún cambio, con scores aproximadamente constantes en toda la red de parámetros. En este caso, esto se debe a una escala y un <em><strong>rango inadecuado para los parámetros</strong></em> <code class="docutils literal notranslate"><span class="pre">C</span></code> y <code class="docutils literal notranslate"><span class="pre">gamma</span></code>. Sin embargo, <em><strong>si no se aprecia ningún cambio en la precisión a lo largo de los diferentes ajustes de los parámetros, también puede ser que un parámetro no sea importante en absoluto</strong></em>.</p></li>
<li><p>Suele ser bueno probar primero valores muy extremos, para ver si hay algún cambio en la precisión como resultado de cambiar un parámetro. El segundo panel muestra un patrón de rayas verticales. Esto indica que solo el ajuste del parámetro <code class="docutils literal notranslate"><span class="pre">gamma</span></code> hace alguna diferencia. Esto podría significar que el parámetro <em><strong>gamma busca valores interesantes, pero el parámetro C no lo hace, o podría significar que el parámetro C no es importante</strong></em>.</p></li>
<li><p>El tercer panel muestra <em><strong>cambios tanto en C como en gamma</strong></em>. Sin embargo, podemos ver que en toda la parte inferior izquierda del gráfico, no ocurre nada interesante. Probablemente, podemos excluir los valores muy pequeños de las futuras búsquedas en la red. <em><strong>La configuración óptima de los parámetros está en la parte superior derecha</strong></em>. <em><strong>Como el óptimo está en el borde del gráfico, podemos esperar que puede haber valores aún mejores más allá de este límite, y podríamos cambiar nuestro rango de búsqueda para incluir más parámetros en esta región</strong></em>.</p></li>
<li><p>Ajustar la red de parámetros basándose en las puntuaciones de validación cruzada es perfectamente correcto, y una buena manera de explorar la importancia de los diferentes parámetros. Sin embargo, <em><strong>no debería probar diferentes rangos de parámetros en el conjunto de pruebas final</strong></em>, ya que, como hemos dicho antes, <em><strong>la evaluación del conjunto de pruebas solo debería realizarse una vez que sepamos exactamente qué modelo queremos utilizar</strong></em>.</p></li>
</ul>
</section>
<section id="busqueda-sobre-espacios-que-no-son-una-red">
<h3><span class="section-number">16.2.5. </span>Búsqueda sobre espacios que no son una red<a class="headerlink" href="#busqueda-sobre-espacios-que-no-son-una-red" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>En algunos casos, probar todas las combinaciones posibles de todos los parámetros, como suele hacer <code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code>, no es una buena idea. Por ejemplo, <code class="docutils literal notranslate"><span class="pre">SVC</span></code> tiene un parámetro de <code class="docutils literal notranslate"><span class="pre">kernel</span></code>, y dependiendo del <code class="docutils literal notranslate"><span class="pre">kernel</span></code> que se elija, otros parámetros serán relevantes. Si <code class="docutils literal notranslate"><span class="pre">kernel='linear'</span></code>, el modelo es lineal, y solo se utiliza el parámetro <code class="docutils literal notranslate"><span class="pre">C</span></code>. Si <code class="docutils literal notranslate"><span class="pre">kernel='rbf'</span></code>, se utilizan los parámetros <code class="docutils literal notranslate"><span class="pre">C</span> <span class="pre">y</span> <span class="pre">gamma</span></code> (pero no otros parámetros como el grado).</p></li>
<li><p>En este caso, la búsqueda de todas las combinaciones posibles de <code class="docutils literal notranslate"><span class="pre">C,</span> <span class="pre">gamma</span> <span class="pre">y</span> <span class="pre">kernel</span></code> no tendría sentido: si <code class="docutils literal notranslate"><span class="pre">kernel='linear',</span> <span class="pre">gamma</span></code> no se utiliza, y probar diferentes valores de <code class="docutils literal notranslate"><span class="pre">gamma</span></code> sería una pérdida de tiempo. Recuerde que <code class="docutils literal notranslate"><span class="pre">kernel='rbf'</span></code> es el <em><strong>kernel de función de base radial (RBF)</strong></em> con mapeo de características <span class="math notranslate nohighlight">\(\phi(\boldsymbol{x})=\exp(\|\boldsymbol{x}-x_{i}\|/2\sigma^2),~\gamma=1/\sigma^2\)</span>. Para ver todas las opciones de kernel gaussiano (ver <a class="reference external" href="https://scikit-learn.org/stable/modules/gaussian_process.html#gp-kernels">Kernels for Gaussian Processes</a>).</p></li>
<li><p>Para tratar este tipo de parámetros “condicionales”, <code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code> permite que <code class="docutils literal notranslate"><span class="pre">param_grid</span></code> sea una lista de diccionarios. Cada diccionario de la lista se expande en una red <code class="docutils literal notranslate"><span class="pre">(grid)</span></code> independiente. Una posible búsqueda en red que incluya el núcleo (<code class="docutils literal notranslate"><span class="pre">kernel</span></code>) y los parámetros podría ser así:</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">param_grid</span> <span class="o">=</span> <span class="p">[{</span><span class="s1">&#39;kernel&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;rbf&#39;</span><span class="p">],</span>
               <span class="s1">&#39;C&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">],</span>
               <span class="s1">&#39;gamma&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">]},</span>
              <span class="p">{</span><span class="s1">&#39;kernel&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;linear&#39;</span><span class="p">],</span>
               <span class="s1">&#39;C&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">]}]</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;List of grids:</span><span class="se">\n</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">param_grid</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>List of grids:
[{&#39;kernel&#39;: [&#39;rbf&#39;], &#39;C&#39;: [0.001, 0.01, 0.1, 1, 10, 100], &#39;gamma&#39;: [0.001, 0.01, 0.1, 1, 10, 100]}, {&#39;kernel&#39;: [&#39;linear&#39;], &#39;C&#39;: [0.001, 0.01, 0.1, 1, 10, 100]}]
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>En la primera red, el parámetro del <code class="docutils literal notranslate"><span class="pre">kernel</span></code> se establece siempre en <code class="docutils literal notranslate"><span class="pre">'rbf'</span></code> (no que la entrada de <code class="docutils literal notranslate"><span class="pre">kernel</span></code> es una lista de longitud uno), y se varían los parámetros <code class="docutils literal notranslate"><span class="pre">C</span></code> y <code class="docutils literal notranslate"><span class="pre">gamma</span></code>. <em><strong>En la segunda red, el parámetro kernel siempre se establece como lineal, y sólo se varía C</strong></em>. Ahora apliquemos esta búsqueda de parámetros más compleja</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">grid_search</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">SVC</span><span class="p">(),</span> <span class="n">param_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">grid_search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best parameters: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">grid_search</span><span class="o">.</span><span class="n">best_params_</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best cross-validation score: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">grid_search</span><span class="o">.</span><span class="n">best_score_</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Best parameters: {&#39;C&#39;: 10, &#39;gamma&#39;: 0.1, &#39;kernel&#39;: &#39;rbf&#39;}
Best cross-validation score: 0.97
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Observemos de nuevo el <code class="docutils literal notranslate"><span class="pre">cv_results_</span></code>. Como era de esperar, si el núcleo es <code class="docutils literal notranslate"><span class="pre">&quot;lineal&quot;</span></code>, sólo varía <code class="docutils literal notranslate"><span class="pre">C</span></code>. Nótese que el <em><strong>pandas tiene un total de 16 columnas</strong></em>.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">results</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">grid_search</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">)</span>
<span class="n">display</span><span class="p">(</span><span class="n">results</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span> <span class="p">,</span> <span class="p">:</span><span class="mi">6</span><span class="p">])</span>
<span class="n">results</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
      <th>5</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>mean_fit_time</th>
      <td>0.000407</td>
      <td>0.000398</td>
      <td>0.000359</td>
      <td>0.000364</td>
      <td>0.000408</td>
      <td>0.000429</td>
    </tr>
    <tr>
      <th>std_fit_time</th>
      <td>0.000074</td>
      <td>0.000047</td>
      <td>0.000001</td>
      <td>0.000005</td>
      <td>0.000056</td>
      <td>0.00002</td>
    </tr>
    <tr>
      <th>mean_score_time</th>
      <td>0.000236</td>
      <td>0.000227</td>
      <td>0.000213</td>
      <td>0.000211</td>
      <td>0.000235</td>
      <td>0.000232</td>
    </tr>
    <tr>
      <th>std_score_time</th>
      <td>0.000021</td>
      <td>0.00001</td>
      <td>0.000006</td>
      <td>0.000003</td>
      <td>0.000025</td>
      <td>0.000011</td>
    </tr>
    <tr>
      <th>param_C</th>
      <td>0.001</td>
      <td>0.001</td>
      <td>0.001</td>
      <td>0.001</td>
      <td>0.001</td>
      <td>0.001</td>
    </tr>
    <tr>
      <th>param_gamma</th>
      <td>0.001</td>
      <td>0.01</td>
      <td>0.1</td>
      <td>1.0</td>
      <td>10.0</td>
      <td>100.0</td>
    </tr>
    <tr>
      <th>param_kernel</th>
      <td>rbf</td>
      <td>rbf</td>
      <td>rbf</td>
      <td>rbf</td>
      <td>rbf</td>
      <td>rbf</td>
    </tr>
    <tr>
      <th>params</th>
      <td>{'C': 0.001, 'gamma': 0.001, 'kernel': 'rbf'}</td>
      <td>{'C': 0.001, 'gamma': 0.01, 'kernel': 'rbf'}</td>
      <td>{'C': 0.001, 'gamma': 0.1, 'kernel': 'rbf'}</td>
      <td>{'C': 0.001, 'gamma': 1, 'kernel': 'rbf'}</td>
      <td>{'C': 0.001, 'gamma': 10, 'kernel': 'rbf'}</td>
      <td>{'C': 0.001, 'gamma': 100, 'kernel': 'rbf'}</td>
    </tr>
    <tr>
      <th>split0_test_score</th>
      <td>0.347826</td>
      <td>0.347826</td>
      <td>0.347826</td>
      <td>0.347826</td>
      <td>0.347826</td>
      <td>0.347826</td>
    </tr>
    <tr>
      <th>split1_test_score</th>
      <td>0.347826</td>
      <td>0.347826</td>
      <td>0.347826</td>
      <td>0.347826</td>
      <td>0.347826</td>
      <td>0.347826</td>
    </tr>
    <tr>
      <th>split2_test_score</th>
      <td>0.363636</td>
      <td>0.363636</td>
      <td>0.363636</td>
      <td>0.363636</td>
      <td>0.363636</td>
      <td>0.363636</td>
    </tr>
    <tr>
      <th>split3_test_score</th>
      <td>0.363636</td>
      <td>0.363636</td>
      <td>0.363636</td>
      <td>0.363636</td>
      <td>0.363636</td>
      <td>0.363636</td>
    </tr>
    <tr>
      <th>split4_test_score</th>
      <td>0.409091</td>
      <td>0.409091</td>
      <td>0.409091</td>
      <td>0.409091</td>
      <td>0.409091</td>
      <td>0.409091</td>
    </tr>
    <tr>
      <th>mean_test_score</th>
      <td>0.366403</td>
      <td>0.366403</td>
      <td>0.366403</td>
      <td>0.366403</td>
      <td>0.366403</td>
      <td>0.366403</td>
    </tr>
    <tr>
      <th>std_test_score</th>
      <td>0.022485</td>
      <td>0.022485</td>
      <td>0.022485</td>
      <td>0.022485</td>
      <td>0.022485</td>
      <td>0.022485</td>
    </tr>
    <tr>
      <th>rank_test_score</th>
      <td>27</td>
      <td>27</td>
      <td>27</td>
      <td>27</td>
      <td>27</td>
      <td>27</td>
    </tr>
  </tbody>
</table>
</div></div><div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(16, 42)
</pre></div>
</div>
</div>
</div>
<div class="tip admonition">
<p class="admonition-title">Uso de diferentes estrategias de validación cruzada con la búsqueda en red</p>
<p>Al igual que <code class="docutils literal notranslate"><span class="pre">cross_val_score,</span> <span class="pre">GridSearchCV</span></code> utiliza por defecto la validación cruzada estratificada <code class="docutils literal notranslate"><span class="pre">k-fold</span></code> para la clasificación, y la <em><strong>validación cruzada k-fold</strong></em> para la regresión. Sin embargo, también puede pasar cualquier divisor de validación cruzada, como se describe en <em><strong>“Más control sobre la validación cruzada”</strong></em>, como parámetro <code class="docutils literal notranslate"><span class="pre">cv</span></code> en <code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code>. En particular, para obtener una única división en un conjunto de entrenamiento y otro de validación, puede utilizar <code class="docutils literal notranslate"><span class="pre">ShuffleSplit</span></code> o <code class="docutils literal notranslate"><span class="pre">StratifiedShuffleSplit</span></code> con <code class="docutils literal notranslate"><span class="pre">n_iter=1</span></code> (número de iteraciones de reordenamiento y división). Esto puede ser útil para conjuntos de datos muy grandes o para modelos muy lentos.</p>
</div>
</section>
<section id="validacion-cruzada-anidada">
<h3><span class="section-number">16.2.6. </span>Validación cruzada anidada<a class="headerlink" href="#validacion-cruzada-anidada" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>En los ejemplos anteriores, pasamos de utilizar una única división de los datos en conjuntos de entrenamiento validación y prueba, a <em><strong>dividir los datos en conjuntos de entrenamiento y prueba, y luego de validación cruzada en el conjunto de entrenamiento</strong></em>. Pero al utilizar <code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code> como se ha descrito anteriormente, <em><strong>seguimos teniendo una única división de los datos en conjuntos de entrenamiento y de prueba</strong></em>, lo que puede hacer que nuestros resultados sean inestables y nos haga depender demasiado de esta única división de los datos. Podemos ir un paso más allá, y <em><strong>en lugar de dividir los datos originales en conjuntos de entrenamiento y prueba una vez, utilizar múltiples divisiones de validación cruzada</strong></em>. Esto dará lugar a lo que se denomina <em><strong>validación cruzada anidada</strong></em>.</p></li>
<li><p><em><strong>En la validación cruzada anidada, hay un bucle externo sobre las divisiones de los datos en conjuntos de entrenamiento y de prueba. Para cada uno de ellos, se ejecuta una búsqueda en red</strong></em> (que puede dar lugar a diferentes parámetros óptimos para cada división en el bucle externo). A continuación, para cada división exterior, se informa del scoring del conjunto de prueba utilizando los mejores parámetros. <em><strong>El resultado de este procedimiento es una lista de puntuaciones, no un modelo ni un conjunto de parámetros</strong></em>.</p></li>
<li><p><em><strong>Las puntuaciones nos dicen lo bien que generaliza un modelo</strong></em>, dados los mejores parámetros encontrados por la red. Como no proporciona un modelo que pueda utilizarse con nuevos datos, la <em><strong>validación cruzada anidada no suele utilizarse cuando se busca un modelo predictivo para aplicarlo a datos futuros</strong></em>. Sin embargo, puede ser útil para evaluar lo bien que funciona un modelo determinado en un conjunto de datos concreto. La implementación de la <em><strong>validación cruzada anidada</strong></em> en <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code> es sencilla. Llamamos a <code class="docutils literal notranslate"><span class="pre">cross_val_score</span></code> con una instancia de <code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code> como modelo</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">GridSearchCV</span><span class="p">(</span><span class="n">SVC</span><span class="p">(),</span> <span class="n">param_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">),</span> <span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">iris</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Cross-validation scores: &quot;</span><span class="p">,</span> <span class="n">scores</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Mean cross-validation score: &quot;</span><span class="p">,</span> <span class="n">scores</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cross-validation scores:  [0.96666667 1.         0.9        0.96666667 1.        ]
Mean cross-validation score:  0.9666666666666668
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>El resultado de nuestra <em><strong>validación cruzada anidada</strong></em> puede resumirse en que <em><strong>“SVC puede alcanzar un 96.67% de precisión media de validación cruzada en el conjunto de datos del iris”</strong></em>, nada más y nada menos. Aquí, utilizamos la validación cruzada estratificada de cinco pliegues (<em><strong>5-fold</strong></em>) tanto en el bucle interno como en el externo. Como nuestra red de parámetros contiene 36 combinaciones de parámetros, <em><strong>el resultado es la cantidad de 36 * 5 * 5 = 900 modelos construidos, lo que hace que la validación cruzada anidada sea un procedimiento muy costoso</strong></em>.</p></li>
<li><p>Aquí, <em><strong>utilizamos el mismo divisor de validación cruzada en el bucle interno y en el externo</strong></em>; sin embargo, esto no es necesario y se puede utilizar cualquier combinación de estrategias de validación cruzada en el bucle interno y en el externo. Puede ser un poco complicado entender lo que está sucediendo en la línea simple dada anteriormente, y puede ser útil <em><strong>visualizarlo como bucles for, como se hace en la siguiente implementación simplificada</strong></em></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">nested_cv</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">inner_cv</span><span class="p">,</span> <span class="n">outer_cv</span><span class="p">,</span> <span class="n">Classifier</span><span class="p">,</span> <span class="n">parameter_grid</span><span class="p">):</span>
    <span class="n">outer_scores</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">training_samples</span><span class="p">,</span> <span class="n">test_samples</span> <span class="ow">in</span> <span class="n">outer_cv</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="n">best_parms</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">best_score</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span>
        <span class="k">for</span> <span class="n">parameters</span> <span class="ow">in</span> <span class="n">parameter_grid</span><span class="p">:</span>
            <span class="n">cv_scores</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">inner_train</span><span class="p">,</span> <span class="n">inner_test</span> <span class="ow">in</span> <span class="n">inner_cv</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">training_samples</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">training_samples</span><span class="p">]):</span>
                <span class="n">clf</span> <span class="o">=</span> <span class="n">Classifier</span><span class="p">(</span><span class="o">**</span><span class="n">parameters</span><span class="p">)</span>
                <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">inner_train</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">inner_train</span><span class="p">])</span>
                <span class="n">score</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">inner_test</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">inner_test</span><span class="p">])</span>
                <span class="n">cv_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">score</span><span class="p">)</span>
            <span class="n">mean_score</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">cv_scores</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">mean_score</span> <span class="o">&gt;</span> <span class="n">best_score</span><span class="p">:</span>
                <span class="n">best_score</span> <span class="o">=</span> <span class="n">mean_score</span>
                <span class="n">best_params</span> <span class="o">=</span> <span class="n">parameters</span>
        <span class="n">clf</span> <span class="o">=</span> <span class="n">Classifier</span><span class="p">(</span><span class="o">**</span><span class="n">best_params</span><span class="p">)</span>
        <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">training_samples</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">training_samples</span><span class="p">])</span>
        <span class="n">outer_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">test_samples</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">test_samples</span><span class="p">]))</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">outer_scores</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">ParameterGrid</span><span class="p">,</span> <span class="n">StratifiedKFold</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">scores</span> <span class="o">=</span> <span class="n">nested_cv</span><span class="p">(</span><span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">iris</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> <span class="n">StratifiedKFold</span><span class="p">(</span><span class="mi">5</span><span class="p">),</span>
<span class="n">StratifiedKFold</span><span class="p">(</span><span class="mi">5</span><span class="p">),</span> <span class="n">SVC</span><span class="p">,</span> <span class="n">ParameterGrid</span><span class="p">(</span><span class="n">param_grid</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Cross-validation scores: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">scores</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cross-validation scores: [0.96666667 1.         0.96666667 0.96666667 1.        ]
</pre></div>
</div>
</div>
</div>
</section>
<section id="paralelizacion-de-la-validacion-cruzada-y-la-busqueda-en-red">
<h3><span class="section-number">16.2.7. </span>Paralelización de la validación cruzada y la búsqueda en red<a class="headerlink" href="#paralelizacion-de-la-validacion-cruzada-y-la-busqueda-en-red" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>Si bien la ejecución de un <em><strong>grid search</strong></em> sobre muchos parámetros y en grandes conjuntos de datos puede ser <em><strong>computacionalmente un reto</strong></em>, también es un paralelismo tedioso. Esto significa que la construcción de un modelo utilizando un ajuste de parámetros particular en una división de validación cruzada particular <em><strong>puede hacerse con total independencia de los demás ajustes de parámetros y modelos</strong></em>. <em><strong>Esto hace que la búsqueda en red y la validación cruzada sean candidatas ideales para la paralelización en múltiples núcleos de CPU o en un clúster</strong></em>. Se puede hacer uso de múltiples núcleos en <code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code> y <code class="docutils literal notranslate"><span class="pre">cross_validation</span></code> estableciendo el parámetro <code class="docutils literal notranslate"><span class="pre">n_jobs</span></code> con el número de núcleos de CPU que desee utilizar. <em><strong>Puede establecer n_jobs=-1 para utilizar todos los núcleos disponibles</strong></em>.</p></li>
<li><p>Debe tener en cuenta que <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code> no permite el anidamiento de operaciones paralelas. Por lo tanto, si está utilizando la opción <code class="docutils literal notranslate"><span class="pre">n_jobs</span></code> en su modelo (por ejemplo, <code class="docutils literal notranslate"><span class="pre">random</span> <span class="pre">forest</span></code>), no puede utilizarla en <code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code> para buscar sobre este modelo. Si su <em><strong>conjunto de datos y su modelo son muy grandes, puede ser que el uso de muchos núcleos consuma demasiada memoria</strong></em>, y deberías controlar el uso de la memoria cuando construyas modelos grandes en paralelo. <em><strong>También es posible paralelizar la búsqueda en red y la validación cruzada en varias máquinas en un clúster</strong></em>. Sin embargo, es posible utilizar el marco paralelo de <code class="docutils literal notranslate"><span class="pre">IPython</span></code> para las búsquedas paralelas de la red, también puede <em><strong>escribir el bucle for sobre los parámetros como lo hicimos en “Búsqueda simple en la red”</strong></em>. <strong><code class="docutils literal notranslate"><span class="pre">Para</span> <span class="pre">los</span> <span class="pre">usuarios</span> <span class="pre">de</span> <span class="pre">Spark,</span> <span class="pre">también</span> <span class="pre">existe</span> <span class="pre">el</span> <span class="pre">paquete</span> <span class="pre">spark-sklearn,</span> <span class="pre">recientemente</span> <span class="pre">desarrollado,</span> <span class="pre">que</span> <span class="pre">permite</span> <span class="pre">ejecutar</span> <span class="pre">una</span> <span class="pre">búsqueda</span> <span class="pre">grid</span> <span class="pre">sobre</span> <span class="pre">un</span> <span class="pre">cluster</span> <span class="pre">Spark</span> <span class="pre">ya</span> <span class="pre">establecido</span></code></strong>.</p></li>
</ul>
</section>
</section>
<section id="metricas-de-evaluacion-y-scoring">
<h2><span class="section-number">16.3. </span>Métricas de evaluación y scoring<a class="headerlink" href="#metricas-de-evaluacion-y-scoring" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Hasta ahora, hemos evaluado el <em><strong>rendimiento de la clasificación utilizando la precisión (accuracy)</strong></em> (la fracción de muestras correctamente clasificadas) y el <em><strong>rendimiento de la regresión</strong></em> mediante el <span class="math notranslate nohighlight">\(R^2\)</span>. Sin embargo, éstas son sólo dos de las muchas formas posibles de resumir la eficacia de un modelo supervisado en un conjunto de datos determinado. <em><strong>En la práctica, estas métricas de evaluación pueden no ser apropiadas para su aplicación, y es importante elegir la métrica correcta cuando se selecciona entre modelos y se ajustan los parámetros</strong></em>.</p></li>
</ul>
<section id="tenga-en-cuenta-el-objetivo-final">
<h3><span class="section-number">16.3.1. </span>Tenga en cuenta el objetivo final<a class="headerlink" href="#tenga-en-cuenta-el-objetivo-final" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>Al seleccionar una métrica, siempre hay que tener en cuenta el objetivo final de la aplicación de aprendizaje automático. En la práctica, normalmente nos interesa no sólo hacer predicciones precisas, sino que utilizar estas predicciones como parte de un proceso de decisiones. <em><strong>Antes de elegir una métrica de aprendizaje automático, debería pensar en el objetivo de alto nivel de la aplicación, a menudo llamado métrica de negocio</strong></em>. <em><strong>Las consecuencias de la elección de un algoritmo concreto para una aplicación de aprendizaje automático se denominan impacto empresarial</strong></em>.</p></li>
<li><p>Puede que el objetivo de alto nivel sea evitar accidentes de tráfico, o reducir el número de ingresos hospitalarios. También podría ser conseguir más usuarios para su sitio web, o que los usuarios gasten más dinero en su tienda. Al elegir un modelo o ajustar los parámetros, <em><strong>debe elegir el modelo o los valores de los parámetros que influyan más positivamente en la métrica del negocio</strong></em>. A menudo, esto es difícil, ya que <em><strong>la evaluación del impacto comercial de un modelo particular puede requerir ponerlo en producción en un sistema de la vida real</strong></em>.</p></li>
<li><p>En las primeras fases de desarrollo, y para ajustar los parámetros, <em><strong>a menudo es inviable poner los modelos en producción sólo para probarlos, debido a los elevados riesgos empresariales o personales que puede conllevar</strong></em>. Imagínese que se evalúa la <em><strong>capacidad que tiene un coche autodirigido de evitar a los peatones de un coche, dejándolo circular sin verificarlo primero</strong></em>. Si el modelo es malo, los peatones tendrán problemas. Por lo tanto, a menudo tenemos que encontrar un procedimiento de evaluación alternativo, utilizando una métrica de evaluación que sea más fácil de calcular. Por ejemplo, podríamos probar la <em><strong>clasificación de imágenes de peatones frente a las de no peatones y medir la precisión</strong></em>.</p></li>
<li><p>Hay que tener en cuenta que esto es sólo un sustituto, y que vale la pena encontrar la métrica más cercana al objetivo original de la empresa, que sea factible de evaluar. Esta métrica más cercana debe utilizarse siempre que sea posible para la evaluación y selección de modelos. <em><strong>El resultado de esta evaluación puede no ser un solo número - consecuencia de su algoritmo puede ser que tenga un 10% más de clientes, pero que cada cliente gaste un 15% menos - pero debería capturar el impacto empresarial esperado de la elección de un modelo en lugar de otro.</strong></em> En esta sección, primero discutiremos las métricas para el importante caso especial de la clasificación binaria, y luego pasaremos a la clasificación multiclase, y por último, a la regresión.</p></li>
</ul>
</section>
<section id="metricas-para-la-clasificacion-binaria">
<h3><span class="section-number">16.3.2. </span>Métricas para la clasificación binaria<a class="headerlink" href="#metricas-para-la-clasificacion-binaria" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>La clasificación binaria es probablemente la aplicación más común y conceptualmente simple de aprendizaje automático en la práctica. <em><strong>Sin embargo, todavía hay una serie de advertencias en evaluar incluso esta sencilla tarea</strong></em>. Antes de entrar en las métricas alternativas, echemos un vistazo a la forma en que se mide la precisión, la cual puede ser engañosa. Recordemos que para la clasificación binaria, a menudo hablamos de una <em><strong>clase positiva</strong></em> y una <em><strong>clase negativa</strong></em>, entendiendo que la clase positiva es la que estamos buscando.</p></li>
</ul>
</section>
<section id="tipos-de-errores">
<h3><span class="section-number">16.3.3. </span>Tipos de errores<a class="headerlink" href="#tipos-de-errores" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>A menudo, la precisión (<code class="docutils literal notranslate"><span class="pre">accuracy</span></code>), la cual divide el número de predicciones correctas por el número total de predicciones, no es una buena medida del rendimiento predictivo, ya que el número de errores que cometemos no contiene toda la información que nos interesa. <em><strong>Imagine una aplicación para la detección temprana del cáncer mediante una prueba automatizada. Si la prueba es negativa, el paciente se considerará sano, mientras que si la prueba es positiva, el paciente se someterá a un examen adicional</strong></em>. En este caso, llamaríamos <em><strong>clase positiva</strong></em> a una prueba positiva (un indicio de cáncer), y <em><strong>clase negativa</strong></em> a una prueba negativa. <em><strong>No podemos suponer que nuestro modelo funcione siempre a la perfección, este cometerá errores</strong></em>. Para cualquier aplicación, tenemos que preguntarnos cuáles son las consecuencias de estos errores en el mundo real.</p></li>
<li><p>Un posible error es que un <em><strong>paciente sano sea clasificado como positivo</strong></em>, lo que lleva a pruebas adicionales. Esto conlleva algunos costes y una molestia para el paciente (y posiblemente angustia mental). Una <em><strong>predicción positiva incorrecta se denomina</strong></em> <strong><code class="docutils literal notranslate"><span class="pre">falso</span> <span class="pre">positivo</span></code></strong>.  Otro error posible es que un <em><strong>paciente enfermo sea clasificado como negativo</strong></em>, y no reciba más pruebas ni tratamiento. <strong><code class="docutils literal notranslate"><span class="pre">El</span> <span class="pre">cáncer</span> <span class="pre">no</span> <span class="pre">diagnosticado</span> <span class="pre">podría</span> <span class="pre">dar</span> <span class="pre">lugar</span> <span class="pre">a</span> <span class="pre">graves</span> <span class="pre">problemas</span> <span class="pre">de</span> <span class="pre">salud,</span> <span class="pre">e</span> <span class="pre">incluso</span> <span class="pre">podría</span> <span class="pre">ser</span> <span class="pre">mortal</span></code></strong>. Un error de este tipo - una <em><strong>predicción negativa incorrecta se denomina</strong></em> <strong><code class="docutils literal notranslate"><span class="pre">falso</span> <span class="pre">negativo</span></code></strong>. En estadística, un <em><strong>falso positivo también se conoce como error de tipo I</strong></em>, y un <em><strong>falso negativo como error de tipo II</strong></em>. Nos ceñiremos a los términos <em><strong>“falso negativo” y “falso positivo”</strong></em>, ya que son más explícitos y fáciles de recordar. En el ejemplo del diagnóstico de cáncer, está claro que <em><strong>queremos evitar los falsos negativos</strong></em> en la medida de lo posible, <em><strong>mientras que los falsos positivos pueden ser un problema, pueden considerarse más bien una molestia menor</strong></em>.</p></li>
<li><p>Aunque este es un ejemplo especialmente drástico, <em><strong>las consecuencias de los falsos positivos y los falsos negativos no suelen ser las mismas</strong></em>. En las <em><strong>aplicaciones comerciales, podría ser posible asignar valores en dólares a ambos tipos de errores, lo que permitiría medir el error de una predicción concreta en dólares, en lugar de en precisión</strong></em>. Esto podría ser mucho más significativo para tomar decisiones comerciales sobre qué modelo utilizar.</p></li>
</ul>
</section>
<section id="conjuntos-de-datos-desequilibrados">
<h3><span class="section-number">16.3.4. </span>Conjuntos de datos desequilibrados<a class="headerlink" href="#conjuntos-de-datos-desequilibrados" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>Los tipos de errores desempeñan un papel importante cuando una de las dos clases es mucho más frecuente que la otra. Esto es muy común en la práctica; un buen ejemplo es la predicción de <em><strong>clicks</strong></em>, en la que cada punto de datos representa una “impresión”, es decir, un elemento que se ha mostrado a un usuario. Este elemento puede ser un anuncio, una historia relacionada o una persona relacionada a la que seguir en las redes sociales. El objetivo es, si se muestra un elemento concreto, predecir si un usuario hará click en él (indicando que está interesado). La mayoría de las cosas que se muestran a los usuarios en Internet (en particular, los anuncios) no darán lugar a un click. Es posible que tenga que mostrar a un usuario 100 anuncios o artículos antes de que encuentre algo lo suficientemente interesante como para hacer click.</p></li>
<li><p>Esto da lugar a un conjunto de datos en el que, por cada 99 puntos de datos “no click”, hay 1 punto de datos “con click”. <em><strong>En otras palabras, el 99% de las muestras pertenecen a la clase “no click”</strong></em>. <strong><code class="docutils literal notranslate"><span class="pre">Conjuntos</span> <span class="pre">de</span> <span class="pre">datos</span> <span class="pre">en</span> <span class="pre">los</span> <span class="pre">que</span> <span class="pre">una</span> <span class="pre">clase</span> <span class="pre">es</span> <span class="pre">mucho</span> <span class="pre">más</span> <span class="pre">frecuente</span> <span class="pre">que</span> <span class="pre">la</span> <span class="pre">otra</span> <span class="pre">se</span> <span class="pre">denominan</span> <span class="pre">conjuntos</span> <span class="pre">de</span> <span class="pre">datos</span> <span class="pre">con</span> <span class="pre">clases</span> <span class="pre">desequilibradas</span></code></strong>. En realidad, los datos desequilibrados son la norma, y <em><strong>es raro que los eventos de interés tengan una frecuencia igual o incluso similar en los datos</strong></em>. Supongamos que construimos un clasificador que tiene una precisión del 99% en la tarea de predicción de clicks. ¿Qué nos dice esto? <em><strong>Un 99% de precisión suena impresionante, pero este no toma en cuenta el desequilibrio de clases</strong></em>.</p></li>
<li><p>Se puede conseguir un 99% de precisión sin construir un modelo de aprendizaje automático, prediciendo siempre “no click”. Por otro lado, incluso con datos desequilibrados, un modelo con un 99% de precisión podría ser bastante bueno. Sin embargo, <em><strong>la precisión no nos permite distinguir el modelo constante “no click” de un modelo potencialmente bueno</strong></em>. Para ilustrarlo, crearemos un conjunto de datos desequilibrados 9:1 a partir del conjunto de datos <em><strong>digits</strong></em>, clasificando el dígito 9 contra las otras nueve clases.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_digits</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">digits</span> <span class="o">=</span> <span class="n">load_digits</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Data shape: &quot;</span><span class="p">,</span> <span class="n">digits</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="s2">&quot;; Target shape&quot;</span><span class="p">,</span> <span class="n">digits</span><span class="o">.</span><span class="n">target</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Data shape:  (1797, 64) ; Target shape (1797,)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">digits</span><span class="o">.</span><span class="n">target</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">digits</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,
       13., 14., 15., 16.])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">digits</span><span class="o">.</span><span class="n">target</span> <span class="o">==</span> <span class="mi">9</span> <span class="c1"># Boolean</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">digits</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Podemos utilizar <code class="docutils literal notranslate"><span class="pre">DummyClassifier</span></code> para predecir siempre la clase mayoritaria (aquí “not nine”) <em><strong>para ver lo poco informativa que puede ser el (accuracy)</strong></em></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.dummy</span> <span class="kn">import</span> <span class="n">DummyClassifier</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dummy_majority</span> <span class="o">=</span> <span class="n">DummyClassifier</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s1">&#39;most_frequent&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">pred_most_frequent</span> <span class="o">=</span> <span class="n">dummy_majority</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Unique predicted labels: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">pred_most_frequent</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test score: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">dummy_majority</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Unique predicted labels: [False]
Test score: 0.90
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Obtuvimos una precisión cercana al 90% sin aprender nada. Esto puede parecer sorprendente, pero pero piénselo un momento. <em><strong>Imagine que alguien le dice que su modelo tiene un 90% de precisión. Podrías pensar que han hecho un buen trabajo. Pero dependiendo del problema, ¡eso podría ser posible con sólo predecir una clase! Comparemos esto con el uso de un clasificador real</strong></em>.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tree</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">pred_tree</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test score: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">tree</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Test score: 0.92
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Según la precisión, el <em><strong>DecisionTreeClassifier es sólo ligeramente mejor que el predictor constante. Esto podría indicar que algo está mal en la forma en que utilizamos DecisionTreeClassifier, o bien que accuracy no es una buena medida en este caso</strong></em>. Para comparar, evaluemos otro clasificador, <code class="docutils literal notranslate"><span class="pre">LogisticRegression</span></code></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">logreg</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">C</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">pred_logreg</span> <span class="o">=</span> <span class="n">logreg</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;logreg score: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">logreg</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>logreg score: 0.98
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>El clasificador <code class="docutils literal notranslate"><span class="pre">dummy</span></code> que produce resultados aleatorios es claramente el peor de todos (según su <code class="docutils literal notranslate"><span class="pre">accuracy</span></code>), mientras que <code class="docutils literal notranslate"><span class="pre">LogisticRegression</span></code> produce muy buenos resultados. Esto hace que sea muy difícil juzgar cuál de estos resultados es realmente útil. El problema es que accuracy es una medida inadecuada para cuantificar el rendimiento predictivo en este entorno desequilibrado. <em><strong>En el resto de este capítulo, exploraremos métricas alternativas que proporcionen una mejor orientación en la selección de modelos</strong></em>. En particular, nos gustaría disponer de métricas que nos digan cuán mejor es un modelo, en vez de hacer predicciones “más frecuentes” o predicciones aleatorias, como se calculan en <code class="docutils literal notranslate"><span class="pre">pred_most_frequent</span></code>. <em><strong>Si utilizamos una métrica adecuada para evaluar nuestros modelos, debería ser capaz de eliminar estas predicciones sin sentido</strong></em>.</p></li>
</ul>
</section>
<section id="matrices-de-confusion">
<h3><span class="section-number">16.3.5. </span>Matrices de confusión<a class="headerlink" href="#matrices-de-confusion" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>Una de las formas más completas de representar el resultado de la evaluación de la clasificación binaria es el uso de <em><strong>matrices de confusión</strong></em>. Inspeccionemos las predicciones de <code class="docutils literal notranslate"><span class="pre">LogisticRegres</span></code> de la sección anterior utilizando la función <code class="docutils literal notranslate"><span class="pre">confusion_matrix</span></code>. Ya hemos almacenado las predicciones del conjunto de prueba en <code class="docutils literal notranslate"><span class="pre">pred_logreg</span></code></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">confusion</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">pred_logreg</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Confusion matrix:</span><span class="se">\n</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">confusion</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Confusion matrix:
[[402   1]
 [  6  41]]
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>La salida de <code class="docutils literal notranslate"><span class="pre">confusion_matrix</span></code> es una <em><strong>matriz de dos por dos, donde las filas corresponden a las clases verdaderas y las columnas corresponden a las clases predichas</strong></em>. Cada entrada cuenta la frecuencia con la que una muestra que pertenece a la clase correspondiente a la fila (aquí “not nine” y “nine”) fue clasificada como la clase correspondiente a la columna.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mglearn</span><span class="o">.</span><span class="n">plots</span><span class="o">.</span><span class="n">plot_confusion_matrix_illustration</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/11103c5e86611f1ce3af8695501b801d5446ec857fc9741651a131b9c387683c.png" src="_images/11103c5e86611f1ce3af8695501b801d5446ec857fc9741651a131b9c387683c.png" />
</div>
</div>
<ul class="simple">
<li><p>Las entradas de la <em><strong>diagonal principal de la matriz de confusión corresponden a las clasificaciones correctas, mientras que las demás entradas nos indican cuántas muestras se han clasificado erróneamente en una clase</strong></em>. Si declaramos que “nine” es la clase positiva, podemos relacionar las entradas de la matriz de confusión con los términos <em><strong>falso positivo y falso negativo</strong></em> que hemos introducido anteriormente. Para completar el cuadro, llamamos <em><strong>verdaderos positivos a las muestras correctamente clasificadas que pertenecen a la clase positiva y verdaderos negativos a las muestras correctamente clasificadas que pertenecen a la clase negativa. Estos términos suelen abreviarse como</strong></em> <strong>FP, FN, TP y TN</strong>, y conducen a la siguiente interpretación de la matriz de confusión</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mglearn</span><span class="o">.</span><span class="n">plots</span><span class="o">.</span><span class="n">plot_binary_confusion_matrix</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/919d33fd5494029644cef9f3a35f2ed7d5b259fc76d16cfada01ae13ea330e7a.png" src="_images/919d33fd5494029644cef9f3a35f2ed7d5b259fc76d16cfada01ae13ea330e7a.png" />
</div>
</div>
<ul class="simple">
<li><p>Ahora utilicemos la <em><strong>matriz de confusión</strong></em> para comparar los modelos que hemos ajustado antes (los dos modelos <em><strong>dummy, árbol de decisión y regresión logística</strong></em>)</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Dummy model:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">pred_most_frequent</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Dummy model:
[[403   0]
 [ 47   0]]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Decision tree:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">pred_tree</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Decision tree:
[[390  13]
 [ 24  23]]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Logistic Regression&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">pred_logreg</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Logistic Regression
[[402   1]
 [  6  41]]
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Si se observa la matriz de confusión, está claro que algo va mal con <code class="docutils literal notranslate"><span class="pre">pred_most_frequent</span></code> porque siempre predice la misma clase, tiene cero verdaderos y falsos positivos (0). <em><strong>Las predicciones realizadas por el árbol de decisión tienen mucho más sentido que las predicciones dummy, aunque el accuracy era casi el misma</strong></em>. Por último, podemos ver que la regresión logística es mejor que <code class="docutils literal notranslate"><span class="pre">pred_tree</span></code> en todos los aspectos: tiene más verdaderos positivos y verdaderos negativos, mientras que tiene menos falsos positivos y falsos negativos. <em><strong>De esta comparación se desprende que, sólo el árbol de decisión y la regresión logística dan resultados razonables, y que la regresión logística funciona mejor que el árbol en todos los aspectos</strong></em>. Sin embargo, la inspección de la matriz de confusión completa es un poco acumulativa, y aunque obtuvimos mucha información al observar todos los aspectos de la matriz, <em><strong>el proceso fue muy manual y cualitativo</strong></em>. Hay varias formas de resumir la información de la matriz de confusión, las cuales discutiremos a continuación.</p></li>
</ul>
<div class="tip admonition">
<p class="admonition-title">Accuracy</p>
<p>Ya vimos una forma de resumir el resultado en la <em><strong>matriz de confusión</strong></em>, calculando su <code class="docutils literal notranslate"><span class="pre">accuracy</span></code>, que puede expresarse como</p>
<div class="math notranslate nohighlight">
\[
\text{Accuracy}=\frac{TP+TN}{TP+TN+FP+FN}.
\]</div>
<p>En otras palabras, el <em><strong>accuracy es el número de predicciones correctas (TP y TN) dividido por el número de todas las muestras</strong></em> (todas las entradas de la matriz de confusión sumadas).</p>
</div>
<ul class="simple">
<li><p><em><strong>Precision, recall y f-score</strong></em>. Hay otras formas de resumir la matriz de confusión, siendo las más comunes: <em><strong>precision, recall y f-score</strong></em>.</p></li>
</ul>
<div class="tip admonition">
<p class="admonition-title">Precision</p>
<p><em><strong>Precision</strong></em> mide cuántas de las muestras predichas como positivas son realmente positivas, es decir, <code class="docutils literal notranslate"><span class="pre">precision</span></code> intenta responder a la siguiente pregunta: ¿qué proporción de identificaciones positivas fue correcta?</p>
<div class="math notranslate nohighlight">
\[
\text{Precision} = \frac{TP}{TP+FP} 
\]</div>
<p><em><strong>Precision</strong></em> se utiliza como métrica de rendimiento cuando <em><strong>el objetivo es limitar el número de falsos positivos</strong></em>.</p>
</div>
<ul class="simple">
<li><p>Como ejemplo, imaginemos un modelo para predecir si un nuevo medicamento será eficaz en el tratamiento de una enfermedad en los ensayos clínicos. <em><strong>Los ensayos clínicos son notoriamente caros, y una empresa farmacéutica sólo querrá realizar un experimento si está muy seguro de que el fármaco funcionará realmente. Por lo tanto, es importante que el modelo no produzca muchos falsos positivos</strong></em>, es decir, que tenga <code class="docutils literal notranslate"><span class="pre">precision</span></code> alto. <em><strong>Precision</strong></em> <em><strong>también se conoce como valor predictivo positivo (VPP)</strong></em>. Nótese que: <span class="math notranslate nohighlight">\(FP\rightarrow0\)</span> cuando <span class="math notranslate nohighlight">\(\text{Precision}\rightarrow1\)</span> y viceversa; similarmente, <span class="math notranslate nohighlight">\(FN\rightarrow0\)</span> cuando <span class="math notranslate nohighlight">\(\text{Recall}\rightarrow1\)</span> y viceversa.</p></li>
</ul>
<div class="tip admonition">
<p class="admonition-title">Recall</p>
<p>El <code class="docutils literal notranslate"><span class="pre">recall</span></code> mide cuántas de las muestras de la clase positiva son realmente predichas positivas, es decir, <code class="docutils literal notranslate"><span class="pre">recall</span></code> intenta responder a la siguiente pregunta: ¿qué proporción de positivos reales se identificó en forma correcta?</p>
<div class="math notranslate nohighlight">
\[
\text{Recall} = \frac{TP}{TP+FN} 
\]</div>
<p><em><strong>Recall</strong></em> se utiliza como métrica de rendimiento cuando <em><strong>el objetivo es limitar el número de falsos negativos</strong></em>.</p>
</div>
<ul class="simple">
<li><p>Existe un equilibrio entre la optimización del <code class="docutils literal notranslate"><span class="pre">recall</span></code> y el <code class="docutils literal notranslate"><span class="pre">precision</span></code>. Se puede obtener de forma sencilla, una recuperación perfecta si se predice que todas las muestras pertenecen a la clase positiva. Si se predice que todas las muestras pertenecen a la clase positiva, no habrá falsos negativos ni verdaderos negativos. Sin embargo, predecir todas las muestras como positivas, dará lugar a muchos falsos positivos y, por lo tanto, su <code class="docutils literal notranslate"><span class="pre">precision</span></code> será muy baja. Por otro lado, si se encuentra un modelo que predice sólo el punto de datos del que se está más seguro como positivo y el resto como negativo, entonces <code class="docutils literal notranslate"><span class="pre">precision</span></code> será perfecto (suponiendo que este punto de datos sea de hecho positivo), pero el <code class="docutils literal notranslate"><span class="pre">recall</span></code> será muy malo.</p></li>
</ul>
<div class="tip admonition">
<p class="admonition-title">Observación</p>
<p><em><strong>Precision</strong></em> y <em><strong>recall</strong></em> son sólo dos de las muchas medidas de clasificación derivadas de <em><strong>TP, FP, TN y FN</strong></em>. Puede encontrar un gran resumen de todas las medidas en <a class="reference external" href="https://en.wikipedia.org/wiki/Sensitivity_and_specificity">Sensitivity_and_specificity</a>. En la comunidad del aprendizaje automático, <code class="docutils literal notranslate"><span class="pre">precision</span></code> y <code class="docutils literal notranslate"><span class="pre">recall</span></code> son las medidas más utilizadas para la clasificación binaria, aunque pueden utilizar otras métricas relacionadas.</p>
</div>
<div class="tip admonition">
<p class="admonition-title"><span class="math notranslate nohighlight">\(f_{1}\)</span>-score</p>
<p>Por lo tanto, aunque <code class="docutils literal notranslate"><span class="pre">precision</span></code> y <code class="docutils literal notranslate"><span class="pre">recall</span></code> sean medidas muy importantes, si sólo se tiene en cuenta una de ellas no se obtiene una visión completa. Una forma de resumirlas es usando el <em><strong>f-score o f-measure</strong></em>, que es la <em><strong>media armónica entre precision y recall</strong></em>:</p>
<div class="math notranslate nohighlight">
\[
F=2\cdot\frac{\text{precision}\cdot\text{recall}}{\text{precision}+\text{recall}}.
\]</div>
<p>Esta variante concreta también se conoce como <span class="math notranslate nohighlight">\(f_{1}\)</span>-score.</p>
</div>
<ul class="simple">
<li><p>Como tiene en cuenta a <code class="docutils literal notranslate"><span class="pre">precision</span></code> (precisión) y <code class="docutils literal notranslate"><span class="pre">recall</span></code> (recuperación) el <span class="math notranslate nohighlight">\(f_{1}\)</span>-score puede ser una medida mejor que <code class="docutils literal notranslate"><span class="pre">accuracy</span></code> (exactitud) en conjuntos de datos de clasificación binaria desequilibrados. Vamos a aplicarlo a las predicciones del conjunto de datos “nine vs. rest” que hemos calculado antes. En este caso, supondremos que la clase “nine” es la clase positiva (está etiquetada como <code class="docutils literal notranslate"><span class="pre">True</span></code> mientras que el resto está etiquetado como <code class="docutils literal notranslate"><span class="pre">False</span></code>), por lo que la clase positiva es la clase minoritaria.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">f1_score</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;f1 score dummy: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">f1_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">pred_most_frequent</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>f1 score dummy: 0.00
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;f1 score tree: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">f1_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">pred_tree</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>f1 score tree: 0.55
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;f1 score logistic regression: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">f1_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">pred_logreg</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>f1 score logistic regression: 0.92
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Podemos ver una distinción bastante fuerte entre las predicciones dummy y las predicciones del árbol, lo que no estaba claro cuando se miraba <code class="docutils literal notranslate"><span class="pre">accuracy</span></code> por sí sola. Utilizando <span class="math notranslate nohighlight">\(f\)</span>-score para la evaluación, resumimos el rendimiento predictivo de nuevo en un número. <em><strong>Sin embargo,</strong></em> <span class="math notranslate nohighlight">\(f\)</span><em><strong>-score parece captar nuestra intuición de lo que es un buen modelo mucho mejor que el accuracy</strong></em>.</p></li>
<li><p>Sin embargo, una desventaja del <span class="math notranslate nohighlight">\(f\)</span>-score es que es más difícil de interpretar y explicar que accuracy. Si queremos un resumen más completo de <code class="docutils literal notranslate"><span class="pre">precision</span></code>, <code class="docutils literal notranslate"><span class="pre">recall</span></code> y <span class="math notranslate nohighlight">\(f_{1}\)</span>-score, podemos utilizar la función de conveniencia <code class="docutils literal notranslate"><span class="pre">classification_report</span></code> para calcular los tres a la vez e imprimirlos en un formato agradable. Las dos últimas filas corresponden a <code class="docutils literal notranslate"><span class="pre">macro</span> <span class="pre">avg</span></code> que da a cada predicción un peso similar al calcular la pérdida, pero para datos desequilibrados como lo es este caso, se quiera dar más importancia a alguna predicción en función de su proporción, en ese caso se utiliza la <code class="docutils literal notranslate"><span class="pre">weighted</span> <span class="pre">avg</span></code>. Para mas información acerca del uso de <code class="docutils literal notranslate"><span class="pre">classification_report</span></code> (ver <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html">sklearn.metrics.classification_report</a>).</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">classification_report</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">pred_most_frequent</span><span class="p">,</span> <span class="n">target_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;not nine&quot;</span><span class="p">,</span> <span class="s2">&quot;nine&quot;</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>              precision    recall  f1-score   support

    not nine       0.90      1.00      0.94       403
        nine       0.00      0.00      0.00        47

    accuracy                           0.90       450
   macro avg       0.45      0.50      0.47       450
weighted avg       0.80      0.90      0.85       450
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>La función <code class="docutils literal notranslate"><span class="pre">classification_report</span></code> produce una línea por clase (aquí, <code class="docutils literal notranslate"><span class="pre">True</span></code> y <code class="docutils literal notranslate"><span class="pre">False</span></code>) e informa <code class="docutils literal notranslate"><span class="pre">precision,</span> <span class="pre">recall</span></code> y <span class="math notranslate nohighlight">\(f\)</span><code class="docutils literal notranslate"><span class="pre">-score</span></code>. Si consideramos la clase positiva por “not nine”, podemos ver en la salida de <code class="docutils literal notranslate"><span class="pre">classification_report</span></code> que obtenemos un <span class="math notranslate nohighlight">\(f\)</span>-score de 0.94 con el modelo <code class="docutils literal notranslate"><span class="pre">dummy</span></code>. Además, para la clase “not nine” tenemos un <code class="docutils literal notranslate"><span class="pre">recall</span></code> de 1, ya que clasificamos todas las muestras como “not nine”.</p></li>
<li><p>La última columna junto al <span class="math notranslate nohighlight">\(f\)</span>-score proporciona el soporte de cada clase, lo que significa simplemente el número de muestras en esta clase según la verdad básica. La última fila del informe de clasificación muestra una media ponderada (por el número de muestras en la clase) de los números de cada clase. Aquí hay dos informes más, uno para el clasificador <em><strong>arbol de decisión</strong></em> y otro para la <em><strong>regresión logística</strong></em></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">pred_tree</span><span class="p">,</span> <span class="n">target_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;not nine&quot;</span><span class="p">,</span> <span class="s2">&quot;nine&quot;</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>              precision    recall  f1-score   support

    not nine       0.94      0.97      0.95       403
        nine       0.64      0.49      0.55        47

    accuracy                           0.92       450
   macro avg       0.79      0.73      0.75       450
weighted avg       0.91      0.92      0.91       450
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">pred_logreg</span><span class="p">,</span> <span class="n">target_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;not nine&quot;</span><span class="p">,</span> <span class="s2">&quot;nine&quot;</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>              precision    recall  f1-score   support

    not nine       0.99      1.00      0.99       403
        nine       0.98      0.87      0.92        47

    accuracy                           0.98       450
   macro avg       0.98      0.93      0.96       450
weighted avg       0.98      0.98      0.98       450
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Como puede observar al mirar los informes, las diferencias entre los modelos <code class="docutils literal notranslate"><span class="pre">dummy</span></code> y un modelo muy bueno ya no son tan claras. La elección de la clase que se declarada como clase positiva, tiene un gran impacto en las métricas. Mientras que el <span class="math notranslate nohighlight">\(f\)</span>-score de la clasificación <code class="docutils literal notranslate"><span class="pre">dummy</span></code> es de 0.13 (frente a 0.89 para la <em><strong>regresión logística</strong></em>) en la clase “nine” es de 0.90 frente a 0.99, lo que parece un resultado razonable. Sin embargo, si se observan todas las cifras juntas, se obtiene una imagen bastante precisa, y podemos ver claramente la superioridad de la regresión logística.</p></li>
</ul>
</section>
<section id="teniendo-en-cuenta-la-incertidumbre">
<h3><span class="section-number">16.3.6. </span>Teniendo en cuenta la incertidumbre<a class="headerlink" href="#teniendo-en-cuenta-la-incertidumbre" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>La matriz de confusión y el informe de clasificación proporcionan un análisis muy detallado de un conjunto concreto de predicciones. Sin embargo, las propias predicciones ya arrojan mucha información que está contenida en el modelo. Como ya comentamos, la mayoría de los clasificadores proporcionan un método <code class="docutils literal notranslate"><span class="pre">decision_function</span></code> o <code class="docutils literal notranslate"><span class="pre">predict_proba</span></code> para <em><strong>evaluar el grado de certeza de las predicciones</strong></em>. Hacer predicciones puede verse como un umbral para <code class="docutils literal notranslate"><span class="pre">decision_function</span></code> o <code class="docutils literal notranslate"><span class="pre">predict_proba</span></code> en un punto fijo determinado. En la clasificación binaria utilizamos 0 para <code class="docutils literal notranslate"><span class="pre">decision_function</span></code> y 0.5 para <code class="docutils literal notranslate"><span class="pre">predict_proba</span></code>.</p></li>
<li><p>El siguiente es un ejemplo de una tarea de <em><strong>clasificación binaria desequilibrada, con 400 puntos en la clase negativa clasificados contra 50 puntos en la clase positiva</strong></em>. Los datos de entrenamiento se muestran a la izquierda en la siguiente figura. Entrenamos un modelo <em><strong>kernel SVM</strong></em> en estos datos, y los gráficos a la derecha de los datos de entrenamiento ilustran los valores de la función de decisión como un mapa de calor. <em><strong>Puede ver un círculo negro en el gráfico de la parte superior central, que denota que el umbral donde la función de decisión es exactamente cero</strong></em>. Los puntos dentro de este se clasificarán como la clase positiva, y los puntos fuera de ella como la clase negativa</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mglearn.datasets</span> <span class="kn">import</span> <span class="n">make_blobs</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_blobs</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">400</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">centers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">cluster_std</span><span class="o">=</span><span class="p">[</span><span class="mf">7.0</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">22</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">svc</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">(</span><span class="n">gamma</span><span class="o">=</span><span class="mf">.05</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mglearn</span><span class="o">.</span><span class="n">plots</span><span class="o">.</span><span class="n">plot_decision_threshold</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/92692614d9169b2871f2ac1fc0cfdd7a523727c772007bcc7ae208fe98b688df.png" src="_images/92692614d9169b2871f2ac1fc0cfdd7a523727c772007bcc7ae208fe98b688df.png" />
</div>
</div>
<ul class="simple">
<li><p>Podemos utilizar la función <code class="docutils literal notranslate"><span class="pre">classification_report</span></code> para evaluar <code class="docutils literal notranslate"><span class="pre">precision</span></code> y <code class="docutils literal notranslate"><span class="pre">recall</span></code> de ambas clases</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">svc</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>              precision    recall  f1-score   support

           0       0.49      1.00      0.66        49
           1       0.00      0.00      0.00        51

    accuracy                           0.49       100
   macro avg       0.24      0.50      0.33       100
weighted avg       0.24      0.49      0.32       100
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">svc</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[[49  0]
 [51  0]]
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Para la <em><strong>clase 1</strong></em>, obtenemos un <code class="docutils literal notranslate"><span class="pre">recall</span></code> bastante pequeño, y un <code class="docutils literal notranslate"><span class="pre">precision</span></code> mixto. Como la clase 0 es mucho más grande, el clasificador se centra en acertar la clase 0 y no la clase 1, más pequeña. Supongamos que, en nuestra aplicación, es más importante tener un alto <code class="docutils literal notranslate"><span class="pre">recall</span></code> para la clase 1, como en el ejemplo del cáncer. <em><strong>Esto significa que estamos dispuestos a arriesgar más falsos positivos (clase 1 falsa) a cambio de más positivos verdaderos (que aumentarán el recall)</strong></em>. Las predicciones generadas por <code class="docutils literal notranslate"><span class="pre">svc.predict</span></code> realmente no cumplen con este requisito, pero <em><strong>podemos ajustar las predicciones para que se centren en un mayor recall para la clase 1, cambiando el umbral de decisión 0</strong></em>. Por defecto, los puntos con un valor de <code class="docutils literal notranslate"><span class="pre">decision_function</span></code> mayor que 0 se clasificarán como clase 1. <em><strong>Queremos que más puntos se clasifiquen como de la clase 1, así que tenemos que reducir el umbral (threshold)</strong></em>.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y_pred_lower_threshold</span> <span class="o">=</span> <span class="n">svc</span><span class="o">.</span><span class="n">decision_function</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span> <span class="o">&gt;</span> <span class="o">-</span><span class="mf">0.014</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Veamos el informe de clasificación de esta predicción</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_lower_threshold</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>              precision    recall  f1-score   support

           0       0.00      0.00      0.00        49
           1       0.51      1.00      0.68        51

    accuracy                           0.51       100
   macro avg       0.26      0.50      0.34       100
weighted avg       0.26      0.51      0.34       100
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_lower_threshold</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[[ 0 49]
 [ 0 51]]
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Como se esperaba, <em><strong>recall y precision</strong></em> para la clase 1 subió. Ahora estamos clasificando una <em><strong>región más grande del espacio como clase 1</strong></em>, como se ilustra en el panel superior derecho de la anterior figura. <em><strong>Si valora más la precisión que la recuperación, o al revés, o sus datos están muy desequilibrados, cambiar el umbral de decisión es la forma más fácil de obtener mejores resultados</strong></em>. <em>Como la función de decisión puede tener rangos arbitrarios, es difícil proporcionar una regla general sobre cómo elegir un umbral</em>.</p></li>
</ul>
<div class="tip admonition">
<p class="admonition-title">Observación</p>
<ul class="simple">
<li><p><em><strong>Si establece un umbral, debe tener cuidado de no hacerlo utilizando el conjunto de prueba</strong></em>. Como con cualquier otro parámetro, establecer un umbral de decisión en el conjunto de prueba es probable que produzca resultados demasiado optimistas. <em><strong>Utilice un conjunto de validación o aplique validación cruzada</strong></em>.</p></li>
<li><p>La <em><strong>media geométrica o G-mean</strong></em> es una métrica de clasificación desequilibrada que, si se optimiza, <em><strong>buscará un equilibrio entre la precision y recall</strong></em>.</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\text{G-mean}=\sqrt{\text{precision}\times\text{recall}}.
\]</div>
<ul class="simple">
<li><p>Un enfoque consistiría en <em><strong>probar el modelo con cada umbral</strong></em> devuelto por la llamada <code class="docutils literal notranslate"><span class="pre">precision_recall_curve()</span></code> y <em><strong>seleccionar el umbral con el mayor valor G-mean</strong></em>. Otras técnicas de oversampling, tales como <code class="docutils literal notranslate"><span class="pre">SMOTE</span></code> también pueden ser adecuadas, para datos de entrenamiento desbalanceados.</p></li>
</ul>
</div>
<ul class="simple">
<li><p>La elección de un umbral para los modelos que aplican el método <code class="docutils literal notranslate"><span class="pre">predict_proba</span></code> puede ser más fácil, ya que la salida de <code class="docutils literal notranslate"><span class="pre">predict_proba</span></code> está en una escala fija de 0 a 1. <em><strong>Por defecto, el umbral de 0.5 significa que si el modelo está más del 50% “seguro” de que un punto es de la clase positiva, se clasificará como tal</strong></em>. Aumentar el umbral significa que el modelo debe estar más seguro para tomar una decisión positiva (y menos para tomar una decisión negativa).</p></li>
<li><p>Aunque trabajar con probabilidades puede ser más intuitivo que trabajar con umbrales arbitrarios, <em><strong>no todos los modelos proporcionan modelos realistas de incertidumbre</strong></em> (un <code class="docutils literal notranslate"><span class="pre">DecisionTree</span></code> que crece en toda su profundidad está siempre 100% seguro de sus decisiones, aunque a menudo se equivoque). Esto se relaciona con el concepto de calibración: <em><strong>un modelo calibrado es un modelo que proporciona una medida de su incertidumbre</strong></em>. Discutir la calibración en detalle está fuera del alcance de este curso, pero puede encontrar más detalles en el artículo <em><strong>“Predicting Good Probabilities with Supervised Learning” de Alexandru Niculescu-Mizil y Rich Caruana</strong></em>.</p></li>
</ul>
</section>
</section>
<section id="curvas-precision-recall-y-roc">
<h2><span class="section-number">16.4. </span>Curvas precision-recall y ROC<a class="headerlink" href="#curvas-precision-recall-y-roc" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Como acabamos de comentar, cambiar el umbral que se utiliza para tomar una decisión de clasificación en un modelo es una forma de ajustar el equilibrio entre <code class="docutils literal notranslate"><span class="pre">precision</span></code> y <code class="docutils literal notranslate"><span class="pre">recall</span></code> para una clase determinada. Tal vez quiera <em><strong>fallar menos del 10% de las muestras positivas, lo que significa un recall deseado del 90%</strong></em>. <em><strong>Esta decisión depende de la aplicación, y debe ser impulsada por objetivos empresariales</strong></em>.</p></li>
<li><p>Una vez que se ha establecido un objetivo concreto por ejemplo, un valor de <code class="docutils literal notranslate"><span class="pre">recall</span></code> o de <code class="docutils literal notranslate"><span class="pre">precision</span></code> para una clase, se puede establecer un umbral adecuado. <em><strong>Siempre es posible establecer un umbral para cumplir un objetivo concreto, como el 90% de recall</strong></em>. Lo difícil es desarrollar un modelo que siga teniendo una precisión razonable con este umbral: si clasifica todo como como positivo, tendrá un <code class="docutils literal notranslate"><span class="pre">recall</span></code> del 100%, pero su modelo será inútil. <em><strong>Establecer un requisito para un clasificador, como el 90% de recall, suele denominarse</strong></em> <strong><code class="docutils literal notranslate"><span class="pre">establecer</span> <span class="pre">el</span> <span class="pre">punto</span> <span class="pre">operativo</span></code></strong>.</p></li>
<li><p>La fijación de un <em><strong>punto operativo</strong></em> suele ser útil en el ámbito empresarial para <em><strong>ofrecer garantías de rendimiento a los clientes o a otros grupos de la organización</strong></em>. A menudo, cuando se desarrolla un nuevo modelo, no está del todo claro cuál será el <em><strong>punto operativo</strong></em>. Por esta razón, y para entender mejor un problema de modelamiento, es instructivo examinar todos los umbrales posibles, o todas las compensaciones posibles de <code class="docutils literal notranslate"><span class="pre">precision-recall</span></code>.</p></li>
<li><p><em><strong>Esto es posible gracias a una herramienta llamada curva precision-recall</strong></em>. Puede encontrar la función para calcular la curva <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_curve.html">precision_recall_curve()</a> <em><strong>en el módulo sklearn.metrics</strong></em>. Esta necesita el etiquetado real y las incertidumbres predichas, creadas a través de <code class="docutils literal notranslate"><span class="pre">decision_function</span></code> o <code class="docutils literal notranslate"><span class="pre">predict_proba</span></code></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">precision_recall_curve</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">precision</span><span class="p">,</span> <span class="n">recall</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">precision_recall_curve</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">svc</span><span class="o">.</span><span class="n">decision_function</span><span class="p">(</span><span class="n">X_test</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>La función <code class="docutils literal notranslate"><span class="pre">precision_recall_curve</span></code> devuelve una <em><strong>lista de valores precision y recall para todos los umbrales posibles</strong></em> (todos los valores que aparecen en la función de decisión) en orden para que podamos trazar una curva, como se podrá observar en la figura que presentaremos a continuación. Puede utilizar más puntos de datos para obtener una curva más suave. Recuerde que <code class="docutils literal notranslate"><span class="pre">make_blobs</span></code> generar puntos gaussianos isotrópicos para la agrupación (ver <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_blobs.html">sklearn.datasets.make_blobs</a>).</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_blobs</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">4000</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">centers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">cluster_std</span><span class="o">=</span><span class="p">[</span><span class="mf">7.0</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">22</span><span class="p">)</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Para este ejemplo, usaremos el conjunto de datos de <em><strong>cancer de mama</strong></em>, importado por medio de <code class="docutils literal notranslate"><span class="pre">load_breast_cancer</span></code>.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_breast_cancer</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">precision_recall_curve</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cancer</span> <span class="o">=</span> <span class="n">load_breast_cancer</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">cancer</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">cancer</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">cancer</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">svc</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">(</span><span class="n">gamma</span><span class="o">=</span><span class="mf">.05</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">precision</span><span class="p">,</span> <span class="n">recall</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">precision_recall_curve</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">svc</span><span class="o">.</span><span class="n">decision_function</span><span class="p">(</span><span class="n">X_test</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Encontrar el <em><strong>umbral más cercano a cero</strong></em></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">close_zero</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">thresholds</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">precision</span><span class="p">[</span><span class="n">close_zero</span><span class="p">],</span> <span class="n">recall</span><span class="p">[</span><span class="n">close_zero</span><span class="p">],</span> <span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;threshold zero&quot;</span><span class="p">,</span> <span class="n">fillstyle</span><span class="o">=</span><span class="s2">&quot;none&quot;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">mew</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">precision</span><span class="p">,</span> <span class="n">recall</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;precision recall curve&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Precision&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Recall&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/98154c410094c2de60d1bce585f8c8fcd914a979c638cd701632cdd2517bfb9f.png" src="_images/98154c410094c2de60d1bce585f8c8fcd914a979c638cd701632cdd2517bfb9f.png" />
</div>
</div>
<ul class="simple">
<li><p>Cada punto de la curva corresponde a un posible umbral de <code class="docutils literal notranslate"><span class="pre">decision_function</span></code>. Podemos ver, por ejemplo, que podemos conseguir un <em><strong>recall aproximado de 0.99</strong></em> con un <em><strong>precision de aproximadamente 0.63</strong></em>. <strong><code class="docutils literal notranslate"><span class="pre">El</span> <span class="pre">círculo</span> <span class="pre">negro</span> <span class="pre">marca</span> <span class="pre">el</span> <span class="pre">punto</span> <span class="pre">que</span> <span class="pre">corresponde</span> <span class="pre">a</span> <span class="pre">un</span> <span class="pre">umbral</span> <span class="pre">de</span> <span class="pre">0,</span> <span class="pre">el</span> <span class="pre">umbral</span> <span class="pre">por</span> <span class="pre">defecto</span> <span class="pre">de</span> <span class="pre">decision_function</span></code></strong>. Este punto es la compensación que se elige al llamar al método <code class="docutils literal notranslate"><span class="pre">predict</span></code>. Cuanto más cerca esté la curva de la esquina superior derecha, mejor será el clasificador. <em><strong>Un punto en la parte superior derecha significa alto precision y alto recall para el mismo umbral</strong></em>.</p></li>
<li><p><em><strong>La curva comienza en la esquina superior izquierda, que corresponde a un umbral muy bajo, clasificando todo como clase positiva</strong></em>. Al aumentar el umbral, la curva se desplaza hacia un mayor <code class="docutils literal notranslate"><span class="pre">precision</span></code>, pero también hacia un menor <code class="docutils literal notranslate"><span class="pre">recall</span></code>. Aumentando el umbral cada vez más, llegamos a una situación donde los puntos clasificados como positivos son verdaderos positivos, lo que lleva a un <code class="docutils literal notranslate"><span class="pre">precision</span></code> muy alto pero a un <code class="docutils literal notranslate"><span class="pre">recall</span></code> más bajo. Cuanto más se mantenga el modelo en un nivel alto para <code class="docutils literal notranslate"><span class="pre">precision</span></code>, mejor.</p></li>
<li><p>Si observamos un poco más esta curva en particular, podemos ver que con este modelo es posible obtener un <code class="docutils literal notranslate"><span class="pre">precision</span></code> de hasta alrededor de 0.6 con un <code class="docutils literal notranslate"><span class="pre">recall</span></code> muy alto. Si queremos un <code class="docutils literal notranslate"><span class="pre">precision</span></code> mucho mayor, tenemos que sacrificar una gran cantidad de <code class="docutils literal notranslate"><span class="pre">recall</span></code>. <em><strong>En otras palabras, a la izquierda, la curva es relativamente plana, lo que significa que el recall no disminuye mucho cuando necesitamos mayor precision</strong></em>. Para un precision superior a 0.5, cada ganancia de <code class="docutils literal notranslate"><span class="pre">precision</span></code> nos cuesta mucho <code class="docutils literal notranslate"><span class="pre">recall</span></code>.</p></li>
<li><p>Diferentes clasificadores pueden funcionar bien en diferentes partes de la curva, es decir, en <em><strong>diferentes puntos de operación</strong></em>. Comparemos el modelo <code class="docutils literal notranslate"><span class="pre">SVM</span></code> que hemos entrenado con un <code class="docutils literal notranslate"><span class="pre">RandomForestClassifier</span></code> entrenado en el mismo conjunto de datos. El <code class="docutils literal notranslate"><span class="pre">RandomForestClassifier</span></code> no tiene una función de decisión, sólo <code class="docutils literal notranslate"><span class="pre">predict_proba</span></code>. La función <code class="docutils literal notranslate"><span class="pre">precision_recall_curve</span></code> espera como segundo argumento una medida de certeza para la clase positiva (clase 1), por lo que pasamos la probabilidad de que una muestra sea de la clase 1, es decir, <code class="docutils literal notranslate"><span class="pre">rf.predict_proba(X_test)[:,</span> <span class="pre">1]</span></code>. El umbral por defecto para <code class="docutils literal notranslate"><span class="pre">predict_proba</span></code> en la clasificación binaria es 0.5, por lo que este es el punto marcado en la curva. Por defecto, <code class="docutils literal notranslate"><span class="pre">max_features=sqrt(n_features)</span></code> en la clase <code class="docutils literal notranslate"><span class="pre">RandomForestClassifier</span></code>.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rf</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">max_features</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">rf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><style>#sk-container-id-3 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: black;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;

  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-icon: #696969;

  @media (prefers-color-scheme: dark) {
    /* Redefinition of color scheme for dark theme */
    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-icon: #878787;
  }
}

#sk-container-id-3 {
  color: var(--sklearn-color-text);
}

#sk-container-id-3 pre {
  padding: 0;
}

#sk-container-id-3 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-3 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-3 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-3 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-3 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-3 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-3 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-3 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-3 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-3 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-3 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-3 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-3 label.sk-toggleable__label {
  cursor: pointer;
  display: block;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
}

#sk-container-id-3 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "▸";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-3 div.sk-toggleable__content {
  max-height: 0;
  max-width: 0;
  overflow: hidden;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-3 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-3 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-3 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  max-height: 200px;
  max-width: 100%;
  overflow: auto;
}

#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "▾";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-3 div.sk-label label.sk-toggleable__label,
#sk-container-id-3 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-3 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  display: inline-block;
  line-height: 1.2em;
}

#sk-container-id-3 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-3 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-3 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-3 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-3 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 1ex;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
  color: var(--sklearn-color-unfitted-level-1);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-3 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-3 a.estimator_doc_link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-3 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-3 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}
</style><div id="sk-container-id-3" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>RandomForestClassifier(max_features=2, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-5" type="checkbox" checked><label for="sk-estimator-id-5" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;&nbsp;RandomForestClassifier<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestClassifier.html">?<span>Documentation for RandomForestClassifier</span></a><span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span></label><div class="sk-toggleable__content fitted"><pre>RandomForestClassifier(max_features=2, random_state=0)</pre></div> </div></div></div></div></div></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">RandomForestClassifier</span></code> tiene <code class="docutils literal notranslate"><span class="pre">predict_proba</span></code>, pero no <code class="docutils literal notranslate"><span class="pre">decision_function</span></code>. El método <code class="docutils literal notranslate"><span class="pre">predict_proba()</span></code> devuelve una matriz bidimensional que contiene las <em><strong>probabilidades estimadas para cada instancia y cada clase</strong></em></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">precision_rf</span><span class="p">,</span> <span class="n">recall_rf</span><span class="p">,</span> <span class="n">thresholds_rf</span> <span class="o">=</span> <span class="n">precision_recall_curve</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">rf</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">precision</span><span class="p">,</span> <span class="n">recall</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;svc&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">precision</span><span class="p">[</span><span class="n">close_zero</span><span class="p">],</span> <span class="n">recall</span><span class="p">[</span><span class="n">close_zero</span><span class="p">],</span> <span class="s1">&#39;o&#39;</span><span class="p">,</span> 
         <span class="n">markersize</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;threshold zero svc&quot;</span><span class="p">,</span> <span class="n">fillstyle</span><span class="o">=</span><span class="s2">&quot;none&quot;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">mew</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">precision_rf</span><span class="p">,</span> <span class="n">recall_rf</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;rf&quot;</span><span class="p">)</span>

<span class="n">close_default_rf</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">thresholds_rf</span> <span class="o">-</span> <span class="mf">0.5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">precision_rf</span><span class="p">[</span><span class="n">close_default_rf</span><span class="p">],</span> <span class="n">recall_rf</span><span class="p">[</span><span class="n">close_default_rf</span><span class="p">],</span> <span class="s1">&#39;^&#39;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span>
         <span class="n">markersize</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;threshold 0.5 rf&quot;</span><span class="p">,</span> <span class="n">fillstyle</span><span class="o">=</span><span class="s2">&quot;none&quot;</span><span class="p">,</span> <span class="n">mew</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Precision&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Recall&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s2">&quot;best&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/44995fe36349a0d23a3e6470c84220eb830346d2baba95487053625219e051ad.png" src="_images/44995fe36349a0d23a3e6470c84220eb830346d2baba95487053625219e051ad.png" />
</div>
</div>
<ul class="simple">
<li><p>En el gráfico de comparación podemos ver que el bosque aleatorio funciona mejor en los extremos, para requisitos de <code class="docutils literal notranslate"><span class="pre">recall</span></code> o de <code class="docutils literal notranslate"><span class="pre">precision</span></code> muy altos. Alrededor de cualquier nivel de precision, <code class="docutils literal notranslate"><span class="pre">RF</span></code> tiene un mejor rendimiento. Si sólo nos fijamos en el <span class="math notranslate nohighlight">\(f_{1}\)</span>-score para comparar el rendimiento general, habríamos pasado por alto estas sutilezas. El <span class="math notranslate nohighlight">\(f_{1}\)</span>-score sólo capta un punto de la curva <em><strong>precision-recall</strong></em>, el dado por el <em><strong>umbral por defecto</strong></em>.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;f1_score of random forest: </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">f1_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">rf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">))))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;f1_score of svc: </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">f1_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">svc</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">))))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>f1_score of random forest: 0.973
f1_score of svc: 0.773
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>La comparación de dos curvas <em><strong>precision-recall</strong></em> proporciona una visión muy detallada, pero <em><strong>es un proceso bastante manual</strong></em>. Para la comparación automática de modelos, es posible que queramos resumir la información contenida en la curva, sin limitarnos a un umbral o punto de operación. Una forma concreta de resumir la curva <em><strong>precisión-recall</strong></em> es <strong><code class="docutils literal notranslate"><span class="pre">calcular</span> <span class="pre">la</span> <span class="pre">integral</span> <span class="pre">o</span> <span class="pre">el</span> <span class="pre">área</span> <span class="pre">bajo</span> <span class="pre">la</span> <span class="pre">curva</span> <span class="pre">precision-recall,</span> <span class="pre">también</span> <span class="pre">conocida</span> <span class="pre">como</span> <span class="pre">precisión</span> <span class="pre">media</span></code></strong>. Para calcular la precisión media se puede utilizar la función <code class="docutils literal notranslate"><span class="pre">average_precision_score</span></code>. Como tenemos que calcular la curva ROC y considerar múltiples umbrales, el resultado de <code class="docutils literal notranslate"><span class="pre">decision_function</span></code> o <code class="docutils literal notranslate"><span class="pre">predict_proba</span></code> debe pasarse a <code class="docutils literal notranslate"><span class="pre">average_precision_score</span></code>, no el resultado de <code class="docutils literal notranslate"><span class="pre">predict</span></code>.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">average_precision_score</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ap_rf</span> <span class="o">=</span> <span class="n">average_precision_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">rf</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">ap_svc</span> <span class="o">=</span> <span class="n">average_precision_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">svc</span><span class="o">.</span><span class="n">decision_function</span><span class="p">(</span><span class="n">X_test</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Average precision of random forest: </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">ap_rf</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Average precision of svc: </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">ap_svc</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Average precision of random forest: 0.997
Average precision of svc: 0.962
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Al promediar todos los umbrales posibles, vemos que el bosque aleatorio y el SVC tienen un rendimiento similar, con <code class="docutils literal notranslate"><span class="pre">RF</span></code> ligeramente por delante. Esto es bastante diferente del resultado que obtuvimos antes con <span class="math notranslate nohighlight">\(f_{1}\)</span>-score. Como la <em><strong>precisión media es el área área bajo una curva que va de 0 a 1, la precisión media siempre devuelve un valor entre 0 (worst) y 1 (best)</strong></em>. La precisión media de un clasificador que asigna <code class="docutils literal notranslate"><span class="pre">decision_function</span></code> al azar es la fracción de muestras positivas en el conjunto de datos.</p></li>
</ul>
<section id="caracteristicas-operativas-del-receptor-roc-y-auc">
<h3><span class="section-number">16.4.1. </span>Características operativas del receptor (ROC) y AUC<a class="headerlink" href="#caracteristicas-operativas-del-receptor-roc-y-auc" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>Existe otra herramienta que se utiliza habitualmente para analizar el comportamiento de los clasificadores a diferentes umbrales: la <em><strong>receiver operating characteristics curve</strong></em> o <em><strong>ROC curve</strong></em>. Al igual que la curva <code class="docutils literal notranslate"><span class="pre">precision-recall</span></code>, la curva ROC considera todas los posibles umbrales para un clasificador determinado, pero en lugar de informar sobre su <code class="docutils literal notranslate"><span class="pre">precision</span></code> y <code class="docutils literal notranslate"><span class="pre">recall</span></code>, muestra la tasa de falsos positivos <em><strong>false positive rate (FPR)</strong></em> frente a la tasa de verdaderos positivos <em><strong>true positive rate (TPR)</strong></em>. Recordemos que la tasa de verdaderos positivos es simplemente otro nombre para el <code class="docutils literal notranslate"><span class="pre">recall</span></code>, mientras que la <em><strong>tasa de falsos positivos</strong></em>, es la fracción de falsos positivos entre todas las muestras negativas, esto es, la <strong><code class="docutils literal notranslate"><span class="pre">proporción</span> <span class="pre">de</span> <span class="pre">negativos</span> <span class="pre">reales,</span> <span class="pre">clasificados</span> <span class="pre">de</span> <span class="pre">forma</span> <span class="pre">incorrecta</span></code></strong>.</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
FPR=\frac{FP}{FP+TN}.
\]</div>
<ul class="simple">
<li><p>Nótese que <span class="math notranslate nohighlight">\(FPR\)</span> se utiliza como métrica de rendimiento cuando el objetivo es <em><strong>limitar el número de verdaderos negativos</strong></em>. La curva ROC puede calcularse mediante la función <code class="docutils literal notranslate"><span class="pre">roc_curve</span></code>. Nótese que si <span class="math notranslate nohighlight">\(FPR\rightarrow 0\)</span> entonces el número de <span class="math notranslate nohighlight">\(TN\)</span> crece.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">roc_curve</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">svc</span><span class="o">.</span><span class="n">decision_function</span><span class="p">(</span><span class="n">X_test</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;ROC Curve&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;FPR&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;TPR (recall)&quot;</span><span class="p">)</span>
<span class="n">close_zero</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">thresholds</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fpr</span><span class="p">[</span><span class="n">close_zero</span><span class="p">],</span> <span class="n">tpr</span><span class="p">[</span><span class="n">close_zero</span><span class="p">],</span> <span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;threshold zero&quot;</span><span class="p">,</span> <span class="n">fillstyle</span><span class="o">=</span><span class="s2">&quot;none&quot;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">mew</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">4</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/33ac162630aba8e1fb4329528ae54b797f9568535606e80e14445f26fb6bcee5.png" src="_images/33ac162630aba8e1fb4329528ae54b797f9568535606e80e14445f26fb6bcee5.png" />
</div>
</div>
<ul class="simple">
<li><p>Nótese que, <em><strong>los valores más pequeños en el eje</strong></em> <span class="math notranslate nohighlight">\(x\)</span> <em><strong>indican menos falsos positivos (FP) y más verdaderos negativos (TN). Los valores más grandes en el eje</strong></em> <span class="math notranslate nohighlight">\(y\)</span> <em><strong>indican más verdaderos positivos (TP) y menos falsos negativos (FN)</strong></em>. En cuanto a la curva <code class="docutils literal notranslate"><span class="pre">precision-recall</span></code>, a menudo queremos resumir la curva ROC utilizando un solo número, <em><strong>el área bajo la curva (comúnmente se denomina simplemente AUC, y se entiende que la curva en cuestión es la curva ROC)</strong></em>. Podemos calcular el área bajo la curva <code class="docutils literal notranslate"><span class="pre">ROC</span></code> con la función <code class="docutils literal notranslate"><span class="pre">roc_auc_score</span></code></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">roc_auc_score</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rf_auc</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">rf</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">svc_auc</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">svc</span><span class="o">.</span><span class="n">decision_function</span><span class="p">(</span><span class="n">X_test</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;AUC for Random Forest: </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">rf_auc</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;AUC for SVC: </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">svc_auc</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>AUC for Random Forest: 0.995
AUC for SVC: 0.940
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">roc_curve</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fpr_rf</span><span class="p">,</span> <span class="n">tpr_rf</span><span class="p">,</span> <span class="n">thresholds_rf</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">rf</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;ROC Curve SVC&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fpr_rf</span><span class="p">,</span> <span class="n">tpr_rf</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;ROC Curve RF&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;FPR&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;TPR (recall)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fpr</span><span class="p">[</span><span class="n">close_zero</span><span class="p">],</span> <span class="n">tpr</span><span class="p">[</span><span class="n">close_zero</span><span class="p">],</span> <span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;threshold zero SVC&quot;</span><span class="p">,</span> <span class="n">fillstyle</span><span class="o">=</span><span class="s2">&quot;none&quot;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">mew</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">close_default_rf</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">thresholds_rf</span> <span class="o">-</span> <span class="mf">0.5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fpr_rf</span><span class="p">[</span><span class="n">close_default_rf</span><span class="p">],</span> <span class="n">tpr_rf</span><span class="p">[</span><span class="n">close_default_rf</span><span class="p">],</span> <span class="s1">&#39;^&#39;</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;threshold 0.5 RF&quot;</span><span class="p">,</span> <span class="n">fillstyle</span><span class="o">=</span><span class="s2">&quot;none&quot;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">mew</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">4</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/c8e22eb405e1dbde5af7b02081e26d88202ae26f3a4dd14e508af36fbbe6468e.png" src="_images/c8e22eb405e1dbde5af7b02081e26d88202ae26f3a4dd14e508af36fbbe6468e.png" />
</div>
</div>
<ul class="simple">
<li><p>Comparando el bosque aleatorio y las SVM utilizando el AUC-score, encontramos que el bosque aleatorio es ligeramente poco mejor que SVM. <em><strong>Recordemos que la precisión media es el área bajo una curva que va de 0 a 1, siempre devuelve un valor entre 0 (worst) y 1 (best)</strong></em>. La predicción aleatoria siempre produce un AUC de 0.5, independientemente de lo desequilibradas que estén las clases de un conjunto de datos. <em><strong>Esto hace que el AUC sea una métrica mucho mejor para los problemas de clasificación desequilibrada que el accuracy</strong></em>.</p></li>
<li><p>El <code class="docutils literal notranslate"><span class="pre">AUC</span></code> puede interpretarse como la evaluación del ranking de muestras positivas. Equivale a la probabilidad de que un punto elegido al azar de la clase positiva tenga un scoring más alto, según el clasificador, que de forma aleatoria toma un punto al azar de la clase negativa. Así, un AUC perfecto de 1 significa que todos los puntos positivos tienen un scoring más alto que todos los puntos negativos. <em><strong>Para los problemas de clasificación con clases desequilibradas, utilizar el AUC para la selección del modelo es a menudo mucho más significativo que el uso de accuracy</strong></em>. Volvamos al problema que estudiamos antes de clasificar todos los nueves del conjunto de datos de dígitos frente a todos los demás dígitos. Clasificaremos el conjunto de datos con una SVM con tres ajustes diferentes anchos de banda del kernel, <code class="docutils literal notranslate"><span class="pre">gamma</span></code></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="k">for</span> <span class="n">gamma</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mf">0.07</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">]:</span>
    <span class="n">svc</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">(</span><span class="n">gamma</span><span class="o">=</span><span class="n">gamma</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">svc</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
    <span class="n">auc</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">svc</span><span class="o">.</span><span class="n">decision_function</span><span class="p">(</span><span class="n">X_test</span><span class="p">))</span>
    <span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_test</span> <span class="p">,</span> <span class="n">svc</span><span class="o">.</span><span class="n">decision_function</span><span class="p">(</span><span class="n">X_test</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;gamma = </span><span class="si">{:.2f}</span><span class="s2"> accuracy = </span><span class="si">{:.2f}</span><span class="s2"> AUC = </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">gamma</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">,</span> <span class="n">auc</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;gamma=</span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">gamma</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;FPR&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;TPR&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="o">-</span><span class="mf">0.01</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">1.02</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s2">&quot;best&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>gamma = 1.00 accuracy = 0.63 AUC = 0.51
gamma = 0.07 accuracy = 0.63 AUC = 0.94
gamma = 0.01 accuracy = 0.63 AUC = 0.95
</pre></div>
</div>
<img alt="_images/179cff1d2e3acbd0c2998adef9fab3f2e8cbac5e49d91395c30f33a8cd18c793.png" src="_images/179cff1d2e3acbd0c2998adef9fab3f2e8cbac5e49d91395c30f33a8cd18c793.png" />
</div>
</div>
<ul class="simple">
<li><p>Los valores de <code class="docutils literal notranslate"><span class="pre">accuracy</span></code> de los tres ajustes de <code class="docutils literal notranslate"><span class="pre">gamma</span></code> son <code class="docutils literal notranslate"><span class="pre">0.51,</span> <span class="pre">0.94,</span> <span class="pre">y</span> <span class="pre">0.95</span></code>. Con <code class="docutils literal notranslate"><span class="pre">gamma=1.0</span></code> el AUC está realmente al nivel del azar, lo que significa que el resultado de la función de decisión es tan bueno como el azar. Con <code class="docutils literal notranslate"><span class="pre">gamma=0.07</span></code>, el rendimiento mejora drásticamente hasta un AUC de 0.94. Por último, con <code class="docutils literal notranslate"><span class="pre">gamma=0.01</span></code>, obtenemos un AUC de <code class="docutils literal notranslate"><span class="pre">0.95</span></code>. <em><strong>Esto significa que todos los puntos positivos están mejor clasificados que los negativos según la función de decisión</strong></em>. En otras palabras, con el umbral adecuado, este modelo puede clasificar los datos perfectamente. Sabiendo esto, podemos ajustar el umbral de este modelo y obtener grandes predicciones.</p></li>
<li><p>Si sólo hubiéramos utilizado <code class="docutils literal notranslate"><span class="pre">accuracy</span></code>, nunca habríamos descubierto esto. <em><strong>Por este motivo, recomendamos altamente utilizar el AUC cuando se evalúan los modelos con datos desequilibrados</strong></em>. Tenga en cuenta que <code class="docutils literal notranslate"><span class="pre">AUC</span></code> no utiliza el umbral por defecto, por lo que podría ser necesario ajustar el umbral de decisión para obtener resultados de clasificación útiles de un modelo con un AUC alto.</p></li>
</ul>
</section>
</section>
<section id="metricas-para-la-clasificacion-multiclase">
<h2><span class="section-number">16.5. </span>Métricas para la clasificación multiclase<a class="headerlink" href="#metricas-para-la-clasificacion-multiclase" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Ahora que hemos discutido en profundidad la evaluación de las tareas de clasificación binaria, nos movemos a las métricas para evaluar la clasificación multiclase. <em><strong>Básicamente, todas las métricas para clasificación multiclase se derivan de las métricas de clasificación binaria, pero promediadas sobre todas las clases</strong></em>. Un <code class="docutils literal notranslate"><span class="pre">accuracy</span></code> para la clasificación multiclase se define de nuevo como la fracción de ejemplos clasificados correctamente. Y de nuevo, cuando las clases están desequilibradas, el <code class="docutils literal notranslate"><span class="pre">accuracy</span></code> no es una buena medida de evaluación.</p></li>
<li><p>Imagínese un problema de clasificación de tres clases con un 85% de puntos que pertenecen a la clase A, el 10% a la clase B y el 5% a la clase C. ¿Qué significa tener un 85% de precisión en este conjunto de datos?. En general, los resultados de la clasificación multiclase son más difíciles de entender que los resultados de la clasificación binaria. Además del <code class="docutils literal notranslate"><span class="pre">accuracy</span></code>, las herramientas habituales son la <em><strong>matriz de confusión</strong></em> y el <em><strong>informe de clasificación</strong></em> que vimos en el caso binario en la sección anterior. Apliquemos estos dos métodos de evaluación detallados a la tarea de clasificar los 10 dígitos diferentes escritos a mano en el conjunto de datos <code class="docutils literal notranslate"><span class="pre">digits</span></code>.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">digits</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">digits</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">lr</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">pred</span> <span class="o">=</span> <span class="n">lr</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy: </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">pred</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Confusion matrix:</span><span class="se">\n</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">pred</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Accuracy: 0.951
Confusion matrix:
[[37  0  0  0  0  0  0  0  0  0]
 [ 0 40  0  0  0  0  0  0  2  1]
 [ 0  1 40  3  0  0  0  0  0  0]
 [ 0  0  0 43  0  0  0  0  1  1]
 [ 0  0  0  0 37  0  0  1  0  0]
 [ 0  0  0  0  0 46  0  0  0  2]
 [ 0  1  0  0  0  0 51  0  0  0]
 [ 0  0  0  1  1  0  0 46  0  0]
 [ 0  3  1  0  0  0  0  0 43  1]
 [ 0  0  0  0  0  1  0  0  1 45]]
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>El modelo tiene un accuracy del 95.1%, lo que ya nos dice que lo estamos haciendo bastante bien. La matriz de confusión nos proporciona algunos detalles más. Como en el caso binario, <em><strong>cada fila corresponde a una etiqueta verdadera y cada columna a una etiqueta predicha</strong></em>. En la siguiente figura se puede encontrar una mejor representación visual</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>

<span class="n">conf_matrix</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">pred</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">conf_matrix</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s2">&quot;d&quot;</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;gray_r&quot;</span><span class="p">,</span> 
            <span class="n">xticklabels</span><span class="o">=</span><span class="n">digits</span><span class="o">.</span><span class="n">target_names</span><span class="p">,</span> 
            <span class="n">yticklabels</span><span class="o">=</span><span class="n">digits</span><span class="o">.</span><span class="n">target_names</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Etiqueta Predicha&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Etiqueta Real&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Matriz de Confusión&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/db8844e1ca026b2e1d1cbea6341b7b6fb8910af91c5f89f559445badfeb0fa9e.png" src="_images/db8844e1ca026b2e1d1cbea6341b7b6fb8910af91c5f89f559445badfeb0fa9e.png" />
</div>
</div>
<ul class="simple">
<li><p><em><strong>Para la primera clase, el dígito 0, hay 37 muestras en la clase, y todas estas muestras fueron clasificadas como clase 0 (no hay falsos negativos para la clase 0)</strong></em>. Podemos ver el por qué todas las demás entradas de la primera fila de la matriz de confusión son 0. También podemos ver que ningún otro dígito fue clasificado erróneamente como 0, porque todas las demás entradas de la primera columna de la matriz de confusión son 0 (no hay falsos positivos para la clase 0). <em><strong>Sin embargo, algunos dígitos se confundieron con otros; por ejemplo, el dígito 2 (tercera fila), tres de los cuales fueron clasificados como el dígito 3 (cuarta columna) y uno fué clasificado como el dígito 1 (segunda columna)</strong></em>. También hubo un dígito 8 que se clasificó como 2 (tercera columna, novena fila). Con la función <code class="docutils literal notranslate"><span class="pre">classification_report</span></code>, podemos calcular <code class="docutils literal notranslate"><span class="pre">precision,</span> <span class="pre">recall</span></code> y <span class="math notranslate nohighlight">\(f\)</span>-score para cada clase.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">pred</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>              precision    recall  f1-score   support

           0       1.00      1.00      1.00        37
           1       0.89      0.93      0.91        43
           2       0.98      0.91      0.94        44
           3       0.91      0.96      0.93        45
           4       0.97      0.97      0.97        38
           5       0.98      0.96      0.97        48
           6       1.00      0.98      0.99        52
           7       0.98      0.96      0.97        48
           8       0.91      0.90      0.91        48
           9       0.90      0.96      0.93        47

    accuracy                           0.95       450
   macro avg       0.95      0.95      0.95       450
weighted avg       0.95      0.95      0.95       450
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>No es de extrañar que los valores para <code class="docutils literal notranslate"><span class="pre">precision</span></code> y <code class="docutils literal notranslate"><span class="pre">recall</span></code> sean un 1 perfecto para la clase 0, ya que no hay confusiones con esta clase. Para la clase 6, en cambio, el <code class="docutils literal notranslate"><span class="pre">precision</span></code> es de 1 porque ninguna otra clase se clasificó erróneamente como 6. <em><strong>La métrica más utilizada para conjuntos de datos desequilibrados en el entorno multiclase es la versión multiclase del</strong></em> <span class="math notranslate nohighlight">\(f\)</span><code class="docutils literal notranslate"><span class="pre">-score</span></code>.</p></li>
<li><p>La idea detrás del <span class="math notranslate nohighlight">\(f\)</span>-score multiclase es calcular un <span class="math notranslate nohighlight">\(f\)</span>-score <em><strong>binario por clase, siendo esa clase la positiva y las otras clases las negativas</strong></em>. Luego, estos <span class="math notranslate nohighlight">\(f\)</span>-scores por clase se promedian utilizando una de las siguientes estrategias:</p>
<ul>
<li><p><em><strong>El promedio “macro”</strong></em> calcula los <span class="math notranslate nohighlight">\(f\)</span>-scores no ponderadas por clase. De este modo, se da el mismo peso a todas las clases, independientemente de su tamaño.</p></li>
<li><p><em><strong>El promedio “weighted”</strong></em> calcula la media de los <span class="math notranslate nohighlight">\(f\)</span>-scores por clase, ponderada por su soporte. Esto es lo que se indica en el informe de clasificación.</p></li>
<li><p><em><strong>El promedio “micro”</strong></em> calcula el número total de falsos positivos, falsos negativos y verdaderos positivos en todas las clases, y luego calcula <code class="docutils literal notranslate"><span class="pre">precision,</span> <span class="pre">recall</span></code> y <span class="math notranslate nohighlight">\(f\)</span><code class="docutils literal notranslate"><span class="pre">-score</span></code> utilizando estos recuentos.</p></li>
</ul>
</li>
<li><p>Si se preocupa por igual de cada muestra, se recomienda utilizar el “micro” <span class="math notranslate nohighlight">\(f\)</span>-score; si le importa cada clase por igual, se recomienda utilizar la media macro <span class="math notranslate nohighlight">\(f\)</span>-score.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Macro average f1 score: </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">f1_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s2">&quot;macro&quot;</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Weighted average f1 score: </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">f1_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s2">&quot;weighted&quot;</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Micro average f1 score: </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">f1_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s2">&quot;micro&quot;</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Macro average f1 score: 0.952
Weighted average f1 score: 0.951
Micro average f1 score: 0.951
</pre></div>
</div>
</div>
</div>
</section>
<section id="metricas-de-regresion">
<h2><span class="section-number">16.6. </span>Métricas de regresión<a class="headerlink" href="#metricas-de-regresion" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>La evaluación de la regresión puede hacerse con un detalle similar al que hicimos para la clasificación. Por ejemplo, analizando la sobrepredicción del objetivo frente a la subpredicción del objetivo. <em><strong>Sin embargo, en la mayoría de las aplicaciones que hemos visto, el uso del <span class="math notranslate nohighlight">\(R^2\)</span> por defecto utilizado en el score de todos los regresores es suficiente</strong></em>. A veces, las <em><strong>decisiones empresariales se toman sobre la base de error medio al cuadrado o el error medio absoluto, lo que podría incentivar el ajustar los modelos utilizando estas métricas</strong></em>. En general, sin embargo, hemos encontrado que <span class="math notranslate nohighlight">\(R^2\)</span> es una métrica más intuitiva para evaluar los modelos de regresión. En el curso de <em><strong>Time Series Forecasting</strong></em> profundizaremos en el uso de este tipo de métricas, así como tambíen: <code class="docutils literal notranslate"><span class="pre">MAE,</span> <span class="pre">MAPE,</span> <span class="pre">MSE,</span> <span class="pre">RMSE</span></code>.</p></li>
</ul>
<section id="uso-de-metricas-de-evaluacion-en-la-seleccion-de-modelos">
<h3><span class="section-number">16.6.1. </span>Uso de métricas de evaluación en la selección de modelos<a class="headerlink" href="#uso-de-metricas-de-evaluacion-en-la-seleccion-de-modelos" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>Hemos discutido muchos métodos de evaluación en detalle, y cómo aplicarlos para ciertos conjuntos de datos y un modelo. Sin embargo, <em><strong>a menudo queremos utilizar métricas como AUC en la selección de modelos utilizando GridSearchCV o cross_val_score</strong></em>. Afortunadamente, <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code> proporciona una manera muy simple de lograr esto, a través del argumento <code class="docutils literal notranslate"><span class="pre">scoring</span></code> que se puede utilizar en ambos <code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code> y <code class="docutils literal notranslate"><span class="pre">cross_val_score</span></code>. Es posible simplemente proporcionar una cadena que describa la métrica de evaluación que desea utilizar. Digamos, por ejemplo, que queremos evaluar el clasificador SVM en la tarea “nine vs. rest” en el conjunto de datos <code class="docutils literal notranslate"><span class="pre">digits</span></code>, utilizando el scoring AUC. El cambio del scoring por defecto (accuracy) a AUC se puede hacer proporcionando “<code class="docutils literal notranslate"><span class="pre">roc_auc</span></code>” como parámetro de scoring</p></li>
</ul>
<ul class="simple">
<li><p>Scoring por defecto para la clasificación es <code class="docutils literal notranslate"><span class="pre">accuracy</span></code></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Default scoring: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">SVC</span><span class="p">(),</span> <span class="n">digits</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">digits</span><span class="o">.</span><span class="n">target</span> <span class="o">==</span> <span class="mi">9</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Default scoring: [0.975      0.99166667 1.         0.99442897 0.98050139]
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Proporcionar <code class="docutils literal notranslate"><span class="pre">scoring=&quot;accuracy&quot;</span></code> no cambia los resultados</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">explicit_accuracy</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">SVC</span><span class="p">(),</span> <span class="n">digits</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">digits</span><span class="o">.</span><span class="n">target</span> <span class="o">==</span> <span class="mi">9</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s2">&quot;accuracy&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Explicit accuracy scoring: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">explicit_accuracy</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Explicit accuracy scoring: [0.975      0.99166667 1.         0.99442897 0.98050139]
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Ahora asignemos <code class="docutils literal notranslate"><span class="pre">scoring=&quot;roc_auc&quot;</span></code> para modificar la técnica de <code class="docutils literal notranslate"><span class="pre">scoring</span></code> utilizada</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">roc_auc</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">SVC</span><span class="p">(),</span> <span class="n">digits</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">digits</span><span class="o">.</span><span class="n">target</span> <span class="o">==</span> <span class="mi">9</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s2">&quot;roc_auc&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;AUC scoring: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">roc_auc</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>AUC scoring: [0.99717078 0.99854252 1.         0.999828   0.98400413]
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Del mismo modo, podemos cambiar la métrica utilizada para elegir los mejores parámetros en <code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">digits</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">digits</span><span class="o">.</span><span class="n">target</span> <span class="o">==</span> <span class="mi">9</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Proporcionamos una red a manera de ilustración del punto</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;gamma&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.0001</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">]}</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Utilizando el score <code class="docutils literal notranslate"><span class="pre">accuracy</span></code> por defecto</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">grid</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">SVC</span><span class="p">(),</span> <span class="n">param_grid</span><span class="o">=</span><span class="n">param_grid</span><span class="p">)</span>
<span class="n">grid</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Grid-Search with accuracy&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best parameters:&quot;</span><span class="p">,</span> <span class="n">grid</span><span class="o">.</span><span class="n">best_params_</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best cross-validation score (accuracy)): </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">grid</span><span class="o">.</span><span class="n">best_score_</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test set AUC: </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
<span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">grid</span><span class="o">.</span><span class="n">decision_function</span><span class="p">(</span><span class="n">X_test</span><span class="p">))))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test set accuracy: </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">grid</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Grid-Search with accuracy
Best parameters: {&#39;gamma&#39;: 0.0001}
Best cross-validation score (accuracy)): 0.976
Test set AUC: 0.992
Test set accuracy: 0.973
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Utilizando el scoring AUC en su lugar</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">grid</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">SVC</span><span class="p">(),</span> <span class="n">param_grid</span><span class="o">=</span><span class="n">param_grid</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s2">&quot;roc_auc&quot;</span><span class="p">)</span>
<span class="n">grid</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Grid-Search with AUC&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best parameters:&quot;</span><span class="p">,</span> <span class="n">grid</span><span class="o">.</span><span class="n">best_params_</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best cross-validation score (AUC): </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">grid</span><span class="o">.</span><span class="n">best_score_</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test set AUC: </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
<span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">grid</span><span class="o">.</span><span class="n">decision_function</span><span class="p">(</span><span class="n">X_test</span><span class="p">))))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test set accuracy: </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">grid</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Grid-Search with AUC
Best parameters: {&#39;gamma&#39;: 0.01}
Best cross-validation score (AUC): 0.998
Test set AUC: 1.000
Test set accuracy: 1.000
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Cuando se utiliza <code class="docutils literal notranslate"><span class="pre">accuracy</span></code>, se selecciona el parámetro <code class="docutils literal notranslate"><span class="pre">gamma=0.0001</span></code>, mientras que cuando se utiliza el AUC se selecciona <code class="docutils literal notranslate"><span class="pre">gamma=0.01</span></code>. Accuracy score para la validación cruzada es coherente con el <code class="docutils literal notranslate"><span class="pre">accuracy</span></code> del conjunto de prueba en ambos casos. <em><strong>Sin embargo, al utilizar AUC se encontró un mejor ajuste de los parámetros en en términos de AUC e incluso en términos de accuracy</strong></em>. Los valores más importantes del parámetro de scoring para la clasificación son <code class="docutils literal notranslate"><span class="pre">accuracy</span></code> (por defecto); <code class="docutils literal notranslate"><span class="pre">roc_auc</span></code> para el área bajo la curva ROC; <code class="docutils literal notranslate"><span class="pre">average_precision</span></code> para el área bajo la curva de <code class="docutils literal notranslate"><span class="pre">precision-recall</span></code>; <code class="docutils literal notranslate"><span class="pre">f1,</span> <span class="pre">f1_macro,</span> <span class="pre">f1_micro</span></code> y <code class="docutils literal notranslate"><span class="pre">f1_weighted</span></code> para <span class="math notranslate nohighlight">\(f_{1}\)</span>-score binario y las diferentes variantes ponderadas.</p></li>
<li><p>En cuanto a la regresión, los valores más utilizados son <code class="docutils literal notranslate"><span class="pre">r2</span></code> para el score <span class="math notranslate nohighlight">\(R^{2}\)</span>, <code class="docutils literal notranslate"><span class="pre">mean_squared_error</span></code> para el error medio al cuadrado y <code class="docutils literal notranslate"><span class="pre">mean_absolute_error</span></code> para el error medio absoluto. Puede encontrar una lista completa de argumentos admitidos en la <a class="reference external" href="https://scikit-learn.org/stable/modules/model_evaluation.html#the-scoring-parameter-defining-model-evaluation-rules">documentación</a> o consultando el diccionario SCORER definido en el módulo <code class="docutils literal notranslate"><span class="pre">metrics.scorer</span></code>.</p></li>
</ul>
<div class="admonition-resumen-y-conclusiones admonition">
<p class="admonition-title">Resumen y conclusiones</p>
<ul class="simple">
<li><p>En esta sección hemos hablado de la validación cruzada, el grid-search y las métricas de evaluación, los pilares de la evaluación y la mejora de los algoritmos de aprendizaje automático. Las herramientas descritas en este capítulo, junto con los algoritmos descritos, son el pan de cada día para cualquier profesional del aprendizaje automático. Hay dos puntos particulares que hemos hecho en este capítulo que merecen ser repetidos, porque a menudo son pasados por alto por quienes inician investigación en este campo.</p></li>
<li><p>El primero tiene que ver con la validación cruzada. <em><strong>La validación cruzada o el uso de un conjunto de pruebas nos permite evaluar un modelo de aprendizaje automático tal y como se comportará en el futuro</strong></em>. Sin embargo, si utilizamos el conjunto de prueba o la validación cruzada para seleccionar un modelo o los parámetros del mismo, “agotamos” los datos de prueba, y <em><strong>utilizar los mismos datos para evaluar el rendimiento de nuestro modelo en el futuro nos llevará a estimaciones demasiado optimistas</strong></em>. Por lo tanto, tenemos que recurrir a una división en <em><strong>datos de entrenamiento para la construcción del modelo, datos de validación para la selección del modelo y los parámetros-datos de prueba para la evaluación del modelo</strong></em>. En lugar de una simple división, podemos sustituir cada una de estas divisiones con la validación cruzada. La forma más comúnmente utilizada (como se describió anteriormente) es la de entrenamiento/prueba para la evaluación, y el uso de la validación cruzada en el conjunto de entrenamiento para la selección de modelos y parámetros.</p></li>
<li><p>El segundo punto tiene que ver con la importancia de la métrica de evaluación o la función de scoring de evaluación utilizada para la selección y la evaluación del modelo. La teoría de cómo tomar decisiones empresariales a partir de las predicciones de un modelo de machine learning, se sale de los alcances del curso (ver por ejemplo <a class="reference external" href="https://www.oreilly.com/library/view/data-science-for/9781449374273/">Data Science for Business</a>). Sin embargo, rara vez el objetivo final de una tarea de aprendizaje automático es la construcción de un modelo con una gran precisión (accuracy). Asegúrese de que la que la métrica que elija para evaluar y seleccionar un modelo sea un buen sustituto de aquello para lo que se utilizará el modelo.</p></li>
<li><p><em><strong>En realidad, los problemas de clasificación rara vez tienen clases equilibradas, y a menudo los falsos positivos y los falsos negativos tienen consecuencias muy diferentes</strong></em>. Asegúrese de entender cuáles son estas consecuencias y elija un método de evaluación en consecuencia. Las técnicas de evaluación y selección de modelos que hemos descrito hasta ahora son las herramientas más importantes en la caja de herramientas de un científico de datos. <em><strong>El grid-search y la validación cruzada, tal y como la hemos descrito en esta sección, sólo pueden aplicarse a un único modelo supervisado</strong></em>. Sin embargo, ya hemos visto que muchos modelos requieren un preprocesamiento y que en algunas aplicaciones, como por ejemplo, el reconocimiento de caras en imágenes, puede ser útil extraer una representación de los datos. En la siguiente sección, presentaremos la clase <code class="docutils literal notranslate"><span class="pre">Pipeline</span></code>, que nos permite utilizar grid-search y validación cruzada en cadenas complejas de algoritmos.</p></li>
</ul>
</div>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "tf"
        },
        kernelOptions: {
            name: "tf",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'tf'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="practical_pca.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">15. </span>Análisis de Componentes Principales</p>
      </div>
    </a>
    <a class="right-next"
       href="chains_pipelines.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">17. </span>Cadenas de Algoritmos y Pipelines</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cross-validation">16.1. Cross-Validation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#validacion-cruzada-en-scikit-learn">16.1.1. Validación cruzada en scikit-learn</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ventajas-de-la-validacion-cruzada">16.1.2. Ventajas de la validación cruzada</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#validacion-cruzada-estratificada-k-fold-y-otras-estrategias">16.1.3. Validación cruzada estratificada <span class="math notranslate nohighlight">\(k\)</span>-fold y otras estrategias</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mas-control-sobre-la-validacion-cruzada">16.1.4. Más control sobre la validación cruzada</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#validacion-cruzada-con-exclusion-leave-one-out">16.1.5. Validación cruzada con exclusión (<code class="docutils literal notranslate"><span class="pre">leave-one-out</span></code>)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#validacion-cruzada-aleatoria-y-dividida">16.1.6. Validación cruzada aleatoria y dividida</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#validacion-cruzada-con-grupos">16.1.7. Validación cruzada con grupos</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#grid-search">16.2. Grid Search</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#grid-search-simple">16.2.1. Grid Search simple</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#el-peligro-de-sobreajustar-los-parametros-y-el-conjunto-de-validacion">16.2.2. El peligro de sobreajustar los parámetros y el conjunto de validación</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#grid-search-con-validacion-cruzada">16.2.3. Grid Search con validación cruzada</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#analisis-del-resultado-de-la-validacion-cruzada">16.2.4. Análisis del resultado de la validación cruzada</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#busqueda-sobre-espacios-que-no-son-una-red">16.2.5. Búsqueda sobre espacios que no son una red</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#validacion-cruzada-anidada">16.2.6. Validación cruzada anidada</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#paralelizacion-de-la-validacion-cruzada-y-la-busqueda-en-red">16.2.7. Paralelización de la validación cruzada y la búsqueda en red</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#metricas-de-evaluacion-y-scoring">16.3. Métricas de evaluación y scoring</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#tenga-en-cuenta-el-objetivo-final">16.3.1. Tenga en cuenta el objetivo final</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#metricas-para-la-clasificacion-binaria">16.3.2. Métricas para la clasificación binaria</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#tipos-de-errores">16.3.3. Tipos de errores</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#conjuntos-de-datos-desequilibrados">16.3.4. Conjuntos de datos desequilibrados</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#matrices-de-confusion">16.3.5. Matrices de confusión</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#teniendo-en-cuenta-la-incertidumbre">16.3.6. Teniendo en cuenta la incertidumbre</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#curvas-precision-recall-y-roc">16.4. Curvas precision-recall y ROC</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#caracteristicas-operativas-del-receptor-roc-y-auc">16.4.1. Características operativas del receptor (ROC) y AUC</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#metricas-para-la-clasificacion-multiclase">16.5. Métricas para la clasificación multiclase</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#metricas-de-regresion">16.6. Métricas de regresión</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#uso-de-metricas-de-evaluacion-en-la-seleccion-de-modelos">16.6.1. Uso de métricas de evaluación en la selección de modelos</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Lihki Rubio, Ph.D.
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
<div class="extra_footer">
  <p>Lihki Rubio, Ph.D. All rights reserved.</p>
</div>
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>